[{"title":"IAI-神经网络与机器学习","path":"/2024/06/17/IAI-神经网络与机器学习/","content":"人智导 神经网络与机器学习 神经网络 多层神经网络示意图 神经元 接收输入x⃗\\vec{x}x，计算net=w⃗⋅x⃗+bnet = \\vec{w} \\cdot \\vec{x} + bnet=w⋅x+b，之后使用激活函数ggg对其进行激活（限制其值域范围） 常见的激活函数有： 符号函数sgn\\mathrm{sgn}sgn Sigmoid函数σ(z)=11+e−z\\sigma(z) = \\frac{1}{1 + e^{-z}}σ(z)=1+e−z1​ 双曲正切函数tanh⁡(z)=ez−e−zez+e−z\\tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}tanh(z)=ez+e−zez−e−z​ 线性整流函数ReLU(z)=max⁡{0,z}\\mathrm{ReLU}(z) = \\max\\{0, z\\}ReLU(z)=max{0,z} 输出归一化 采用Softmax函数将输出层netinet_{i}neti​归一化： oi=eneti∑k=1menetko_{i} = \\frac{e^{net_{i}}}{\\sum\\limits_{k=1}^{m}e^{net_{k}}} oi​=k=1∑m​enetk​eneti​​ 全连接网络 隐含层之间是全连接的神经网络 训练方式为： 构建数据集，划分为训练集与验证集（实际应用的数据被称为为测试集，我们在训练阶段理应不能得到这批数据） 选择损失函数，通常选用误差平方和或交叉熵，误差平方和为：E(w⃗)=12∑d=1n∑k=1m(tkd−okd)2E(\\vec{w}) = \\frac{1}{2}\\sum\\limits_{d=1}^{n}\\sum\\limits_{k=1}^{m}(t_{kd} - o_{kd})^{2} E(w)=21​d=1∑n​k=1∑m​(tkd​−okd​)2 训练：求损失函数最小值，一种算法为梯度下降：wi⇐wi−η∂E∂wiw_{i} \\Leftarrow w_{i} - \\eta \\frac{\\partial E}{\\partial w_{i}} wi​⇐wi​−η∂wi​∂E​ 也即：w⇐w−η(∇wE)w \\Leftarrow w - \\eta( abla_{w}E) w⇐w−η(∇w​E) 梯度下降分为批量、小批量、随机样本三种，差距在与每次处理的样本个数 梯度的计算 随机梯度下降中最麻烦的问题在于梯度的计算，主要思想是链式法则与反向传播，以激活函数为σ\\sigmaσ为例，具体来说，算法为： 随机初始化为权重为较小随机值给定样本，计算所有输出对于输出层第jjj个元素，有：∂E∂wji=∂E∂oj∂oj∂netj∂netj∂wji=−(tj−oj)oj(1−oj)xji=−δjxji\\begin{align*} \\frac{\\partial E}{\\partial w_{ji}} &amp;= \\frac{\\partial E}{\\partial o_{j}} \\frac{\\partial o_{j}}{\\partial net_{j}} \\frac{\\partial net_{j}}{\\partial w_{ji}} \\\\ &amp;= -(t_{j} - o_{j})o_{j}(1-o_{j})x_{ji} \\\\ &amp;= - \\delta_{j}x_{ji}\\end{align*}∂wji​∂E​​=∂oj​∂E​∂netj​∂oj​​∂wji​∂netj​​=−(tj​−oj​)oj​(1−oj​)xji​=−δj​xji​​更新权重对于隐含层第jjj个元素，有：∂E∂wji=∑k∈succ(j)(∂E∂netk∂netk∂oj∂oj∂netj)∂netj∂wji=−∑k∈succ(j)(δkwkjoj(1−oj))xji=−δjxji\\begin{align*} \\frac{\\partial E}{\\partial w_{ji}} &amp;= \\sum\\limits_{k \\in \\text{succ}(j)}\\biggl(\\frac{\\partial E}{\\partial net_{k}} \\frac{\\partial net_{k}}{\\partial o_{j}} \\frac{\\partial o_{j}}{\\partial net_{j}}\\biggr) \\frac{\\partial net_{j}}{\\partial w_{ji}} \\\\ &amp;= -\\sum\\limits_{k \\in \\text{succ}(j)}\\bigl(\\delta_{k}w_{kj}o_{j}(1-o_{j})\\bigr)x_{ji} \\\\ &amp;= -\\delta_{j}x_{ji}\\end{align*}∂wji​∂E​​=k∈succ(j)∑​(∂netk​∂E​∂oj​∂netk​​∂netj​∂oj​​)∂wji​∂netj​​=−k∈succ(j)∑​(δk​wkj​oj​(1−oj​))xji​=−δj​xji​​更新权重 交叉熵 交叉熵损失函数为： H(w)=−∑d=1N∑k=1Mtkdlog⁡(okd)H(w) = -\\sum\\limits_{d=1}^{N}\\sum\\limits_{k=1}^{M}t_{kd}\\log(o_{kd}) H(w)=−d=1∑N​k=1∑M​tkd​log(okd​) 其中okdo_{kd}okd​为实际值，要求是概率，因此其输入层需要经过一次softmax 平方和损失函数常用于输出是具体数值的问题，交叉熵损失函数用于分类问题 卷积神经网络 全连接的不足：参数过多，影响速度与效率 卷积示意图 因此卷积神经网络利用卷积核对于输入数据进行卷积，降低输出维数，卷积核通过训练得到，并且卷积核是共享的，也即对于同一组数据的不同部分其参数值不变 填充与步长 填充为在原输入的最外围填充若干圈000来增加维数，例如5×55\\times 55×5变为7×77 \\times 77×7 步长为卷积核每次滑动的距离，必须要保证卷积核被完整的包含在输入当中 多卷积核与多通道 多个卷积共同卷同一个数据，每个卷积产生一个通道，通道数等于卷积核数 当输入为多通道时，例如6×6×36\\times 6\\times 36×6×3，卷积核的深度一定要与之一致，即x×y×3x \\times y \\times 3x×y×3 池化 降维的手段，通常是将一定的区域压缩为一个值，通常包括最大池化、平均池化等，窗口的大小与步长都可以设置 最大池化示意图 实例 两个实例 LeNet神经网络 VGG-16神经网络 总结 卷积神经网络总结： 卷积核能够提取特征 参数较少 梯度消失问题 神经网络的主要问题之一 在BP中，我们有： δh=oh(1−oh)∑k∈succ(h)δkwkh≤14∑k∈succ(h)δkwkh\\delta_{h} = o_{h}(1 - o_{h})\\sum\\limits_{k\\in \\mathrm{succ}(h)}\\delta_{k}w_{kh} \\leq \\frac{1}{4}\\sum\\limits_{k\\in \\mathrm{succ}(h)}\\delta_{k}w_{kh} δh​=oh​(1−oh​)k∈succ(h)∑​δk​wkh​≤41​k∈succ(h)∑​δk​wkh​ 因此层数过多的时候，梯度将以指数级下降，一种解决思路是采用ReLU\\mathrm{ReLU}ReLU 两个实例 GoogLeNet中的Inception模块 利用1×11\\times 11×1等卷积核改变通道数之后拼接起来，相当于在参数尽可能少的情况下减弱梯度消失的问题 残差网络中的残差模块 在残差网络中，在一层的常规计算结束之后，将计算结果与输入取加和得到下一层的输入，这样可以一定程度上避免神经网络发生退化（层数过多导致再增加层数的时候效果提升不显著） 注意要求F(X)F(X)F(X)与XXX的维数、通道数必须相同，因此需要对二者进行相应的填充 过拟合问题 对于训练集数据过拟合，训练出的模型不具有普适性，解决方法有： 使用验证集，个人理解是利用验证集来模拟测试集，在训练集上训练，在验证集上防止过拟合 正则化项法：将损失函数加上正则化项∣∣w⃗∣∣2||\\vec{w}||^{2}∣∣w∣∣2其中w⃗\\vec{w}w为所有的参数组成的向量，从而降低模型参数个数，降低模型复杂性 Dropout：随机临时舍弃一些神经元，使之不参与计算，减少参数量，舍弃率可调 数据增强：增加数据量，将同一份数据进行多种变换，例如图像的缩放、旋转等等，也有非线性化等高级的做法 词向量 第一个问题：如何来表示词与文本 独热编码(One-hot) 用于词表等长的向量来表示词，第iii个词的第iii位为111，其余全000 优点： 简单方便 缺点： 编码太长 无法度量相似性 分布式表示 稠密向量表示，向量的每一位代表一个特征，具体的数值代表这个词该种特征的强弱 克服了独热的两种问题，但是编码很困难，具体的值不容易找出，需要在训练过程中调整 语言模型 nnn元语言模型是指，通过前n−1n - 1n−1个词来推断下一个词，在神经网络中实现方式如下： n元模型神经网络 其中第一步为词嵌入得到词向量，具体的向量需要通过训练得到 参数的估计采用最大似然估计的方式，即： max⁡θ∏w∈CP(w=k ∣ context(w),θ)\\max\\limits_{\\theta}\\prod\\limits_{w\\in C}P(w = k\\,|\\, \\text{context}(w), \\theta) θmax​w∈C∏​P(w=k∣context(w),θ) word2vec 训练词向量的模型，有连续词袋模型和跳词模型 连续词袋模型(CBOW) 我们有一个词表WWW，训练集为大量的句子，对于某个句子w1…wmw_{1}\\dots w_{m}w1​…wm​，我们采用如下的方式进行训练： 在句中任选一位置合适的词wtw_{t}wt​ 取其前后各ccc个词的词向量进行求和并激活：xw=g(∑i=1c(wt−i+wt+i))x_{w} = g(\\sum\\limits_{i=1}^{c}(w_{t-i} + w_{t + i}))xw​=g(i=1∑c​(wt−i​+wt+i​)) 将xwx_{w}xw​作为输入传给一个霍夫曼树，其中每一个内部节点是一个神经元，叶节点为所有的词 霍夫曼树的内部节点，输入为一个词，输出为选择左边或者右边的概率，最终我们要极大到达原来的词wtw_{t}wt​的概率，也即神经网络需要训练每个节点的参数使得root→wt\\mathrm{root}\\rightarrow w_{t}root→wt​这条路径的概率尽可能大 跳词模型 PPT没说，略 循环神经网络RNN 循环神经网络 如上图，我们利用输入来更新状态向量h(k)=[h1(k),…,hm(k)]h^{(k)} = [h_{1}^{(k)}, \\dots, h_{m}^{(k)}]h(k)=[h1(k)​,…,hm(k)​] 最终输出的处理方式根据相应的实际问题变化而变化，例如情感分类问题可以接一个全连接层与一个softmax 并且我们可以将每一次循环的结果都输出出来进行相应的处理，例如看图说话的过程可以将每一次循环的结果分别做一次全连接与softmax来作为一个字，最终组成一段话 双向循环神经网络 由于一些情况下序列不仅是有正向的关系，利于一句话的某个词需要根据上下文而不是上文才能确定，而采用传统的RNN会导致下文信息的丢失，因此采用一个双向的形式 双向循环神经网络 如上图，这样可以同时考虑上下文的信息 序列到序列 考虑在实际中，许多问题的输入也是一个序列而不是一个简单的向量或矩阵，例如问答、翻译等，因此采用序列到序列的RNN模式，即采用编码器-解码器模块，现将输入序列编码为矩阵或向量，再将其放入解码器中 序列到序列循环神经网络 长短期记忆网络LSTM 简单RNN的问题： 长期依赖：如果输入序列具有距离较远的依赖关系，那RNN很容易丢失这层关系，例如&quot;bei jing shi yi ge mei li de&quot;这句话，&quot;shi&quot;具体的字的确认就很困难，需要根据后续的输入来确定，而这层关系被短期的RNN丢弃 重点选择问题：序列中不同部分的重要性不同 梯度消失问题 因此改进为LSTM LSTM循环结构 在上图的循环结构中，维护两个状态sss与hhh，循环结构内部是由“门”组成的 门是指一层神经网络，例如σ\\sigmaσ门就指的是将输入接一个全连接层和一个σ\\sigmaσ激活函数作为输出，全连接层的作用是将输入维数与状态的维数进行匹配 结构中×\\times×等算数运算符代表的是按位操作，相当于是对原有数据进行重新加权与筛选 下面依次介绍上图中的门 遗忘门 左数第一个，为σ\\sigmaσ门，将原有状态h(t−1)h^{(t-1)}h(t−1)和输入共同作为输入，经过全连接与σ\\sigmaσ之后直接与状态向量s(t−1)s^{(t-1)}s(t−1)按位相乘 表示遗忘掉状态中的一些信息，防止过拟合 输入部分 输入门：左数第二个，也为σ\\sigmaσ门 输入处理单元：左数第三个，为tanh⁡\\tanhtanh门 将这两个门的处理结果按位乘，表示这一轮学到的东西，之后与遗忘后的状态向量s′(t−1)s^{&#x27;(t-1)}s′(t−1)按位加，完成学习的过程得到s(t)s^{(t)}s(t) 输出部分 输出门：左数第四个，为σ\\sigmaσ门 输出处理单元：不是门！是一个单独的tanh⁡\\tanhtanh函数 将这两个的处理结果按位乘得到新一轮的输出状态h(t)h^{(t)}h(t) 实例 利用LSTM解决序列到序列的问题 编码器-解码器模式的LSTM","tags":["笔记","IAI","神经网络","机器学习"],"categories":["人工智能导论"]},{"title":"概统复习笔记","path":"/2024/06/15/概统复习笔记/","content":"概统 复习随笔 概统复习笔记 两两独立但不相互独立 例1 四张卡牌，分别写有2,3,5,302, 3, 5, 302,3,5,30，随机抽取一张，定义事件AAA为取出的数字是222的倍数，事件BBB为取出的数字是333的倍数，事件CCC为取出的数字是555的倍数，则有 P(A)=P(B)=P(C)=12P(AB)=P(BC)=P(CA)=14=12×12P(ABC)=14≠P(A)P(B)P(C)\\begin{align*} P(A) = P(B) &amp;= P(C) = \\frac{1}{2} \\\\ P(AB) = P(BC) &amp;= P(CA) = \\frac{1}{4} = \\frac{1}{2}\\times \\frac{1}{2} \\\\ P(ABC) = \\frac{1}{4} &amp; eq P(A)P(B)P(C) \\end{align*} P(A)=P(B)P(AB)=P(BC)P(ABC)=41​​=P(C)=21​=P(CA)=41​=21​×21​=P(A)P(B)P(C)​ 例2 连续独立抛一枚质地均匀的硬币两次，AAA代表第一次正面向上，BBB代表第二次正面向上，CCC代表一正一反，则 P(A)=P(B)=P(C)=12P(AB)=P(BC)=P(CA)=14=12×12P(ABC)=0≠P(A)P(B)P(C)\\begin{align*} P(A) = P(B) &amp;= P(C) = \\frac{1}{2} \\\\ P(AB) = P(BC) &amp;= P(CA) = \\frac{1}{4} = \\frac{1}{2}\\times \\frac{1}{2} \\\\ P(ABC) = 0 &amp; eq P(A)P(B)P(C) \\end{align*} P(A)=P(B)P(AB)=P(BC)P(ABC)=0​=P(C)=21​=P(CA)=41​=21​×21​=P(A)P(B)P(C)​ 条件独立与独立无关 条件独立不蕴含独立 对于任意非空事件A,BA, BA,B有： P(AB ∣ B)=P(AB)P(B)=P(A ∣ B)≡P(A ∣ B)P(B ∣ B)P(AB\\,|\\,B) = \\frac{P(AB)}{P(B)} = P(A\\,|\\,B) \\equiv P(A\\,|\\,B)P(B\\,|\\,B) P(AB∣B)=P(B)P(AB)​=P(A∣B)≡P(A∣B)P(B∣B) 因此它们都在条件BBB下独立，显然不一定A,BA, BA,B独立 独立不蕴含条件独立 对于独立事件A,BA, BA,B，满足C=A∪B⊊ΩC = A\\cup B \\subsetneq \\OmegaC=A∪B⊊Ω，则有： P(AB ∣ C)=P(ABC)P(C)=P(AC)P(BC)P(C)≠P(AC)P(BC)P(C)2=P(A ∣ C)P(B ∣ C)P(AB\\,|\\,C) = \\frac{P(ABC)}{P(C)} = \\frac{P(AC)P(BC)}{P(C)} eq \\frac{P(AC)P(BC)}{P(C)^{2}} = P(A\\,|\\,C)P(B\\,|\\,C) P(AB∣C)=P(C)P(ABC)​=P(C)P(AC)P(BC)​=P(C)2P(AC)P(BC)​=P(A∣C)P(B∣C) 泊松分布与指数分布 泊松分布P(λ)P(\\lambda)P(λ)为离散型分布，其PMF为： P(X=k)=λkk!e−λP(X = k) = \\frac{\\lambda^{k}}{k!}e^{-\\lambda} P(X=k)=k!λk​e−λ 其数字特征为： E(X)=Var(X)=λE(X) = Var(X) = \\lambda E(X)=Var(X)=λ 而指数分布Exp(λ)Exp(\\lambda)Exp(λ)为连续型分布，其PDF为： f(x)=λe−λxf(x) = \\lambda e^{-\\lambda x} f(x)=λe−λx 其数字特征为： E(X)=1λVar(X)=1λ2E(X) = \\frac{1}{\\lambda}\\quad Var(X) = \\frac{1}{\\lambda^{2}} E(X)=λ1​Var(X)=λ21​ 尾概率为： P(X&gt;x)=e−λxP(X &gt; x) = e^{-\\lambda x} P(X&gt;x)=e−λx 指数分布与泊松分布为对同一事件的不同描述，指数分布为两次发生这一事件之间的时间间隔（连续），泊松分布为固定时间段内发生事件的次数（离散） 全期望公式 E(Y)=E(E(Y ∣ X))E(E(g(X)Y ∣ X))=E(g(X)E(Y∣X))\\begin{align*} E(Y) &amp;= E(E(Y\\,|\\, X)) \\\\ E(E(g(X)Y\\,|\\, X)) &amp;= E(g(X)E(Y|X)) \\end{align*} E(Y)E(E(g(X)Y∣X))​=E(E(Y∣X))=E(g(X)E(Y∣X))​ 条件期望是均方误差意义下的最优预测，即∀ g\\forall\\, g∀g： E((Y−g(X))2)≥E((Y−E(Y∣X))2)E((Y - g(X))^{2})\\geq E((Y - E(Y|X))^{2}) E((Y−g(X))2)≥E((Y−E(Y∣X))2) 矩母函数与矩 nnn阶原点矩为矩母函数的nnn阶导数 E(Xn)=MX(n)(0)E(X^{n}) = M_{X}^{(n)}(0) E(Xn)=MX(n)​(0) 相对应的标准矩为： E((X−μ)n)=∑k=0nCnkE(Xk)μn−k=∑k=0nCnkMX(n)(0)μn−k\\begin{align*} E((X - \\mu)^{n}) &amp;= \\sum\\limits_{k=0}^{n}C_{n}^{k}E(X^{k})\\mu^{n-k} \\\\ &amp;= \\sum\\limits_{k=0}^{n}C_{n}^{k}M^{(n)}_{X}(0)\\mu^{n-k} \\end{align*} E((X−μ)n)​=k=0∑n​Cnk​E(Xk)μn−k=k=0∑n​Cnk​MX(n)​(0)μn−k​ 概率不等式 Markov 若随机变量X≥0X\\geq 0X≥0，则∀ a&gt;0\\forall\\, a &gt; 0∀a&gt;0 P(X≥a)≤E(X)aP(X \\geq a) \\leq \\frac{E(X)}{a} P(X≥a)≤aE(X)​ Chebyshev 若随机变量XXX方差存在，则： P(∣X−E(X)∣≥a)≤Var(X)a2P(|X - E(X)| \\geq a) \\leq \\frac{Var(X)}{a^{2}} P(∣X−E(X)∣≥a)≤a2Var(X)​ Chernoff XXX任意，则∀a&gt;0,t&gt;0\\forall a&gt;0, t&gt;0∀a&gt;0,t&gt;0 P(X≥a)≥E(etX)etaP(X \\geq a) \\geq \\frac{E(e^{tX})}{e^{ta}} P(X≥a)≥etaE(etX)​ Hoeffding bound 随机变量列Xi∈[ai,bi]X_{i} \\in [a_{i}, b_{i}]Xi​∈[ai​,bi​]，记X=∑i=1nXiX = \\sum\\limits_{i=1}^{n} X_{i}X=i=1∑n​Xi​，并记μ=E(X)\\mu = E(X)μ=E(X)，则： P(X≤μ−t)≤exp⁡(−2t2∑i=1n(ai−bi)2)P(X≥μ+t)≤exp⁡(−2t2∑i=1n(ai−bi)2)\\begin{align*} P(X \\leq \\mu - t) &amp;\\leq \\exp\\biggl(-\\frac{2t^{2}}{\\sum\\limits_{i=1}^{n}(a_{i} - b_{i})^{2}}\\biggr) \\\\ P(X \\geq \\mu + t) &amp;\\leq \\exp\\biggl(-\\frac{2t^{2}}{\\sum\\limits_{i=1}^{n}(a_{i} - b_{i})^{2}}\\biggr) \\end{align*} P(X≤μ−t)P(X≥μ+t)​≤exp(−i=1∑n​(ai​−bi​)22t2​)≤exp(−i=1∑n​(ai​−bi​)22t2​)​ Multiplicative-form Chernoff Bound 随机变量列Xi∈[0,1]X_{i} \\in [0, 1]Xi​∈[0,1]，记X=∑i=1nXiX = \\sum\\limits_{i=1}^{n} X_{i}X=i=1∑n​Xi​，并记μ=E(X)\\mu = E(X)μ=E(X)，则： P(X≤(1−ε)μ)≤exp⁡(−ε22μ)P(X≥(1+ε)μ)≤exp⁡(−ε22+εμ)\\begin{align*} P(X \\leq (1 - \\varepsilon)\\mu) &amp;\\leq \\exp\\bigl(-\\frac{\\varepsilon^{2}}{2}\\mu\\bigr) \\\\ P(X \\geq (1 + \\varepsilon)\\mu) &amp;\\leq \\exp\\bigl(-\\frac{\\varepsilon^{2}}{2 + \\varepsilon}\\mu\\bigr) \\end{align*} P(X≤(1−ε)μ)P(X≥(1+ε)μ)​≤exp(−2ε2​μ)≤exp(−2+εε2​μ)​ 收敛性的差异 Ω∼U(0,1)\\Omega \\sim U(0, 1)Ω∼U(0,1)，则考虑如下随机变量列： Y0(ω)=ω+1[0,1](ω)Y1(ω)=ω+1[0,12](ω)Y2(ω)=ω+1[12,1](ω)Y3(ω)=ω+1[0,13](ω)Y4(ω)=ω+1[13,23](ω)Y5(ω)=ω+1[23,1](ω)…\\begin{align*} Y_{0}(\\omega) &amp;= \\omega + \\mathrm{1}_{[0, 1]}(\\omega) \\\\ Y_{1}(\\omega) &amp;= \\omega + \\mathrm{1}_{[0, \\frac{1}{2}]}(\\omega) \\\\ Y_{2}(\\omega) &amp;= \\omega + \\mathrm{1}_{[\\frac{1}{2}, 1]}(\\omega) \\\\ Y_{3}(\\omega) &amp;= \\omega + \\mathrm{1}_{[0, \\frac{1}{3}]}(\\omega) \\\\ Y_{4}(\\omega) &amp;= \\omega + \\mathrm{1}_{[\\frac{1}{3}, \\frac{2}{3}]}(\\omega) \\\\ Y_{5}(\\omega) &amp;= \\omega + \\mathrm{1}_{[\\frac{2}{3}, 1]}(\\omega) \\\\ \\dots \\end{align*} Y0​(ω)Y1​(ω)Y2​(ω)Y3​(ω)Y4​(ω)Y5​(ω)…​=ω+1[0,1]​(ω)=ω+1[0,21​]​(ω)=ω+1[21​,1]​(ω)=ω+1[0,31​]​(ω)=ω+1[31​,32​]​(ω)=ω+1[32​,1]​(ω)​ 记Y(ω)=ωY(\\omega) = \\omegaY(ω)=ω，则Yn(ω)Y_{n}(\\omega)Yn​(ω)依概率收敛至Y(ω)Y(\\omega)Y(ω)，但是不以概率111收敛 中心极限定理连续性修正 由于常规的中心极限定理是： X‾−μσ/n→N(0,1)\\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}}\\rightarrow N(0, 1) σ/n​X−μ​→N(0,1) 因此一些离散分布使用该定理之后反而会失去其单点的概率（连续分布单点恒为0），因此进行连续性修正，以二项分布X∼B(n,p)X \\sim B(n, p)X∼B(n,p)为例： P(t1≤X≤t2)≈Φ(y2)−Φ(y1)P\\bigl(t_{1}\\leq X \\leq t_{2}\\bigr) \\approx \\Phi(y_{2}) - \\Phi(y_{1}) P(t1​≤X≤t2​)≈Φ(y2​)−Φ(y1​) 其中： Φ(yi)=ti−np+(12)inp(1−p)\\Phi(y_{i}) = \\frac{t_{i} - np + (\\frac{1}{2})^{i}}{\\sqrt{np(1-p)}} Φ(yi​)=np(1−p)​ti​−np+(21​)i​ 极大似然估计可能有偏 均匀分布U(0,θ)U(0, \\theta)U(0,θ)，样本值为{Xi}i=1n\\{X_{i}\\}_{i=1}^{n}{Xi​}i=1n​，则其MLE为θ∗=max⁡{Xi}\\theta^{*} = \\max\\{X_{i}\\}θ∗=max{Xi​}，下面我们证明这个不是无偏估计： Y=max⁡{Xi}Y = \\max\\{X_{i}\\}Y=max{Xi​}的CDF为： FY(y)=P(max⁡{Xi}≤y)=(FX(y))n=(yθ)n\\begin{align*} F_{Y}(y) &amp;= P(\\max\\{X_{i}\\} \\leq y) \\\\ &amp;= (F_{X}(y))^{n} \\\\ &amp;= \\bigl(\\frac{y}{\\theta}\\bigr)^{n} \\end{align*} FY​(y)​=P(max{Xi​}≤y)=(FX​(y))n=(θy​)n​ 因此其PDF为f(y)=FY′(y)=nθ(yθ)n−1f(y) = F&#x27;_{Y}(y) = \\frac{n}{\\theta}(\\frac{y}{\\theta})^{n-1}f(y)=FY′​(y)=θn​(θy​)n−1 因此我们有： E(θ∗)=∫0θyf(y)dy=nθn∫0θyndy=nn+1θE(\\theta^{*}) = \\int_{0}^{\\theta}yf(y)dy = \\frac{n}{\\theta^{n}}\\int_{0}^{\\theta}y^{n}dy = \\frac{n}{n+1}\\theta E(θ∗)=∫0θ​yf(y)dy=θnn​∫0θ​yndy=n+1n​θ 也即θ∗\\theta^{*}θ∗并不是θ\\thetaθ的无偏估计 无偏MSE不一定优于有偏 X∼N(μ,σ2)X \\sim N(\\mu, \\sigma^{2})X∼N(μ,σ2)，分别用二阶矩m2m_{2}m2​和样本方差S2S^{2}S2来估计σ2\\sigma^{2}σ2，有： E(m2)=n−1nσ2E(S2)=σ2\\begin{align*} E(m_{2}) &amp;= \\frac{n-1}{n}\\sigma^{2} \\\\ E(S^{2}) &amp;= \\sigma^{2} \\\\ \\end{align*} E(m2​)E(S2)​=nn−1​σ2=σ2​ 但是： E((m2−σ2)2)&lt;E((S2−σ2)2)E((m_{2} - \\sigma^{2})^{2}) &lt; E((S^{2} - \\sigma^{2})^{2}) E((m2​−σ2)2)&lt;E((S2−σ2)2) 区间估计 标准正态 如X∼N(μ,σ2)X \\sim N(\\mu, \\sigma^{2})X∼N(μ,σ2)，其中μ\\muμ未知而σ2\\sigma^{2}σ2已知，则： X‾−μσ/n∼N(0,1)\\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0, 1) σ/n​X−μ​∼N(0,1) 因此(1−α)(1 - \\alpha)(1−α)置信区间为： (X‾−zα/2σn,X‾+zα/2σn)(\\overline{X} - z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}, \\overline{X} + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}) (X−zα/2​n​σ​,X+zα/2​n​σ​) 其中zα2z_{\\frac{\\alpha}{2}}z2α​​为标准正态分布上α2\\frac{\\alpha}{2}2α​分位数 ttt分布 在上述例子中，如果σ2\\sigma^{2}σ2未知，则应利用ttt分布来进行区间估计，具体来说： X‾−μσ/n∼N(0,1)(n−1)S2σ2∼χ2(n−1)\\begin{align*} \\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{n}} &amp;\\sim N(0, 1) \\\\ \\frac{(n-1)S^{2}}{\\sigma^{2}} &amp;\\sim \\chi^{2}(n-1) \\end{align*} σ/n​X−μ​σ2(n−1)S2​​∼N(0,1)∼χ2(n−1)​ 因此有： X‾−μS/n∼t(n−1)\\frac{\\overline{X} - \\mu}{S / \\sqrt{n}} \\sim t(n-1) S/n​X−μ​∼t(n−1) (1−α)(1-\\alpha)(1−α)置信区间为： (X‾−tα/2(n−1)Sn,X‾+tα/2(1−α)Sn)(\\overline{X} - t_{\\alpha/2}(n-1)\\frac{S}{\\sqrt{n}}, \\overline{X} + t_{\\alpha/2}(1-\\alpha)\\frac{S}{\\sqrt{n}}) (X−tα/2​(n−1)n​S​,X+tα/2​(1−α)n​S​) 同样估计均值差也可以使用ttt分布：X∼N(μ1,σ12)X\\sim N(\\mu_{1}, \\sigma_{1}^{2})X∼N(μ1​,σ12​)，Y∼N(μ2,σ22)Y\\sim N(\\mu_{2}, \\sigma_{2}^{2})Y∼N(μ2​,σ22​)，则μ1−μ2\\mu_{1} - \\mu_{2}μ1​−μ2​的估计方法为： (X‾−Y‾)−(μ1−μ2)(1n+1m)(n−1)S12+(m−1)S22n+m−2∼t(n+m−2)\\frac{(\\overline{X} - \\overline{Y}) - (\\mu_{1} - \\mu_{2})}{\\sqrt{(\\frac{1}{n} + \\frac{1}{m})\\frac{(n-1)S_{1}^{2} + (m-1)S_{2}^{2}}{n+m-2}}} \\sim t(n + m - 2) (n1​+m1​)n+m−2(n−1)S12​+(m−1)S22​​​(X−Y)−(μ1​−μ2​)​∼t(n+m−2) F分布 常用在估计两正态总体方差之比上，所依赖的分布为： S12/σ12S22/σ22∼F(n−1,m−1)\\frac{S_{1}^{2}/\\sigma_{1}^{2}}{S_{2}^{2}/\\sigma_{2}^{2}} \\sim F(n - 1, m - 1) S22​/σ22​S12​/σ12​​∼F(n−1,m−1) 渐进估计 利用中心极限定理得到标准正态分布利用S2S^{2}S2或m2m_{2}m2​等方式来估计σ2\\sigma^{2}σ2 极大似然与Fisher θ∗−θ1nI(θ∗)→N(0,1)\\frac{\\theta^{*} - \\theta}{\\sqrt{\\frac{1}{nI(\\theta^{*})}}} \\rightarrow N(0, 1) nI(θ∗)1​​θ∗−θ​→N(0,1) 其中I(θ)I(\\theta)I(θ)为Fisher信息量，具体来说： I(θ)=E((∂ log⁡ f∂θ)2)I(\\theta) = E\\biggl(\\bigl(\\frac{\\partial\\,\\log\\,f}{\\partial \\theta}\\bigr)^{2}\\biggr) I(θ)=E((∂θ∂logf​)2)","tags":["概统","复习"],"categories":["概率论与数理统计"]},{"title":"IAI-搜索","path":"/2024/06/09/IAI-搜索/","content":"人智导 搜索 搜索问题 盲目搜索过于困难的时候，采用一些方法来帮助我们加快搜索进程 深度优先 优先扩展深度更深的节点，略 性质： 一般不能保证最优解 深度限制不合理时可能找不到解，并且可能退化为穷举 是一个通用的算法，并且相对节省内存 宽度优先 优先扩展深度更浅的节点，略 性质： 问题有解的时候一定能找到，如果问题是单位耗散值则一定能找到最优解 通用算法，但是效率较低，存储量较大 Dijkstra 略 优劣： 有解一定可以找到最佳解 只考虑了距离起点的具体 启发式图搜索 引入启发知识，用于评估节点到达目标的距离，尽可能减少搜索范围 A算法 评价函数为： f(n)=g(n)+h(n)f(n) = g(n) + h(n) f(n)=g(n)+h(n) 其中g(n)g(n)g(n)是点nnn到起点sss的耗散值估计值，h(n)h(n)h(n)是点nnn到目标ttt的耗散值估计值，真实值分别为g∗(n)g^{*}(n)g∗(n)与h∗(n)h^{*}(n)h∗(n) AAA算法伪代码如下，主要为维护CLOSE\\text{CLOSE}CLOSE表与OPEN\\text{OPEN}OPEN表： CLOSE=(), OPEN=(s)\\text{CLOSE} = (),\\, \\text{OPEN} = (s)CLOSE=(),OPEN=(s)123456789101112131415161718192021while OPEN is not empty, do: n = OPEN.first() if n == g return n OPEN.pop(n) CLOSE.push(n) expand(n) for child in n.childs() if child in OPEN: # 标记为m_&#123;k&#125; f(child) = min&#123;f(child), f(n) + d(n, child) + h(child)&#125; else if child in CLOSE: # 标记为m_&#123;l&#125; f(child) = min&#123;f(child), f(n) + d(n, child) + h(child)&#125; ### important! OPEN.push(child) if f(child) change else: # 标记为m_&#123;j&#125; f(child) = f(n) + d(n, child) + h(child) OPEN.push(child) sort(OPEN, f) 最终从目标开始顺次访问父节点即可 A*算法 若AAA算法中的启发函数满足条件h(n)≤h∗(n)h(n)\\leq h^{*}(n)h(n)≤h∗(n)，则得到A∗A^{*}A∗算法 放宽了约束条件得到估计值，A∗A^{*}A∗算法的优势在与： 一定能找到最优解 启发信息越少的算法，所拓展的节点越多（不少于信息更多的算法） 对启发函数的评价方式为平均分叉数b∗b^{*}b∗，探索ddd层后其与总搜索节点数NNN的关系为： N=∑i=0db∗d=1−b∗(d+1)1−b∗N = \\sum\\limits_{i=0}^{d}b^{*d} = \\frac{1 - b^{*(d+1)}}{1 - b^{*}} N=i=0∑d​b∗d=1−b∗1−b∗(d+1)​ 一般情况下，b∗b^{*}b∗是与问题相关，而与问题的规模关系不大 改进的A*算法 对于A∗A^{*}A∗算法，其最大的问题就是CLOSE表中的节点可能再次进入OPEN表中，也即没有在第一次探索到节点的时候就找到其最短路径，会造成重复探索，导致资源的浪费。因此我们需要对启发函数做出如下限制： 若启发函数hhh满足，对于节点vvv与其父节点uuu有：h(u)−h(v)≤d(u,v)h(u) - h(v) \\leq d(u, v) h(u)−h(v)≤d(u,v)并且有h(t)=0h(t) = 0h(t)=0，则称hhh是单调的若hhh是单调的，那么扩展了节点nnn之后就已经找到了到达nnn的最优路径，并且单调的hhh一定满足A∗A^{*}A∗条件 改进后有： 扩展的节点一定满足f(n)≤f∗(s)f(n) \\leq f^{*}(s)f(n)≤f∗(s) OPEN表中满足f(n)&lt;f∗(s)f(n) &lt; f^{*}(s)f(n)&lt;f∗(s)的一定会被扩展 再次改进，使用当前被扩展的最大节点来估计f∗(s)f^{*}(s)f∗(s)，即max⁡(f(n))∼f∗(s)\\max(f(n)) \\sim f^{*}(s)max(f(n))∼f∗(s)，具体来说： 维护一个NEST表，满足NEST={ni ∣ f(ni)&lt;fm,ni∈OPEN}\\mathrm{NEST} = \\{n_{i}\\,|\\,f(n_{i}) &lt; f_{m}, n_{i}\\in \\text{OPEN}\\}NEST={ni​∣f(ni​)&lt;fm​,ni​∈OPEN}，并且在选择的时候优先选择NEST表中ggg最小的节点，如果NEST空了再去OPEN表里面选择，并更新fmf_{m}fm​ 这种情况下仍可能会导致重复探索的出现！ 其他搜索算法 例如爬山法，随机搜索算法，动态规划等，h(n)=0h(n) = 0h(n)=0的时候A∗A^{*}A∗算法就变成了动态规划（？ Viterbi算法 Viterbi算法实例 转移方程为： Q(Wij)={min⁡k(Q(W(i−1)k)+D(W(i−1)k,Wij))i≠00i=0\\begin{align*} Q(W_{ij}) = \\begin{cases} \\min\\limits_{k}(Q(W_{(i-1)k}) + D(W_{(i-1)k, W_{ij}})) &amp; i eq 0 \\\\ 0 &amp; i = 0 \\end{cases} \\end{align*} Q(Wij​)={kmin​(Q(W(i−1)k​)+D(W(i−1)k,Wij​​))0​i=0i=0​​","tags":["笔记","IAI","对抗搜索"],"categories":["人工智能导论"]},{"title":"TCS-Lecture-E","path":"/2024/06/05/TCS-Lecture-E/","content":"TCS: Propositions as Types 本文含有大量复杂的LaTeX\\LaTeXLATE​X公式，因此md文档效果不好，仅供参考！ Propositions as Types Intuitionistic Logic and Natural Deduction Intuitionistic logic insists upon a constructionist notion of truth. In particular, a proof of A∨BA\\lor BA∨B must show which of AAA or BBB holds (different from classic logic). Natural Deduction Proof rules should come in pairs: Introduction rules which are like definitions of the logic operators. Elimination rules which are the consequences of theirdefinitions. Both of them should be in harmony. We will define the four kinds of rules, conjunction, implication, disjunction and falsehood in order. Gentzen’s contribution: Subformula principle: Proofs can be normalized so that no concepts enter the proof other than those contained in the final result (subformula). This means we can use only the known proposition and the subformulas of the conclusion. Guiding Question for Defining Logic Martin-Löf: The meaning of a proposition is determined by what counts as a verification (or proof) of it. Proposition: AAA Justification: A trueA \\text{ true}A true, A is true at time tA \\text{ is true at time } tA is true at time t, …\\dots… So that we need to determin a proposition by a verification(not only itself). In this lecture, we only consider justification A trueA \\text{ true}A true so we omit thet suffix true\\text{true}true Conjunction We use ‘→\\to→’ to represents the prooftree in PDF. (∧I)(A,B)→(A∧B)(∧E1)(A∧B)→A(∧E2)(A∧B)→B\\begin{align*} (\\land I)\\qquad &amp;(A, B) \\to (A\\land B) \\\\ (\\land E_{1})\\qquad &amp;(A\\land B) \\to A \\\\ (\\land E_{2})\\qquad &amp;(A\\land B) \\to B \\\\ \\end{align*} (∧I)(∧E1​)(∧E2​)​(A,B)→(A∧B)(A∧B)→A(A∧B)→B​ We define the local soundness and local completeness as follows: Local Soundness: The elimination cannot give us new information.((D→A), (E→B))→(A∧B)→A⇒R(D→A)\\begin{align*}&amp;\\quad((\\mathcal{D} \\to A),\\, (\\mathcal{E} \\to B)) \\to (A\\land B) \\to A \\\\&amp;\\Rightarrow_{R} (\\mathcal{D}\\to A)\\end{align*}​((D→A),(E→B))→(A∧B)→A⇒R​(D→A)​Local Completeness: The elimination can reconstitute the proof by introduction(D→A)⇒E(((D→(A∧B))→A), ((D→(A∧B))→B))→(A∧B)→A\\begin{align*} &amp;\\quad (\\mathcal{D}\\to A)\\\\ &amp;\\Rightarrow_{E}(((\\mathcal{D} \\to (A\\land B)) \\to A),\\, ((\\mathcal{D} \\to (A\\land B)) \\to B)) \\to (A\\land B) \\to A\\end{align*}​(D→A)⇒E​(((D→(A∧B))→A),((D→(A∧B))→B))→(A∧B)→A​ Implication We define the hypothetical judgment at first: (A∧(B∧C))⊢B(A\\land (B\\land C)) \\vdash B (A∧(B∧C))⊢B This is not an inference as it consists of two inferences! We have conjunctions inferences at now. Then we can define implication introduction and elimination rules: (⊃Ix)(A‾x→∗B)→(A⊃B)(⊃E)(A⊃B, A)→B\\begin{align*} (\\supset I^{x})\\qquad &amp;(\\overline{A}^{x} \\to^{*} B) \\to (A\\supset B) (\\supset E)\\qquad &amp; (A\\supset B,\\, A) \\to B \\end{align*} (⊃Ix)​(Ax→∗B)→(A⊃B)(⊃E)​(A⊃B,A)→B​ In which that the x^{x}x means the local scope. Disjunction Define the disjunction as follows: (∨I1)A→(A∨B)(∨I2)B→(A∨B)(∨Ex,y)(A∨B,A‾x→∗C,B‾y→∗C)→C\\begin{align*} (\\lor I_{1})\\qquad &amp;A \\to (A\\lor B) \\\\ (\\lor I_{2})\\qquad &amp;B \\to (A\\lor B) \\\\ (\\lor E^{x, y})\\qquad &amp;(A\\lor B, \\overline{A}^{x}\\to^{*}C, \\overline{B}^{y}\\to^{*}C) \\to C \\end{align*} (∨I1​)(∨I2​)(∨Ex,y)​A→(A∨B)B→(A∨B)(A∨B,Ax→∗C,By→∗C)→C​ Falsehood Falsehood is written as ⊥\\bot⊥. It has no introduction as we shouldn’t prove it. (⊥E)⊥→C(\\bot E) \\bot \\to C (⊥E)⊥→C Intuitionistic Natural Deduction So, we can use these four to define some other operates such as ¬ eg¬, ⊤\\top⊤ and ↔\\leftrightarrow↔ ¬A=defA⊃⊥⊤=def⊥⊃⊥A↔B=def(A⊃B)∧(B⊃A)\\begin{align*} eg A &amp;\\mathop{=}\\limits^{\\text{def}} A \\supset \\bot \\\\ \\top &amp;\\mathop{=}\\limits^{\\text{def}} \\bot \\supset \\bot \\\\ A \\leftrightarrow B &amp;\\mathop{=}\\limits^{\\text{def}} (A \\supset B) \\land (B \\supset A) \\end{align*} ¬A⊤A↔B​=defA⊃⊥=def⊥⊃⊥=def(A⊃B)∧(B⊃A)​ Now we can begin prove! The follows is some interesting conclusion: A⊃B⊃AA⊃¬¬A(A⊃B)⊃(¬B⊃¬A)¬(A∨B)↔(¬A∧¬B)\\begin{align} A \\supset &amp;B \\supset A \\\\ A \\supset &amp; eg eg A \\\\ (A \\supset B) \\supset &amp;( eg B \\supset eg A) \\\\ eg (A \\lor B) \\leftrightarrow &amp;( eg A \\land eg B) \\end{align} A⊃A⊃(A⊃B)⊃¬(A∨B)↔​B⊃A¬¬A(¬B⊃¬A)(¬A∧¬B)​​ But some weird things hapend as the following is not provable: ((A⊃B)⊃A)⊃A¬¬A⊃A(¬A⊃¬B)⊃(B⊃A)¬(A∧B)↔(¬A∨¬B)\\begin{align} ((A \\supset B) \\supset A) &amp;\\supset A \\\\ eg eg A &amp;\\supset A \\\\ ( eg A \\supset eg B) &amp;\\supset (B \\supset A) \\\\ eg (A \\land B) \\leftrightarrow &amp;( eg A \\lor eg B) \\end{align} ((A⊃B)⊃A)¬¬A(¬A⊃¬B)¬(A∧B)↔​⊃A⊃A⊃(B⊃A)(¬A∨¬B)​​ What the f***! The most interesting is that: (Gilvenko’s Theorem):, AAA is valid in classical logic if and only if ¬¬A eg eg A¬¬A is valid in intuitionistic logic! And intuitionistic logic is PSPACE-complete! Propositions as Types We write M:AM: AM:A to represent that MMM is a proof of AAA and alternatively MMM is a program of type AAA. So we can rewrite the four kinds of roles by λ\\lambdaλ-calculus! Implication (⊃Ix)((x:A‾x)→(M:B))→(λx.M):(A⊃B)(⊃E)((M:(A⊃B)),(N:A))→(MN:B)\\begin{align*} (\\supset I^{x})\\qquad &amp;((\\overline{x:A}^{x})\\to (M:B)) \\to (\\lambda x.M):(A\\supset B) \\\\ (\\supset E)\\qquad &amp;((M:(A\\supset B)), (N:A)) \\to (MN: B) \\end{align*} (⊃Ix)(⊃E)​((x:Ax)→(M:B))→(λx.M):(A⊃B)((M:(A⊃B)),(N:A))→(MN:B)​ From its local soundness we can get β\\betaβ reduction, and from local completeness we can get η\\etaη rule! Turing has proved that typed λ\\lambdaλ-calculus always terminates. Conjunction (∧I)((M:A),(N:B))→(⟨M,N⟩:A∧B)(∧E1)(M:(A∧B))→((fstM):A)(∧E2)(M:(A∧B))→((sndM):B)\\begin{align*} (\\land I)\\qquad((M:A), (N:B)) &amp;\\to (\\langle M, N\\rangle: A\\land B) \\\\ (\\land E_{1})\\qquad (M:(A\\land B)) &amp;\\to ((\\mathbf{fst}M):A) \\\\ (\\land E_{2})\\qquad (M:(A\\land B)) &amp;\\to ((\\mathbf{snd}M):B) \\end{align*} (∧I)((M:A),(N:B))(∧E1​)(M:(A∧B))(∧E2​)(M:(A∧B))​→(⟨M,N⟩:A∧B)→((fstM):A)→((sndM):B)​ The local reduction and expansion can give out the meaning of ⟨⋅,⋅⟩\\langle \\cdot, \\cdot\\rangle⟨⋅,⋅⟩, fst\\mathbf{fst}fst and snd\\mathbf{snd}snd Disjunction (∨I1)(M:A)→((inlM):A∨B)(∨I2)(M:B)→((inrM):A∨B)(∨Ex,y)(M:(A∨B),(x:A‾x→(N:C)),(y:B‾y→(P:C)))→case(M,x.N,y.P):C\\begin{align*} (\\lor I_{1})\\qquad (M:A) &amp;\\to ((\\mathbf{inl}M): A\\lor B) \\\\ (\\lor I_{2})\\qquad (M:B) &amp;\\to ((\\mathbf{inr}M): A\\lor B) \\\\ (\\lor E^{x,y}) \\qquad (M:(A\\lor B), &amp;(\\overline{x:A}^{x} \\to (N:C)), (\\overline{y:B}^{y} \\to (P:C))) \\\\ &amp;\\to \\mathbf{case}(M, x.N, y.P):C \\end{align*} (∨I1​)(M:A)(∨I2​)(M:B)(∨Ex,y)(M:(A∨B),​→((inlM):A∨B)→((inrM):A∨B)(x:Ax→(N:C)),(y:B​y→(P:C)))→case(M,x.N,y.P):C​ Falsehood No introduction rule. (⊥E)(M:⊥)→(abortM:C)(\\bot E)\\qquad(M:\\bot) \\to (\\mathbf{abort}M:C) (⊥E)(M:⊥)→(abortM:C)","tags":["TCS","Propositions","Types"],"categories":["理论计算机科学导引"]},{"title":"网原笔记7","path":"/2024/06/05/网原笔记7/","content":"计算机网络原理 笔记 7 无线网络和移动网络 概述 无线网络概述 在无线网络中，体系结构如下： 无线主机：端系统 无线链路：主机通过无线通信链路连接到基站或主机，不同无线链路具有不同的传输速率与覆盖距离 基站：负责协调与之相关联的多个主机之间的数据传输 网络基础设施：无线设备希望与之通信的网络 与基站相关联的主机称为以基础设施模式运行，所有网络服务有基站向主机提供，而自组织网络，主机向自身提供各种服务 由于无线主机可以移动，因此会出现切换现象，即改变与之相关联的基站 无线网络的分类一般是按照无线跳的数目和是否有基础设施（如基站）来共同决定的 基于基础设施 无基础设施 单跳 具有一个与较大有线网络连接的基站如802.11网络、4G LTE等 常用于协调其他节点的传输如蓝牙、自组织 多跳 无线节点为了与更大网络通信需要经过多个无线节点例如无线网状网络 没有基站，每个节点为了通信需要多个节点中继例如MANET或VANET 无线网络特征 相比于有线网络，无线网络有很多不同，例如： 信号强度递减：使用电磁波传输会导致信号的减弱，成为路径损耗 不同源之间会有干扰：在同一个频段中发送信号的源、环境噪声等都会相互干扰 多径传播：电磁波的不同部分在传播途中经过了不同的路径，导致信号模糊（例如经过了多次反射） 相干时间 在多径传播中，相干时间之信道中两次接收到预想信号的时间差，会影响到最大传输速率 相干时间示意图 取决于发送频率与接受者的速度 如果接受者不动则在一定时间后影响会被消除 噪声 由于无线链路非常容易出现差错，因此采用了CRC与ARQ结合的方式 对于主机，其接受到的信号事实上是退化后的初始信号与环境噪声的结合，我们使用信噪比来测量相对污染程度，信噪比越大，更容易提取出有效的信息，同时我们使用比特差错率来衡量接收方收到错误比特概率 不同的调制编码方式对于信号的传输也有影响，如下图 SNR、BER与调制编码方式 主要趋势为： 调制方案给定，BER与SNR成负相关（发送方增加传输速率） SNR给定：BER与调制方案的比特传输率成正相关 物理层调制技术可以动态选择，用于适配信道条件 其它问题 隐藏终端与衰减同样是无线传输中的两个重要问题，隐藏终端是是指两个终端相互之间不可见（被物理阻隔），但是其发送的信号在另一个终端有干扰；衰减很好理解 隐藏终端与衰减 CDMA 在无线领域使用非常广泛的协议，用于避免信号的相互干扰，举例来说如下 码分多址实例 CDMA将每个要发送的bit与编码bit想成来进行编码，编码bit以一个相当高的速率（码片速率）在变化，相当于将一个bit的信息编码为MMMbits的信息序列 理想状态下，编码为： Zi={Zim}∣1≤m≤M={di⋅cm}∣1≤m≤MZ_{i} = \\{Z_{im}\\}|_{1\\leq m \\leq M} = \\{d_{i}\\cdot c_{m}\\}|_{1\\leq m \\leq M} Zi​={Zim​}∣1≤m≤M​={di​⋅cm​}∣1≤m≤M​ 解码为： di=1M∑i=1MZim⋅cmd_{i} = \\frac{1}{M}\\sum\\limits_{i=1}^{M}Z_{im}\\cdot c_{m} di​=M1​i=1∑M​Zim​⋅cm​ 然而当有N&gt;1N &gt; 1N&gt;1个发送方时，接收方作加性处理，即： Zim∗=∑j=1NZimjZ^{*}_{im} = \\sum\\limits_{j=1}^{N}Z^{j}_{im} Zim∗​=j=1∑N​Zimj​ 而解码过程无需变化，在合适的CDMA编码的情况下，仍能辨别出所需要提取的信息 WiFi: 802.11无线LAN 多路访问使用CSMA/CA，有基站版和自组织版 体系结构 体系结构与自组织网络版 基本单位为基本服务集，一个BSS中包含若干个无线站点和一个接入点（中央基站），该种模式的WLAN称之为基础设施WLAN，其中基础设施指的是AP与其连接的有线网 每一个802.11无线站点和AP有一个6字节MAC地址，由IEEE\\text{IEEE}IEEE管理 同样可能存在自组织网络，相当于不需要与外部通信的情况下交换数据 信道与关联 802.11运行在2.4∼2.4835GHz2.4\\sim 2.4835\\text{GHz}2.4∼2.4835GHz的频段中，并将这个频段划分为了11个部分重叠的信道，当且仅当两个新岛之间距离超过4的时候才无重叠 每个AP会被分配一个单字或双字的服务集标识与一个信道号 WiFi丛林指的是一个物理位置，在此处无线站点可以收到多个AP的信号，因此我们需要和某一个AP进行关联，即在其间建立一条虚拟线路 为了了解到丛林中的AP，每个AP会周期性的发送信标帧，包括其SSID与MAC地址，站点通过扫描信道得知当前的AP，称之为被动扫描 指定关联AP没有相关准则，由软件方处理 同样的，站点可以主动向AP发送探测请求帧并期待AP回复探测响应帧，称之为主动扫描 主动扫描与被动扫描 确定了想要关联的AP后，站点发送关联请求帧，AP回复关联响应帧，之后将其加入AP子网中 802.11 MAC协议 采用CDMA/CA，由于无线设备的特殊性，信道的碰撞难以被检测（甚至有一部分无法被检测），因此采用避免碰撞的方式，一旦站点开始发送帧，就完整的发送 接收到信号的强度远小于发送的信号，制造检测碰撞设备代价高 不一定检测到所有碰撞，如隐藏终端和衰减 CSMA/CA协议如下： 站点监听到信道空闲，等待DIFS时间并完整发送帧 否则，选取一个随机回退值，在侦听到空闲时递减，在侦听到忙时不变 回退值减到0时，完整发送帧 等待ACK，若收到，则发送下一帧时从第二步开始 反之重新进入第二步并增大回退值 其与CSMA/CD最大的不同点在于，在侦听到空闲的时候不立即发送帧，而是等待回退值降到0，因此需要期待不同站点之间的回退值有一定距离 链路层确认 处理隐藏终端 采用RTS与CTS，即一个站点发送数据之前首先发送一个RTS控制帧，指示其所需要的总时间，AP接收到后广播CTS控制帧，告诉发送方可以发送，抑制其他的站点发送 处理隐藏终端 优势为： 有效解决隐藏终端 RTS和CTS的碰撞很短，对性能影响不大 用作点对点链路 略 IEEE 802.11帧 802.11帧示例 重要字段为： 有效载荷与CRC：通常包括IP数据报或者ARP分组 地址字段：共有四个，包括 地址1：目的地站点的MAC地址 地址2：源站点的MAC地址 地址3：该BSS所在子网对应的路由器接口MAC地址 地址4：用于自组织网络中互联，略 序号：用于区分同一个帧的不同副本（区分新帧与重传的帧） 持续期：预约享有信道的时间（RTS与CTS） 帧控制：很复杂，具体来说 类型：区分RTS、CTS、ACK与数据帧 到和从：定义地址字段含义 WEP：加密指示 相同IP子网中的移动性 在同一个子网下的多个BSS，TCP会话如何在其间丝滑切换？ 由于BSS在同一IP子网下，因此其IP地址不会发生变化，并且交换机可以通过自学习来改变与站点相连接的AP的端口MAC 高级特色 速率适应：根据信道特点来选择物理层调制技术，如果连续多帧没有收到ACK则降速，反之（或降速达到一定时间后）增速 功率管理：节点可以向AP发送信号表明自己进入睡眠状态，AP缓存发送到对应站点的帧。 节点在信标帧到来之前醒来，通过检测信标帧（包括所有被缓存帧的目标站点列表）确认是否有信号发过来，如果有则发送缓存请求报文，反之继续睡 个人域网络：蓝牙 自组织为一个皮可网，分为主设备、从设备与寄放设备，主设备统筹全局通信，所有通信必须经由主设备，寄放设备是不可活动的 皮可网 其采用TDM，每个时隙625μs625\\mu s625μs，工作在2.4GHz2.4\\text{GHz}2.4GHz，在每个时隙内，发送方利用79个信道中的一个进行传输，并且以不同时隙使用的信道是伪随机的，称之为跳频扩展频谱 蜂窝因特网接入 蜂窝网络与有线网络的同： 设备之间距离很远，但是属于同一个Carrier 全球蜂窝网络是一种网络的网络 广泛使用各种协议 与有线网络互联 蜂窝网络与有线网络的异： 有不同的无线链路层 移动性是第一要求 用户是可区分的（SIM卡） 用户需要向提供商订阅，权威机构提供基础设施 4G：LTE 4G网络架构 其中包括： 移动设备：将订阅者的身份信息ISMI存储在SIM卡中 基站：在服务范围边缘，管理范围内的无线通信资源；管理设备授权，与AP相似 归属订阅者服务：储存有关“归属网络”的信息，用于授权管理 S/P网关：位于数据传输的路径中，P网关是处理蜂窝网络与因特网的交流，提供NAT服务 移动管理实体：与HSS一起管理设备授权；管理设备的交接、位置跟踪等；设置设备到P网关的路径 4G无线网 将每个设备连接到一个基站 可以用很多频带，每个频带内有大量信道，可以区分上行与下行数据 通过OFDM共享信道，速率可以非常高 正交频分复用 图中，每一个PRB是一个传输单元，每一个单元内可以按照时隙与频段划分给不同用户，不同颜色代表不同用户 数据平面与控制平面分离 控制平面：管理移动性、安全与授权 数据平面：管理数据传输 控制平面 LTE中的控制平面有着不同链路层协议，如下： LTE协议1 新增的部分为： 数据收敛：压缩头部信息并加密 无线链路控制：信息的打碎与充足，执行可靠数据传输 中路访问：使用OFDM的需求 LTE协议2 传输规则为： 移动设备将数据传给S网关 S网关传给P网关 优势在与：用户移动的时候只有信道的末端（基站）在变 数据平面 主要是与基站通信，方法为： 基站全频段广播基础同步信号 移动设备找都一个同步信号，之后定位这个频段的第二同步信号（可能有多个基站），并拿到信道的相关信息 之后移动设备挑选基站连接 并且为了节省功率，同样会有睡眠模式，不同的是有两种模式： 浅睡眠：100ms100ms100ms不工作导致，并会时不时醒来检查下行传输 深睡眠：555-10s10s10s不动作导致，可能切换蜂窝 全球蜂窝网络 全IP连接，连接归属网络与被访网络，每个设备的SIM卡中存储了归属网络中的全球性身份信息，可以直接 与归属网络通信，也可以和被访网络进行漫游 5G 适用场景：大信息交流、高可信低延迟交流、增强移动宽带 新无线的新点： 两个频带：毫米波频率 不兼容4G 大量有线天线 毫米波有更高数据传输速率，但是传输距离更短 5G架构 用户直接向与数据中心相连的基站进行通信，数据中心会有分层，中心-边缘-远边缘 5G数据中心图示 移动性 移动性准则 移动性光谱 主要挑战是，如何知道发送的包要到哪，主要处理方式有两种： 路由器处理：路由器决定哪些设备跟它通信，通知这些设备给它发包。这种方式对路由器的变化较简单，可以直接使用之前的转发表和最长前缀匹配，但是当移动设备大量增加以后负担过重 端系统处理：在边缘进行处理： 间接路由：通过归属网络与移动设备进行交流 直接路由：直接与移动设备交流 其中“归属网络”非常重要： 有一个确定的信息源 别人可以与你进行通信 两种网络 4G/5G网络中有两种主要的网络： 归属网络：由蜂窝提供商提供服务，HSS储存了相关信息 被访网络：归属网络之外的所有网络，提供和远端的通信 而在ISP/WiFi中，不再有归属网络的概念： ISP的授权存储在设备或者用户上 ISP的影响力非常巨大 不同的网络有不同的授权，有为4G设计的结构但是未使用 ISP/WiFi网络 注册 移动设备和被访网络中MME相连接 被访网络中的MME向HSS注册移动设备的位置 最终被访MME知道设备存在，HSS知道设备位置 通信过程 通信者和移动设备通信的过程为： 将信息发给归属网关 归属网关将其发送给被访网关 被访网关与移动设备通信 之后被访网关间接路由（经过归属网关转移）或直接路由（直接发回） 但是这种情况下，如果通信者希望与同一网络下的移动设备通信，则效率会有很大降低；但是其优势在与连接的稳定性，移动设备的移动只会带来新的注册，同新方还是只用给HSS发信息即可 另一种通信过程为： 将信息发给归属网关 归属网关回复被访网络有关信息 直接与被访网关通信 克服了上述三角路由的效率问题，但是通信者必须保证自己发送信息到了正确的位置，并且被访网络的变化处理更复杂 实际中的移动性 4G 移动设备与被访网络中的基站通信，向基站提供IMSI 被访MME使用IMSI联系其HSS，并建立控制平面状态（相互知道移动设备在被访网络中） 数据平面建立：归属P网关和被访MME建立联系，被访MME通过基站与移动设备通信 移动设备可能改变其在被访网络中的接入点 移动设备的数据平面建立是通过S网关和基站共同完成的，其信道路径为：设备↔\\leftrightarrow↔基站↔\\leftrightarrow↔被访S网关↔\\leftrightarrow↔归属P网关↔\\leftrightarrow↔通信者，其中信道上通信的数据使用了GTP封装在UDP中 切换基站 源基站选择目的基站，向其发送请求 目的基站预先分配频段与时隙，回复ACK并告知相关信息 源基站告知移动设备新基站的信息（在移动设备看来切换已经完成） 源基站停止向移动设备发送信息，而是发送到目的基站 目的基站告知MME，MME通知S网关，S网关修改目的地 源基站收到ACK，释放资源，完成 基站切换 移动IP 大约20年前有了标准化架构，但是并没有广泛使用，其架构主要是： 间接路由 归属代理：HSS与归属P网关的结合 外部代理：MME与S网关结合 通过ICMP扩展注册，协议用于发现代理","tags":["网原","笔记","WiFi"],"categories":["计算机网络原理"]},{"title":"TCS-Lecture-D","path":"/2024/05/29/TCS-Lecture-D/","content":"TCS: Interactive Proofs and Zero-Knowledge Interactive Proofs and Zero-Knowledge Interactive Proofs Interactive Proof Verification Interactive proof system allows prover PPP and verifier VVV to exchange messages before stopping. We restrict VVV to be PPT while the probabilitic is necessary otherwise this system is NP\\text{NP}NP as PPP is stronger than VVV. Problem AAA is in IP\\text{IP}IP if there is a pair of interactive algorithms (P,V)(P, V)(P,V), with VVV running in probabilistic polynomial time in the length of input xxx, such that(Completeness). If x∈Ax\\in Ax∈A, then P(⟨P,V⟩(x)=1)=1P(\\langle P, V\\rangle(x) = 1) = 1P(⟨P,V⟩(x)=1)=1.(Soundness). If x∉Ax otin Ax∈/A, then for any possibly dishonest P∗P^{*}P∗, we have P(⟨P,V⟩(x)=1)≤12P(\\langle P, V\\rangle(x) = 1) \\leq \\frac{1}{2}P(⟨P,V⟩(x)=1)≤21​.(P,V)(P, V)(P,V) satisfying above is called a proof system for AAA. We say A∈IP[ℓ]A\\in\\text{IP}[\\ell]A∈IP[ℓ] if it has a proof system using ℓ=ℓ(∣x∣)\\ell = \\ell(|x|)ℓ=ℓ(∣x∣) times of message exchanges (number of messages, not rounds!). We have that: BPP⊆IP[1]\\text{BPP} \\subseteq \\text{IP}[1]BPP⊆IP[1] Concretely, we consider two problem GRAPH-ISO\\text{GRAPH-ISO}GRAPH-ISO(图同构问题) and GRAPH-NONISO\\text{GRAPH-NONISO}GRAPH-NONISO. Easily, GRAPH-ISO∈NP\\text{GRAPH-ISO}\\in \\text{NP}GRAPH-ISO∈NP since we can choose the isomorphic permutation π\\piπ as witness. Besides, we have GRAPH-NONISO∈IP\\text{GRAPH-NONISO}\\in \\text{IP}GRAPH-NONISO∈IP. The GNI protocol is: VVV samples a random b∈{0,1}b\\in\\{0, 1\\}b∈{0,1} and a random permutation π\\piπ, send π(Gb)\\pi(G_{b})π(Gb​) to PPPPPP returns an bit b′b&#x27;b′ to VVV and VVV accepts iff b′=bb&#x27; = bb′=b As PPP is all-know, it must have the ability to distinguish bbb if G0≁G1G_{0} ot\\sim G_{1}G0​∼G1​. But it can just guess arbitarily if they are isomorphic. Merlin-Arthur (Public-Coin) Protocols (Skip) A Merlin-Arthur protocol is an interactive proof system where the verifier (Arthur) messages are public random coin flips. A really simple VVV! Let AM[ℓ]\\text{AM}[\\ell]AM[ℓ] to be the Merlin-Arthur protocol with ℓ(∣x∣)\\ell(|x|)ℓ(∣x∣) messages. Consider MA=AM[1]\\text{MA} = \\text{AM}[1]MA=AM[1] and AM=AM[2]\\text{AM} = \\text{AM}[2]AM=AM[2] Though it seems week, but we have: Goldwasser-Sipser theorem: ∀ℓ\\forall \\ell∀ℓ, IP[ℓ]⊆AM[ℓ+2]\\text{IP}[\\ell]\\subseteq\\text{AM}[\\ell + 2]IP[ℓ]⊆AM[ℓ+2] Define a set: S={(H,π) ∣ π∈Aut(H),H∼G0 or H∼G1}S = \\{(H, \\pi) \\,|\\, \\pi\\in\\text{Aut}(H), H\\sim G_{0} \\text{ or } H\\sim G_{1} \\} S={(H,π)∣π∈Aut(H),H∼G0​ or H∼G1​} Aut(H)\\text{Aut}(H)Aut(H) represents the automorphism permutation multiplicity. So we have: ∣S∣={n!G0∼G12n!otherwise|S| = \\begin{cases} n! &amp; G_{0} \\sim G_{1} \\\\ 2n! &amp; \\text{otherwise} \\end{cases} ∣S∣={n!2n!​G0​∼G1​otherwise​ So the GRAPH-NONISO\\text{GRAPH-NONISO}GRAPH-NONISO is transformed into confirming ∣S∣|S|∣S∣ Let H\\mathcal{H}H be a pairwise independent hash family with U={0,1}mU = \\{0, 1\\}^{m}U={0,1}m and R={0,1}kR = \\{0, 1\\}^{k}R={0,1}k where k&lt;mk &lt; mk&lt;m. Then the protocol is: TODO More facts IP=PSPACE\\text{IP} = \\text{PSPACE}IP=PSPACE IP[ℓ]=AM[ℓ]=AM\\text{IP}[\\ell] = \\text{AM}[\\ell] = \\text{AM}IP[ℓ]=AM[ℓ]=AM for all constant ℓ≥2\\ell \\geq 2ℓ≥2 AM=MA=IP\\text{AM} = \\text{MA} = \\text{IP}AM=MA=IP if we allow completeness error Coin Flipping and Commitment We want a protocol where Alice and Bob talk to each other and then decide some important thing on the outcome R(a,b)R(a, b)R(a,b) of the coin flip and it makes sure that the result is not biased even if one of them is cheating (malicious). This means: P(R=0)≤12+negl(n)P(R=1)≤12+negl(n)\\begin{align*} P(R = 0) &amp;\\leq \\frac{1}{2} + \\text{negl}(n) \\\\ P(R = 1) &amp;\\leq \\frac{1}{2} + \\text{negl}(n) \\end{align*} P(R=0)P(R=1)​≤21​+negl(n)≤21​+negl(n)​ So we need something to hide aaa which filped by Alice to Bob to avoid bias. Bit Commitment The commitment scheme is a protocol consisting of the commit phase and reveal phase. A PPT protocol Com\\text{Com}Com is a (computationally hiding and statistically binding) commitment scheme if:Hiding: ∀ x0≠x1\\forall\\, x_{0} eq x_{1}∀x0​=x1​, Com(x0)≈cCom(x1)\\text{Com}(x_{0})\\approx_{c}\\text{Com}(x_{1})Com(x0​)≈c​Com(x1​).Binding: The probability that Alice can open Com(x0)\\text{Com}(x_{0})Com(x0​) to x1x_{1}x1​ with x1≠x0x_{1} eq x_{0}x1​=x0​ is negligible. In this ≈c\\approx_{c}≈c​ means that one cannot distinguish both is polynomial time. Intuitively, this definition means Bob(recevier) can hardly verify x0x_{0}x0​ or x1x_{1}x1​ and Alice(sender) can almost always verify them. Coin Flipping from Bit Commitment The safe protocol is as follows: Alice send Com(a)\\text{Com}(a)Com(a) to Bob with a random aaaBob sends bbb to AliceAlice opens Com(a)\\text{Com}(a)Com(a)Set R=a⊕bR = a \\oplus bR=a⊕b Bit Commitment From PRG (Naor’s Construction) Assume GGG is a PRG with ℓ(n)=3n\\ell(n) = 3nℓ(n)=3n In the commit phase:The receiver sends x∈{0,1}3nx\\in\\{0, 1\\}^{3n}x∈{0,1}3n;The sender samples m∈{0,1}m\\in\\{0, 1\\}m∈{0,1}, z∈{0,1}nz\\in\\{0, 1\\}^{n}z∈{0,1}n and sends y=G(z)⊕xmy = G(z)\\oplus x^{m}y=G(z)⊕xm;In the reveal phase:The sender sends zzz and mmm. Zero-Knowledge Proofs Definition at first is as follows, in which view\\text{view}view contains the transcript of the interaction(all messages and their probabilities) and local information. An interactive protocol (P,V)(P, V)(P,V) is perfect (statistical or computational) ZK for AAA if, ∀\\forall∀ PPT V∗V^{*}V∗, there exists a PPT simulator SSS such that ∀ x∈A\\forall\\, x\\in A∀x∈A, the following two distributions are the same:viewV∗⟨P,V∗⟩(x)\\text{view}_{V^{*}}\\langle P, V^{*}\\rangle(x)viewV∗​⟨P,V∗⟩(x)S(x)S(x)S(x) We have GRAPH-ISO∈PZK\\text{GRAPH-ISO} \\in \\text{PZK}GRAPH-ISO∈PZK. The protocol is as follows: PPP samples a random permutation π\\piπ and sends G=π(G0)G = \\pi(G_{0})G=π(G0​) to VVV VVV samples a random b∈{0,1}b\\in\\{0, 1\\}b∈{0,1} and sends it to PPP PPP responds with a proof that G∼GbG\\sim G_{b}G∼Gb​ with the permutation π∘σb\\pi\\circ\\sigma^{b}π∘σb simulator and rewind To prove this protocol is what we want, we need to prove its completeness, soundness and ZK. The first two are easy to argue, the ZK need a simulator and we generates it as follows: Choose aaa uniformly at random.Sample a random permutation π\\piπ and compute G=π(Ga)G = \\pi(G_{a})G=π(Ga​).Randomly sample rrr and simulate V∗V^{*}V∗ with random tape content rrr.If V∗V^{*}V∗ sends b=ab = ab=a, outputs (G,π)(G, \\pi)(G,π) as the message and the random tape rrr as the internal randomness of V∗V^{*}V∗.If V∗V^{*}V∗ sends b≠ab eq ab=a, rewind and start from the beginning. ZK Proofs for NP We have: (Goldreich-Micali-Wigderson). If statistically binding commitments exist, then there exists a zero-knowledge proof system for 3-COLORING\\text{3-COLORING}3-COLORING The protocol is: PPP samples random permutation π:{0,1,2}→{0,1,2}\\pi: \\{0, 1, 2\\}\\to \\{0, 1, 2\\}π:{0,1,2}→{0,1,2}. PPP sends {Com(π(ϕ(v))) ∣ v∈V}\\{\\text{Com}(\\pi(\\phi(v))) \\,|\\, v\\in V\\}{Com(π(ϕ(v)))∣v∈V} VVV samples a random edge (u,v)←E(u, v)\\gets E(u,v)←E and sends it to PPP PPP opens the commitment cuc_{u}cu​ and cvc_{v}cv​ VVV checks if π(ϕ(u)),π(ϕ(v))∈{0,1,2}\\pi(\\phi(u)), \\pi(\\phi(v))\\in\\{0, 1, 2\\}π(ϕ(u)),π(ϕ(v))∈{0,1,2} and π(ϕ(u))≠π(ϕ(v))\\pi(\\phi(u)) eq \\pi(\\phi(v))π(ϕ(u))=π(ϕ(v)) In this, ϕ\\phiϕ is a coloring scheme","tags":["Interactive Proofs","Zero-Knowledge","TCS"],"categories":["理论计算机科学导引"]},{"title":"IAI-统计机器学习","path":"/2024/05/27/IAI-统计机器学习/","content":"人智导 统计机器学习 统计机器学习 对于数据集D={(xi,yi)}D = \\{(x_{i}, y_{i})\\}D={(xi​,yi​)}，输入输出之间存在关系fff，算法AAA根据训练集从假设空间H\\mathcal{H}H中选取一个合适的函数g≈fg\\approx fg≈f 主要决定因素：模型、策略、算法 分类方式： 监督式学习 半监督式学习 弱监督式学习 支持向量机(SVM) 按照模型的复杂程度，分为线性可分、线性与非线性 线性可分SVM 定义线性可分SVM相关概念如下： 线性可分训练集：T={(xi,yi) ∣ 1≤i≤N,xi∈Rn,yi∈{−1,1}}T = \\{ (x_{i}, y_{i}) \\,|\\, 1\\leq i\\leq N, x_{i}\\in \\mathbb{R}^{n}, y_{i}\\in\\{-1, 1\\} \\}T={(xi​,yi​)∣1≤i≤N,xi​∈Rn,yi​∈{−1,1}}给定超平面wx+b=0wx+b = 0wx+b=0，于是可以定义函数间隔为：γ^=min⁡1≤i≤N{(wxi+b)yi}\\hat{\\gamma} = \\mathop{\\min}\\limits_{1\\le i \\le N}\\{(wx_{i} + b)y_{i}\\}γ^​=1≤i≤Nmin​{(wxi​+b)yi​}相对应的，定义几何间隔为函数间隔的归一化，也即考虑超平面的缩放的影响γ=γ^∣∣w∣∣\\gamma = \\frac{\\hat{\\gamma}}{||w||}γ=∣∣w∣∣γ^​​通过间隔最大化得到分类超平面w∗x+b∗=0w^{*}x+b^{*} = 0w∗x+b∗=0，则得到决策函数：f(x)=sgn(w∗x+b∗)f(x) = \\mathrm{sgn}(w^{*}x+b^{*})f(x)=sgn(w∗x+b∗)此即线性可分SVM 于是关键问题即为间隔最大化： max⁡w,bγ=max⁡w,bγ^∣∣w∣∣\\max\\limits_{w, b}\\gamma = \\max\\limits_{w, b}{\\frac{\\hat{\\gamma}}{||w||}} w,bmax​γ=w,bmax​∣∣w∣∣γ^​​ 显然，函数间隔是可缩放的（函数缩放表示为$w, b$等比例缩放），因此不妨令γ^=1\\hat{\\gamma} = 1γ^​=1，则进一步转化为规划问题： max⁡w,b1∣∣w∣∣=min⁡w,b12∣∣w∣∣2\\max\\limits_{w, b}\\frac{1}{||w||} = \\min\\limits_{w, b} \\frac{1}{2}||w||^{2}w,bmax​∣∣w∣∣1​=w,bmin​21​∣∣w∣∣2使得：∀i,γi^=(wxi+b)yi≥1\\forall i,\\quad \\hat{\\gamma_{i}} = (wx_{i} + b)y_{i} \\geq 1∀i,γi​^​=(wxi​+b)yi​≥1 定义相对应的拉格朗日函数为： L(w,b,α)=12∣∣w∣∣2+∑i=1Nαi[1−(wxi+b)yi]L(w, b, \\alpha) = \\frac{1}{2}||w||^{2} + \\sum\\limits_{i=1}^{N}\\alpha_{i}[1 - (wx_{i} + b)y_{i}] L(w,b,α)=21​∣∣w∣∣2+i=1∑N​αi​[1−(wxi​+b)yi​] 则在满足优化条件的情况下，原问题转化为： min⁡w,bmax⁡αL(w,b,α)\\min\\limits_{w, b}\\max\\limits_{\\alpha}L(w, b, \\alpha) w,bmin​αmax​L(w,b,α) 当满足KKT条件时，该问题可转化为其对偶问题： max⁡αmin⁡w,bL(w,b,α)\\max\\limits_{\\alpha}\\min\\limits_{w, b}L(w, b, \\alpha) αmax​w,bmin​L(w,b,α) ∇w,bL(w,b,α)=0αi[1−(wxi+b)yi]=01−(wxi+b)yi≤0αi≥0\\begin{align*} abla_{w, b}L(w, b, \\alpha) &amp;= 0 \\\\\\alpha_{i}[1 - (wx_{i} + b)y_{i}] &amp;= 0 \\\\1 - (wx_{i} + b)y_{i} &amp;\\leq 0 \\\\\\alpha_{i} &amp;\\geq 0 \\end{align*}∇w,b​L(w,b,α)αi​[1−(wxi​+b)yi​]1−(wxi​+b)yi​αi​​=0=0≤0≥0​ 利用KKT条件转化为对偶问题之后，可以化简为： max⁡α(−12∑i=1N∑j=1Nαiαjyiyj(xi⋅xj)+∑i=1Nαi)=min⁡α(12∑i=1N∑j=1Nαiαjyiyj(xi⋅xj)−∑i=1Nαi)\\begin{align*}&amp;\\quad \\max\\limits_{\\alpha}\\bigl(-\\frac{1}{2}\\sum\\limits_{i = 1}^{N}\\sum\\limits_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(x_{i}\\cdot x_{j}) + \\sum\\limits_{i=1}^{N}\\alpha_{i} \\bigr) \\\\&amp;= \\min\\limits_{\\alpha}\\bigl(\\frac{1}{2}\\sum\\limits_{i = 1}^{N}\\sum\\limits_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(x_{i}\\cdot x_{j}) - \\sum\\limits_{i=1}^{N}\\alpha_{i} \\bigr) \\\\\\end{align*}​αmax​(−21​i=1∑N​j=1∑N​αi​αj​yi​yj​(xi​⋅xj​)+i=1∑N​αi​)=αmin​(21​i=1∑N​j=1∑N​αi​αj​yi​yj​(xi​⋅xj​)−i=1∑N​αi​)​使得：∑i=1Nαiyi=0αi≥0\\sum\\limits_{i=1}^{N}\\alpha_{i}y_{i} = 0\\quad \\alpha_{i} \\geq 0i=1∑N​αi​yi​=0αi​≥0 于是可以求出α∗\\alpha^{*}α∗，相对应的根据KKT条件求出w∗,b∗w^{*}, b^{*}w∗,b∗： w∗=∑i=1Nαi∗yixib∗=yj−∑i=1Nαi∗yi(xi⋅xj)αj≠0\\begin{align*}w^{*} &amp;= \\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}x_{i} \\\\b^{*} = y_{j} - &amp;\\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}(x_{i}\\cdot x_{j})\\quad \\alpha_{j} eq 0\\end{align*}w∗b∗=yj​−​=i=1∑N​αi∗​yi​xi​i=1∑N​αi∗​yi​(xi​⋅xj​)αj​=0​ 所得到的αi&gt;0\\alpha_{i} &gt; 0αi​&gt;0对应的实例xix_{i}xi​即为支持向量 线性SVM 在线性可分SVM中，约束条件要求每一个样本点的函数间隔都不小于111，这个条件事实上要求样本拥有很强的分类性，而对于一些分类性较弱的样本，很难全部满足这个条件，因此引入松弛变量ξi\\xi_{i}ξi​，将约束条件修改为 (wxi+b)yi≥1−ξi(wx_{i} + b)y_{i} \\geq 1 - \\xi_{i} (wxi​+b)yi​≥1−ξi​ 为了让分隔尽量好，因此要满足松弛变量尽量小，因此调整优化问题为： min⁡w,b,ξ(12∣∣w∣∣2+C∑i=1Nξi)\\min\\limits_{w, b, \\xi}\\bigl( \\frac{1}{2}||w||^{2} + C\\sum\\limits_{i=1}^{N}\\xi_{i} \\bigr) w,b,ξmin​(21​∣∣w∣∣2+Ci=1∑N​ξi​) 其中CCC为惩罚参数，用于调整间隔最大与误分类点数之间的矛盾 于是，可以转化为： min⁡α(12∑i=1N∑j=1Nαiαjyiyj(xi⋅xj)−∑i=1Nαi)\\min\\limits_{\\alpha}\\bigl(\\frac{1}{2}\\sum\\limits_{i = 1}^{N}\\sum\\limits_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(x_{i}\\cdot x_{j}) - \\sum\\limits_{i=1}^{N}\\alpha_{i} \\bigr) αmin​(21​i=1∑N​j=1∑N​αi​αj​yi​yj​(xi​⋅xj​)−i=1∑N​αi​)使得：∑i=1Nαiyi=00≤αi≤C\\sum\\limits_{i=1}^{N}\\alpha_{i}y_{i} = 0\\quad 0\\leq \\alpha_{i} \\leq Ci=1∑N​αi​yi​=00≤αi​≤C 可以看出与线性可分的唯一区别在与αi\\alpha_{i}αi​的范围，因此最终求出w∗,b∗w^{*}, b^{*}w∗,b∗时同样和线性可分只有这个区别，具体来说： w∗=∑i=1Nαi∗yixib∗=yj−∑i=1Nαi∗yi(xi⋅xj)0&lt;αj&lt;C\\begin{align*}w^{*} &amp;= \\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}x_{i} \\\\b^{*} = y_{j} - &amp;\\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}(x_{i}\\cdot x_{j})\\quad 0 &lt; \\alpha_{j} &lt; C\\end{align*}w∗b∗=yj​−​=i=1∑N​αi∗​yi​xi​i=1∑N​αi∗​yi​(xi​⋅xj​)0&lt;αj​&lt;C​ 同样，αi∗&gt;0\\alpha_{i}^{*} &gt; 0αi∗​&gt;0所对应的样本成为软间隔的支持向量，具体来说： αi∗&lt;C\\alpha_{i}^{*} &lt; Cαi∗​&lt;C时，ξi=0\\xi_{i} = 0ξi​=0，xix_{i}xi​位于间隔边界 αi∗=C\\alpha_{i}^{*} = Cαi∗​=C时，ξi&gt;0\\xi_{i} &gt; 0ξi​&gt;0： 0&lt;ξi&lt;10 &lt; \\xi_{i} &lt; 10&lt;ξi​&lt;1时，分类正确 ξi=1\\xi_{i} = 1ξi​=1时，位于超平面上 ξi&gt;1\\xi_{i} &gt; 1ξi​&gt;1时，分类错误 非线性SVM 关键思想：利用变换ϕ:X→H\\phi: \\mathcal{X}\\to \\mathcal{H}ϕ:X→H将原空间的数据映射到特征空间，使之变为线性的，相对应的问题为： min⁡α(12∑i=1N∑j=1Nαiαjyiyj(ϕ(xi)⋅ϕ(xj))−∑i=1Nαi)\\min\\limits_{\\alpha}\\bigl(\\frac{1}{2}\\sum\\limits_{i = 1}^{N}\\sum\\limits_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(\\phi(x_{i})\\cdot \\phi(x_{j})) - \\sum\\limits_{i=1}^{N}\\alpha_{i} \\bigr) αmin​(21​i=1∑N​j=1∑N​αi​αj​yi​yj​(ϕ(xi​)⋅ϕ(xj​))−i=1∑N​αi​)使得：∑i=1Nαiyi=00≤αi≤C\\sum\\limits_{i=1}^{N}\\alpha_{i}y_{i} = 0\\quad 0\\leq \\alpha_{i} \\leq Ci=1∑N​αi​yi​=00≤αi​≤C 可以看出其中只有内积有变化，因此若存在函数KKK满足K(x,z)=ϕ(x)⋅ϕ(z)K(x, z) = \\phi(x)\\cdot \\phi(z)K(x,z)=ϕ(x)⋅ϕ(z)对任二元素都成立，则称K(x,z)K(x, z)K(x,z)为核函数 同一个核函数对应的映射不一定相同 映射到新空间之后，可以解得： w∗=∑i=1Nαi∗yiϕ(xi)b∗=yj−∑i=1Nαi∗yiK(xi,xj)0&lt;αj&lt;C\\begin{align*}w^{*} &amp;= \\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}\\phi(x_{i}) \\\\b^{*} = y_{j} - &amp;\\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}K(x_{i}, x_{j})\\quad 0 &lt; \\alpha_{j} &lt; C\\end{align*}w∗b∗=yj​−​=i=1∑N​αi∗​yi​ϕ(xi​)i=1∑N​αi∗​yi​K(xi​,xj​)0&lt;αj​&lt;C​ 常用的核函数包括： K(x,z)=(x⋅z+1)pK(x,z)=exp⁡(−∣∣x−z∣∣22σ2)(Gaussian)\\begin{align*} K(x, z) &amp;= (x\\cdot z + 1)^{p} \\\\ K(x, z) &amp;= \\exp(-\\frac{||x - z||^{2}}{2\\sigma^{2}})\\quad (\\text{Gaussian}) \\end{align*} K(x,z)K(x,z)​=(x⋅z+1)p=exp(−2σ2∣∣x−z∣∣2​)(Gaussian)​ 采用高斯核函数的时候，关键为σ\\sigmaσ的选取，不当会导致欠拟合与过拟合 σ过大导致欠拟合 σ过小导致过拟合 由于求解凸二次规划的算法在样本数很多的时候非常低效，因此有许多快速算法，例如序列最小最优化算法SMO 当样本中有多类怎么办？ 将一类视为正，其余所有视为负 任意两类构造一个SVM，分类时采取投票法 二分类别，依次二分整体直至单独类别 SVM应用举例 文本分类：文本表达为一个向量(w1j,…,wnj)T(w_{1j}, \\dots, w_{nj})^{T}(w1j​,…,wnj​)T，wijw_{ij}wij​表示词iii在文档jjj中的权重，具体计算有很多版本，在此介绍两种： wij=tfijw_{ij} = \\mathrm{tf}_{ij}wij​=tfij​即tf权重，用词频代表权重 wij=tfij∗idfiw_{ij} = \\mathrm{tf}_{ij}*\\mathrm{idf}_{i}wij​=tfij​∗idfi​即tf-idf权重，其中idf为逆文档频率，记cnt(i)\\mathrm{cnt}(i)cnt(i)为词iii所出现的文档数，则idfi=log⁡(Ncnt(i))\\mathrm{idf}_{i} = \\log(\\frac{N}{\\mathrm{cnt}(i)})idfi​=log(cnt(i)N​) 决策树 对样本进行分类，由节点和有向边组成，每个内部节点表示一个特征或者一个属性，每个叶节点表示一个类 决策树通过在训练集中对于分类规则进行训练，得到一组矛盾较小的特征，即KKK分类问题，而最优决策树的选择是一个NPC问题，因此通常采用启发式方法 学习过程包括： 特征选择 决策树生成与剪枝 特征选择 按照信息增益来选择特征，信息增益g(D,A)g(D, A)g(D,A)代表了特征AAA对于数据集DDD分类的不确定性的减少程度，计算如下： 记X,YX, YX,Y是两个随机变量，P(X=xi)=piP(X = x_{i}) = p_{i}P(X=xi​)=pi​，则：随机变量的熵：H(X)=−∑i=1npilog⁡(pi)H(X) = -\\sum\\limits_{i=1}^{n}p_{i}\\log(p_{i})H(X)=−i=1∑n​pi​log(pi​)条件熵：H(Y ∣ X)=∑i=1NpiH(Y ∣ X=xi)H(Y\\,|\\, X) = \\sum\\limits_{i=1}^{N}p_{i}H(Y \\,|\\, X = x_{i})H(Y∣X)=i=1∑N​pi​H(Y∣X=xi​)信息增益：g(D,A)=H(D)−H(D ∣ A)g(D, A) = H(D) - H(D \\,|\\, A)g(D,A)=H(D)−H(D∣A)信息增益越大的特征分类能力越强 具体到特征AAA对于数据集DDD的信息增益，设一共有KKK个类别(C1,…,CK)(C_{1}, \\dots, C_{K})(C1​,…,CK​)，AAA有nnn种不同值(a1,…,an)(a_{1},\\dots, a_{n})(a1​,…,an​)，对应了一个划分(D1,…,Dn)(D_{1}, \\dots, D_{n})(D1​,…,Dn​)，记DijD_{ij}Dij​为DiD_{i}Di​中属于类CjC_{j}Cj​的集合，则： H(D)=∑j=1K∣Cj∣∣D∣log⁡(∣Cj∣∣D∣)H(D ∣ A)=∑i=1n∣Di∣∣D∣H(Di)=−∑i=1n(∣Di∣∣D∣∑j=1K(∣Dij∣∣Di∣log⁡(∣Dij∣∣Di∣)))g(D,A)=H(D)−H(D ∣ A)\\begin{align*}H(D) &amp;= \\sum\\limits_{j=1}^{K}\\frac{|C_{j}|}{|D|}\\log(\\frac{|C_{j}|}{|D|}) \\\\H(D\\,|\\, A) &amp;= \\sum\\limits_{i=1}^{n}\\frac{|D_{i}|}{|D|}H(D_{i}) \\\\&amp;= -\\sum\\limits_{i=1}^{n}\\biggl(\\frac{|D_{i}|}{|D|}\\sum\\limits_{j=1}^{K}\\bigl(\\frac{|D_{ij}|}{|D_{i}|}\\log(\\frac{|D_{ij}|}{|D_{i}|})\\bigr)\\biggr) \\\\g(D, A) &amp;= H(D) - H(D\\,|\\, A)\\end{align*}H(D)H(D∣A)g(D,A)​=j=1∑K​∣D∣∣Cj​∣​log(∣D∣∣Cj​∣​)=i=1∑n​∣D∣∣Di​∣​H(Di​)=−i=1∑n​(∣D∣∣Di​∣​j=1∑K​(∣Di​∣∣Dij​∣​log(∣Di​∣∣Dij​∣​)))=H(D)−H(D∣A)​ 决策树的生成 两个常用的算法为ID3与C4.5 ID3算法 输入：训练集DDD，特征AAA，阈值ε\\varepsilonε 输出：决策树TTT 算法如下： 若DDD中所有实例属于同一类CCC，则TTT单节点，类标记为CCC，直接返回若A=∅A = \\varnothingA=∅，则TTT也为单节点，类标记为DDD中最多的类CjC_{j}Cj​，直接返回计算AAA中所有特征对DDD的信息增益，选择其中信息增益最大的特征AkA_{k}Ak​若g(D,Ak)≤εg(D, A_{k}) \\leq \\varepsilong(D,Ak​)≤ε，则将TTT置为单节点树，类标记为DDD中最多的类CjC_{j}Cj​，直接返回反之，遍历Ak=(ak1,…,aknk)A_{k} = (a_{k1}, \\dots, a_{kn_{k}})Ak​=(ak1​,…,aknk​​)，将DDD划分为nkn_{k}nk​个子集分别作为子节点遍历子节点DiD_{i}Di​，若为空，则将DDD中最多的类标记这个子节点反之以(Di,A−Ak,ε)(D_{i}, A - A_{k}, \\varepsilon)(Di​,A−Ak​,ε)递归返回TTT 也就是按照特征集合不断划分，当出现所有属于同一类或某一个划分为空集的时候进行特判即可 问题：信息增益倾向于选择分支较多的特征，但是有的分支是毫无意义的 C4.5算法 考虑信息增益比： gR(D,A)=g(D,A)HA(D)=g(D,A)(−∑i=1n∣Di∣∣D∣log⁡(∣Di∣∣D∣))−1g_{R}(D, A) = \\frac{g(D, A)}{H_{A}(D)} = g(D, A)\\bigl(-\\sum\\limits_{i=1}^{n}\\frac{|D_{i}|}{|D|}\\log(\\frac{|D_{i}|}{|D|})\\bigr)^{-1} gR​(D,A)=HA​(D)g(D,A)​=g(D,A)(−i=1∑n​∣D∣∣Di​∣​log(∣D∣∣Di​∣​))−1 因此C4.5引入信息增益比来选择特征，同时允许特征的取值为连续的而非离散的，相对于ID3的改进如下： 将选择信息增益最大的特征改为： 选择信息增益前kkk大的特征，再从其中选择信息增益比最大的特征 原因是信息增益比倾向于选择分割不均匀的特征 对于连续的特征，采用二分，找到中间值a0a_{0}a0​，将≤a0\\leq a_{0}≤a0​的划分到左子树，&gt;a0&gt;a_{0}&gt;a0​的划分到右子树 决策树的剪枝 由于决策树非常容易出现过拟合，因此需要对其进行剪枝先生成树再剪枝，这种方法称之为后剪枝 剪枝方式为： 对于某个内部节点，删除这棵子树，用这棵子树的根节点作为新的叶节点，其类别标记为其中最多的类 当数据集比较大的时候，剪枝方式为： 在训练集上训练，逐步剪枝 在验证集上验证直至性能下降 在测试集上测试 当数据集比较小的时候，直接利用训练集进行剪枝，方法如下： 设决策树TTT的叶节点为leaf(T)=(T1,…,Tt)\\mathrm{leaf}(T) = (T_{1}, \\dots, T_{t})leaf(T)=(T1​,…,Tt​)，TiT_{i}Ti​有NiN_{i}Ni​个样本，其中第kkk类的样本点有NikN_{ik}Nik​个，Hi(T)H_{i}(T)Hi​(T)为经验熵，aaa为参数，记损失函数为： Ca(T)=∑i=1tNiHi(T)+at=−∑i=1t∑j=1KNijlog⁡NijNi+at\\begin{align*} C_{a}(T) &amp;= \\sum\\limits_{i=1}^{t}N_{i}H_{i}(T) + at \\\\ &amp;= -\\sum\\limits_{i=1}^{t}\\sum\\limits_{j=1}^{K}N_{ij}\\log\\frac{N_{ij}}{N_{i}} + at \\end{align*} Ca​(T)​=i=1∑t​Ni​Hi​(T)+at=−i=1∑t​j=1∑K​Nij​logNi​Nij​​+at​ 其中两项分别代表预测误差与模型复杂程度 最终，剪枝算法为： 输入：整个树TTT，参数aaa输出：修剪后的TaT_{a}Ta​计算每个节点的经验熵从叶节点向上回溯，如果在某个点剪枝之后可以降低损失函数，则剪枝，反之跳过直到不能继续剪枝，结束 随机森林 由于决策树非常容易过拟合，因此使用多棵决策树组成一片随机森林，利用投票机制进行决策 单棵决策树的生成是通过有放回的数据采样，关键点为集外数据的使用（也即别的决策树怎么使用某棵决策树没使用的数据）","tags":["笔记","IAI","统计机器学习"],"categories":["人工智能导论"]},{"title":"TCS-Lecture-C","path":"/2024/05/22/TCS-Lecture-C/","content":"TCS: Pseudorandomness and Private-Key Encryption Pseudorandomness and Private-Key Encryption Private-Key Encryption This encryption(加密) problem is starting form the transmission question: two people need to transmit information while avoiding others to know the content. The resolution is to maintain a ‘key’ kkk by two people and one can use kkk to encrypt information while the other can use it to decrypt Validity A pair of polynomial-time computable functions (Enc,Dec)(\\text{Enc}, \\text{Dec})(Enc,Dec) is a valid private key encryption scheme if for every n∈Nn\\in \\mathbb{N}n∈N, k∈{0,1}nk\\in \\{0, 1\\}^{n}k∈{0,1}n,and xxx, we haveDec(k,Enc(k,x))=x \\text{Dec}(k, \\text{Enc}(k, x)) = xDec(k,Enc(k,x))=x And we have the length of the ciphertext(密文) is no less than that of the plaintext, written as: lc(n)≥lp(n)l_{c}(n) \\geq l_{p}(n) lc​(n)≥lp​(n) Security We need to define the security with following assumption: A cryptosystem should be secure even if everything about the system, except the key, is public knowledge. Due to this assumption, the kkk must be generated randomly. So, let’s define the security: A valid encryption scheme (Enc,Dec)(\\text{Enc}, \\text{Dec})(Enc,Dec) with plaintext length l(⋅)l(\\cdot)l(⋅) is perfectly secret if for every n∈Nn\\in \\mathbb{N}n∈N and plaintexts x0,x1∈{0,1}l(n)x_{0}, x_{1} \\in \\{0, 1\\}^{l(n)}x0​,x1​∈{0,1}l(n), the following two distributions Y0Y_{0}Y0​and Y1Y_{1}Y1​ over {0,1}∗\\{0, 1\\}^{*}{0,1}∗ are identical:YiY_{i}Yi​ is obtained by sampling kkk and outputting Enc(k,xi)\\text{Enc}(k, x_{i})Enc(k,xi​) for i=0,1i = 0, 1i=0,1. Definition Analysis We have a secrecy experiment as follows: Sample k∈{0,1}nk \\in \\{0, 1\\}^{n}k∈{0,1}n Adversary A\\mathcal{A}A outputs x0,x1x_{0}, x_{1}x0​,x1​ given input 1n1^{n}1n Randomly choose bbb and send y=Enc(k,xb)y = \\text{Enc}(k, x_{b})y=Enc(k,xb​) to A\\mathcal{A}A A\\mathcal{A}A returns b′∈{0,1}b&#x27;\\in\\{0, 1\\}b′∈{0,1} If b=b′b = b&#x27;b=b′, A\\mathcal{A}A wins We can prove A\\mathcal{A}A has at most 12\\frac{1}{2}21​ probability to succeed under perfectly secret. P(Y=y ∣ b=i)=P(Yi=y)=p(y)\\begin{align*} P(Y = y\\,|\\, b = i) &amp;= P(Y_{i} = y) = p(y)\\end{align*}P(Y=y∣b=i)​=P(Yi​=y)=p(y)​And P(Y=y)=p(y)P(Y = y) = p(y)P(Y=y)=p(y) due to YYY is perfect, so:P(Y=y,b=i)=P(b=i)P(Y=y ∣ b=i)=P(b=i)p(y)=P(b=i)P(Y=y)\\begin{align*} P(Y = y, b = i) &amp;= P(b = i)P(Y = y \\,|\\, b = i) \\\\ &amp;= P(b = i)p(y) \\\\ &amp;= P(b = i)P(Y = y)\\end{align*}P(Y=y,b=i)​=P(b=i)P(Y=y∣b=i)=P(b=i)p(y)=P(b=i)P(Y=y)​This means YYY is independent to bbb, so A\\mathcal{A}A cannot improve its probability to win by getting yyy Construction Give the One-time pad construction: lp(n)=lc(n)=nEnc(k,x)=x⊕kDec(k,c)=k⊕c\\begin{align*} l_{p}(n) = l_{c}&amp;(n) = n \\\\ \\text{Enc}(k, x) &amp;= x \\oplus k \\\\ \\text{Dec}(k, c) &amp;= k \\oplus c\\end{align*}lp​(n)=lc​Enc(k,x)Dec(k,c)​(n)=n=x⊕k=k⊕c​ In this construction, we have one glaring dis advantage, that is the kkk has the same length of plaintext! This is necessary for perfect secrecy: For every perfectly secret encryption scheme, the length function lp(n)l_{p}(n)lp​(n) satisfies lp(n)≤nl_{p}(n)\\leq nlp​(n)≤n Computational Secrecy and PRG The long kkk is unadorable in reality. So we use computational secrecy instead. An encryption scheme is computationally secret if no probabilistic polynomial-time(PPT) algorithms can break it. Let Enc,Dec\\text{Enc}, \\text{Dec}Enc,Dec be a valid encryption scheme. The scheme is computationally secret if, for every PPT adversary algorithm A\\mathcal{A}A in the secrecy experiment, there is negligible function negl\\text{negl}negl such thatP(A succ)≤12+negl(n) P(\\mathcal{A} \\text{ succ}) \\leq \\frac{1}{2} + \\text{negl}(n)P(A succ)≤21​+negl(n)where the probability is taken over the randomness of A\\mathcal{A}A and the experiment. Pseudorandom Generators Definition: A cryptographic pseudorandom generator (PRG) with stretch l(⋅)l(\\cdot)l(⋅) is a PPT computable function G:{0,1}∗→{0,1}∗G: \\{0, 1\\}^{*} \\to \\{0, 1\\}^{*}G:{0,1}∗→{0,1}∗ such that:∀ n∈N\\forall \\, n\\in \\mathbb{N}∀n∈N and s∈{0,1}ns\\in \\{0, 1\\}^{n}s∈{0,1}n, ∣G(s)∣=l(n)|G(s)| = l(n)∣G(s)∣=l(n)For any poly-algorithm A\\mathcal{A}A, s∈{0,1}ns\\in \\{0, 1\\}^{n}s∈{0,1}n and r∈{0,1}l(n)r\\in \\{0, 1\\}^{l(n)}r∈{0,1}l(n):∣P(A((G(s)))=1)−P(A((r))=1)∣=negl(n) |{P (\\mathcal{A}((G(s))) = 1) - P (\\mathcal{A}((r)) =1)}| = \\text{negl}(n)∣P(A((G(s)))=1)−P(A((r))=1)∣=negl(n) Intuitively, this means we can get the difference between output of PRG G(⋅)G(\\cdot)G(⋅) and a actual random output rrr in a negligible probability. Its existance is obtained by the cryptographic PRG conjecture: PRG with l(n)=na∀a∈Nl(n) = n^{a}\\quad \\forall a\\in\\mathbb{N}l(n)=na∀a∈N exists. If the cryptographic PRG conjecture is true, then computationally secret encryption exists for l(n)≥na∀a∈Nl(n) \\geq n^{a}\\quad \\forall a\\in\\mathbb{N}l(n)≥na∀a∈N Enc(k,x)=x⊕G(k)Dec(c,k)=c⊕G(k)\\begin{align*} \\text{Enc}(k, x) &amp;= x \\oplus G(k) \\\\ \\text{Dec}(c, k) &amp;= c \\oplus G(k)\\end{align*}Enc(k,x)Dec(c,k)​=x⊕G(k)=c⊕G(k)​ This can be proved to be computation secret by contradiction proof, which is to construct a adversary for PRG by the assuming contradiction. CPA Security and PRF Choose Plaintext Attack (CPA) The CPA experiments is similar to secrecy experiments, while A\\mathcal{A}A can interact freely with Enc(k,⋅)\\text{Enc}(k, \\cdot)Enc(k,⋅) as a black-box. An encryption scheme (Enc,Dec)(\\text{Enc}, \\text{Dec})(Enc,Dec) is CPA-secure if, for all PPT adversary A\\mathcal{A}A, there exists a negligible function negl\\text{negl}negl such thatP(A succ)≤12+negl(n) P(\\mathcal{A} \\text{ succ}) \\leq \\frac{1}{2} + \\text{negl}(n)P(A succ)≤21​+negl(n) All CPA-secure encryption scheme must be probabilistic otherwise A\\mathcal{A}A can query all Enc(k,x)\\text{Enc}(k, x)Enc(k,x) to get ciphertexts and compare. Pseudorandom Functions (PRF) Consider a keyed family of functions: Fk:{0,1}∗→{0,1}∗F_{k}: \\{0, 1\\}^{*} \\to \\{0, 1\\}^{*}Fk​:{0,1}∗→{0,1}∗, then we can define PRF as follows: Let FkF_{k}Fk​ be a keyed family of functions that is efficient and length-preserving. We say FkF_{k}Fk​ is a pseudorandom function if, for all PPT distinguishers D\\mathcal{D}D, there exists a negligible function negl\\text{negl}negl such that:∣P(DFk(⋅)(1n)=1)−P(Dfn(⋅)(1n)=1)∣≤negl(n) |{P \\bigl( D^{F_k(\\cdot)}(1^n) = 1 \\bigr) - P \\bigl( D^{f_n(\\cdot)}(1^n) = 1 \\bigr)}| \\le \\text{negl}(n)∣P(DFk​(⋅)(1n)=1)−P(Dfn​(⋅)(1n)=1)∣≤negl(n)where k←{0,1}nk\\gets\\{0, 1\\}^{n}k←{0,1}n is chosen uniformly at random and fnf_{n}fn​ is chosen uniformly from the set of functions mapping nnn-bit strings to nnn-bit strings. Intuitively, this means we can get the difference between PRF Fk(⋅)F_{k}(\\cdot)Fk​(⋅) and a actual random funtions fff in a negligible probability. PRF =&gt; CPA-secure Encryption Let FFF be a PRF. Define a CPA-secuee private-key encryption scheme for messages of length nnn as follows: Enc(k,x)=⟨r,Fk(r)⊕x⟩\\text{Enc}(k, x) = \\langle r, F_{k}(r)\\oplus x \\rangleEnc(k,x)=⟨r,Fk​(r)⊕x⟩Dec(k,⟨r,s⟩)=Fk(r)⊕s\\text{Dec}(k, \\langle r, s\\rangle) = F_{k}(r) \\oplus sDec(k,⟨r,s⟩)=Fk​(r)⊕sIn this r←{0,1}nr\\gets\\{0, 1\\}^{n}r←{0,1}n is randomly chosen. Proof is as follows, we use contradiction-proof and construct a contradiction to PRF with assumption. Consider above scheme as Π=(Enc,Dec)\\Pi = (\\text{Enc}, \\text{Dec})Π=(Enc,Dec) and the similar scheme Π~=(Enc~,Dec~)\\widetilde{\\Pi} = (\\widetilde{\\text{Enc}}, \\widetilde{\\text{Dec}})Π=(Enc,Dec) in which we replace FkF_{k}Fk​ with an actual random function.Assume that Π\\PiΠ is not CPA-secure, which means there exists an A\\mathcal{A}A:P(AΠ succ)≥12+1poly(n)P(\\mathcal{A}_{\\Pi}\\text{ succ}) \\geq \\frac{1}{2} + \\frac{1}{\\text{poly}(n)}P(AΠ​ succ)≥21​+poly(n)1​Let rcr_{c}rc​ represents the randomness used in encrypting xxx, while r1,…,rqr_{1}, \\dots, r_{q}r1​,…,rq​ represents the q(n)=poly(n)q(n) = \\text{poly}(n)q(n)=poly(n) randomness used when A\\mathcal{A}A queries to the oracle Enc\\text{Enc}Enc.Then we can argue that:P(AΠ~ succ)≤12+negl(n)P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}) \\leq \\frac{1}{2} + \\text{negl}(n) P(AΠ​ succ)≤21​+negl(n)We can argue this according to whether rc∈{r1,…,rq}r_{c} \\in \\{r_{1},\\dots ,r_{q}\\}rc​∈{r1​,…,rq​}If rc∈{r1,…,rq}r_{c} \\in \\{r_{1},\\dots ,r_{q}\\}rc​∈{r1​,…,rq​}, then A\\mathcal{A}A can actually get rcr_{c}rc​ as we contain it in the ciphertext. So A\\mathcal{A}A can always succeed in this case.But this case has a negligible probability q(n)2n\\frac{q(n)}{2^{n}}2nq(n)​ to appear.If rc∉{r1,…,rq}r_{c} otin \\{r_{1},\\dots ,r_{q}\\}rc​∈/{r1​,…,rq​}, then the encryption is like a perfect OTP as we cannot get any information about the random function fff. So A\\mathcal{A}A has a probability of 12\\frac{1}{2}21​ to win.So, we have that:P(AΠ~ succ)=P(AΠ~ succ ∣∈)P(∈)+P(AΠ~ succ ∣∉)P(∉)≤q(n)2n+12=12+negl(n)\\begin{align*}P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}) &amp;= P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}\\,|\\in)P(\\in) + P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}\\,| otin)P( otin) \\\\&amp;\\leq \\frac{q(n)}{2^{n}} + \\frac{1}{2} = \\frac{1}{2} + \\text{negl}(n)\\end{align*}P(AΠ​ succ)​=P(AΠ​ succ∣∈)P(∈)+P(AΠ​ succ∣∈/)P(∈/)≤2nq(n)​+21​=21​+negl(n)​Define the distinguisher D\\mathcal{D}D, who has an orecal O\\mathcal{O}O, as follows:Run A(1n)\\mathcal{A}(1^{n})A(1n), for each oracle query of A\\mathcal{A}A with xxx, do:Choose r←{0,1}nr\\gets \\{0, 1\\}^{n}r←{0,1}nreturn ⟨r,O(r)⊕x⟩\\langle r, \\mathcal{O}(r)\\oplus x\\rangle⟨r,O(r)⊕x⟩ to A\\mathcal{A}AWhen A\\mathcal{A}A gives D\\mathcal{D}D two string x0,x1x_{0}, x_{1}x0​,x1​, randomly choose a bit bbb and:Choose r←{0,1}nr\\gets \\{0, 1\\}^{n}r←{0,1}nreturn ⟨r,O(r)⊕xb⟩\\langle r, \\mathcal{O}(r)\\oplus x_{b}\\rangle⟨r,O(r)⊕xb​⟩ to A\\mathcal{A}AAnswer A\\mathcal{A}A as Step 1 until A\\mathcal{A}A gives an output b′b&#x27;b′. Then we output 111 if b′=bb&#x27; = bb′=b otherwise 000.Actually, this distinguisher is simulating the CPA-experiment. So:P(DFk(⋅)(1n)=1)=P(AΠ succ)P(Df(⋅)(1n)=1)=P(AΠ~ succ)\\begin{align*}P(\\mathcal{D}^{F_{k}(\\cdot)}(1^{n}) = 1) &amp;= P(A_{\\Pi}\\text{ succ}) \\\\P(\\mathcal{D}^{f(\\cdot)}(1^{n}) = 1) &amp;= P(A_{\\widetilde{\\Pi}}\\text{ succ})\\end{align*}P(DFk​(⋅)(1n)=1)P(Df(⋅)(1n)=1)​=P(AΠ​ succ)=P(AΠ​ succ)​This means that:∣P(DFk(⋅)(1n)=1)−P(Df(⋅)(1n)=1)∣=∣P(AΠ succ)−P(AΠ~ succ)∣≥∣1poly(n)−negl(n)∣≥1poly(n)\\begin{align*}&amp;\\quad |P(\\mathcal{D}^{F_{k}(\\cdot)}(1^{n}) = 1) -P(\\mathcal{D}^{f(\\cdot)}(1^{n}) = 1)| \\\\&amp;= |P(\\mathcal{A}_{\\Pi}\\text{ succ}) - P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ})| \\\\&amp;\\geq |\\frac{1}{\\text{poly}(n)} - \\text{negl}(n)| \\geq \\frac{1}{\\text{poly}(n)}\\end{align*}​∣P(DFk​(⋅)(1n)=1)−P(Df(⋅)(1n)=1)∣=∣P(AΠ​ succ)−P(AΠ​ succ)∣≥∣poly(n)1​−negl(n)∣≥poly(n)1​​This is contradict to that FkF_{k}Fk​ is PRF!","tags":["TCS","Pseudorandomness","Private-Key Encryption"],"categories":["理论计算机科学导引"]},{"title":"网原笔记6","path":"/2024/05/22/网原笔记6/","content":"计算机网络原理 笔记 6 链路层与局域网 链路层 运行链路层协议的任何设备称为节点，相邻节点的通信信道称为链路，在链路上传递的数据报被封装为链路层帧 可能提供的服务 成帧：将网络层数据添加一些首部字段封装为链路层帧 链路接入：由MAC规定了帧在链路上的传输规则 可靠交付：保证无差错地传递网络层数据报，但是对于部分低比特差错链路，可靠性是不必要的 差错检测和纠正：由于硬件设备原因可能会导致部分比特被错误传输，因此可以在帧中包含相应差错检测/纠正比特来检测 实现 通常通过网络适配器（又称为网络接口卡）来实现 网络适配器 差错检测与纠正 接收方需要判断接收到的数据是否是原始数据，通常通过EDC来实现，但是需要注意的是EDC本身也有可能被损坏，并且即使使用了EDC也可能出现漏检的情况 差错检测与纠正 常见的EDC方法包括奇偶校验、检验和与循环冗余检测 奇偶校验 增加一位校验位，用于指示原始数据中’1’的个数的奇偶性，但是这只能判断出数据中出现了奇数个比特差错 为了提升其鲁棒性，采用二维奇偶校验的方式，即将原始数据划分为一个矩阵，分别检测每一行与每一列的奇偶校验和，这样可以检测并纠正单个比特差错，并且可以检测双比特差错 二维奇偶校验 检验和 与运输层协议中内容相似，将数据按字节求和取反码 循环冗余检测 现代广泛使用CRC编码，主要思想为将数据流看做系数为0, 1的多项式 CRC编码 如上图，编码操作为： 发送方与接收方协商r+1r+1r+1位比特模式作为生成多项式，记为GGG，要求GGG的最高位必须是1 对于数据段DDD，发送方将其附加rrr个比特RRR，得到d+rd+rd+r位比特模式，使其可以被GGG整除 接收方检测是否可以整除即可 因此关键问题在于如何选取RRR使得： (D&lt;&lt;r)⊕R=nG (D &lt;&lt; r) \\oplus R = nG (D&lt;&lt;r)⊕R=nG 该式可化简为： D&lt;&lt;r=nG⊕R D &lt;&lt; r = nG \\oplus R D&lt;&lt;r=nG⊕R 在CRC中，所有的加法和减法都等价于异或操作，因此乘法和出发需要对应的变化（竖式中的加减法也变成了异或） 因此，可以计算RRR为： R=(D&lt;&lt;r)(modG) R = (D &lt;&lt; r) \\pmod{G} R=(D&lt;&lt;r)(modG) 国际标准的生产多项式为： GCRC-32=10000001001100000010001110110110111 G_{\\text{CRC-32}} = 10000001001100000010001110110110111 GCRC-32​=10000001001100000010001110110110111 CRC可以检测出所有的奇数位、双比特、不大于∣G∣|G|∣G∣长度的错误 多路访问链路和协议 由于所有的节点都可以传输帧，因此同时被接收的信号会在接收方处发生碰撞，导致所有信号丢失，因此需要多路访问协议用于协调多个发送和接收节点共享一个信道的访问。 其应当具有的特性为： 仅有一个节点发送数据时，需要使用完整信道 有多个节点发送数据时，每个节点吞吐量可以趋近于平均 协议是分散的：不会因一个节点崩溃而崩溃 造价便宜！ 可以划分为信道划分协议、随机接入协议与轮流协议 信道划分协议 采用时分复用或频分复用的方式，平均划分时间或频率 时分复用与频分复用 TDM/FDM的特点： 消除了碰撞，并且非常公平 在及诶单书很少的时候效果很差 另一种信道划分协议为码分多址，为每个节点分配一种不同的编码，如果编码选择合适，即可同时传输同时接收并且互不干扰 随机接入协议 每个节点都以信道最大速率发送分组，当发生碰撞时，等待一个随机时延并重发该分组，直到发送成功。 随机试验种类繁多，具体介绍ALOHA协议与载波侦听多路访问(CSMA)协议 时隙ALOHA 假设： 所有帧大小相同，记为LLL 时间被划分为等长的时隙，每个时隙可以发送一帧 只在时隙起点传输帧 节点之间同步时隙信息 如果在一个时隙中发生了碰撞，则时隙结束时所有节点可以检测到碰撞 则时隙ALOHA的操作如下： 当有数据需要发送时，等待下一个时隙起点传输 如果没有碰撞则万事大吉 反之，则在后续的每个时隙起点独立地以 ppp 的概率重传，直到成功发送 定义成功时隙为恰好只有一个节点传输的时隙，成功时隙占所有时隙的比例为效率，则N(N≫1)N(N\\gg 1)N(N≫1)个节点的效率为： f(p)=CN1p(1−p)N−1=Np(1−p)N−1 f(p) = C_{N}^{1}p(1-p)^{N-1} = Np(1-p)^{N-1} f(p)=CN1​p(1−p)N−1=Np(1−p)N−1 极值点为： p=1N p = \\frac{1}{N} p=N1​ 因此： f(p)≤(1−1N)N−1lim⁡N→∞f(p)≤1e\\begin{align*} f(p) &amp;\\leq (1 - \\frac{1}{N})^{N - 1} \\\\ \\lim\\limits_{N\\to\\infty}&amp;f(p) \\leq \\frac{1}{e} \\end{align*} f(p)N→∞lim​​≤(1−N1​)N−1f(p)≤e1​​ 所以当节点数充分大时，效率最高约为37% ALOHA 纯ALOHA将不考虑时隙问题，在分组到达时则立刻进行传输，碰撞时立即以概率 ppp 重传分组，以概率 1−p1-p1−p 等待一个分组传输时间，重复循环直到成功发送 若一个节点想要成功发送，则必须要保证其发送时间的前后各一个分组传输时间之内不能有其他节点发送，因此可以计算得其最大效率为： lim⁡N→∞f(p)≤12e\\lim\\limits_{N\\to\\infty}f(p) \\leq \\frac{1}{2e} N→∞lim​f(p)≤2e1​ CSMA 模仿人类聚会时的发言，CSMA新增了如下协议： 说话之前先听：在传输之前先“听”信道，如果有其他节点正在发送则等待，直到一段时间内没有传输 而CSMA/CD则进一步增加了如下协议 和别人同时开始说话时停止说话：节点在传输过程中保持“听”信道，当有其他节点也开始传输的时候立刻停止传输，等待一段随机时间后，进入上一种状态 采用时空图说明： 时空图，其中B与D碰撞 可以看出，决定其碰撞发生的概率即决定性能的关键因素为信道传播时延，即在节点之间通信的效率 CSMA/CD的一些讨论 讨论两个问题： 每次检测到碰撞后应该等待多久 CSMA/CD效率如何 对于等待时间的问题，采用二进制指数后退算法，具体为： 在nnn次碰撞之后，令K∼U({0,1,…,2n−1})K \\sim \\text{U}(\\{0, 1, \\dots, 2^{n} - 1\\})K∼U({0,1,…,2n−1})，并且等待发送512K512K512K比特所需要的时间 对于效率问题，定义CSMA/CD的效率为： 节点数和分组数充分多的时候，分组能够无碰撞传输所占有的时间比例 定义dpropd_{\\text{prop}}dprop​为两个适配器之间传递信号的最大时间，dtransd_{\\text{trans}}dtrans​为传输一个最大以太网帧的时间，则CSMA/CD的效率为： f=11+5dprop/dtrans f = \\frac{1}{1 + 5d_{\\text{prop}}/ d_{\\text{trans}}} f=1+5dprop​/dtrans​1​ 轮流协议 是一大类能够满足大量节点平均享有吞吐量的协议，主要讨论轮询协议与令牌传递协议 轮询协议 指定主节点，主节点可以轮询每个节点，告知其可以传输的最大帧数 这种方法引入了轮询时延，并且是集中式的（主节点坏了就似了） 令牌传递协议 讲一个称之为令牌的特殊帧在节点之间以一个固定的次序进行交换，每个节点持有令牌当且仅当自己需要发送帧，反之立刻传递给下一节点 同样的，该协议单个节点的故障可能导致整体的崩溃 DOCSIS 一个实际应用的综合性协议 上行与下行信道 DOCSIS定义了电缆数据网络体系结构及其协议，对于上行信道与下行信道都采用FDM，每个信道均为广播信道，并且下行信道不会存在多路访问问题，主要考虑上行信道 上行信道被划分时间间隔，每个时间间隔包含微时隙序列（类似TDM） CMTS发送MAP报文指定特定的调制解调器在特定时间间隔发送分组 调制解调器们在一组特殊的微时隙间隔内向CMTS发送请求帧，向其请求分配微时隙用于发送数据 请求帧以随机接入的方式发送，当其发生碰撞时（调制解调器只能通过下行信道的数据推测是否碰撞），采用二进制指数回退算法决定等待时间并重新发送 交换局域网 链路层寻址 MAC地址 链路层地址的所有者并非主机或路由器，而是其中的适配器（网络接口），链路层地址有多种称呼，包括LAN地址，物理地址，MAC地址，常用的为MAC地址，长度为6字节即48bits MAC地址示意图 每个适配器拥有唯一MAC地址，其唯一性由IEEE保证（付费！） 与IP不同，MAC具有扁平化特征，即不再具有类似IP的层次化特征，其地址值是随着设备而固定下来的 MAC寻址方法为，向帧中插入目的MAC地址后发送到局域网上，当接收时，检测目的MAC地址是否与己方一致，一致则解析数据，反之则丢给局域网，如果需要广播则使用广播地址（全1） ARP 地址解析协议用于实现网络层地址与链路层地址之间的转换，是一个介于链路层和网络层之间的协议 ARP只解析同一个子网下的IP地址，不能解析任意的IP地址 工作方式为询表，ARP表中存有IP地址到MAC地址的映射，以及该表项的过期时间，当表项缺失时，会广播ARP查询分组，向子网上所有的主机询问此IP地址对应的MAC地址，相应的适配器接收到报文后会发送ARP响应报文 注意：查询报文是广播而发送报文不是 向子网外发送 通过路由器的转发表实现不同子网之间的转换，每个子网中的主机只需要把数据传到路由器就可以了，不然就会到达数据报天国！ 以太网 简易、便宜、首发、告诉，在物理结构上采用交换机（之前是总线与集线器），有效避免了碰撞 帧结构 以太网帧架构 字段意义如下： 数据字段（46-1500字节）：过长的数据需要被分片 目的地址（6字节）：目的地MAC 源地址（6字节）：发送方MAC 类型字段（2字节）：用于指示需要使用的网络层协议 CRC（4字节）：检测差错 前同步码（8字节）：AA-AA-AA-AA-AA-AA-AA-AB，用于同步时钟，最后两个1用于指示数据到来 以太网是无连接的，没有类似TCP的握手需求，也没有重传机制 以太网技术 100MHz以太网标准 一种标准是IEEE 803.2z： 使用上述帧格式 允许点对点以及广播 使用CSMA/CD来共享广播信道 点对点信道允许40Gbps全双工 链路层交换机 主要任务是接收入链路层帧并将其转发到出链路，对于主机来说是透明的，可能会存在过量数据，因此设有缓存 转发与过滤 过滤是决定一帧应该被转发到某个接口还是被丢弃，转发决定帧应该被导向哪个接口，这两项操作由交换机表完成，每个表项包含： MAC地址 通往该地址的交换机接口 表项存在时间 当接口xxx到达一帧链路层帧后，交换机表的索引过程如下： 如果不存在目的地MAC地址对应的表项，则广播 如果存在，但是表中的接口是xxx，也即想发给自己所在子网，直接丢弃（过滤） 如果存在，并且接口为y≠xy eq xy=x，则转发到yyy的输出缓存 自学习 交换机表的建立是自动、自治、动态建立的，即自学习，方法如下： 初始表为空 对于每个接口存储到的每个入帧，存储：源MAC地址、到达的接口、当前时间 一段时间后，如果没有接收到该MAC为源的帧，则删除之 交换机是即插即用的、双工的 链路层交换机的性质 清除碰撞：有缓存，网段上至多同时传输一帧 异质的：链路之间彼此隔离，不同链路能够以不同速率在不同媒体上运行 管理：更加安全，易于管理，例如可以自行解决异常适配器 交换机与路由器 交换机是链路层的分组交换机，路由器是网络层的分组交换机 路由器与交换机 虚拟局域网 交换局域网的缺点： 缺乏流量隔离：广播可以被整个机构的网络接收到，无法局部广播 交换机的无效使用：如果组小而交换机大，每个交换机将会有大量端口被浪费 用户管理：用户换组或多组将会导致复杂的物理布线变化 因此引入虚拟局域网，由网管将一个交换机的不同端口划分为不同组，每个VLAN中的端口形成一个广播域 VLAN实例 但是这样会导致VLAN之间完全隔离，常用的解决办法是引入一个路由器进行VLAN间的通信，与交换机中某个空闲的端口连接，该端口可以视作同时属于多个VLAN 如果需要多个交换机，并且交换机之间的VLAN需要互联（也许就是同种VLAN），采用的方法为VLAN干线互联而并非将各个VLAN分别互联，每个干线端口同时属于所有VLAN 为了确保帧可以正确跨越干线，对以太网帧进行扩展 扩展以太网帧 增加字段有： 标签协议控制符（2字节）：固定81-00 标签控制信息（2字节）：包含12比特的VLAN标识符字段和3比特的优先权字段 新增字段被干线端口添加与删除 EVPN 链路层交换机在逻辑上联结在一起，并且使用更顶层的协议进行通信，如将链路层帧包裹在IP数据报中 链路虚拟化 引入多协议标签交换，用于改善IP路由器交换速度，目标是通过选择性的标识数据报，并允许路由器通过固定长度标签转发数据报 MPLS首部 MPLS会扩展链路层帧，增加的首部字段位于链路层和网络层首部之间，新增字段包括： 标签 实验字段（3比特）：预留 S字段：用于指示MPLS首部栈的结束 TTL：寿命字段 MPLS使能的路由器称为标签交换路由器，其在转发表中查找MPLS标签并将数据报传递给相应的输出接口进行转发，但是这要求通信的两个路由器都是MPLS使能的 利用MPLS进行通信，其中R1234都是MPLS使能的 从上图可以看出，MPLS可以提供多条路径（同样的也可以人为限制路径），例如图中R4-A具有两条MPLS路径，这被称为流量工程 相比于传统网络，MPLS的优势有： 交换速度增加 流量工程 转发路径的快速恢复 VPN 数据中心网络 数据中心：包含大量主机，称为刀片，刀片堆叠在机架上，每个机架顶部有一台交换机，交换机之间互联，数据中心网络需要支持两种类型的流量——外部通信与内部交换，由边界路由器负责与公共因特网相连 数据中心网络示意 负载均衡 外部请求首先被重定向到负载均衡器，向主机发送请求并在主机之间尽量保持负载均衡，基于目的端口号和IP地址做决定 同时其提供了客户与数据中心网络之间的屏障，形成了类似NAT的效果（公网内网转换） 等级体系结构 大型数据中心需要使用路由器和交换机等级结构，以保证交换机工作的稳定性（如上图），其中每台接入路由器下的主机构成了子网，并且可以被进一步划分为多个VLAN子网 但是这种等级体系结构可能导致主机之间容量首先，即交换机速率不足以支撑并发时主机之间能够以最大速率通信 发展趋势 全连接拓扑示意 克服等级结构缺陷可以采用FCT，即第一层和第二层之间全连接，提升了主机之间不相交的路径数，并且未直接连接到同一个交换机的机架之间的通信逻辑上是等价的 另一种修改方式称为模块化数据中心，略过 目前数据中心常用的协议有： 链路层：RoCE 运输层：DCTCP/DCQCN 路由选择：SDN","tags":["网原","笔记","链路层","局域网"],"categories":["计算机网络原理"]},{"title":"IAI-对抗搜索","path":"/2024/05/20/IAI-对抗搜索/","content":"人智导 对抗搜索 对抗搜索 对于一些分支极多的对抗式问题，穷举法所需要消耗的时间、空间资源无法承受，无法实现，因此考虑充分的剪枝 极小-极大模型 进行有限步内的穷举，从根节点出发，叶节点标记得分，并且期望每位选手都选择对于自己最有利的走法，最后选择期望得分最高的一步 极大-极小模型示例图 图中，两种图形代表两位选手，分别记为A,BA, BA,B，叶节点上所标记的为AAA在四步之后的期望得分，每位选手每步都是期望自身得分尽量高（对方得分尽量低） 但是极小极大仍然没有剪枝，时空资源仍然无法承受 α-β剪枝算法 α\\alphaα-β\\betaβ 剪枝算法如下 α\\alphaα为极大节点（我方选手尽量多得分）的下界 β\\betaβ为极小节点（我方选手尽量少得分）的上界 后辈 β≤\\beta \\leqβ≤ 祖先 α\\alphaα 时，α\\alphaα 剪枝 后辈 α≥\\alpha \\geqα≥ 祖先 β\\betaβ 时，β\\betaβ 剪枝 实例如下：注意比较时需要和祖先节点而不是父节点比较 alpha-beta剪枝实例 每次α\\alphaα-β\\betaβ 剪枝只能得到下一步的走法 局限性：非常依赖局面估计（也就是叶节点的得分）的准确性，需要大量的专家知识与人工整理 蒙特卡洛(MCTS) 基本思想： 可能出现的状态用状态树表示 逐步扩展树节点 父节点利用子节点的结果 随时得到行为评价 基本过程为： 选择 →\\to→ 扩展 →\\to→ 模拟 →\\to→ 回传 选择策略 考虑两方面因素： 充分探索尚未探索的节点 利用效果尽量好的节点 因此采用多臂老虎机模型 拥有kkk个拉杆的老虎机，拉动每个拉杆的收益相互独立并且遵循一定分布，求如何使得受益最大化 采用信心上限算法：每次选择信心上限最大的节点，节点jjj的信心上限计算方式为： Ij=X‾j+c2ln⁡(n)Tj(n)I_{j} = \\overline{X}_{j} + c\\sqrt{\\frac{2\\ln(n)}{T_{j}(n)}} Ij​=Xj​+cTj​(n)2ln(n)​​ 其中参数含义为： ccc：调节参数 nnn：访问次数 Tj(n)T_{j}(n)Tj​(n)：此时节点 jjj 被访问的次数 X‾j\\overline{X}_{j}Xj​：此时节点 jjj 的平均收益 以围棋为例，每一次模拟可以看成是随机落点，平均收益可以看成是胜率，如下图，其中为简便令c=0c = 0c=0，最终选择根节点的子节点中胜率最大的节点作为下一步： 采用UBC选择的MCTS 注意： 每个节点的胜率是站在己方的角度考虑的！ AlphaGo 为了解决MCTS的盲目性问题（随机落子），将神经网络与蒙特卡洛结合起来，使用了策略网络与估值网络两种神经网络 策略网络 一个神经网络，用于提供行棋概率 输入：48个通道，每个通道大小19*19，记录了棋局的相关信息输出：棋盘上每个节点的行棋概率 策略网络 策略网络可以看成是一个361类别分类问题，通过人类棋手的棋谱进行训练，损失函数为 L(w)=−talog⁡(pa)L(w) = -t_{a}\\log(p_{a}) L(w)=−ta​log(pa​) 其中tat_{a}ta​为实际落子概率，pap_{a}pa​为网络落子概率 估值网络 一个神经网络，用于提供棋局收益 输入：49个通道，每个通道大小19*19，记录了棋局的相关信息（比策略网络多一个）输出：当前棋局收益 ∈[−1,1]\\in [-1, 1]∈[−1,1] 估值网络 估值网络可以看成回归问题，也是通过人类棋手棋谱进行训练，损失函数： L(w)=(R−V(s))2L(w) = (R - V(s))^{2} L(w)=(R−V(s))2 其中RRR为实际收益，111 胜 −1-1−1 负，V(s)V(s)V(s)为网络输出 与MCTS融合 给定参数 λ\\lambdaλ 每次模拟收益为： vi(s)=λvalue(s)+(1−λ)sim(s)v_{i}(s) = \\lambda \\text{value}(s) + (1 - \\lambda)\\text{sim}(s) vi​(s)=λvalue(s)+(1−λ)sim(s) 其中 value(s)\\text{value}(s)value(s) 为估值网络输出，sim(s)\\text{sim}(s)sim(s) 为模拟结果 因此定义平均收益： Q(sa)=∑i=1nvi(sa)nQ(s_{a}) = \\frac{\\sum\\limits_{i=1}^{n}v_{i}(s_{a})}{n} Q(sa​)=ni=1∑n​vi​(sa​)​ 定义探索项： u(sa)=c⋅p(sa)N(s)N(sa)+1u(s_{a}) = c \\cdot p(s_{a})\\frac{\\sqrt{N(s)}}{N(s_{a}) + 1} u(sa​)=c⋅p(sa​)N(sa​)+1N(s)​​ 其中： sas_{a}sa​代表棋局sss在aaa处落子后的棋局 N(s)N(s)N(s)代表对于棋局sss的模拟次数 p(s)p(s)p(s)代表策略网络对于sss的输出 ccc为系数 信心上限切换为： Ij=Q(sa)+u(sa)I_{j} = Q(s_{a}) + u(s_{a})Ij​=Q(sa​)+u(sa​) MCTS过程如下： 信息：每个节点记录收益、到达该节点概率与被选择次数 选择：从根节点开始，每次选择子节点中信心上限最大的节点，直到叶节点即停止并选中 生成：生成选中节点的所有叶节点（也即所有可能的落子），并规定了最大的节点深度 模拟：采用推演策略网络（更快），计算其viv_{i}vi​ 回传：注意正负号（即注意行棋是双方依次进行） 最终将根节点的子节点中，被选择次数最多的节点作为选择 深度强化学习方法 强化学习：学习“做什么可以使得收益最大化”深度强化学习：利用深度学习实现的强化学习 以围棋为例，通过自己博弈训练策略网络，三种实现方法： 策略梯度：学习每个点获胜的概率 价值评估：学习每个点获得最大收益的概率 演员评价方法：学习到每个落子点获得最大收益增量的概率 策略梯度 数据由自我博弈产生，损失函数为： L(w)=−talog⁡(pa)L(w) = - t_{a}\\log(p_{a}) L(w)=−ta​log(pa​) 其中，pap_{a}pa​为当前棋局在aaa处下棋的概率，ta∈{−1,1}t_{a}\\in\\{-1, 1\\}ta​∈{−1,1}为胜负值 基于策略梯度的强化学习流程 注意点： 强化学习过程中，每个样本只使用一次 该方法学习到的是每个可落子点行棋的获胜概率 价值评估 输入为当前棋局和行棋点，输出为该行棋点的价值，在[−1,1][-1, 1][−1,1]之间，数据也是自我博弈产生，损失函数为： L(w)=(R−V(s,a))2L(w) = (R - V(s, a))^{2} L(w)=(R−V(s,a))2 其中，RRR为胜负值，V(s,a)V(s, a)V(s,a)为棋局sss在aaa处落子后网络的输出 演员-评价方法 利用收益增量评价一步棋的好坏： A=Q(s,a)−V(s)A = Q(s, a) - V(s) A=Q(s,a)−V(s) 其中，V(s)∈[−1,1]V(s)\\in[-1, 1]V(s)∈[−1,1]为棋局sss的预期收益，Q(s,a)∈[−1,1]Q(s, a)\\in[-1, 1]Q(s,a)∈[−1,1]为sss在aaa处行棋之后的收益，在实际中常去Q(s,a)=RQ(s, a) = RQ(s,a)=R为胜负值，最终AAA越大收益越好 演员-策略网络，评价-估值网络 损失函数为： L(w)=L1(w)+λL2(w)=A2−λAlog⁡(pa)\\begin{align*} L(w) &amp;= L_{1}(w) + \\lambda L_{2}(w) \\\\ &amp;= A^{2} - \\lambda A\\log(p_{a}) \\end{align*} L(w)​=L1​(w)+λL2​(w)=A2−λAlog(pa​)​ AlphaGo Zreo 将估值网络和策略网络合并为“双输出”网络 输入：17个通道，记录8个棋局，每个棋局2通道，1个通道记录行棋方输出：策略网络输出362维，增加的一维为放弃；估值网络输出棋局的估值 Alpha-Zero原理 与MCTS融合 与AlphaGo基本相同，差别如下： 模拟被估值网络完全取代，模拟收益vi(s)v_{i}(s)vi​(s)即为估值网络的输出 规定了总模拟次数 结合MCTS与深度强化学习 Alpha-Zero中的深度强化学习 损失函数为： Lvalue=(R−v)2Lstrategy=−∑i=1362πilog⁡(pi)L=Lvalue+Lstrategy+∣∣θ∣∣2\\begin{align*} L_{value} &amp;= (R - v)^{2} \\\\ L_{strategy} &amp;= -\\sum\\limits_{i=1}^{362}\\pi_{i}\\log(p_{i}) \\\\ L &amp;= L_{value} + L_{strategy} + ||\\theta||^{2} \\end{align*} Lvalue​Lstrategy​L​=(R−v)2=−i=1∑362​πi​log(pi​)=Lvalue​+Lstrategy​+∣∣θ∣∣2​ 其中RRR为胜负值，vvv为估值网络输出，πi\\pi_{i}πi​为MCTS给出的该走法概率，pip_{i}pi​为策略网络给出的该走法概率 引入多样性 人为引入噪声，增加策略网络输出的随机性，通常增加一个狄利克雷分布，生成一些大多值为0，小部分值较大的随机变量，并修正策略网络输出为： p⇐λp+(1−λ)pdp \\Leftarrow \\lambda p + (1 - \\lambda) p_{d} p⇐λp+(1−λ)pd​","tags":["笔记","IAI","对抗搜索"],"categories":["人工智能导论"]},{"title":"TCS-Lecture-B","path":"/2024/05/15/TCS-Lecture-B/","content":"TCS: Randomized Computation Randomized Computation Randomized Algorithm A randomized algorithm outputs the correct value with good probability on every possible input. Matrix multiplication Input matrix A,B,CA, B, CA,B,C, decide if C=ABC = ABC=AB Obviously there is a deterministic and polynomial algorithm for this. A random algorithm: Freivalds’ algorithm Repeat the following for kkk times.Randomly choose v∈{0,1}nv\\in \\{0, 1\\}^{n}v∈{0,1}nCompute (d=A(Bv)−Cv)(d = A(Bv) - Cv)(d=A(Bv)−Cv)Reject if d≠0d eq 0d=0Accept We have that this algorithm can solve this problem in O(kn2)O(kn^{2})O(kn2) time with a probability of failure ≤2−k\\leq 2^{-k}≤2−k Proof: If AB≠CAB eq CAB=C, we prove P(d=0)≤12P(d = 0) \\leq \\frac{1}{2}P(d=0)≤21​ for each time.So D=AB−C≠0D = AB - C eq 0D=AB−C=0. Let Dij≠0D_{ij} eq 0Dij​=0The iii-th entry of ddd holds that:di=∑Dikvk=Dijvj+∑k≠jDikvkd_{i} = \\sum D_{ik}v_{k} = D_{ij}v_{j} + \\sum\\limits_{k eq j}D_{ik}v_{k}di​=∑Dik​vk​=Dij​vj​+k=j∑​Dik​vk​Let s=∑k≠jDikvks = \\sum\\limits_{k eq j}D_{ik}v_{k}s=k=j∑​Dik​vk​, so:P(di=0)=P(di=0 ∣ s=0)P(s=0)+P(di=0 ∣ s≠0)P(s≠0)≤P(vi=0)P(s=0)+P(vi=1)P(s≠0)≤12(P(s=0)+P(s≠0))≤12\\begin{align*}P(d_{i} = 0) &amp;= P(d_{i} = 0 \\,|\\, s = 0)P(s = 0) \\\\&amp;\\quad +P(d_{i} = 0 \\,|\\, s eq 0)P(s eq 0) \\\\&amp;\\leq P(v_{i} = 0)P(s = 0) + P(v_{i} = 1)P(s eq 0)\\\\&amp;\\leq \\frac{1}{2}(P(s = 0) + P(s eq 0)) \\leq \\frac{1}{2}\\end{align*}P(di​=0)​=P(di​=0∣s=0)P(s=0)+P(di​=0∣s=0)P(s=0)≤P(vi​=0)P(s=0)+P(vi​=1)P(s=0)≤21​(P(s=0)+P(s=0))≤21​​So P(d=0n)≤P(di=0)≤12P(d = 0^{n}) \\leq P(d_{i} = 0) \\leq \\frac{1}{2}P(d=0n)≤P(di​=0)≤21​ Maxcut Approximation The MAX-CUT problem is NP-Complete. So our task is to find a cut CCC whose size is not far from the optimal one C∗C^{*}C∗. If sizeC≥α sizeC∗\\text{size}_C \\ge \\alpha\\,\\text{size}_{C^*}sizeC​≥αsizeC∗​, we call CCC is an α\\alphaα-approximation, then we have an easily way to find 12\\frac{1}{2}21​-approximation, which is universal randomly distribute each vertex into set 000 or 111. E(sizeC)=E∑{u,v}∈E1xu≠xv=12∣E∣≥12sizeC∗.\\begin{equation*} \\mathbb{E}(\\text{size}_C) = \\mathbb{E} \\sum_{\\{u, v\\} \\in E} 1_{x_u e x_v} = \\frac{1}{2} |E| \\ge \\frac{1}{2} \\text{size}_{C^*}. \\end{equation*} E(sizeC​)=E{u,v}∈E∑​1xu​=xv​​=21​∣E∣≥21​sizeC∗​.​ This is just sufficient expection, but we can give an always-large-enough cut by conditional expection if we can compute this equation efficiently. E(sizeC(x1,…,xi,Xi+1,…Xn)),\\begin{equation*} \\mathbb{E}(\\text{size}_C(x_1, \\ldots, x_i, X_{i+1}, \\ldots X_{n})), \\end{equation*} E(sizeC​(x1​,…,xi​,Xi+1​,…Xn​)),​ We maximize this in each choice. Derandomize Above algorithm uses nnn random choices, covering 2n2^{n}2n possibilities. We can try to reduce the randomness to a polynomial number of possibilities, we can derandomize the algorithm. Considering Universal hash function: Consider a family of hash functions H={h:U→R}\\mathcal{H} = \\{ h : U \\to R \\}H={h:U→R}. Universal hash functions are a family of functions with the random-like property while the size of the family is small. We can use a small seed to choose hash functions from the family. Pairwise independent hash functions. A family H={h:U→R}\\mathcal{H} = \\{h : U \\to R\\}H={h:U→R} is called Pairwise independent if for any distinct x1,x2∈Ux_{1}, x_{2}\\in Ux1​,x2​∈Uand any y1,y2∈Ry_{1}, y_{2}\\in Ry1​,y2​∈R, we have:Ph∈H(h(x1)=y1 and h(x2)=y2)=1∣R∣2.\\begin{equation*}P_{h \\in \\mathcal{H}} \\bigl( h(x_1) = y_1 \\text{ and } h(x_2) = y_2 \\bigr) = \\frac{1}{|R|^2}.\\end{equation*}Ph∈H​(h(x1​)=y1​ and h(x2​)=y2​)=∣R∣21​.​ A pairwise independent hash functions mapping {0,1}k\\{0, 1\\}^{k}{0,1}k to {0,1}\\{0, 1\\}{0,1}. H={h(x)=(ax+b)(mod 2) ∣ a∈{0,1}kb∈{0,1}}\\mathcal{H} = \\{ h(x) = (ax + b)(\\text{mod }2) \\,|\\, a \\in \\{0, 1\\}^{k}\\quad b\\in\\{0, 1\\} \\}H={h(x)=(ax+b)(mod 2)∣a∈{0,1}kb∈{0,1}} This family size is ∣H∣=2k+1|\\mathcal{H}| = 2^{k+1}∣H∣=2k+1. Assign k=⌈log⁡n⌉k = \\lceil \\log n\\rceilk=⌈logn⌉, then UUU can encoding each vertex in GGG. So ∣H∣≤2n|\\mathcal{H}| \\leq 2n∣H∣≤2n, which means we can go through all the hash function in H\\mathcal{H}H and output the maximized cut. BPP Define Prob TM as follows: A probabilistic Turing machine is a type of NTM in which each nondeterministic step is called a coin-flip step and has two legal next moves. We assign a probability 2−k2^{-k}2−k to each branch of the machine’s computation where kkk is the number of coin flips occur in the branch.The probability of the machine accepting the input is defined asP(M accepts w)=∑b:b is acceptingP(b).\\begin{equation*}P(M \\text{ accepts } w) = \\sum_{b:b \\text{ is accepting}} P(b).\\end{equation*}P(M accepts w)=b:b is accepting∑​P(b).​ This is equvilant to that each son of a vertex in NTM can be reach in the same probability. Define the error probability ε\\varepsilonε: If w∈Aw \\in Aw∈A, then P(M(w)=1)≥1−εP(M(w) = 1) \\geq 1 - \\varepsilonP(M(w)=1)≥1−εIf w∉Aw otin Aw∈/A, then P(M(w)=1)≤εP(M(w) = 1) \\leq \\varepsilonP(M(w)=1)≤ε Then we can define BPP\\text{BPP}BPP with error probability: BPP\\text{BPP}BPP is the class of languages decided by probabilistic polynomial-time Turing machines with an error probability of 13\\frac{1}{3}31​Actually, the 13\\frac{1}{3}31​ can be replaced by any constant exactly greatly than 12\\frac{1}{2}21​ BPP\\text{BPP}BPP can be also defined with verifier: A decision problem AAA is in BPP\\text{BPP}BPP if and only if there is a polynomial-time verifier VVV such that for all xxx, x∈Ax\\in Ax∈A if and only ifPr(V(x,r)=1)≥23.\\begin{equation*}P_{r} \\bigl(V(x, r) = 1 \\bigr) \\ge \\frac{2}{3}.\\end{equation*}Pr​(V(x,r)=1)≥32​.​ Error Reduction Any decision problem A∈BPPA\\in\\text{BPP}A∈BPP has a polynomial-time randomized algorithm whose error probability is 2−p(n)2^{-p(n)}2−p(n) where ppp is a polynomial and nnn is the input size. This can be proved by Chernoff bound or Sampling Theroem Circuits v.s. BPP Define SIZEn(s)\\text{SIZE}_{n}(s)SIZEn​(s): For a finite function g:{0,1}n→{0,1}g: \\{0, 1\\}^{n}\\rightarrow\\{0, 1\\}g:{0,1}n→{0,1}, g∈SIZEn(s)g \\in \\text{SIZE}_{n}(s)g∈SIZEn​(s) if there is a circuit of at most sss NAND gates computing ggg. And we define the restricted function: F↾n(x)=F(x) for x∈{0,1}n.\\begin{equation*} F_{\\restriction n} (x) = F(x) \\text{ for } x\\in \\{0,1\\}^n. \\end{equation*} F↾n​(x)=F(x) for x∈{0,1}n.​ Then FFF is non-uniformly computable in T(n)T(n)T(n) size, as F∈SIZE(T)F\\in\\text{SIZE}(T)F∈SIZE(T) if there is a sequence C0,C1,…C_{0}, C_{1}, \\dotsC0​,C1​,… of NAND circuits such that: CnC_{n}Cn​ computes F↾nF_{\\restriction n}F↾n​CnC_{n}Cn​ has at most T(n)T(n)T(n) gates when nnn is sufficiently large So the non-uniform analog P\\text{P}P: P/poly=⋃c∈NSIZE(nc)\\text{P}/\\text{poly} = \\bigcup\\limits_{c\\in\\mathbb{N}}\\text{SIZE}(n^{c})P/poly=c∈N⋃​SIZE(nc) Obviously, P⊊P/poly\\text{P}\\subsetneq\\text{P}/\\text{poly}P⊊P/poly and it can be proved BPP⊂P/poly\\text{BPP}\\subset\\text{P}/\\text{poly}BPP⊂P/poly as follows: Due to error reduction, A∈BPPA\\in \\text{BPP}A∈BPP has a polynomial-time randomized algorithm whose error probability is less than 2−n2^{-n}2−n, which means there is a verifier VVV, such that∀x Py(V(x,y)≠A(x))&lt;12n\\forall x \\,\\, P_{y}(V(x, y) eq A(x)) &lt; \\frac{1}{2^{n}}∀xPy​(V(x,y)=A(x))&lt;2n1​So due to the union bound:Py(∃x V(x,y)≠A(x))≤∑xPy(V(x,y)≠A(x))&lt;1P_{y}(\\exist x\\,V(x, y) eq A(x)) \\leq \\sum\\limits_{x}P_{y}(V(x, y) eq A(x)) &lt; 1Py​(∃xV(x,y)=A(x))≤x∑​Py​(V(x,y)=A(x))&lt;1As this probability is not 111, there must exist some y∗y^{*}y∗ for which ∀x V(x,y∗)=A(x)\\forall x\\, V(x, y^{*}) = A(x)∀xV(x,y∗)=A(x).Thus there exists a circuit with poly(n)\\text{poly}(n)poly(n) gates to caculate problem AAA beacuse y∗y^{*}y∗ is polynomial P = BPP &lt;= P = NP Sipser–Gács Theorem: BPP∈Σ2P∩Π2P\\text{BPP} \\in \\Sigma^{P}_{2} \\cap \\Pi_{2}^{P}BPP∈Σ2P​∩Π2P​, while the ΣP\\Sigma^{P}ΣP and ΠP\\Pi^{P}ΠP are defined as:ΣiP=∃∀∃…PΠiP=∀∃∀…P \\begin{align*} \\Sigma_{i}^{P} &amp;= \\exists\\forall\\exists\\dots \\text{P} \\\\ \\Pi_{i}^{P} &amp;= \\forall\\exists\\forall\\dots \\text{P} \\end{align*}ΣiP​ΠiP​​=∃∀∃…P=∀∃∀…P​ And we have the following theroem P=NP\\text{P} = \\text{NP}P=NP implies P=BPP\\text{P} = \\text{BPP}P=BPP The proof is diffcult with the technique ‘probabilistic method’ And there is also a theroem that reveals the relation between B\\text{B}B and BPP\\text{BPP}BPP Relations with P NP EXP We know P⊊EXP\\text{P} \\subsetneq \\text{EXP}P⊊EXP and BPP⊆EXP\\text{BPP} \\subseteq \\text{EXP}BPP⊆EXP Expected: P=BPP⊊NP⊆EXP\\text{P} = \\text{BPP} \\subsetneq \\text{NP} \\subseteq \\text{EXP}P=BPP⊊NP⊆EXP Extreme: P⊊NP⊆BPP=EXP\\text{P} \\subsetneq \\text{NP} \\subseteq \\text{BPP} = \\text{EXP}P⊊NP⊆BPP=EXP Extreme also: P=BPP=NP⊊EXP\\text{P} = \\text{BPP} = \\text{NP} \\subsetneq \\text{EXP}P=BPP=NP⊊EXP","tags":["TCS","Randomized Computation"],"categories":["理论计算机科学导引"]},{"title":"网原单词表","path":"/2024/05/15/网原单词表/","content":"计算机网络原理 中-英对照表 packet：分组 circuit switching：电路交换 packet switching：分组交换 packet switch：分组交换机 rooter：路由器 linker layer：链路层交换机 store-and-forword transmission：存储转发传输 output buffer/queue：输出缓存/队列 queuing delay：排队时延 packet loss：丢包 forwarding table：转发表 routing protocol：路由转发协议 Frequency-Division Multiplexing Address(FDMA)：频分复用地址 Time-Division Multiplexing Address(TDMA)：时分复用地址 bandwidth：带宽 slient period：静默期 Internet service provider(ISP)：因特网提供商 Point of Presence(PoP)：存在点 multi-home：多宿 peer(P2P)：对等 Internet Exchange Point(IXP)：因特网交换点 content provider network：内容提供商网络 nodal processing delay：节点处理时延 queuing delay：排队时延 transmission delay：传输时延 propagation delay：传播时延 total nodal delay：节点总时延 traffic intensity：流量强度 instantaneous throughout：瞬时吞吐量 average throughout：平均吞吐量 bottleneck link：瓶颈链路 layer：分层 protocol stack：协议栈 top-down approach：自顶向下方法 application-layer：应用层 message：报文 transport-layer：运输层 segment：报文段 network-layer：网络层 datagram：数据报 link-layer：链路层 frame：帧 encapsulation：封装 payload field：有效载荷字段 malware：恶意软件 botnet：僵尸网络 self-replicating：自我复制 worm：蠕虫 Denial-of-Service(DoS) attack：拒绝服务攻击 Distributed Dos(DDoS)：分布式拒绝网络攻击 packet sniffer：分组嗅探器 IP spoofing：IP哄骗 application architexture：应用程序体系结构 data ceenter：数据中心 process：进程 socket：套接字 Appllication Programming Interface(API)：应用程序编程接口 port numbe：端口号 reliable data transfer：可靠数据传输 bindwidth-sensitive application：带宽敏感应用 elastic application：弹性应用 Secure Socket Layer：安全套接字层 HyperText Transfer Protocol(HTTP)：超文本传输协议 stateless protocol：无状态协议 persistent connection：持续连接 non-persistent connection：非持续连接 Round-Trip Time(RTT)：往返时间 request line：请求行 header line：首部行 entity body：实体体 Web cache：Web缓存器 proxy server：代理服务器 Simple Mail Transfer Protocol(SMTP)：简单邮件传输协议 Post Office Protocol-Version3(POP3)：第三版的邮局协议 Internet Mail Access Protocol：因特网邮件访问协议 authorization：特许 transaction：事务处理 update：更新 Domain Name System(DNS)：域名系统 host aliasing：主机别名 canonical hostname：规范主机名 mail server aliasing：邮件服务器别名 load distribution：负载分配 distant centralized database：远距离集中式数据库 torrent：洪流 chunk：块 unchoked：疏通 tit-for-tat：一报还一报 Dynamic Adaptive Streaming over HTTP(DASH)：经HTTP的动态适应性流 manifest file：告示文件 content distribution network(CDN)：内容分发网络 reliable data transfer：可靠数据传输 Automatic Repeat reQuest(ARQ)：自动重传请求 Positive acknowledgment(ACK)：肯定确认 negative acknowledgment(NCK)：否定确认 duplicate packet：冗余分组 alter-nating-bit protocol：比特交替协议 Go-Back-N(GBN)：回退N步 sliding-window protocol：滑动窗口协议 cumulative acknowledgmemt：累计确认 Transmission Control Protocol：传输控制协议 connection oriented：面向连接的 full-duplex service：全双工服务 three-way handshake：三次握手 Maximum Segment Size(MSS)：最大报文长度 Maximum Transmission Unit(MTU)：最大设置单元 piggybacked：捎带 Exponential Weighted Moving Average(EWMA)：指数加权移动平均 congestion control：拥塞控制 per-connection throughput：每连接的吞吐量 Available Bite Rate(ABR)：可用比特率 congestion window：拥塞窗口 self-clocking：自计时 Additive-Increase, Multiplicative-Decrease(AIMD)：加性增，乘性减 Explicit Congestion Notification：明确拥塞通告 Explicit Congestion Notification Echo：明确拥塞通告回显 forwarding：转发 routing：路由选择 forwarding table：转发表 Software Defined Network(SDN)：软件定义网络 best-effort service：尽力而为服务 Tenary Content Address Memory(TCAM)：三态内容可寻址寄存器 Active Queue Management(AQM)：主动队列管理 Random Early Detection(RED)：随机早期检测 packet scheduler：分组调度 non-preemptive priority ququeing：非抢占式优先权排队 round robin queuing discipline：循环排队规则 work-conserving queuing：保持工作排队 weighted fair queuing：加权公平排队 Maximum Transmission Unit(MTU)：最大传送单元 dotted-decimal notation：点分十进制记法 Classless Interdomain Routing(CIDR)：无类别域间路由选择 address aggreration：地址聚合 Dynamic Host Configuration Protocol(DHCP)：动态主机配置协议 Plug-and-play Protocol：即插即用协议 Nonzero Protocol：需配置协议 Network Address Translation(NAT)：网络地址转换 tunneling：建隧道 Link State(LS) Algorithm：链路状态算法 Distance Vector(DV) Algorithm：距离向量算法 link state broadcast：链路状态广播 Autonomous System(AS)：自治系统 Open Shortest Path First(OSPF)：开放最短路优先 Broder Gateway Protocol(BGP)：边界网关协议 Routing Information Protocol(RIP)：路由信息协议 anycast：任播 switch farbic：交换结构 northbound/southbound API：北向/南向API Internet Control Messsage Protocol(ICMP)：因特网控制报文协议 Simple Network Management Protocol(SNMP)：简单网络管理协议 Management Information Base(MIB)：管理信息库 Structure of Management Information(SMI)：管理信息结构 Prorocol Data Unit(PDU)：协议数据单元 framing：成帧 Medium Access Control(MAC)：媒体访问控制 network adapter：网络适配器 Network Interface Card(NIC)：网络接口卡 Error Detection and Correction(EDC)：差错检测和纠正 undetected bit error：未检出比特差错 parity bit：奇偶校验位 two-dimensional parity：二维奇偶校验 Cyclic Redundancy Check(CRC)：循环冗余检测 polynomial code：多项式编码 generator：生成多项式 point-to-point link：点对点链路 point-to-point protocol(PPP)：点对点协议 high-level data link control(HIDC)：高级数据链路控制 broadcast link：广播链路 myltiple access problem：多路访问问题 Myltiple Access Control(MAC)：多路访问控制 collide：碰撞 channel partitioning protocol：信道划分协议 random access protocol：随机接入协议 taking-turns protocol：轮流协议 time-frame：时间帧 slot：时隙 Code Division Multiple Access(CDMA)：码分多址 Carrier Sense Multiple Access(CSMA)：载波侦听多路访问 CSMA with Collision Detection(CSMA/CD)：具有碰撞检测的CSMA channel propagation delay：信道传播时延 binary exponential backoff：二进制指数后退 polling protocol：轮询协议 token-passing protocol：令牌传递协议 Cable Modem Termination System(CMTS)：电缆调制解调器端接系统 Data-Over-Cable Service Interface CMTS(DOCSIS)：数据经电缆服务接口 Address Resolution Protocol(ARP)：地址解析协议 repeater:：转发器 filtering：过滤 forwording：转发 self-learning：自学习 aging-time：老化期 plug-and-play device：即插即用设备 jabbering：快而含糊的 switch poisoning：交换机毒化 Virtual Local Network(VLAN)：虚拟局域网 VLAN trunking：VLAN干线互联 Tag Protocol Identifier(TPID)：标签协议标识符 Multiprotocol Label Switchig(MPLS)：多协议标签交换 Ether VPN(EVPN or VXLAN)：链路层虚拟专用网络 Virtual Circuit(VC)：虚拟电路 label-switched router：标签交换路由器 Virtual Private Network(VPN)：虚拟专用网 traffic engineering：流量工程 data center network：数据中心网络 Top of Rack(TOR)：机架顶部交换机 blade：刀片 board router：边界路由器 load balancer：负载均衡器 hierachy of router and swtich：路由器和交换机等级结构 fully connected topology(FCT)：全连接拓扑 Modular Data Center(MDC)：模块化数据中心 Remote DMA(RDMA) over Converged Ethernet(RoCE)：??? base station：基站 cell tower：蜂窝塔 Access Point(AP)：接入点 infrastructure mode：基础设施模式 ad hoc network：自组织网络 handoff：切换 single/Multiple hop：单/多跳 mesh network：网状网络 mobile ad hoc network(MANET)：移动自组织网络 vehihcular ad hoc network(VANET)：车载自组织网络 path loss：路径损耗 multipath propagation：多径传播 coherence time：相干时间 Signal-to-Noise Ratio(SNR)：信噪比 Bit Error Ratio(BER)：比特差错率 hidden terminal problem：隐藏终端问题 fading：衰减 chipping rate：码片速率 Basic Service Set(BSS)：基本服务集 Service Set Identifier(SSID)：服务集标识 WiFi jungle：WiFi丛林 associate：关联 beacon frame：信标帧 active/passive scanning：主动/被动扫描 CSMA with Collision Avoidance(CSMA/CA)：具有碰撞避免的CSMA link-layer acknowledgement：链路层确认 Short Inter-Frame Spacing(SIFS)：短帧间间隔 Distributed Inter-Frame Spacing(DIFS)：分布式帧间间隔 Request to Send(RTS)：请求发送 Clear to Send(CTS)：允许发送 Wireless Personal Area Network(WPAN)：无线个人域网络 Frequency-Hopping Spread Spectrum(FHSS)：跳频扩展频谱 piconet：皮克网 Long-Term Evolution(LTE)：长期演进 Mobile divice(UE)：移动设备 Base station(eNode-B)：基站 Mobility Management Entity(MME)：移动管理实体 Home Subscriber Service(HSS)：家庭订阅者服务 Serving/PDN Gateway(S/P-GW)：服务/PDN网关 Mobile Subscriber Identity(IMSI)：移动订阅者身份 Subscriber Identity Module(SIM)：订阅者身份模型 Radio Access Network(RAN)：无线接入网络 Orthogonal Frequency Division Multiplexing(OFDM)：正交频分复用 All-IP Enhanced Packet Core(EPC)：全IP加强分组核 Packet Data Convergence(PDC)：数据收敛 Radio Link Control(PLC)：无线链路控制 GPRS Tunneling Protocol(GTP)：GPRS信道协议 Massive Machine Type Communications(mMTC)：大信息传输 Ultra-reliable and low latency communications(URLLC)：高可信低延迟交流 Multiple Directional Antennae(MIMO)：什么什么天线","tags":["网原","笔记"],"categories":["计算机网络原理"]},{"title":"网原笔记5","path":"/2024/05/15/网原笔记5/","content":"计算机网络原理 笔记 5 控制平面 路由选择算法 在路由器中寻找到最短路径，对于一个路由器，主要寻找到将其数据转发到其他路由器所需要的最短路径 算法分类方式 根据信息量 集中式路由选择：全局，了解该路由网络的全部信息并据此进行计算 分散式路由选择：局部，每个节点只知道与自己到相邻接点的花销 根据可变性 静态：路由基本不随时间变化 动态：随着网络流量或拓扑变化而动态改变路径，更加方便但是受一些特殊问题的影响 对负载敏感性： 敏感：趋近于绕开拥塞链路 迟钝：拥塞无影响，现代多采用这种，原因是链路开销不明确反映拥塞水平 LS 信息的全局性通过链路状态广播算法来完成 之后使用——伟大的Dijkstra!!! 路由振荡问题： 如图的链路为了避免选择高拥塞的道路，每次LS之后都会改变道路，导致了路由实际上处在振荡之中，并且从结果上来看，其选择的也并不是全局最优解 解决方案： 要求链路开销不依赖负载（不合理） 确保并非所有路由器同时运行LS，但是由于自同步的存在很困难，避免自同步可以采用链路通告随机化的方式 DV 迭代：循环计算直到没有更多信息需要交换 异步：不要求所有计算同步执行 分发式：每个节点计算接收邻居的信息，执行计算之后再发回去 基本原理是动态规划Bellman-Ford方程： dx→y=min⁡v∈Γ(x)(cx→v+dv→y)d_{x\\to y} = \\min_{v\\in\\Gamma(x)}(c_{x\\to v} + d_{v\\to y}) dx→y​=v∈Γ(x)min​(cx→v​+dv→y​) 算法如下： 给定图G=(V,E)G = (V, E)G=(V,E) ∀x∈V\\forall x \\in V∀x∈V，维护如下信息： 其与每个直接邻居的开销cx→vc_{x\\to v}cx→v​ 距离向量Dx→=[Dx→y: ∀y∈V]\\overrightarrow{D_{x}} = [D_{x\\to y}:\\text{ } \\forall y \\in V]Dx​​=[Dx→y​: ∀y∈V] 其所有邻居的距离向量 每个节点不时向邻居发送自己的距离向量 某个节点接收到邻居的信息或发现与自己连接的链路开销有变的时候，根据BF方程更新自己的距离向量 如果距离向量发生了变化，则发送给邻居 可以证明，lim⁡Dx→y→dx→y\\lim D_{x\\to y} \\to d_{x\\to y}limDx→y​→dx→y​ 注：图中cx→yc_{x\\to y}cx→y​应该是222而非212121 链路开销改变与链路故障 当链路开销增加时，很容易导致链路故障，如下图 右边的图会出现选择选择环路，即： Init: Dz→x=5(z→y→∗x),Dy→x=4(y→z→∗x)D_{z\\to x} = 5(z \\to y \\to^{*}x), D_{y\\to x} = 4(y \\to z \\to^{*}x)Dz→x​=5(z→y→∗x),Dy→x​=4(y→z→∗x) 1st forward: Dy→x=6(y→z→∗x),Dz→x=7(z→y→∗x)D_{y\\to x} = 6(y \\to z \\to^{*}x), D_{z\\to x} = 7(z \\to y \\to^{*}x)Dy→x​=6(y→z→∗x),Dz→x​=7(z→y→∗x) 2nd forward: Dz→x=8(z→y→∗x),Dy→x=9(y→z→∗x)D_{z\\to x} = 8(z \\to y \\to^{*}x), D_{y\\to x} = 9(y \\to z \\to^{*}x)Dz→x​=8(z→y→∗x),Dy→x​=9(y→z→∗x) … Until: Dz→x=50(z→x),Dy→x=51(y→z→x)D_{z\\to x} = 50(z\\to x), D_{y\\to x} = 51(y\\to z \\to x)Dz→x​=50(z→x),Dy→x​=51(y→z→x) 在最终情况之前，y,zy, zy,z所保存的到xxx的路径都是错误的，当变化后的开销（此处是4→604\\to 604→60）过大的时候，迭代轮次会过大导致传播速率迅速降低 毒性逆转 解决上述特定问题的方式（对于节点度数超过333的环路将无法解决） 如果zzz需要通过yyy到达xxx，则在zzz发送过去的信息中，记Dz→x=∞D_{z\\to x} = \\inftyDz→x​=∞ 善意的小谎言~ 两种算法的比较 记n=∣V∣,m=∣E∣n = |V|, m = |E|n=∣V∣,m=∣E∣： 报文复杂性：由于LS是全局的，因此其需要O(mn)O(mn)O(mn)个报文进行初始化，并且在一条链路发生改变时需要传递给所有节点，更复杂 收敛速度：LS复杂度O((m+n)log⁡n)O((m + n)\\log n)O((m+n)logn)，DV收敛很慢 鲁棒性：LS鲁棒性更强，因为全局算法相对来说路由器是解耦的，但是DV中一个不正确的节点会扩散到全局 OSPF 自治系统：由一组通常处在相同管理控制下的路由器组成，通常一个ISP中的路由器和其链路构成同一个AS，一个自治系统内的路由选择算法为自治系统内部路由选择协议 OSPF是一种LS，也即一个自治系统内采用全局广播的形式，并且即使未发生变化，也要周期性的广播链路状态，同时各条链路的开销，同时要检查链路运行状态，并允许路由器向相邻路由器广播 优点： 安全：能够鉴别OSPF路由器之间的交换，防止数据入侵 并发：允许使用多条相同开销的路径 可综合：容易扩展为MOSPF，从而支持多播 可层次化：支持一个AS中的层次化，即一个自治系统可以被划分为多个区域，每个区域之间可以相互交流，并且只包含一个主干 BGP 用于AS之间的通信，是一种分布式、异步的协议。 作用 在BGP中，一个路由器的转发表具有(xi,I)(x_{i}, I)(xi​,I)的形式，分别代表前缀与接口号 从邻接AS处获得前缀的可达性信息 并且每个子网可以向其他部分广播自己的存在性 确定到该前缀的最优路由 可达性通告 如上图，每对路由器中间使用179端口的半永久TCP连接，每个AS内部的会话为iBGP，跨AS的称为eBGP，于是通告路径如下： xxx子网向自己所在的AS的网关路由器发报文通知自己存在 网关路由器3a3a3a告知邻接的AS网关路由器：AS3中存在子网xxx 2c2c2c接收到这个消息，并通知AS2内的所有路由器 2a2a2a将信息发送给相邻的AS1，告知其xxx存在AS3内，并且可由AS2到达 同样的，不同AS之间可以增加对等链路，这样会导致子网和路由器之间存在多条路径 最优路由选择 在通告的子网前缀中增加一些属性，称为BGP属性，前缀及其属性称为路由，比较重要的属性包括： AS-PATH：这个AS是一条路由器路径中的一个，包含了已经通过的路由器列表，可以用于防止环路 NEXT-HOP：AS-PATH的起始路由器接口地址，每个AS的不同路由器接收到的NEXT-HOP属性可能不一样，用于指示从该路由器出发怎么找到子网 热土豆 查找AS内部路由转发信息，找到通往不同NEXT-HOP的最低开销路径，进而选择开销最低的那条 也即，热土豆追求的是贪心的尽快将报文传递出这个AS 路由器选择 当一个路由器希望到达一个前缀时，会将到该前缀的路由集合进行优先级排序，优先级如下： 每个路由增加一个本地偏好属性，属性值取决于管理员，本地偏好越高越优先 本地偏好相同时，选择AS-PATH最短的路由，由此规则确定路由之后通过DV决定路径 都相同时，采用热土豆 热土豆仍然无法选择时，采用BGP标识符 IP 任播 用于DNS中的服务，通常用语降低时延，例如CDN会向其下的多台服务器分配相同的IP，这样当一台路由器向这个IP发送信息的时候，路由器会向最近的一个服务器转发请求 路由选择策略 客户网络在多宿的情况下，可能会有类似提供商网络的行为，因此，其需要向相邻的所有提供商网络通告自己不能连通任何其他目的地，这样可以确保客户与提供商身份的相对稳定性 任何穿越ISP主干网的流量必须是其源或目的中至少一个唯一ISP的客户网络中（商业原因） SDN SDN体系结构具有4个关键特征： 基于流的转发：分组转发规则被规定在流表中，SDN控制平面用于计算、管理和安装流表项 数据平面和控制平面分离 位于数据平面交换机外部的网络控制：控制平面独立于数据平面之外 可编程的网络：网络控制应用程序是可编程的 控制器与控制程序 控制器的功能需要有： 通信层：负责控制器与数据平面之间的交流，称为南向API 网络范围管理层：控制决定层，配置流表以完成端到端转发、负载均衡、防火墙等功能 与应用程序接口：负责控制器与控制程序之间的交流，称为北向API OpenFlow协议 运行在实现了OpenFlow API的设备上，例如SDN控制器和数据平面之间，基于TCP，默认端口6653 控制器发送的重要报文包括： 配置：查询并设置交换机的配置参数 修改状态：增加、删除或修改交换机的流表项，设置交换机端口特性 发送分组：在交换机的特定端口发送特定报文 交换机发送的重要报文报告： 流删除：通知控制器删除一个流表项 端口状态：通知控制器端口状态的变化 分组入：将分组发送给控制器，如果该分组不能被流表匹配则控制器会做额外处理，如果可以匹配则会将该分组作为一个动作 实例 ICMP 主机和路由器之间用来沟通网络层信息的协议，最典型的用途是差错报告 通常被认为是IP的一部分，体系上位于IP之上，其内容作为IP报文的有效载荷 报文中包含一个类型字段和一个编码字段，包含引发该ICMP的IP的首部和前8个字节 这些报文可被用于探测，例如Traceroute程序利用ICMP来探测路由器的名字与IP地址 网络管理和SNMP 定义是一个冗长的单句： 网络管理框架 网络管理关键组件 如上图，关键组件包括： 管理服务器：控制网络管理信息的收集、处理、分析与显示，由人类控制 被管设备：被管理的真实设备，有若干个被管对象组成，被管对象包括实际硬件与配置参数 MIB：位于一个被管设备中收集被管对象的关联信息的数据库，其每个对象由SMI语言定义 网络管理代理：运行在被管设备中的进程，用于与管理服务器通信 网络管理协议：运行在管理服务器和被管设备之间的协议，为管理者提供了相应操作的能力 SNMP 一种网络管理协议，最常用的是请求响应模式，即管理服务器向代理发送请求，通常用于检索或修改MIB对象。其次可被用于代理向管理服务器发送陷阱报文，通知服务器有异常情况导致了MIB对象的改变 SNMP的PDU通过UDP传输，超时重传由管理服务器决定","tags":["网原","笔记","网络层"],"categories":["计算机网络原理"]},{"title":"网原笔记4","path":"/2024/05/08/网原笔记4/","content":"计算机网络原理 笔记 4 网络层 概述 网络层分为数据平面和控制平面 数据平面是将数据在输入链路和输出链路之间进行转发，控制平面是协调转发操作 转发和路由选择 转发：将数据报从输入链路转移到输出链路（数据平面） 路由选择：决定每个分组的路由（控制平面） 转发表：由路由选择确定，决定了转发的路由 确定转发表 传统方法：人工 路由器决定自身的转发表，但是需要路由器间的通信 SDN：由远程控制器决定每个路由器的转发表 网络服务模型 可能的服务： 确保交付 时延上界 有序分组 最小带宽 安全性 尽力而为服务：不提供任何服务 工作原理 四个组件： 输入端口：查询转发表决定输出路由，并且将数据转移至交换结构 交换结构：连接输入端口与输出端口 输出端口：从建环结构获取数据并此昂输出链路传输 路由选择处理器：执行控制平面功能，计算转发表（通常是一种传统的CPU） 转发策略： 基于目的地转发 通用转发 输入端口处理和基于目的地转发 最简单的情况下，每一个目的地址有一个对应的链路接口对应，采用前缀匹配的方法与最长前缀匹配规则（同时匹配多个前缀的时候选择最长的那个），为了效率通常使用SRAM，DRAM，TCAM 排队是指不同输入端口的数据在进入交换结构时排队 交换 交换方式很多 内存：直接经由CPU控制，这导致了速率较慢（受到内存带宽的限制），并且不能同时转发多个分组 总线：每一段数据会加上一个标签用于标记输出端口，所有输出端口都能接收数据但是只有被标记的可以保存数据，速率受到总线速率的影响，并且不允许并发 互联网：如纵横式交换机，共2N2N2N条总线，当想从输入端口发送到特定输出端口时只需要闭合对应交点即可，不同输出端口的分组可以并行 输出端口 何处排队 输入排队 当交换结构的速率不够快的时候会发生，并且会有线路前部阻塞，即同一个输出端口队列中前部的分组被堵塞会导致后面的也被堵塞 如果分组到达速率达到容量的58%58\\%58%，则输入队列会无限增长 输出排队 发送过快时会发生，采用丢弃新包或已有包来解决，同时有主动队列管理策略，如随机早期检测 传输顺序由分组调度决定 缓存的数量BBB与链路容量CCC的关系为： B=RTT∗CB = \\text{RTT} * C B=RTT∗C 分组调度 排队的分组怎么经过输出链路传输问题 FCFS：先来先服务 优先权排队：被分类放入优先权类中，同一类中的分组采用FCFS，非抢占式优先权排队中，分组开始传输就不能被打断 循环和加权公平排队：分组会被分类，但是不同类之间是平等的，也即会依次循环发送每一个类中的队列头，当某个类为空（链路空闲）时立即寻找其下一个类，例如加权公平排队，每个类会分配一个权重，并且加权分类吞吐量 网际协议 IPv4 版本号：确定剩余解释方式 首部长度：确定载荷与选项的分隔 服务类型：区别不同类型IP数据报 数据报长度：首部 + 数据 标识、标志、片偏移：与分片有关 寿命（TTL）：确保数据报不会循环 协议：指定运输层协议 检验和：检测比特错误，求和取反码 IPv4分片 一个链路层帧能承载的最大数据量称为最大传送单元，限制着IP数据包长度，并且一段路径上的链路之间可能有不同协议不同的MTU，因此采用分片技术，每一个大数据报被分为若干片 标识、标志、片偏移三个字段用于分片，标志比特用于标记最后一个片，片偏移用于决定正确的顺序 IPv4编址 点分十进制记法：每个字节用十进制书写，不同字节用句点隔开，如127.0.0.1127.0.0.1127.0.0.1 具有相同前缀的一些主机或路由器可以连接形成子网 其中223.1.1.0/24223.1.1.0/24223.1.1.0/24代表前242424为相同，/24/24/24为子网掩码 地址分配策略为无类别域间路由选择 地址聚合 得到地址 获取组织地址 由上游管理机构分配 获取主机地址 采用动态主机配置协议（又称即插即用或零配置），主机可以通过其来自动获取IP地址 DHCP发现：主机发现能够交互的DHCP服务器，通过DHCP发现报文，由链路层进行广播 DHCP提供：DHCP服务器回应一份DHCP提供报文，包含一些必要信息 DHCP请求：客户选择一个服务器，向其发送DHCP请求报文 DHCP ACK：服务器回应DHCP ACK报文 网络地址转换 在小型区域内合理使用一个IP地址的方法 NAT路由器是一个具有单一IP地址的打你设备，其中包含一张NAT转换表，用于将公网IP和端口转换为子网IP与端口 也即NAT用公网的端口进行寻址 中间盒 网络核心中的非交换机组成，包括NAT，流量负载均衡，流量防火墙等 IPv6 改动： 地址容量扩大：32→12832\\rightarrow 12832→128，引入任播地址，将数据报交给一组主机中的任意一个 简化首部 流标签：发送方要求进行特殊处理的流 字段： 版本号，指明是IPv4还是IPv6 流量类型：同IPv4的TOS 下一个首部：运输层协议 跳限制：最多能经过的路由器数目 去除了分片，取而代之的是差错报文，即数据太大时会被直接丢弃，并且向发送方返回一个ICMP差错报文 IPv4迁移到IPv6 好笑版：宣布标志日 实用版：建隧道 隧道指两台IPv6路由器之间的IPv4路由器的集合，方法是将IPv6的整个数据报作为数据包裹在IPv4载荷中进行传输，并且在下一个IPv6节点进行解包 通用转发和SDN 匹配加动作转发表称为流表，每个表项包括： 首部字段值的集合 计数器集合 动作集合 匹配 对来自不同层次的协议首部的一部分字段进行匹配，允许通配，例如192.118.∗192.118.*192.118.∗将匹配所有192.118192.118192.118开头的IP地址 动作 转发：转发到特定端口、端口集合或其余所有端口 丢弃 修改字段：在被转发之前重写首部字段（IP协议不可重写） 封装并转发给远程控制器","tags":["网原","笔记","网络层"],"categories":["计算机网络原理"]},{"title":"网原笔记3","path":"/2024/05/08/网原笔记3/","content":"计算机网络原理 笔记 3 网络原理 运输层 无连接运输：UDP 优势： 关于发送什么数据以及何时发送的应用层控制更加精细 无需建立连接（无需握手） 无连接状态 报文段首部短 报文段 检验和 发送方将所有161616比特字段求和并取反码，得到检验和，接收方将所有161616比特字段（包括检验和）进行求和，如果结果不是全111则有错，只能检验不能恢复 可靠数据传输 下层协议可能不可靠 (ARQ) 功能： 差错检测 接收方反馈 重传 在上一组数据传完并得到ACK相应之前不会有下一组数据，也即上层协议的send不会被调用，称为停等协议 考虑处理ACK/NAK受损的问题： 在2.22.22.2中，可以看出在接收到ACK的时候会判断其数字是否与当前状态相同，如果不相同则视作NAK 为了处理丢包，在发送发建立一个定时器，使得其能够在一定时间未接收到ACK之后默认为丢包，重发分组并且重置定时器 流水线 减少停等带来的传输利用率低下（传播时延远远大于传输时延） 增加序号 双方缓存多个分组 差错恢复：回退N步与选择重传 回退N步 当base得到确认之后窗口开始滑动，具体的FSM如下： 超时的时候，重传所有已发送但是未被确认的分组，同时接收方会丢弃所有失序的分组 选择重传 窗口长度必须不大于分组序号空间大小的一半，反之无法正常工作，接收方会出现无法分辨重传与新分组的现象 接收方收到自身的滑动窗口之前的分组时仍要发送ACK，否则发送方无法知道已被接收，窗口不能滑动 可靠数据传输总结 TCP 连接 全双工服务：双向传输 点对点：一对一传输 传输路径：进程 -&gt; 套接字 -&gt; 发送缓存 -&gt; 网络层 -&gt; 接收缓存 -&gt; 套接字 -&gt; 进程 典型的MSS的值为146014601460字节 报文 接收窗口字段：用于流量控制，指示接收方愿意接受的字节数量 选项字段：协商MSS，或在高速网络下作为窗口调解因子 标志字段： ACK：确认接收 RST, SYN, FIN：用于建立和拆除连接 PSH：指示接收方立即上传数据 URG：指示紧急数据 序号和确认号 一个报文段的序号是指该报文段首字节的字节流编号，TCP将数据看成有序字节流，对每一个字节分别标号 确认号指的是期待收到的最小字节标号，例如发送方已经收到0∼1000\\sim1000∼100和200∼300200\\sim300200∼300，则确认号为101101101 往返时间与超时 时限必须要大于RTT SampleRTT：报文段从发出到接被确认接收所需要的时间，在任意时刻仅测量一个报文段的SampleRTT而不是计算所有待确认的报文段，得到结果后加权更新，同时计算RTT偏差：EstimatedRTT=(1−α)EstimatedRTT+αSampleRTT\\text{EstimatedRTT} = (1-\\alpha)\\text{EstimatedRTT} + \\alpha\\text{SampleRTT} EstimatedRTT=(1−α)EstimatedRTT+αSampleRTT DevRTT=(1−β)DevRTT+β∣SampleRTT−EstimatedRTT∣\\text{DevRTT} = (1-\\beta)\\text{DevRTT} + \\beta|\\text{SampleRTT} - \\text{EstimatedRTT}| DevRTT=(1−β)DevRTT+β∣SampleRTT−EstimatedRTT∣ 时限应当确定为：Timeout=EstimatedRTT+4DevRTT\\text{Timeout} = \\text{EstimatedRTT} + 4\\text{DevRTT} Timeout=EstimatedRTT+4DevRTT 在真实处理中，有一种技术是在每次超时之后将时限翻倍 可靠数据传输 冗余ACK：用于指示报文丢失，当重复收到一个报文段的333次冗余ACK，之后，立即重传其下一个报文 流量控制 使得发送速率与接收方的读取速率相匹配，通过发送发来维护接收窗口实现，指示接收方剩余的缓存空间 发送方保证发送到连接中但是未被确认的数据量小于rwnd即可 特例：当缓存已经满了的时候发送仅含一字节数据的报文段，此时接收方开始清空缓存，并在确认报文里发送新rwnd 三次握手 客户向服务器发送一个SYN为111的报文段，随机选择一个初始序号，请求连接 服务器接收，分配缓存与变量，选择初始序号，返回SYNACK报文段表示允许连接 客户端接收，分配缓存与变量，连接建立 关闭过程： 客户端发送FIN置111的报文段表示关闭请求，并接收ACK，清理变量和缓存 服务端发送FIN置111的报文段表示关闭请求，并接收ACK，清理变量和缓存 拥塞控制 原因 理想路由器，分组的到达速率接近链路容量时，排队时间趋近于无穷大 有缓存的路由器，发送方因为大时延进行不必要重传占据链路带宽 上游路由器发送的分组最终被丢弃，这样发送它所占用的资源就被浪费了 控制方法 端到端：网络层不反馈，全部依靠运输层 网络辅助：网络层会反馈一些信息 TCP拥塞控制 发送方维护一个拥塞窗口cwnd，满足 LastByteSent−LastByteAck≤min⁡(cwnd,rwnd)\\text{LastByteSent} - \\text{LastByteAck} \\leq \\min(\\text{cwnd}, \\text{rwnd}) LastByteSent−LastByteAck≤min(cwnd,rwnd) 发送速率为 cwndRTT字节/秒\\frac{\\text{cwnd}}{\\text{RTT}}字节/秒 RTTcwnd​字节/秒 发送方判定丢包为超时或三个冗余ACK TCP为自计时的 TCP拥塞控制算法 慢启动： cwnd初始值被确定为一个MSS，传输的报文段被首次确认的时候增加一个MSS，因此整体呈现几何级数增长的形式，同时在发送方维护ssthresh（慢启动阈值），结束增长有如下情况： 超时丢包：重新初始化并慢启动，令ssthresh=cwnd/2\\text{ssthresh} = \\text{cwnd}/2ssthresh=cwnd/2 cwnd=ssthresh\\text{cwnd} = \\text{ssthresh}cwnd=ssthresh：进入拥塞避免 333个冗余ACK：快速重传，进入快速恢复 拥塞避免 每个RTT只增加一个MSS而不是翻倍，例如每个ACK增加MSS2/cwnd\\text{MSS}^{2}/\\text{cwnd}MSS2/cwnd，结束控制如下： 超时丢包：同慢启动 333个冗余：快速重传，令ssthresh=cwnd/2,cwnd=ssthresh+3MSS\\text{ssthresh} = \\text{cwnd}/2, \\text{cwnd} = \\text{ssthresh} + 3\\text{MSS}ssthresh=cwnd/2,cwnd=ssthresh+3MSS 快速恢复 每个冗余ACK增加一个MSS，结束控制： 超时丢包：同慢启动 回顾 整体拥塞控制方法成为加性增，乘性减 另一种拥塞控制方法为基于延迟，即实时检测吞吐量，并于最大吞吐量cwnd/RTT\\text{cwnd}/\\text{RTT}cwnd/RTT进行比较，并且线性增减去趋近最大吞吐量 宏观吞吐量 以WWW代表窗口长度，则 Mean=0.75∗WRTTMean = \\frac{0.75*W}{\\text{RTT}} Mean=RTT0.75∗W​ 高带宽TCP 设LLL为丢包率，则 Mean=1.22∗MSSRTT∗LMean = \\frac{1.22*\\text{MSS}}{\\text{RTT}*\\sqrt{L}} Mean=RTT∗L​1.22∗MSS​ 这代表高吞吐率需要非常低的丢包率来支持 TCP公平性 公平性代表瓶颈链路分配给每条链路的资源应该是相近的 TCP趋近于多条链路之间平等分享，但是在实际应用中，RTT较小的通常吞吐量更大 公平与UDP UDP无拥塞控制，并且可能会抑制TCP 公平与并行TCP 一个应用使用多条TCP并行会导致占用过多资源，但是资源的公平应该是在应用层面上的 明确拥塞公告 网络层辅助的拥塞控制机制 IP协议的首部中有两个比特被用于标记ECN，当接收方收到ECN时则在回复的ACK中设置ECE，发送发收到之后进行窗口减半处理（和超时丢包相同），并在下一个报文段首部标记CWR字段（拥塞窗口缩减）","tags":["网原","运输层","笔记"],"categories":["计算机网络原理"]},{"title":"网原笔记2","path":"/2024/05/08/网原笔记2/","content":"计算机网络原理 笔记 2 网络原理 应用层 应用层协议原理 APP是运行在端系统上，而不是诸如路由器等的网络核心设备上，因为网络核心设备基本只在网络层及以下的地方起作用 网络应用程序体系结构 两种主流体系结构： 客户-服务器体系 对等体系 客户-服务器 服务器：一个总是打开的主机，处理来自其他客户主机的请求，例如Web浏览器等 客户之间不会直接通信，而是需要经过服务器中转，并且服务器具有固定的地址（称之为IP地址） 数据中心：为了防止单一的服务器主机无法处理大量请求，部分服务商会部署数据中心，其中配备有大量主机，用于模拟服务器 对等 端系统主机之间直接通信，无需经过服务器中转，一些流量密集型应用采用的是P2P结构 P2P结构具有自扩展性，每个对等方通过请求文件产生工作负载，但是其也可以通过向其他对等方分发文件提升系统服务能力 进程通信 这里讨论的是不同端系统之间进程的通信，其通过交换报文相互通信 客户与服务器进程 对于任意一对进行通信的进程，在会话开始时等待联系的一方为服务器，发起通信的一方为客户，无论其采用的体系结构是可恶-服务器或P2P 进程与计算机网络的接口 进程间通过套接字（也被称为API）接口进行报文的发送和接收，套接字是应用层与运输层的接口，开发者可以选择运输层协议，并借助该协议进行开发 进程寻址 接收进程的地址包括： 主机地址 在目标主机中指定接收进程的标识符 主机由其IP地址确定，是一个32bit32bit32bit的量并且可以唯一标识一个主机，指定接收进程由目的地端口号保证，一个端口号只能接收一个进程的信息 可供应用程序使用的运输服务 一个运输层协议所能提供的服务分为四类： 可靠数据传输 吞吐量 定时 安全性 可靠数据传输 由于丢包、数据损坏等情况，数据可能发生丢失，因此，我们需要一种使得发送的数据一定可以正确、完全的交付给另一方的协议，称之为可靠数据运输 部分应用（例如音视频、原神等）允许一定量的数据丢失，这被称为容忍丢失的应用 吞吐量 可用吞吐量：两个进程之间发送比特的速率，由于其他会话会共享带宽，因此可用吞吐量会随着时间波动 因此，一部分协议保证了应用可用吞吐量的下界，这对于一些带宽敏感应用（具有特定的吞吐量要求）是很有必要的，与之相对，弹性应用不需要限制吞吐量 定时 定时协议可以保证时延的上界，例如可以确保发送的比特一定会在100ms100ms100ms内到达接收方，广泛应用于实时交互的应用中 安全性 协议能够提供数据的加密、解密，以保证只有进程可以直接观察到发送的的数据，同时还有数据完整性鉴别、端点鉴别等 因特网提供的运输服务 包括TCP与UDP两种 TCP 包括面向连接服务与可靠传输服务 面向连接服务：应用岑报文开始流动之前，TCP让客户服务器进行握手（交换运输层控制信息），握手结束后即建立了一条TCP连接，双方进程可以在该连接上进行报文的收发，结束发送至后必须拆除连接 可靠传输服务：同上 同时，TCP拥有拥塞控制机制，可以在适当时机抑制发送进程，并且限制每个连接使之公平共享带宽 由于其没有加密机制，因此有基于TCP的SSL，可以提供关键的安全性服务,SSL不是一种新的因特网运输协议 UDP 轻量级，仅提供最小服务，没有握手机制、拥塞控制机制、可靠传输等 因特网运输协议所不提供的服务 没有包括定时和吞吐量等，这些操作被巧妙的设计所尽量保障，但是在一些极端情况下仍然会被限制 应用层协议 应用层协议定义了进程之间传递报文的格式，如： 交换报文的类型 各种报文类型的语法 报文中字段的语义 确定进程何时、如何发送报文 对报文进行响应的规则 应用层协议是网络应用的重要组成部分 Web &amp; HTTP HTTP概况 Web页面有对象组成，可以通过URL（由主机名+路径名构成）寻址访问Web服务器实现了HTTP服务器端，用于存储Web对象，基本通信方式如下： HTTP是一个无状态协议，也即其不会存储有关客户的任何信息（例如短时间内连续请求信息，则服务器每次会重新发送） 持续连接与非持续连接 客户与服务器之间需要进行一系列请求，并且两个请求之间的间隔可能是随机的或是周期性的，所以不同请求可以使用不同的TCP连接或者同一个TCP连接，被分为非持续连接和持续连接两种，HTTP1.1及更高版本默认情况下使用的是持续连接，HTTP1.0采用的是非持续连接，而HTTP2.0版本更新了队列机制，不强制要求FCFS，而是可以让用户自己定义优先级 非持续连接 每一个对象需要一次TCP连接 定义往返时间：一个短分组从客户到服务器再返回客户的时间，如下： 上图中设计三次握手过程，其中前两个过程消耗了一个RTT，最后一次握手以及发送HTML文件这个响应操作消耗了一个RTT，因此总响应时间为2∗RTT+2*\\text{RTT} +2∗RTT+传输文件时间 持续连接 非持续连接需要为每个请求的对象建立并维护一个连接，需要大量TCP缓冲区与变量，并且会导致相对更高的时延 持续连接即建立连接后，即使完成请求也不关闭，因此不同请求可以使用这一条连接进行，避免了反复建立连接，当连接在一定时间内没有被使用时才会被关闭 HTTP 报文格式 分为请求报文与响应报文两种 HTTP请求报文 第一行称作请求行，其后续都称为首部行 请求行分为方法、URL、HTTP版本三个字段 主机的信息提供给Web代理高速缓存 第三行用于关闭持续连接 第四行用于指明用户代理，即浏览器类型 第五行用于指明需要得到的语言版本 通用格式如下： 实体体在GET方法中为空，在POST等方法中包含信息，例如用户在搜索框内的输入信息等，而需要给服务器提供信息的操作不一定是POST操作，例如可以将信息附在URL中然后使用GET操作 HTTP响应报文 比请求报文多了一个实体体的部分，同时第一行称作状态行 状态行包括协议版本，状态码与状态信息三部分 第二行与请求报文相同 第三行表示了发送响应报文的时间 第四行表示服务器 第五行表示发送的对象被最后修改的时间，对于缓存来说非常重要 第六行表示发送对象的字节数 第七行表示对象类型 通用格式如下： 用户与服务器的交互：cookie 允许站点对用户进行跟踪，技术有如下四个组件： 响应报文中的cookie首部行 请求报文中的cookie首部行 端系统中的cookie文件 后端数据库 用户首次访问一个站点的时候，服务器会为其建立一个 cookie用来唯一标识这个客户，并将其发送给浏览器，后续会话中浏览器与服务器之间可以通过cookie来确定用户信息 Web缓存 又称代理服务器，可以理解为是客户和初始服务器之间的一个代理，可以提升用户的访问速度，用户可以往缓存中发请求，如果缓存中拥有的话则可以直接返回响应，反之则需要在初始服务器中进行寻找，因此可以有效的降低时延并且减少供应商成本 条件GET方法 用于确定缓存中的数据是最新的方法，具体来说，缓存数据会存储数据的最近修改时间，因此，如果用户在请求报文中增加了行 1If-modified-since: xxx 则缓存与代理之间会经过一次通信确定文件在xxx时间之后是否有被修改过，这种报文称之为条件GET请求 电子邮件 &amp; SMTP SMTP 步骤如下： 发送方代理将报文发送给自身邮件服务器，并存储在报文队列中 发送方服务器SMTP与接收方服务器SMTP直接建立TCP连接 握手结束后，通过该连接发送报文 接收方服务器接收报文，并将其放入接收方的邮箱中 SMTP可以通过可靠数据传输将邮件完整的发送到接收方，并且其采用的是直接连接的方式 SMTP有一条特殊规则是：只包含nnn个句点符号的单行，表示的是n−1n-1n−1个句点，因为单个句点是指示报文结束，对话形式如下图： 由用户端发送的、全大写的字符串代表特殊命令，其含义可以直接翻译理解 与HTTP比较 同： 都用于在两台主机之间传送文件 都是持续连接 异： HTTP是拉协议，即此时连接由接收方向发送方发起；TCP是推协议，即此时连接由发送方向接收方发起 SMTP要求发送数据必须编码为ASCII字符，但是HTTP没有限制 对于多对象（例如包含图片、视频、音频等）文档，HTTP将每个对象分别封装，但是SMTP将其全部封装在一起 报文格式 使用的是RFC 5322定义，其中的From, To两行是必选的 访问协议 由于SMTP是一个推协议，因此用户是无法通过自己设备上的代理向服务器请求邮件的，因此我们没有办法实时读取到存储在服务器中的邮件，为了解决这个问题引入了邮件访问协议，如POP3, IMAP, HTTP POP3 由RFC 1939定义，极其简单，首先用户向服务器提出建立TCP连接，建立之后依次分为三个阶段：特许，事务处理与更新 鉴权（特许）阶段：客户端使用命令user 与pass 鉴别身份信息（明文发送） 事务处理：客户端允许使用list, retr , dele 三条命令，分别代表：列出所有邮件长度，接收id号邮件，删除id邮件 更新：当用户使用了quit命令之后进入更新阶段，服务器删除被标记的斑纹，POP3会话结束 每次客户端发来一个命令之后，服务端的回复是+OK 或-ERR IMAP 允许用户可以在远程服务器上操作邮件，包括创建文件夹、移动邮件、在远程文件夹上查询邮件等，更加方便，并且允许用户获取报文的部分，以避免大量信息造成网络负担过重 邮件中的HTTP 在代理和服务器直接发送信息的时候采用HTTP协议，在服务器之间传输的时候采用SMTP，也即将浏览器当成用户代理 DNS：因特网的目录 用于转换主机在主机名与IP地址之间的一种系统，主机名方便人类记忆，而IP更容易被计算机处理 DNS的服务 DNS是指： 由分层的DNS服务器实现的分布式数据库 使主机能够查询分布式数据库的应用层协议 DNS服务器运行BIND软件，协议运行在UDP之上，使用53号端口 DNS通常是一种被其他应用层协议使用的应用程协议，用于将它们请求报文中的主机名转换为IP地址，而并不常与用户直接通信 除了转换外还有其他服务： 主机别名，部分主机拥有多个主机名，而其中有一个成为规范主机名，而别名的存在是为了更方便的记忆，因此DNS可以识别别名 邮件服务器别名：电子邮件的后缀可以是别名，由邮件app调用DNS进行处理 负载分配：部分站点有多个服务器，也即一个规范主机名会对应多个IP地址，因此DNS用于调配这些地址之间的负载，用户向这个主机名发送请求等效于向当前队列中最前方的IP发送请求 工作机理概述 从用户来看，DNS是一个提供转换服务的黑盒，但是其内部是由大量DNS服务器及应用层协议组成的 简单设计：全球仅有一台DNS服务器，会有诸多问题 单点故障导致全球故障 通信容量巨大 远距离的集中式数据库导致高时延 维护复杂 因此采用了分布式的设计方案 分布式层次数据库 从上到下依次为：根服务器，顶级域服务器与权威服务器，访问一个主机名的时候从上至下访问服务器，从右至左依次匹配 根服务器：全球有400400400多个 顶级域：例如.com, .edu等 权威：每个公共可访问主机的组织需要提供公共可访问的DNS记录，这些记录被记录在权威服务器中 本地DNS服务器：属于ISP，起到的是代理、加速作用 每次向服务器发送请求是，得到的是下一级的服务器IP地址列表，权威服务器将会返回查询地址的IP，同时，权威服务器有可能需要用过中间服务器再次分层，也即权威-&gt;中间-&gt;权威 查询方式分为递归查询与迭代查询，上图中，请求主机与本地服务器之间为递归查询，其与全部为迭代查询，即迭代查询是接受请求后直接返回，而递归查询是接受请求后向其他服务器查询之后再返回给请求方 DNS缓存 为了改善时延并且减少报文数量，DNS服务器可以将请求/回答信息环城存在本地存储器中，以便更快返回，由于IP对应关系不永久，因此缓存信息会被定时清除 DNS记录与报文 DNS服务器存储了资源记录，其提供了主机名到IP地址的映射，形式为： (Name, Value, Type, TTL)\\text{(Name, Value, Type, TTL)} (Name, Value, Type, TTL) 其中TTL代表的是应当删除的时间，其余三个的对应如下： Type = A，则Name是主机名，Value是对应的IP地址 Type = NS，则Name是一个域，Value是域中可获取主机IP的权威服务器主机名 Type = CNAME，则Name是一个别名，Value是对应的规范主机名 Type = MX，则Name是一个别名，Value是对应邮件服务器的规范主机名 报文 前121212字节称为首部区域，标识符用于匹配，标志用于提供一些额外信息 问题区域包含查询信息，包括主机名、问题类型（查规范主机名还是邮件服务器等） 回答区域包含了资源记录，可以包含多条 在DNS数据库中插入 略 P2P文件分发 对等方直接通信，减少对服务器的依赖 P2P体系的可扩展性 FFF：文件长度 NNN：对等方数量 usu_sus​：服务器接入链路的上传速率 uiu_iui​：第iii个对等方接入链路的上传速率 did_idi​：第iii个对等方接入链路的下载速率 考虑在客户-服务端与P2P两种模式下所需要的分发时间 客户-服务器体系Dcs≥max(NFus,Fdmin)D_{cs} \\geq max(\\frac{NF}{u_s}, \\frac{F}{d_{min}}) Dcs​≥max(us​NF​,dmin​F​) P2PDP2P≥max(Fus,Fdmin,NFus+∑ui)D_{P2P} \\geq max(\\frac{F}{u_s}, \\frac{F}{d_{min}}, \\frac{NF}{u_s + \\sum u_i}) DP2P​≥max(us​F​,dmin​F​,us​+∑ui​NF​) 当对等方数量非常多时，采用P2P将会具有很好的效果（增长缓慢） BitTorrent 一种P2P协议，其中，参与特定文件分发的所有对等方集合被称为一个洪流，每个洪流有一个基础设施节点称为追踪器，其中记录并追踪了每个对等方及其是否离开了洪流 新对等方向追踪器请求对等方列表，并尝试向所有对等方建立TCP连接，成功建立连接之后称为邻近对等方，并向所有的邻近对等方请求未含有的块 请求块的方法是最稀缺优先，请求其邻居中所含副本最少的块，以便尽快达到块数量的均衡 给其他对等方上传数据时，每隔一段时间选择向其发送数据最快的444个对等方，其集合成为疏通，并向它们上传块，同时会每隔一段时间随机寻找新对等方进行对换，也即最多会向555个对等方上传块，这种激励机制成为一报还一报 视频流和CDN 因特网视频 比特率决定视频质量以及对传输所需要的流量 HTTP流和DASH 常规的HTTP流为对视频进行编码后使用常规方法进行发送，在用户端有两种方式，一种为缓存字节数超过一定数目就开始播放，另一种为流式视频，即按帧缓存，从接受视频开始即播放 DASH被称为经HTTP的动态适应性流，其将视频编码为不同版本，随着带宽的变化选择不同版本，服务器中存在告示文件，提供不同版本的URL与分辨率 CDN 分布在多个地理位置上的服务器，用于帮助世界各地的用户尽快获取内容 服务器安置原则为： 深入：遍历接入ISP来深入其中，靠近端用户 邀请做客：在关键位置部署少量大集群，邀请ISP做客 CDN采用拉策略，并非将视频存储在每一个集群中，当集群缺少这个视频时则会向其他集群检索并缓存 CDN操作","tags":["网原","笔记","应用层"],"categories":["计算机网络原理"]},{"title":"网原笔记1","path":"/2024/05/08/网原笔记1/","content":"计算机网络原理 笔记 1 网络原理 概要 考核 随堂测 15% 作业 25% 期末考试 60% Key problems Multiple access control: MAC rooting naming: how to give each user a unique id Congestion control（阻塞控制） RDT: Reliable Data Transfrom Protocol 协议：协议定义了网络实体之间发送和接收消息的格式、顺序，以及对消息传输、接收所采取的操作 网络核心 分组交换 端系统（主机）之间交换报文，报文包含了通讯者需要的信息，并通过通信链路从源发送至目的地 源会将长报文划分为较小的数据块，称为分组，通信链路上拥有分组交换机，以使得以链路允许的最大传输速率传输报文，分为路由器和链路层交换机两种 存储转发传输：在链路发送信息时必须要整组发送，即需要等待源将一组信息完全发送至交换机才能发送至目的地 端到端时延：通过NNN条传输速率为RRR的链路组成的路径，从源向目的地发送一个LLL比特的分组，端到端时延（传输时延）为d=NLRd = N\\frac{L}{R} d=NRL​ 发送PPP个分组的时延为d=(N+P−1)LRd = (N+P-1)\\frac{L}{R} d=(N+P−1)RL​ 排队时延与丢包：分组交换机拥有一个输出队列（缓存），当交换机的输出速率小于输入速率时，后进入的包会进入缓存中等待，这一种延迟称之为排队时延，主要取决于网络阻塞程度，当缓存被填满时，再次有包进入时会导致有的包（可能是新来的或队列中的）被丢弃，即为丢包 转发表：路由器决定应该将信息往哪一条链路发送的方式，可以将目的地IP地址（或其一部分）映射到对应的输出链路，转发表通常会根据路由转移协议来自动设置 电路交换 与分组交换的最大区别在与：电路交换会提前预留端到端通信所需要的资源，包括缓存、链路传输数据等，每一条链接称为一条电路，因此其时延主要来自于建立电路与在电路上传播 复用：分为频分复用与时分复用 频分复用指一组连接共用一段频谱，每个连接有一个独享的频段。例如调频无线电台使用FDM共享88MHz-108MHz的频谱，每一个电台会被分配一个特定的频段（通常带宽为4MHz），使用完毕之后会被回收投入下一次使用 时分复用指，将时间分割为固定的帧，每一帧被分割为固定量的时隙，每个时隙只传播一个连接的数据（类似并行的概念） 电路交换会有静默期，也即建立了电路之后不传播信息，可能会引发资源浪费，但是电路交换的端到端时延与链路数量无关（在路由器处无需等待） 通常情况下，分组交换的效率会优于电路交换 网络的网络 此节讨论我们怎么能够使用网络资源，也即因特网的结构（发展动力主要是商业竞争） 网络结构111：一个单一的全球ISP互联所有接入ISP，所有的客户直接向该全球ISP付费 网络结构222：多个全球ISP，全球ISP之间是互联的，用户可以向性价比最高的全球ISP付费 网络结构333：有区域ISP，ISP按照层级高低分为接入、区域、第一层（全球传输），低层需要向直接连接的高层付费 网络结构444：在结构333的基础上增加了PoP、多宿，对等与IXP PoP：提供商网络中位于相同位置的一组路由器，客户ISP可以通过其与提供商ISP相连接 多宿：任何非顶层ISP可以与多台上游ISP相连接 对等：同层的相邻ISP之间直接连接，无需通过上游ISP进行中转，通常对等无需付费 IXP：可以使得多个ISP一起对等，类似于一个中转站 网络结构555：在网络结构444的基础上增加了内容提供商网络，更多的用于直接与较低层的ISP互联，避免由于中间ISP的收费 时延、丢包与吞吐量 时延 delay=dproc+dqueue+dtrans+dpropdelay = d_{proc} + d_{queue} + d_{trans} + d_{prop} delay=dproc​+dqueue​+dtrans​+dprop​ 处理时延：检查数据是否有错，决定输出链路等，数量级为μs\\mu sμs 排队时延：在输出队列中等待的时间，取决于网络拥塞程度，数量级为ms−μsms-\\mu sms−μs 传输时延：将数据从路由器传输到链路的时间，数量级在ms−μsms-\\mu sms−μs 传播时延：数据在链路上传播的时间，通常很小（传播速率在108m/s10^8m/s108m/s量级），但是在长距离传播中需要考虑 排队时延和丢包 流量强度定义为 ti=LaRti=\\frac{La}{R} ti=RLa​ 其中，aaa代表数据到达队列的平均速率，LLL代表分组的平均比特数，ti→0ti\\rightarrow 0ti→0时排队时延很小，ti→1−ti\\rightarrow 1^-ti→1−时排队时延很大，ti&gt;1ti&gt;1ti&gt;1的时候排队时延无界 当ti≤1ti\\leq 1ti≤1的时候，分组到达的方式（周期性或突发性等）将会影响排队时延 当路由器的输出队列已满时，新进入的分组会被丢弃，称为丢包 端到端时延 dend−end=N(dproc+dtrans+dprop)d_{end-end} = N(d_{proc} + d_{trans} + d_{prop}) dend−end​=N(dproc​+dtrans​+dprop​) 其中 dtrans=LRd_{trans} = \\frac{L}{R} dtrans​=RL​ 这个式子假设了网络是畅通的 吞吐量 定义：主机接受文件的速率，分为瞬间吞吐量与平均吞吐量 瓶颈链路：指平均传输速率最小的一条链路，限制了整个网络的吞吐量 上述的平均指的是，分配给每条链路的传输速率，例如一条速率为100Mbps的高速链路，需要同时承担100010001000个客户-服务器的通信，那平均速率将会降至100kbps，有可能成为瓶颈链路 协议层次及其服务模型 分层的体系结构 协议分层 为了更好的结构化与模块化，网络以分层的方式组织协议与硬软件，每一层通过在该层中执行动作或使用直接下层的服务来提供服务。 各层的所有协议被称为协议栈，因特网的协议栈自顶向下为应用层，运输层，网络层，链路层，物理层 应用层：网络应用程序以及其应用层协议存留的地方，其中的信息分组称为报文。应用层提供了许多协议，如： HTTP：Web文档协议 SMTP：电子邮件报文协议 FTP：端系统协议 DNS：域名系统协议 运输层：用于在应用程序端点之间传送应用层报文，有两种运输协议：TCP, UDP，其中TCP提供了截断机制与拥塞控制机制。运输层的分组称为报文段 网络层：分组称为数据报，网络层负责将数据报从一台主机移动到另一台主机，网际协议包括IP，其定义了数据报中的各个字段以及端、路由器如何作用在这些字段上 链路层：在节点之间传递数据，每个节点的网络层将数据下放给链路层，传递至下一个节点之后再上传至网络层。如以太网、WiFi、电缆接入网的DOCSIS协议，其中的分组称为帧 物理层：在物理层面上将帧中的比特移到下一个节点，每一种链路层中包括很多物理层协议，与实际的物理媒介有关 OSI模型 777层分层，包括应用层、表示层、会话层、运输层、数据链路层、物理层。 表示层用于将交换的数据可以被应用程序解释，会话层提供了数据交换的定界和同步功能，包括检查与恢复等 封装 每一层会将来自上一层的数据进行封装，也即附加一些首部信息，包括一些权限信息以及检测信息等，引测，每一层的分组都有两种字段，首部字段和有效载荷字段 坏家伙 危害终端设备 坏家伙将恶意软件植入设备中，并利用僵尸网络（被控制的主机）展开攻击，从而实现自我复制。恶意软件分为病毒与蠕虫两类： 病毒：需要用户交互来感染用户设备的恶意软件 蠕虫：无需用户交互即可进入设备 危害服务器和网络设施 拒绝服务攻击，也即DoS, 包括以下三种： 弱点攻击：攻击不完备的应用或操作系统 带宽洪泛：往目标发送大量分组，例如DDoS通过大量源向目标发送分组造成目标瘫痪 连接洪泛：在目标中创建大量的半开或全开TCP连接 嗅探分组：在传输分组时，精心布置的被动接收机可以得到传输信息的副本，并且由于其不会注入信息，所以很难被检测出来，这种接收机被称为分组嗅探器 身份伪装：通过IP哄骗，向目标发送具有恶意的信息","tags":["网原","笔记","概要"],"categories":["计算机网络原理"]},{"title":"Hexo + Stellar","path":"/2024/05/07/Hexo初探/","content":"终于弄好了www 经过一天的不懈奋斗，在经过了jekyll配置环境的痛苦折磨之后，最后选择了用hexo+github pages配置，hexo是一款静态博客工具，使用起来比较简单，指比让从来没有配过ruby的我去弄明白jekyll简单多了！ 配置方法 新建github仓库，名为&lt;username&gt;.github.io，这个是后来访问用的 回到本地命令行（笔者用的是wsl）123456npm install -g hexo-clisudo npm install -g hexo-cli (Mac) # 据说Mac得这么干cd AN-EMPTY-FLRODER # 进入你想放置的本地文件夹 一定要是空的！hexo init # 初始化hexo内容npm install # 下载配置npm install hexo-deployer-git --save # 下载部署工具 此时环境基本配置完毕了，开始修改配置，打开_config.yml，将其Deployment部分改为1234deploy: type: git repository: git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git branch: main 部署准备完成1hexo g -d # 生成页面并部署 此时可以访问https://&lt;username&gt;.github.io访问自己的博客！ 操作方法 12345678hexo new &quot;name&quot; # 新建文章hexo new page &quot;name&quot; # 新建页面hexo g # 生成页面hexo d # 部署hexo g -d # 生成页面并部署hexo s # 本地预览hexo clean # 清除缓存和已生成的静态文件hexo help # 帮助 更换主题 进入网站https://hexo.io/themes/可以选择主题，挑选好后进行配置，配置方法为在博客根目录.下执行如下命令： 1git clone THEME-REPO themes/&lt;theme-name&gt; 例如本博客使用的是stellar主题，执行命令为： 1git clone git@github.com:xaoxuu/hexo-theme-stellar.git themes/stellar 下载好后，在./_config.yml下修改theme的内容为你想要的即可 致谢 https://zhuanlan.zhihu.com/p/60578464 Debug TypeError: Cannot read properties of null (reading 'utcOffset') 时区设置错误，允许的中国时区只有Asia/Harbin,Asia/Shanghai,Asia/Chongqing,Asia/Urumqi,Asia/Kashgar 无法生成.html文件 检查themes下的文件名和配置文件中的是否相同，如果相同尝试先clean再重新创建，如果还是不行则直接重新clone一下主题库（原因未知） 行内公式无法渲染 更换md渲染器，并添加Katex支持，方法为：123npm un hexo-renderer-marked --savenpm i hexo-renderer-markdown-it --savenpm i @traptitech/markdown-it-katex --save 并在_config.yml中加入（注意缩进）：123456789101112131415161718markdown: preset: &#x27;default&#x27; render: html: true xhtmlOut: true breaks: true langPrefix: &#x27;language-&#x27; linkify: true typographer: true quotes: &#x27;“”‘’&#x27; plugins: - plugin: name: &#x27;@traptitech/markdown-it-katex&#x27; options: # see https://katex.org/docs/options.html blockClass: &quot;math-block&quot; strict: false throwOnError: false errorColor: &quot;#cc0000&quot; 单纯做了上面的操作之后会出现行内数字/字母重复渲染的现象，也即一遍纯文本一遍公式文本，例如’ISP’会被渲染成’ISPISPISPISP’ 在文章头部加上katex: true即可 静态图片问题 使用相对于source文件夹的绝对路径，例如/assets/...代表存在/blog/sources/assets/...下，这样在本地md可能显示会有问题，但是stellar可以正常生成"},{"title":"杂记","path":"/freenotes/index.html","content":"目测本文会经常记录一些环境配置相关的问题www WSL配置Chrome环境 在wsl环境下进行一些Web相关的开发时需要使用chrome来进行，因此我们需要在其中安装chrome浏览器，总结出可行的步骤如下： 换源，否则在apt install的时候会出现404的错误，以更换清华源为例，具体方法为： 进入/etc/apt文件夹，保存一份source.list的副本（副本名字任取）： $ cd /etc/apt &amp;&amp; cp ./source.list ./source.copy.list lsb_release -a查看wsl版本相关信息 前往清华镜像源网址 找到自己对应的版本格式对应的镜像信息，例如本人是Ubuntu 22.04 LTS(jammy) 利用vim等工具将source.list中的内容修改为清华镜像的内容 更新apt： $ sudo apt-get upgrade 进入想要安装的目录，依次执行： 123$ wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb$ sudo apt install --fix-broken -y$ sudo dpkg -i google-chrome-stable_current_amd64.deb 使用google-chrome --version确认已安装成功 参考资料：https://blog.csdn.net/m0_63834988/article/details/135044587https://blog.csdn.net/m0_63834988/article/details/135044587 https://blog.csdn.net/Jason_Todd/article/details/125479130https://blog.csdn.net/Jason_Todd/article/details/125479130 尚未解决的问题 无法显示中文 谷歌搜索不能进行（代理？ 会报一些关于dbus的错误，例如Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are &quot;tcp&quot; and on UNIX &quot;unix&quot;)等等比较多的 Windows环境配置问题 Anaconda在不同环境下python的优先级不同，有的用本地的python有得用虚拟环境里的，原因未知 PyQt开发问题记录 QSplitter 利用setSizes([., .])来设置弹性框比例的时候，如果我们期待最终的比例为x:yx: yx:y，则我们需要使用splitter.setSizes[1000x, 1000y]，这是因为： 输入的列表中的元素都小于等于真实的长度，则不会发生变化 如果有一方大于真实值，则按照比例缩放 Latex使用问题记录 minipage 如果想让多个minipage在水平方向上排列，则需要所有组件水平方向上的宽度之和小于\\linewidth vscode 编译Beamer的时候vscode有的情况下会出现一些奇怪的问题，例如和lstlisting不兼容，但是关机重启之后就能编译过了（不能理解"},{"title":"关于","path":"/about/index.html","content":"欢迎来到我的个人博客！本人为清华大学计算机系二字班学生，第一次尝试写博客还请大家多多担待噢~ 这里主要想写一写平时学习中遇到的笔记和内容，也方便统一管理一些，当然以后也会有可能有一些随笔和杂谈之类的"}]