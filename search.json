[{"title":"manim配置记录","path":"/2025/08/19/manim配置记录/","content":"linux 配置 manim 过程中的一些问题记录 最近看 3B1B 心血来潮，想着自己整个里面的动画引擎 manim 玩玩，遂开始了配置，一开始想着是在 wsl 里面配置，但是遇到了很多奇怪的问题，总结下来是我的 wsl 里面没有装任何的渲染引擎导致的，然后里面也没装 latex，所以最后是在 windows 里面再装了一个 另外我是直接下载源码然后 pip install -e . 的，感觉如果直接 pip install manimgl 会简单很多 配置方法 如果要下载源码，完整的配置方法为： 下载 FFmpeg windows 参考 这里 linux 直接 sudo apt update &amp;&amp; sudo apt install ffmpeg 即可 下载 latex windows 可以用清华镜像，在里面找到最新的 iso 文件下载即可 linux 直接 sudo apt update &amp;&amp; sudo apt install texlive-full 注意 texlive 肥硕的身材 下载源码并安装（建议虚拟环境） 123git clone https://github.com/3b1b/manim.gitcd manimpip install -e . 如果只希望使用 manim 工具，将最后一项换成 pip install manimgl 即可 问题记录 python 版本问题 官方推荐的版本是 &gt;=3.7，README 里面写了如下命令 conda create -n manim python=3.8，所以我第一次装的时候就按照 python 3.8 来装了，很快遇到第一个问题： 123456789manim_slides/slide/manimlib.py:4: in &lt;module&gt; from manimlib import Scene, ThreeDCamera.venv/lib/python3.9/site-packages/manimlib/__init__.py:12: in &lt;module&gt; from manimlib.window import *.venv/lib/python3.9/site-packages/manimlib/window.py:20: in &lt;module&gt; class Window(PygletWindow):.venv/lib/python3.9/site-packages/manimlib/window.py:117: in Window def on_mouse_motion(self, x: int, y: int, dx: int, dy: int) -&gt; None:TypeError: &#x27;staticmethod&#x27; object is not callable 虽然我想出的第一个办法是把 @staticmethod 都注释了（而且还真有用），但是这显然很愚蠢，然后我在 issue 里面翻到了 这个 省流：python &lt; 3.10 的时候是不支持静态方法被调用的，这是 python 本身的 bug，然后这个代码太 OOP 导致静态方法在某些神奇地方被调用而出错 因此需要用 python &gt;= 3.10 OpenGL 依赖问题 解决了上述版本问题之后其实有很多问题也一并得到了解决，包括 setup.cfg 中的很多包版本问题 之后，运行的时候会在尝试 from OpenGL.GL import * as gl 的时候出现： 1234567891011Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;/home/ywang/miniconda3/envs/manim/lib/python3.11/site-packages/OpenGL/GL/__init__.py&quot;, line 4, in &lt;module&gt; from OpenGL.GL.VERSION.GL_1_1 import * File &quot;/home/ywang/miniconda3/envs/manim/lib/python3.11/site-packages/OpenGL/GL/VERSION/GL_1_1.py&quot;, line 14, in &lt;module&gt; from OpenGL.raw.GL.VERSION.GL_1_1 import * File &quot;/home/ywang/miniconda3/envs/manim/lib/python3.11/site-packages/OpenGL/raw/GL/VERSION/GL_1_1.py&quot;, line 7, in &lt;module&gt; from OpenGL.raw.GL import _errors File &quot;/home/ywang/miniconda3/envs/manim/lib/python3.11/site-packages/OpenGL/raw/GL/_errors.py&quot;, line 4, in &lt;module&gt; _error_checker = _ErrorChecker( _p, _p.GL.glGetError )AttributeError: &#x27;NoneType&#x27; object has no attribute &#x27;eglGetCurrentContext&#x27; 首先我在这个 issue 下面找到了解决方案，即： 12cd /usr/lib/x86_64-linux-gnusudo ln -s libglut.so.3.12 libglut.so.3 看上去是在帮助系统能够找到 libglut 这个库，但是这个方法对我并没有作用 最后在这个 issue 下面找到了有用的解决方案，本质是没有安装各种图形化引擎： 123sudo apt-get install freeglut3-devsudo apt install freeglut3-dev freeglut3 libgl1-mesa-dev libglu1-mesa-dev libxext-dev libxt-devsudo apt install python3-opengl libgl1-mesa-glx libglu1-mesa 遂成功运行样例 最终解决 然后样例跑到一半炸了 一看报错：no latex，然后发现我好像确实没有用 wsl 写过 latex，但是又不太想在 wsl 里面再装这一坨，于是就在 windows 里面直接重装了，花费了我整整 5 分钟就装好了，并且丝滑运行样例 生气中","tags":["manim","配置","踩坑"],"categories":["闲的"]},{"title":"计系构复习","path":"/2025/06/08/计系构复习/","content":"计算机系统结构 复习笔记 计系构 互连网络 互联函数 恒等函数I(xn−1xn−2…x1x0)=xn−1xn−2…x1x0I(x_{n - 1}x_{n - 2} \\dots x_1x_0) = x_{n - 1}x_{n - 2} \\dots x_1x_0 I(xn−1​xn−2​…x1​x0​)=xn−1​xn−2​…x1​x0​ 交换函数（把某一位取反）Cubei(xn−1xn−2…xi…x1x0)=xn−1xn−2…xi‾…x1x0\\text{Cube}_i(x_{n - 1}x_{n - 2} \\dots x_i \\dots x_1x_0) = x_{n - 1}x_{n - 2} \\dots \\overline{x_i} \\dots x_1x_0 Cubei​(xn−1​xn−2​…xi​…x1​x0​)=xn−1​xn−2​…xi​​…x1​x0​ 均匀洗牌（循环左移 1 位）σ(xn−1xn−2…x1x0)=xn−2…x1x0xn−1\\sigma(x_{n - 1}x_{n - 2} \\dots x_1x_0) = x_{n - 2} \\dots x_1x_0x_{n - 1} σ(xn−1​xn−2​…x1​x0​)=xn−2​…x1​x0​xn−1​ 逆均匀洗牌（循环右移 1 位）σ−1(xn−1xn−2…x1x0)=x0xn−1xn−2…x1\\sigma^{-1}(x_{n - 1}x_{n - 2} \\dots x_1x_0) = x_0x_{n - 1}x_{n - 2} \\dots x_1 σ−1(xn−1​xn−2​…x1​x0​)=x0​xn−1​xn−2​…x1​ 蝶式函数（交换第一位和最后一位）β(xn−1xn−2…x1x0)=x0xn−2…x1xn−1\\beta(x_{n - 1}x_{n - 2} \\dots x_1x_0) = x_0x_{n - 2} \\dots x_1x_{n - 1} β(xn−1​xn−2​…x1​x0​)=x0​xn−2​…x1​xn−1​ 反位序函数（倒序）ρ(xn−1xn−2…x1x0)=x0x1…xn−2xn−1\\rho(x_{n - 1}x_{n - 2} \\dots x_1x_0) = x_0x_1 \\dots x_{n - 2}x_{n - 1} ρ(xn−1​xn−2​…x1​x0​)=x0​x1​…xn−2​xn−1​ 移数函数（十进制编号错位）α(x)=(x±k) mod N\\alpha(x) = (x \\plusmn k) \\text{ mod } N α(x)=(x±k) mod N PM2I 函数（二进制编号某一位加减 1，之后正常进位或借位，忽略超出比特位数的进位或借位）PM2±i(xn−1xn−2…xi…x1x0)=xn−1xn−2…(xi±1)…x1x0\\text{PM2}_{\\plusmn\\text{i}}(x_{n - 1}x_{n - 2} \\dots x_i \\dots x_1x_0) = x_{n - 1}x_{n - 2} \\dots (x_i \\plusmn 1) \\dots x_1x_0 PM2±i​(xn−1​xn−2​…xi​…x1​x0​)=xn−1​xn−2​…(xi​±1)…x1​x0​ 静态互连网络 静态互联网络参数表 注： Illiac 网是指度为 4 的带弦环，同样也可以对二位网格做如下操作得到： 把网络的每一列的两个端结点连接起来 把每一行的尾结点与下一行的头结点连接起来 把最后一行的尾结点与第一行的头结点连接起来 CCC 是指带环立方体，将 k 维立方体中的每一个顶点都换成包含 k 个结点的环 动态互连网络 每一层有若干个开关，开关相当于是一个映射，将输入的 sss 个编号映射到输出的 sss 个编号上 控制方式：对各个开关模块进行控制的方式 级控制：每一级的所有开关只用一个控制信号控制，只能同时处于同一种状态 单元控制：每一个开关都有一个独立的控制信号，可各自处于不同的状态 部分级控制：第 iii 级的所有开关分别用 i+1i+1i+1 个信号控制，0≤i≤n−10\\leq i \\leq n-10≤i≤n−1","tags":["复习","计算机系统"],"categories":["计算机系统结构"]},{"title":"数值分析 - 常微分方程","path":"/2025/05/31/数值分析8/","content":"数值分析 笔记 8 常微分方程 形如： g(t,y,y′,⋯ ,y(k))=0g(t, y, y&#x27;,\\cdots, y^{(k)}) = 0 g(t,y,y′,⋯,y(k))=0 的方程称为常微分方程，其中 y=y(t)y = y(t)y=y(t) 是单变量函数，ODE 的阶数定义为未知函数的最高阶导数次数 如果最高阶导数可以分离出来，则得到显式常微分方程： y(k)(t)=f(t,y,y′,⋯ ,y(k−1))y^{(k)}(t) = f(t, y, y&#x27;, \\cdots, y^{(k - 1)}) y(k)(t)=f(t,y,y′,⋯,y(k−1)) 对于显式 ODE，我们可以令 ui(t)=y(i−1)(t)u_i(t) = y^{(i-1)}(t)ui​(t)=y(i−1)(t)，得到 kkk 个新变量，并构造得到一个一阶 ODE 方程组： {u1′(t)=u2(t)u2′(t)=u3(t)…uk′(t)=f(t,u1,u2,⋯ ,uk)\\begin{cases} u_1&#x27;(t) = u_2(t) \\\\ u_2&#x27;(t) = u_3(t) \\\\ \\dots \\\\ u_k&#x27;(t) = f(t, u_1, u_2, \\cdots, u_k) \\end{cases} ⎩⎨⎧​u1′​(t)=u2​(t)u2′​(t)=u3​(t)…uk′​(t)=f(t,u1​,u2​,⋯,uk​)​ 这样我们只用考虑一阶 ODE 的求解即可 初值问题 一般来说，如果不给定初始条件，ODE 会有无穷多个解，为了得到确定的解，会给出在 t=t0t = t_0t=t0​ 时候的函数值 y0y_0y0​，这种问题称为初值问题 而给定初始值有扰动的情况下，解得到的函数会有偏差，我们利用这个偏差来定义初值问题的稳定性： 如果 t→∞t\\to\\inftyt→∞ 的时候 Δy∈(c1,c2)\\Delta y \\in (c_1, c_2)Δy∈(c1​,c2​)，即自变量充分大时偏差有界，则称该问题稳定 如果 lim⁡t→∞Δy=∞\\lim\\limits_{t\\to\\infty}\\Delta y = \\inftyt→∞lim​Δy=∞，即无穷远处偏差发散为无穷，则称该问题不稳定 如果 lim⁡t→∞Δy=0\\lim\\limits_{t\\to\\infty}\\Delta y = 0t→∞lim​Δy=0，即无穷远处偏差趋近于 000，则称该问题渐进稳定 考虑下列 ODE （称为模型问题）的稳定性：{y′=λyy(t0)=y0\\begin{cases} y&#x27; = \\lambda y \\\\ y(t_0) = y_0\\end{cases}{y′=λyy(t0​)=y0​​其对应的解为：y(t)=y0eλ(t−t0)y(t) = y_0 e^{\\lambda(t - t_0)}y(t)=y0​eλ(t−t0​)给定扰动后，初值变为：y(t0)=t0+δy(t_0) = t_0 + \\deltay(t0​)=t0​+δ解为：y^(t)=(y0+δ)eλ(t−t0)\\hat{y}(t) = (y_0 + \\delta)e^{\\lambda(t - t_0)}y^​(t)=(y0​+δ)eλ(t−t0​)因此偏差为：Δy=δeλ(t−t0)\\Delta y = \\delta e^{\\lambda(t - t_0)}Δy=δeλ(t−t0​)因此当 λ≤0\\lambda \\leq 0λ≤0 时，问题稳定，反之不稳定 对于非线性 ODE 来说，其稳定性分析比线性情况更复杂$一个重要的方法是局部线性化，即在特定点附近用线性 ODE 近似原方程： 非线性 ODE 的局部稳定性分析 考虑一般形式的非线性 ODE： y′=f(t,y)y&#x27; = f(t, y) y′=f(t,y) 在任意点 (tc,yc)(t_c, y_c)(tc​,yc​) 处进行泰勒展开： f(t,y)=f(tc,yc)+∂f∂t∣(tc,yc)(t−tc)+J⋅(y−yc)+⋯f(t, y) = f(t_c, y_c) + \\dfrac{\\partial f}{\\partial t}\\bigg|_{(t_c,y_c)}(t - t_c) + \\boldsymbol{J} \\cdot (y - y_c) + \\cdots f(t,y)=f(tc​,yc​)+∂t∂f​​(tc​,yc​)​(t−tc​)+J⋅(y−yc​)+⋯ 其中雅可比矩阵 J=∂f∂y∣(tc,yc)\\boldsymbol{J} = \\dfrac{\\partial f}{\\partial y}\\bigg|_{(t_c,y_c)}J=∂y∂f​​(tc​,yc​)​ 是函数对状态变量的偏导数矩阵，具体分析步骤如下： 局部线性近似原方程在 (tc,yc)(t_c, y_c)(tc​,yc​) 附近可近似为：y′≈J⋅y+b(t)y&#x27; \\approx \\boldsymbol{J} \\cdot y + b(t)y′≈J⋅y+b(t)稳定性判据系统的局部稳定性由雅可比矩阵 J\\boldsymbol{J}J 的特征值决定，若 J\\boldsymbol{J}J 所有特征值的实部 Re(λk)≤0\\text{Re}(\\lambda_k) \\leq 0Re(λk​)≤0，则局部稳定，反之不稳定证明若 J\\boldsymbol{J}J 可对角化 J=VΛV−1\\boldsymbol{J} = \\boldsymbol{V}\\boldsymbol{\\Lambda} \\boldsymbol{V}^{-1}J=VΛV−1，通过变量代换 x=V−1yx = \\boldsymbol{V}^{-1}yx=V−1y 可将方程组解耦为：x′=Λxx&#x27; = \\boldsymbol{\\Lambda} xx′=Λx即得到一组独立方程 xk′=λkxkx_k&#x27; = \\lambda_k x_kxk′​=λk​xk​最终，解 y(t)y(t)y(t) 的局部稳定性完全由特征值 {λk}\\{\\lambda_k\\}{λk​} 的实部决定 欧拉法 对于一阶初值问题，大部分情况下其没有解析解，因此一种常见的手段是步进地计算函数值，即分别计算： t0,t1,t2 ⋯ tn ⋯\\begin{align*} t_0,\\quad t_1,\\quad t_2 \\,\\,\\cdots\\,\\, t_n\\,\\,\\cdots \\end{align*} t0​,t1​,t2​⋯tn​⋯​ 处的函数值，其中 hn=tn+1−tnh_n = t_{n + 1} - t_nhn​=tn+1​−tn​ 被称为步长，计算方法为： yn+1=G(yn+1,yn,yn−1,…,yn−k)y_{n + 1} = G(y_{n + 1}, y_n, y_{n - 1}, \\dots, y_{n - k}) yn+1​=G(yn+1​,yn​,yn−1​,…,yn−k​) 其中 GGG 是近似方程，分类包括： 若 k=0k = 0k=0 则称为单步法，反之为多步法 若 GGG 与 yn+1y_{n + 1}yn+1​ 无关，则称为显格式方法，反之为隐格式方法 当求解 y′=f(t,y)y&#x27; = f(t, y)y′=f(t,y) 的时候，一种显式单步法为： yn+1=yn+hnf(tn,yn)y_{n + 1} = y_n + h_nf(t_n, y_n) yn+1​=yn​+hn​f(tn​,yn​) 这被称之为欧拉法 推导是容易的，例如使用向前差分公式： f(tn,yn)=y′(tn)≈yn+1−ynhnf(t_n, y_n) = y&#x27;(t_n) \\approx \\dfrac{y_{n + 1} - y_n}{h_n} f(tn​,yn​)=y′(tn​)≈hn​yn+1​−yn​​ 或者使用数值积分的方式： yn+1−yn=∫tntn+1y′(s)ds=∫tntn+1f(s,y(s))ds≈hnf(tn,yn)y_{n + 1} - y_{n} = \\int_{t_n}^{t_{n + 1}}y&#x27;(s)ds = \\int_{t_n}^{t_{n + 1}}f(s, y(s))ds \\approx h_nf(t_n, y_n) yn+1​−yn​=∫tn​tn+1​​y′(s)ds=∫tn​tn+1​​f(s,y(s))ds≈hn​f(tn​,yn​) 稳定性 在计算函数近似值的过程中，我们需要考虑误差在递推计算过程中的传播过程，即欧拉法的稳定性，我们定义： 如果在节点 tnt_ntn​ 上，函数的近似值产生的扰动为 δn\\delta_nδn​，这个扰动引起节点 tmt_mtm​ 上的误差为 δm\\delta_mδm​，则该方法稳定等价于 ∣δm∣≤∣δn∣|\\delta_m| \\leq |\\delta_n|∣δm​∣≤∣δn​∣ 对于欧拉法来说，其 δn\\delta_nδn​ 在下一个节点上产生的误差为： δn+1=δn+hn[f(tn,yn+δn)−f(tn,yn)]=δn+hn[δn∂f∂y(tn,yn)+O(δn2)]=δn[1+hn∂f∂y(tn,yn)]+O(δn2)\\begin{align*} \\delta_{n + 1} &amp;= \\delta_n + h_n[f(t_n, y_n + \\delta_n) - f(t_n, y_n)] \\\\ &amp;= \\delta_n + h_n\\Big[\\delta_n\\dfrac{\\partial f}{\\partial y}(t_n, y_n) + O(\\delta^{2}_n)\\Big] \\\\ &amp;= \\delta_n \\Big[1 + h_n\\dfrac{\\partial f}{\\partial y}(t_n, y_n)\\Big] + O(\\delta^{2}_n) \\end{align*} δn+1​​=δn​+hn​[f(tn​,yn​+δn​)−f(tn​,yn​)]=δn​+hn​[δn​∂y∂f​(tn​,yn​)+O(δn2​)]=δn​[1+hn​∂y∂f​(tn​,yn​)]+O(δn2​)​ 因此当 ∣1+hn∂f∂y(tn,yn)∣≤1|1 + h_n\\dfrac{\\partial f}{\\partial y}(t_n, y_n)| \\leq 1∣1+hn​∂y∂f​(tn​,yn​)∣≤1 的时候，这种方法是稳定的 局部截断误差 在计算 yn+1=G(yn+1,yn,yn−1,…,yn−k)y_{n + 1} = G(y_{n + 1}, y_n, y_{n - 1}, \\dots, y_{n - k}) yn+1​=G(yn+1​,yn​,yn−1​,…,yn−k​) 的时候，假设 0≤i≤k0 \\leq i \\leq k0≤i≤k 的时候，yn−i=y(tn−i)y_{n - i} = y(t_{n - i})yn−i​=y(tn−i​)，即这些数据是准确的，则定义局部截断误差为： ln+1=y(tn+1)−yn+1l_{n + 1} = y(t_{n + 1}) - y_{n + 1} ln+1​=y(tn+1​)−yn+1​ 对于模型问题来说，解为 y=y0eλ(t−t0)y = y_0 e^{\\lambda(t - t_0)}y=y0​eλ(t−t0​)，局部截断误差为： ln+1=y(tn)ehnλ−[y(tn)+hnλy(tn)]=y(tn)(ehnλ−1−hnλ)=O(hn2)\\begin{align*} l_{n + 1} &amp;= y(t_{n})e^{h_n\\lambda} - [y(t_n) + h_n\\lambda y(t_n)] \\\\ &amp;= y(t_n)(e^{h_n\\lambda} - 1 - h_n\\lambda) = O(h^{2}_n) \\end{align*} ln+1​​=y(tn​)ehn​λ−[y(tn​)+hn​λy(tn​)]=y(tn​)(ehn​λ−1−hn​λ)=O(hn2​)​ 并且可以证明，任意欧拉法的局部截断误差都是 O(h2)O(h^2)O(h2) 的 如果某种解法的局部截断误差为 O(hp+1)O(h^{p + 1})O(hp+1)，则我们称这个方法具有 ppp 阶准确度 相容性 对于一般的显式单步法： yn+1=yn+hnφ(tn,yn,hn)y_{n + 1} = y_n + h_n\\varphi(t_n, y_n, h_n) yn+1​=yn​+hn​φ(tn​,yn​,hn​) 其满足相容性当且仅当其准确度阶数不小于 1，等价于： φ(t,y,0)=f(t,y)\\varphi(t, y, 0) = f(t, y) φ(t,y,0)=f(t,y) 向后欧拉法与梯形法 在欧拉法的推导中，一种是使用向前差分公式进行的，如果将这个公式换为向后差分公式或中心差分公式，则得到向后欧拉法或梯形法，对应的公式分别为： yn+1=yn+hnf(tn+1,yn+1)yn+1=yn+12hn[f(tn,yn)+f(tn+1,yn+1)]\\begin{align*} y_{n + 1} &amp;= y_n + h_nf(t_{n + 1}, y_{n + 1}) \\\\ y_{n + 1} &amp;= y_n + \\dfrac{1}{2}h_n[f(t_{n}, y_{n}) + f(t_{n + 1}, y_{n + 1})] \\end{align*} yn+1​yn+1​​=yn​+hn​f(tn+1​,yn+1​)=yn​+21​hn​[f(tn​,yn​)+f(tn+1​,yn+1​)]​ 这两种方法都是隐式单步法 可以证明的是，这两种方法的效果都远高于向前欧拉法，以稳定的模型问题即 λ≤0\\lambda \\leq 0λ≤0 为例： 向后欧拉法：yn+1=yn+hnλyn+1⇒yn+1=11−hnλyny_{n + 1} = y_{n} + h_n\\lambda y_{n + 1} \\Rightarrow y_{n + 1} = \\dfrac{1}{1 - h_n\\lambda}y_n yn+1​=yn​+hn​λyn+1​⇒yn+1​=1−hn​λ1​yn​ 则误差的传播：∣δn+1∣=1∣1−hnλ∣∣δn∣|\\delta_{n + 1}| = \\dfrac{1}{|1 - h_n\\lambda|}|\\delta_n| ∣δn+1​∣=∣1−hn​λ∣1​∣δn​∣ 由于 λ≤0,hn&gt;0\\lambda \\leq 0, h_n &gt; 0λ≤0,hn​&gt;0，因此一定有 ∣δn+1∣≤∣δn∣|\\delta_{n + 1}| \\leq |\\delta_n|∣δn+1​∣≤∣δn​∣ 梯形法：yn+1=yn+12hn(λyn+λyn+1)⇒yn+1=2+hnλ2−hnλyny_{n + 1} = y_{n} + \\dfrac{1}{2}h_n(\\lambda y_n + \\lambda y_{n + 1}) \\Rightarrow y_{n + 1} = \\dfrac{2 + h_n\\lambda}{2 - h_n\\lambda}y_n yn+1​=yn​+21​hn​(λyn​+λyn+1​)⇒yn+1​=2−hn​λ2+hn​λ​yn​ 则误差的传播：∣δn+1∣=∣2+hnλ2−hnλ∣∣δn∣|\\delta_{n + 1}| = |\\dfrac{2 + h_n\\lambda}{2 - h_n\\lambda}||\\delta_n| ∣δn+1​∣=∣2−hn​λ2+hn​λ​∣∣δn​∣ 由于 λ≤0,hn&gt;0\\lambda \\leq 0, h_n &gt; 0λ≤0,hn​&gt;0，因此也一定有 ∣δn+1∣≤∣δn∣|\\delta_{n + 1}| \\leq |\\delta_n|∣δn+1​∣≤∣δn​∣ 这说明，无论步长如何，这两种方法都是稳定的，这被称为 无条件稳定，并且可以证明这对于任意的方程都是成立的 准确度方面： 向后欧拉法具有 111 阶准确度 梯形法具有 222 阶准确度 Runge-Kutta 方法 该方法源自欧拉法推导过程中的数值积分方法，即： y(tn+1)=y(tn)+∫tntn+1f(s,y(s))dsy(t_{n + 1}) = y(t_{n}) + \\int_{t_{n}}^{t_{n + 1}}f(s, y(s))ds y(tn+1​)=y(tn​)+∫tn​tn+1​​f(s,y(s))ds 将这个积分展开成一般的机械求积公式并适当变形，得到： yn+1=yn+hn∑i=1rcif(tn+λihn,y(tn+λihn))\\begin{align} y_{n + 1} = y_{n} + h_n\\sum\\limits_{i = 1}^{r}c_if(t_n + \\lambda_i h_n, y(t_n + \\lambda_i h_n)) \\end{align} yn+1​=yn​+hn​i=1∑r​ci​f(tn​+λi​hn​,y(tn​+λi​hn​))​​ 其中 λi∈[0,1]\\lambda_{i} \\in [0, 1]λi​∈[0,1] 是积分节点的相对距离因子，rrr 为区间划分的数量 很显然，如果我们令 r=1,c1=1,λ1=0r = 1, c_1 = 1, \\lambda_1 = 0r=1,c1​=1,λ1​=0，则得到了欧拉法 而对于更一般的情况，最大的问题在与我们只知道这个函数在 tnt_ntn​ 处的值，而无法得知其在 tn+λihnt_n + \\lambda_ih_ntn​+λi​hn​ 处的值，于是我们希望逐步使用已知的值来近似得到积分节点处的值，这便得到了一般的 Runge-Kutta 公式，具体来说： 令0=λ1&lt;λ2&lt;λ3&lt;⋯&lt;λr0 = \\lambda_1 &lt; \\lambda_2 &lt; \\lambda_3 &lt; \\dots &lt; \\lambda_r0=λ1​&lt;λ2​&lt;λ3​&lt;⋯&lt;λr​则第一个积分节点处的导数值是准确的：k1=f(tn+λ1hn,y(tn+λ1hn))=f(tn,yn)k_1 = f\\big(t_n + \\lambda_1 h_n, y(t_n + \\lambda_1 h_n)\\big) = f(t_n, y_n)k1​=f(tn​+λ1​hn​,y(tn​+λ1​hn​))=f(tn​,yn​)利用欧拉法，也即公式 (1)(1)(1) 的一种特例，来估计第二个节点处的函数值：y(tn+λ2hn)=y(tn)+λ2hnk1=yn+λ2hnk1y(t_n + \\lambda_2 h_n) = y(t_n) + \\lambda_2h_nk_1 = y_n + \\lambda_2h_nk_1y(tn​+λ2​hn​)=y(tn​)+λ2​hn​k1​=yn​+λ2​hn​k1​因此第二个节点处的导数值为：k2=f(tn+λ2hn,yn+λ2hnk1)k_2 = f\\big(t_n + \\lambda_2 h_n, y_n + \\lambda_2h_nk_1\\big)k2​=f(tn​+λ2​hn​,yn​+λ2​hn​k1​)之后，利用前两个节点处的导数值来估计第三个节点处的函数值：y(tn+λ3hn)=yn+hn(μ31k1+μ32k2)y(t_n + \\lambda_3 h_n) = y_n + h_n(\\mu_{31}k_1 + \\mu_{32}k_2)y(tn​+λ3​hn​)=yn​+hn​(μ31​k1​+μ32​k2​)也可以第三个节点处的导数值，之后每一个节点处的函数值都使用前面所有节点处的信息来得到，也即依次对每一个节点使用公式 (1)(1)(1)最终，得到总的 R-K 公式为：{yn+1=yn+hn∑i=1rcikik1=f(tn,yn)k2=f(tn+λ2hn,yn+λ2hnk1)ki=f(tn+λihn,yn+hn∑j=1r−1μijkj)i≥3\\begin{cases} y_{n + 1} = y_n + h_n\\sum\\limits_{i = 1}^{r}c_ik_i \\\\ k_1 = f(t_n, y_n) \\\\ k_2 = f\\big(t_n + \\lambda_2 h_n, y_n + \\lambda_2h_nk_1\\big) \\\\ k_i = f\\big(t_n + \\lambda_i h_n, y_n + h_n\\sum\\limits_{j = 1}^{r - 1}\\mu_{ij}k_j) &amp; i \\geq 3\\end{cases}⎩⎨⎧​yn+1​=yn​+hn​i=1∑r​ci​ki​k1​=f(tn​,yn​)k2​=f(tn​+λ2​hn​,yn​+λ2​hn​k1​)ki​=f(tn​+λi​hn​,yn​+hn​j=1∑r−1​μij​kj​)​i≥3​其中 λi,ci,μij\\lambda_i, c_i, \\mu_{ij}λi​,ci​,μij​ 都是待定参数，这些参数一般是根据特定的准确度需求去求出的我们将这个 R-K 公式称为 r 级公式 下面介绍几种特殊的 R-K 公式 2 级 R-K 方法 可以得到，其一般的公式为： {yn+1=yn+hn(c1k1+c2k2)k1=f(tn,yn)k2=f(tn+λ2hn,yn+λ2hnk1)\\begin{cases} y_{n + 1} = y_n + h_n(c_1k_1 + c_2k_2) \\\\ k_1 = f(t_n, y_n) \\\\ k_2 = f\\big(t_n + \\lambda_2 h_n, y_n + \\lambda_2h_nk_1\\big) \\\\ \\end{cases} ⎩⎨⎧​yn+1​=yn​+hn​(c1​k1​+c2​k2​)k1​=f(tn​,yn​)k2​=f(tn​+λ2​hn​,yn​+λ2​hn​k1​)​ 则一共需要确定 c1,c2,λ2c_1, c_2, \\lambda_2c1​,c2​,λ2​ 三个参数的值 下面以模型问题为例，研究应该如何确定这三个参数，代入公式： yn+1=yn+hnc1λyn+hnc2λ(yn+λ2hnλyn)=yn(1+(c1+c2)hnλ+c2λ2(hnλ)2)\\begin{align*} y_{n+1} &amp;= y_n + h_nc_1\\lambda y_n + h_nc_2\\lambda(y_n +\\lambda_2 h_n\\lambda y_n) \\\\ &amp;= y_n(1 + (c_1 + c_2)h_n\\lambda + c_2\\lambda_2(h_n\\lambda)^{2}) \\end{align*} yn+1​​=yn​+hn​c1​λyn​+hn​c2​λ(yn​+λ2​hn​λyn​)=yn​(1+(c1​+c2​)hn​λ+c2​λ2​(hn​λ)2)​ 而对 y(tn+1)y(t_{n+1})y(tn+1​) 作 Taylor 展开可以得知，这种方法最多有 2 阶准确度，即： ln+1=O(h3)l_{n + 1} = O(h^3) ln+1​=O(h3) 此时要求： {c1+c2=1c2λ2=12\\begin{cases} c_1 + c_2 = 1 \\\\[1em] c_2\\lambda_2 = \\dfrac{1}{2} \\end{cases} ⎩⎨⎧​c1​+c2​=1c2​λ2​=21​​ 这个方程有无穷多组解，比较经典的解是： Heun 方法（改进的欧拉法）：c1=c2=1/2,λ2=1c_1 = c_2 = 1/2, \\lambda_2 = 1c1​=c2​=1/2,λ2​=1，对应公式为： {yn+1=yn+hn2(k1+k2)k1=f(tn,yn)k2=f(tn+hn,yn+hnk1)\\begin{cases} y_{n + 1} = y_n + \\dfrac{h_n}{2}(k_1 + k_2) \\\\[1em] k_1 = f(t_n, y_n) \\\\[1em] k_2 = f\\big(t_n + h_n, y_n + h_nk_1\\big) \\end{cases} ⎩⎨⎧​yn+1​=yn​+2hn​​(k1​+k2​)k1​=f(tn​,yn​)k2​=f(tn​+hn​,yn​+hn​k1​)​ 中点公式：c1=0,c2=1,λ2=1/2c_1 = 0, c_2 = 1, \\lambda_2 = 1/2c1​=0,c2​=1,λ2​=1/2，对应公式为： {yn+1=yn+hnk2k1=f(tn,yn)k2=f(tn+hn2,yn+hn2k1)\\begin{cases} y_{n + 1} = y_n + h_nk_2 \\\\[1em] k_1 = f(t_n, y_n) \\\\[1em] k_2 = f\\big(t_n + \\dfrac{h_n}{2}, y_n + \\dfrac{h_n}{2}k_1\\big) \\end{cases} ⎩⎨⎧​yn+1​=yn​+hn​k2​k1​=f(tn​,yn​)k2​=f(tn​+2hn​​,yn​+2hn​​k1​)​ 这种方法其实就是用中点矩形法计算机械求积公式 2 级公式的稳定条件是： hn≤−2λh_n \\leq \\frac{-2}{\\lambda} hn​≤λ−2​ 3 级 R-K 方法 和 2 级的方法类似，3 级最多有 3 阶准确度，也能得到无数种，两种经典的解为： 3 阶 Kutta 公式： {yn+1=yn+hn6(k1+4k2+k3)k1=f(tn,yn)k2=f(tn+hn2,yn+hn2k1)k3=f(tn+hn,yn−hnk1+2hnk2)\\begin{cases} y_{n + 1} = y_n + \\dfrac{h_n}{6}(k_1 + 4k_2 + k_3) \\\\[1em] k_1 = f(t_n, y_n) \\\\[1em] k_2 = f(t_n + \\dfrac{h_n}{2}, y_n + \\dfrac{h_n}{2}k_1) \\\\[1em] k_3 = f(t_n + h_n, y_n - h_nk_1 + 2h_nk_2) \\end{cases} ⎩⎨⎧​yn+1​=yn​+6hn​​(k1​+4k2​+k3​)k1​=f(tn​,yn​)k2​=f(tn​+2hn​​,yn​+2hn​​k1​)k3​=f(tn​+hn​,yn​−hn​k1​+2hn​k2​)​ 3 阶 Ralston 公式： {yn+1=yn+hn9(2k1+3k2+4k3)k1=f(tn,yn)k2=f(tn+hn2,yn+hn2k1)k3=f(tn+3hn4,yn+3hn4k2)\\begin{cases} y_{n + 1} = y_n + \\dfrac{h_n}{9}(2k_1 + 3k_2 + 4k_3) \\\\[1em] k_1 = f(t_n, y_n) \\\\[1em] k_2 = f(t_n + \\dfrac{h_n}{2}, y_n + \\dfrac{h_n}{2}k_1) \\\\[1em] k_3 = f(t_n + \\dfrac{3h_n}{4}, y_n + \\dfrac{3h_n}{4}k_2) \\end{cases} ⎩⎨⎧​yn+1​=yn​+9hn​​(2k1​+3k2​+4k3​)k1​=f(tn​,yn​)k2​=f(tn​+2hn​​,yn​+2hn​​k1​)k3​=f(tn​+43hn​​,yn​+43hn​​k2​)​ 3 级公式的稳定条件是： hn≤−2.51λh_n \\leq \\frac{-2.51}{\\lambda} hn​≤λ−2.51​ 4 级 R-K 方法 和 2 级的方法类似，4 级最多有 4 阶准确度，也能得到无数种，一种经典的解为： {yn+1=yn+hn6(k1+2k2+2k3+k4)k1=f(tn,yn)k2=f(tn+hn2,yn+hn2k1)k3=f(tn+hn2,yn+hn2k2)k4=f(tn+hn,yn+hnk3)\\begin{cases} y_{n + 1} = y_n + \\dfrac{h_n}{6}(k_1 + 2k_2 + 2k_3 + k_4) \\\\[1em] k_1 = f(t_n, y_n) \\\\[1em] k_2 = f(t_n + \\dfrac{h_n}{2}, y_n + \\dfrac{h_n}{2}k_1) \\\\[1em] k_3 = f(t_n + \\dfrac{h_n}{2}, y_n + \\dfrac{h_n}{2}k_2) \\\\[1em] k_4 = f(t_n + h_n, y_n + h_nk_3) \\end{cases} ⎩⎨⎧​yn+1​=yn​+6hn​​(k1​+2k2​+2k3​+k4​)k1​=f(tn​,yn​)k2​=f(tn​+2hn​​,yn​+2hn​​k1​)k3​=f(tn​+2hn​​,yn​+2hn​​k2​)k4​=f(tn​+hn​,yn​+hn​k3​)​ 对于这种方法，如果我们令 f(t,y)=f(t)f(t, y) = f(t)f(t,y)=f(t)，也即这个常微分方程是一个求积分的问题，则这种方法就等价于 Simpson 公式 4 级公式的稳定条件是： hn≤−2.78λh_n \\leq \\frac{-2.78}{\\lambda} hn​≤λ−2.78​ 多步法 多步法是指在公式： yn+1=G(yn+1,yn,yn−1,…,yn−k)y_{n + 1} = G(y_{n + 1}, y_n, y_{n - 1}, \\dots, y_{n - k}) yn+1​=G(yn+1​,yn​,yn−1​,…,yn−k​) 中，k≥1k \\geq 1k≥1 的方法，一般来说，求解初值问题的方法是线性多步法，固定步长为 hhh，则 mmm 步对应的公式可以写成： yn+1=∑i=1mαiyn+1−i+h∑i=0mβif(tn+1−i,yn+1−i)y_{n + 1} = \\sum\\limits_{i = 1}^{m}\\alpha_i y_{n + 1 - i} + h\\sum\\limits_{i = 0}^{m}\\beta_i f(t_{n + 1 - i}, y_{n + 1 - i}) yn+1​=i=1∑m​αi​yn+1−i​+hi=0∑m​βi​f(tn+1−i​,yn+1−i​) 通过 Taylor 展开等方法，可以证明，在达到 ppp 阶准确度时，需要让 Taylor 展开的前 p+1p + 1p+1 个系数为零，其中前三个对应的方程为： {∑i=1mαi=1∑i=1miαi=∑i=0mβi12∑i=1mi2αi=∑i=1miβi\\begin{cases} \\sum\\limits_{i = 1}^{m} \\alpha_{i} = 1 \\\\[1em] \\sum\\limits_{i = 1}^{m}i\\alpha_{i} = \\sum\\limits_{i = 0}^{m} \\beta_i \\\\[1em] \\dfrac{1}{2}\\sum\\limits_{i = 1}^{m}i^{2}\\alpha_{i} = \\sum\\limits_{i = 1}^{m} i\\beta_i \\\\[1em] \\end{cases} ⎩⎨⎧​i=1∑m​αi​=1i=1∑m​iαi​=i=0∑m​βi​21​i=1∑m​i2αi​=i=1∑m​iβi​​ 其中前两个方程保证了相容性 由于这种方法比较繁琐，一种更简单的保证有 ppp 阶准确度的方式是： 若 y(t)=ti(i=0,1,…,p)y(t) = t^{i}\\quad (i = 0, 1, \\dots, p)y(t)=ti(i=0,1,…,p) 均满足 ln+1=0l_{n + 1} = 0ln+1​=0，则满足条件的参数列对应的多步法一定至少有 ppp 阶准确度 Adams 公式 一种常用的多步法公式： yn+1=yn+h∑i=0mβif(tn+1−i,yn+1−i)y_{n + 1} = y_n + h\\sum\\limits_{i = 0}^{m}\\beta_i f(t_{n + 1 - i}, y_{n + 1 - i}) yn+1​=yn​+hi=0∑m​βi​f(tn+1−i​,yn+1−i​) 则利用 Taylor 展开可以推出，当 β0=0\\beta_0 = 0β0​=0 的时候，其参数的系数矩阵为 Vandermonde 矩阵的转置，因此一定是非奇异的，有唯一解 可以证明：当 β0=0\\beta_0 = 0β0​=0 时，其一定至少有 mmm 阶准确度，反之一定具有至少 m+1m + 1m+1 阶准确度 由于求解 Vandermonde 矩阵为系数的方程组求解比较困难，一种求系数的方式是，将数值积分公式中的被积函数 f(s,y(s))f(s, y(s))f(s,y(s)) 用 Langrange 插值，之后直接积分，并且根据系数对应关系得到 βi\\beta_iβi​ 利用这种方法，可以得到几种常用的 Adams 公式，例如： 显式 4 阶 Adams-Bashforth 公式：yn+1=yn+h24(55fn−59fn−1+37fn−2−9fn−3)y_{n + 1} = y_{n} + \\dfrac{h}{24}(55f_n - 59f_{n - 1} + 37f_{n - 2} - 9f_{n - 3}) yn+1​=yn​+24h​(55fn​−59fn−1​+37fn−2​−9fn−3​) 隐式 4 阶 Adams-Bashforth 公式：yn+1=yn+h24(9fn+1+19fn−5fn−1+fn−2)y_{n + 1} = y_{n} + \\dfrac{h}{24}(9f_{n + 1} + 19f_{n} - 5f_{n - 1} + f_{n - 2}) yn+1​=yn​+24h​(9fn+1​+19fn​−5fn−1​+fn−2​) Adams 参数表为： 几种显式公式的系数 几种隐式公式的系数 其中稳定阈值为 qqq 代表该方法在 (q,0)(q, 0)(q,0) 上稳定，而误差常数则是指局部截断误差中的首项系数","tags":["笔记","ODE"],"categories":["数值分析"]},{"title":"数值分析 - 数值微分与数值积分","path":"/2025/05/24/数值分析7/","content":"数值分析 笔记 7 数值微分与数值积分 数值积分 指的是用数值方法计算定积分，在一些解析解非常复杂，或根本没有解析解的情况下使用 根据定积分的定义： I(f)=∫abf(x)dx=lim⁡n→∞∑i=0n(xi+1−xi)f(ξi)I(f) = \\int_a^b f(x)dx = \\lim\\limits_{n \\to \\infty}\\sum\\limits_{i = 0}^{n}(x_{i + 1} - x_{i})f(\\xi_i) I(f)=∫ab​f(x)dx=n→∞lim​i=0∑n​(xi+1​−xi​)f(ξi​) 则一种近似是取一个充分大的 nnn，计算： In(f)=∑i=0nAif(xi)I_n(f) = \\sum\\limits_{i = 0}^{n}A_if(x_i) In​(f)=i=0∑n​Ai​f(xi​) 其中 AiA_iAi​ 称为积分系数，xkx_kxk​ 称为积分节点 插值型求积公式 使用多项式函数 p(x)p(x)p(x) 来插值原函数 f(x)f(x)f(x)，则将 I(f)I(f)I(f) 转化为了易于计算的多项式积分形式 具体来说，在区间 [a,b][a, b][a,b] 上取 n+1n + 1n+1 个插值点，之后使用多项式进行 Lagrange 插值，则求积公式为： In(f)=∑k=0n[f(xk)∫ablk(x)dx]I_n(f) = \\sum\\limits_{k = 0}^{n}\\Big[f(x_k)\\int_a^bl_k(x)dx\\Big] In​(f)=k=0∑n​[f(xk​)∫ab​lk​(x)dx] 当 n=0,1n = 0, 1n=0,1 时： I0(f)=(b−a)f(a+b2)I1(f)=b−a2[f(a)+f(b)]\\begin{align*} I_0(f) &amp;= (b - a)f(\\frac{a + b}{2}) \\\\ I_1(f) &amp;= \\frac{b - a}{2}[f(a) + f(b)] \\end{align*} I0​(f)I1​(f)​=(b−a)f(2a+b​)=2b−a​[f(a)+f(b)]​ 数值积分的性质 积分余项 定义积分余项为： Rn(x)=I(f)−In(f)R_n(x) = I(f) - I_n(f) Rn​(x)=I(f)−In​(f) 对于插值型求积公式，有： Rn(x)=∫abf(n+1)(ξ)(n+1)!ωn+1(x)dxR_n(x) = \\int_a^b \\frac{f^{(n + 1)}(\\xi)}{(n + 1)!}\\omega_{n + 1}(x)dx Rn​(x)=∫ab​(n+1)!f(n+1)(ξ)​ωn+1​(x)dx 代数精度 定义一个求积公式的代数精度为：如果 In(f)I_n(f)In​(f) 在 fff 为次数不大于 mmm 时均准确，在 fff 为次数 m+1m + 1m+1 时不准确，则称该公式的代数精度为 mmm 可以证明的是： 求积公式的代数精度至少为 mmm 的充分必要条件是：当 f(x)=x0,x1,…,xmf(x) = x^0, x^1, \\dots, x^mf(x)=x0,x1,…,xm 时，I(f)=In(f)I(f) = I_n(f)I(f)=In​(f) 两个推论： 由于代数精度不低于 000，因此取 f(x)=1f(x) = 1f(x)=1，则有： ∑k=0nAk=b−a\\sum\\limits_{k = 0}^{n}A_k = b - a k=0∑n​Ak​=b−a In(f)I_n(f)In​(f) 至少有 nnn 阶代数精度当且仅当 In(f)I_n(f)In​(f) 是插值型求积公式 数值性质 若对于求积公式 In(f)I_n(f)In​(f)，有： lim⁡n→∞In(f)=I(f)\\lim\\limits_{n \\to\\infty}I_n(f) = I(f) n→∞lim​In​(f)=I(f) 则称该求积公式是收敛的 考虑对积分的输入进行微扰，f(x)→f~(x)f(x) \\to \\tilde{f}(x)f(x)→f~​(x)，则扰动大小为： δ=∣∣f(x)−f~(x)∣∣∞=max⁡a≤x≤b∣f(x)−f~(x)∣\\delta = ||f(x) - \\tilde{f}(x)||_\\infty = \\max\\limits_{a\\leq x \\leq b}|f(x) - \\tilde{f}(x)| δ=∣∣f(x)−f~​(x)∣∣∞​=a≤x≤bmax​∣f(x)−f~​(x)∣ 因此结果的误差为： ∣I(f)−I(f~)∣=(b−a)∣f(ξ)−f~(ξ)∣≤(b−a)δ|I(f) - I(\\tilde{f})| = (b - a)|f(\\xi) - \\tilde{f}(\\xi)| \\leq (b - a)\\delta ∣I(f)−I(f~​)∣=(b−a)∣f(ξ)−f~​(ξ)∣≤(b−a)δ 这说明求积分的问题一般是不敏感的 而使用求积公式时，输入进行微扰会导致： ∣In(f)−In(f~)∣=∣∑k=0nAk[f(xk)−f~(xk)]∣≤∑k=0n∣Ak∣∣f(xk)−f~(xk)∣≤ε∑k=0n∣Ak∣\\begin{align*} |I_n(f) - I_n(\\tilde{f})| &amp;= \\Big|\\sum\\limits_{k = 0}^{n}A_k\\big[f(x_k) - \\tilde{f}(x_k)\\big]\\Big| \\\\ &amp;\\leq \\sum\\limits_{k = 0}^{n}\\big|A_k\\big|\\big|f(x_k) - \\tilde{f}(x_k)\\big| \\\\ &amp;\\leq \\varepsilon\\sum\\limits_{k = 0}^{n}\\big|A_k\\big| \\\\ \\end{align*} ∣In​(f)−In​(f~​)∣​=​k=0∑n​Ak​[f(xk​)−f~​(xk​)]​≤k=0∑n​​Ak​​​f(xk​)−f~​(xk​)​≤εk=0∑n​​Ak​​​ 其中 ε=max⁡0≤k≤n∣f(xk)−f~(xk)∣≤δ\\varepsilon = \\max\\limits_{0\\leq k \\leq n}|f(x_k) - \\tilde{f}(x_k)| \\leq \\deltaε=0≤k≤nmax​∣f(xk​)−f~​(xk​)∣≤δ 如果我们确定所有的积分系数都为正，则： ∣In(f)−In(f~)∣≤ε(b−a)\\begin{align*} |I_n(f) - I_n(\\tilde{f})| \\leq \\varepsilon(b - a) \\\\ \\end{align*} ∣In​(f)−In​(f~​)∣≤ε(b−a)​ 也即在 Ak≥0A_k \\geq 0Ak​≥0 的情况下，求积公式是稳定的 Newton-Cotes 公式 Newton-Cotes 是插值型求积公式的一种，将一个区间 [a,b][a, b][a,b] 均匀划分为 nnn 个小区间，其积分系数为： Ak=∫ab[∏j=0j≠kn(x−xj)(xk−xj)]dxA_k = \\int_a^b \\Bigg[ \\prod\\limits_{\\substack{j = 0 \\\\j eq k}}^{n}\\frac{(x - x_j)}{(x_k - x_j)}\\Bigg] dx Ak​=∫ab​[j=0j=k​∏n​(xk​−xj​)(x−xj​)​]dx 令 x=a+thx = a + thx=a+th，其中 h=b−anh = \\dfrac{b - a}{n}h=nb−a​，则积分系数为： Ak=∫0n[∏j=0j≠kn(t−j)(k−j)]b−andt=(b−a)Ck(n)A_k = \\int_0^n \\Bigg[ \\prod\\limits_{\\substack{j = 0 \\\\j eq k}}^{n}\\frac{(t - j)}{(k - j)}\\Bigg]\\frac{b - a}{n} dt = (b - a)C_k^{(n)} Ak​=∫0n​[j=0j=k​∏n​(k−j)(t−j)​]nb−a​dt=(b−a)Ck(n)​ 其中 Ck(n)C_k^{(n)}Ck(n)​ 是与积分区间无关的系数，被称为 Cotes 系数，低阶的 Cotes 系数表为： k = 0 k = 1 k = 2 k = 3 k = 4 n = 1 12\\frac{1}{2}21​ 12\\frac{1}{2}21​ n = 2 16\\frac{1}{6}61​ 23\\frac{2}{3}32​ 16\\frac{1}{6}61​ n = 3 18\\frac{1}{8}81​ 38\\frac{3}{8}83​ 38\\frac{3}{8}83​ 18\\frac{1}{8}81​ n = 4 790\\frac{7}{90}907​ 1645\\frac{16}{45}4516​ 215\\frac{2}{15}152​ 1645\\frac{16}{45}4516​ 790\\frac{7}{90}907​ 注：n = 1 的时候即为梯形公式，且一般不使用 n=3n = 3n=3 的 N-C 公式 几个特例： 梯形公式，n=1n = 1n=1 时的 N-C 公式T(f)=(b−a)[12f(a)+12f(b)]T(f) = (b - a)\\big[\\frac{1}{2}f(a) + \\frac{1}{2}f(b)\\big] T(f)=(b−a)[21​f(a)+21​f(b)] 其余项为：RT=∫abf′′(ξ)2!(x−a)(x−b)dx=−f′′(η)12(b−a)3R_T = \\int_a^b \\frac{f&#x27;&#x27;(\\xi)}{2!}(x - a)(x - b)dx = -\\frac{f&#x27;&#x27;(\\eta)}{12}(b - a)^{3} RT​=∫ab​2!f′′(ξ)​(x−a)(x−b)dx=−12f′′(η)​(b−a)3 Simpson 公式，n=2n = 2n=2 时的 N-C 公式S(f)=(b−a)[16f(a)+23f(a+b2)+16f(b)]S(f) = (b - a)\\big[\\frac{1}{6}f(a) + \\frac{2}{3}f(\\frac{a + b}{2}) + \\frac{1}{6}f(b)\\big] S(f)=(b−a)[61​f(a)+32​f(2a+b​)+61​f(b)] 其余项为：RT=∫abf(4)(ξ)4!(x−a)(x−a+b2)(x−b)dx=−f(4)(η)2880(b−a)5R_T = \\int_a^b \\frac{f^{(4)}(\\xi)}{4!}(x - a)(x - \\frac{a + b}{2})(x - b)dx = -\\frac{f^{(4)}(\\eta)}{2880}(b - a)^{5} RT​=∫ab​4!f(4)(ξ)​(x−a)(x−2a+b​)(x−b)dx=−2880f(4)(η)​(b−a)5 Cotes 公式，n=4n = 4n=4 时的 N-C 公式C(f)=(b−a)[790f(x0)+1645f(x1)+215f(x2)+1645f(x3)+790f(x4)]C(f) = (b - a)\\big[\\frac{7}{90}f(x_0) + \\frac{16}{45}f(x_1) + \\frac{2}{15}f(x_2) + \\frac{16}{45}f(x_3) + \\frac{7}{90}f(x_4)\\big] C(f)=(b−a)[907​f(x0​)+4516​f(x1​)+152​f(x2​)+4516​f(x3​)+907​f(x4​)] 但是 n=8n = 8n=8 或 n≥10n \\geq 10n≥10 的时候，Cotes系数表中出现了负系数，这代表此时的求积公式不稳定，并且由于 Runge 现象，nnn 增大并不会代表收敛性一定会增强，因此高阶 N-C 公式是不稳定、不一定准确的 可以证明，当 nnn 为偶数的时候，nnn 阶 N-C 公式至少有 n+1n + 1n+1 阶的代数精度 因此，综合考虑计算量、稳定性与准确性，通常情况下只会使用 1,2,4,61, 2, 4, 61,2,4,6 阶四种 N-C 公式 复合求积公式 类似全局插值和分段插值的思路，既然 N-C 公式在高阶的时候很多方面的表现都很差，那就将全局区间划分成若干个小区间，之后在每一个小区间上用低阶的 N-C 公式即可，这种方法被称为复合求积公式 复合梯形公式 将 [a,b][a, b][a,b] 划分为 nnn 个小区间，则： ∫xkxk+1f(x)dx≈Tn(k)=b−a2n[f(xk)+f(xk+1)]\\int_{x_k}^{x_{k + 1}}f(x)dx \\approx T_{n}^{(k)} = \\frac{b - a}{2n}[f(x_k) + f(x_{k + 1})] ∫xk​xk+1​​f(x)dx≈Tn(k)​=2nb−a​[f(xk​)+f(xk+1​)] 在全区间上： Tn=∑k=0n−1(∫xkxk+1f(x)dx)=b−a2n[f(a)+2∑k=1n−1f(xk)+f(b)]T_n = \\sum\\limits_{k = 0}^{n - 1}\\Bigg(\\int_{x_k}^{x_{k + 1}}f(x)dx\\Bigg) = \\frac{b - a}{2n}\\Big[f(a) + 2\\sum\\limits_{k = 1}^{n - 1}f(x_k) + f(b)\\Big] Tn​=k=0∑n−1​(∫xk​xk+1​​f(x)dx)=2nb−a​[f(a)+2k=1∑n−1​f(xk​)+f(b)] 这被称为复合梯形公式 每个区间上的截断误差，即求积余项为： RT(k)=−f′′(η)12(b−an)3R_T^{(k)} = -\\frac{f&#x27;&#x27;(\\eta)}{12}\\big(\\frac{b - a}{n}\\big)^{3} RT(k)​=−12f′′(η)​(nb−a​)3 则复合梯形公式的截断误差为： RT=∑k=0n−1RT(k)=−f′′(η)12n2(b−a)3=O(h2)R_T = \\sum\\limits_{k = 0}^{n - 1}R_{T}^{(k)} = -\\frac{f&#x27;&#x27;(\\eta)}{12n^{2}}\\big(b - a)^{3} = O(h^{2}) RT​=k=0∑n−1​RT(k)​=−12n2f′′(η)​(b−a)3=O(h2) 随着 nnn 的增加，即划分的精细化，误差会显著降低 对于等距节点求积公式，若其截断误差为 O(hp)O(h^p)O(hp)，则称其准确度阶数为 ppp，其中 hhh 为两个节点之间的距离 则根据上述推导，复合梯形公式具有 2 阶准确度 同样，复合梯形公式还有几条性质： TnT_nTn​ 具有 1 阶代数精度 对于任意可积函数 fff，TnT_nTn​ 是收敛的 由于我们很难预知 nnn 的值，因此一般采取动态折半的方式，每次在区间折半的过程中，之前的所有点仍然是区间端点，计算也可以复用 记 xk+1/2=xk+xk+12x_{k + 1/2} = \\dfrac{x_k + x_{k + 1}}{2}xk+1/2​=2xk​+xk+1​​，则： T2n(k)+T2n(k+1/2)=b−a4n[f(xk)+f(xk+1/2)]+b−a4n[f(xk+1/2)+f(xk+1)]=12Tn(k)+b−a2nf(xk+1/2)\\begin{align*} T_{2n}^{(k)} + T_{2n}^{(k + 1/2)} &amp;= \\frac{b - a}{4n}[f(x_k) + f(x_{k + 1/2})] + \\frac{b - a}{4n}[f(x_{k + 1/2}) + f(x_{k + 1})] \\\\ &amp;= \\frac{1}{2}T_{n}^{(k)} + \\frac{b - a}{2n}f(x_{k + 1/2}) \\end{align*} T2n(k)​+T2n(k+1/2)​​=4nb−a​[f(xk​)+f(xk+1/2​)]+4nb−a​[f(xk+1/2​)+f(xk+1​)]=21​Tn(k)​+2nb−a​f(xk+1/2​)​ 因此： T2n=∑k=0n−1[T2n(k)+T2n(k+1/2)]=12Tn+b−a2n∑k=0n−1f(xk+1/2)\\begin{align*} T_{2n} &amp;= \\sum\\limits_{k = 0}^{n - 1}\\big[T_{2n}^{(k)} + T_{2n}^{(k + 1/2)}\\big] \\\\ &amp;= \\frac{1}{2}T_{n} + \\frac{b - a}{2n}\\sum\\limits_{k = 0}^{n - 1}f(x_{k + 1/2}) \\end{align*} T2n​​=k=0∑n−1​[T2n(k)​+T2n(k+1/2)​]=21​Tn​+2nb−a​k=0∑n−1​f(xk+1/2​)​ 这说明，我们只需要计算新节点的函数值，即可递推得出区间折半之后的复合梯形公式 复合 Simpson 同理，我们对每一个小区间使用 Simpson 公式，则得到复合 Simpson 公式，最后化简得到的结果为： Sn=b−a6n[f(a)+4∑k=0n−1f(xk+xk+12)+2∑k=1n−1f(xk)+f(b)]S_n = \\frac{b - a}{6n}\\Big[f(a) + 4\\sum\\limits_{k = 0}^{n - 1}f(\\frac{x_k + x_{k + 1}}{2}) + 2\\sum\\limits_{k = 1}^{n - 1}f(x_k) + f(b)\\Big] Sn​=6nb−a​[f(a)+4k=0∑n−1​f(2xk​+xk+1​​)+2k=1∑n−1​f(xk​)+f(b)] 余项为： RS=∑k=0n−1RS(k)=−f(4)(η)2880n4(b−a)5=O(h4)R_S = \\sum\\limits_{k = 0}^{n - 1}R_{S}^{(k)} = -\\frac{f^{(4)}(\\eta)}{2880n^4}(b - a)^{5} = O(h^{4}) RS​=k=0∑n−1​RS(k)​=−2880n4f(4)(η)​(b−a)5=O(h4) 复合 Simpson 公式的性质为： SnS_nSn​ 是稳定、收敛的 SnS_nSn​ 具有 3 阶代数精度 SnS_nSn​ 具有 4 阶准确度 同样，复合 Simpson 也可以递推得到，但是计算复杂度更高 Gauss 求积公式 以上的推导都是基于等距节点的，即 Akf(xk)A_kf(x_k)Ak​f(xk​) 中的 xkx_kxk​ 是一个已知量，而如果让其成变距节点，则可以得到更高的代数精度 我们定义当 In(f)I_n(f)In​(f) 的代数精度不小于 2n+12n + 12n+1 时，其称为 Gauss 求积公式，积分节点为 Gauss 点 考虑一般的带权积分： I(f)=∫abf(x)ρ(x)dxI(f) = \\int_a^b f(x)\\rho(x)dx I(f)=∫ab​f(x)ρ(x)dx 其对应的 Gauss 求积公式被称为 ρ(x)\\rho(x)ρ(x) 对应的 Gauss 积分公式 对于一般的 Gauss 积分公式，{xk}\\{x_{k}\\}{xk​} 为 Gauss 点的充要条件是：ωn+1(x)\\omega_{n + 1}(x)ωn+1​(x) 与 ∀P(x)∈Pn\\forall P(x) \\in \\mathbb{P}_{n}∀P(x)∈Pn​ 带权正交，即： ∫abP(x)ωn+1(x)ρ(x)dx=0\\int_a^b P(x)\\omega_{n + 1}(x)\\rho(x)dx = 0 ∫ab​P(x)ωn+1​(x)ρ(x)dx=0 证明如下： 首先证明必要性：显然有 P(x)ωn+1(x)∈P2n+1P(x)\\omega_{n + 1}(x) \\in \\mathbb{P}_{2n + 1}P(x)ωn+1​(x)∈P2n+1​由于 {xk}\\{x_{k}\\}{xk​} 是 Gauss 点，且 Gauss 积分有 2n+12n + 12n+1 阶代数精度，则有：∫abP(x)ωn+1(x)ρ(x)dx=∑k=0nAkP(xk)ωn+1(xk)=0\\begin{align*}\\int_a^b P(x)\\omega_{n + 1}(x)\\rho(x)dx &amp;= \\sum\\limits_{k = 0}^{n}A_{k}P(x_k)\\omega_{n + 1}(x_{k}) = 0\\end{align*}∫ab​P(x)ωn+1​(x)ρ(x)dx​=k=0∑n​Ak​P(xk​)ωn+1​(xk​)=0​之后证明充分性：∀f(x)∈P2n+1\\forall f(x) \\in \\mathbb{P}_{2n + 1}∀f(x)∈P2n+1​，令：f(x)=P(x)ωn+1(x)+Qn(x)f(x) = P(x)\\omega_{n + 1}(x) + Q_{n}(x)f(x)=P(x)ωn+1​(x)+Qn​(x)其中 Qn(x)∈PnQ_n(x) \\in \\mathbb{P}_{n}Qn​(x)∈Pn​，则：I(f)=∫abf(x)ρ(x)dx=∫abP(x)ωn+1(x)ρ(x)dx+∫abQn(x)ρ(x)dx=∑k=0nAkQn(xk)=∑k=0nAk[P(xk)ωn+1(xk)+Qn(xk)]=∑k=0nAkf(xk)=In(f)\\begin{align*} I(f) = \\int_a^b f(x)\\rho(x)dx &amp;= \\int_a^b P(x)\\omega_{n + 1}(x)\\rho(x)dx + \\int_a^b Q_n(x)\\rho(x)dx \\\\ &amp;= \\sum\\limits_{k = 0}^{n}A_kQ_n(x_k) \\\\ &amp;= \\sum\\limits_{k = 0}^{n}A_k[P(x_k)\\omega_{n + 1}(x_k) + Q_n(x_k)] \\\\ &amp;= \\sum\\limits_{k = 0}^{n}A_kf(x_k) = I_n(f)\\end{align*}I(f)=∫ab​f(x)ρ(x)dx​=∫ab​P(x)ωn+1​(x)ρ(x)dx+∫ab​Qn​(x)ρ(x)dx=k=0∑n​Ak​Qn​(xk​)=k=0∑n​Ak​[P(xk​)ωn+1​(xk​)+Qn​(xk​)]=k=0∑n​Ak​f(xk​)=In​(f)​因此其具有 2n+12n + 12n+1 阶代数精度证毕 这引出了如下的求 Gauss 积分公式的方式： 根据权函数，计算 n+1n + 1n+1 次正交多项式的零点，即 Gauss 点 求出带权积分系数：Ak=∫ablk(x)ρ(x)dxA_k = \\int_a^b l_k(x)\\rho(x)dx Ak​=∫ab​lk​(x)ρ(x)dx Gauss 积分公式有如下性质： Gauss 积分公式是稳定的、准确的 积分余项为：Rn[f]=f(2n+2)(η)(2n+2)!∫abωn+12(x)ρ(x)dxR_n[f] = \\frac{f^{(2n + 2)}(\\eta)}{(2n + 2)!}\\int_a^b\\omega_{n + 1}^{2}(x)\\rho(x)dx Rn​[f]=(2n+2)!f(2n+2)(η)​∫ab​ωn+12​(x)ρ(x)dx 稳定性的证明方法： Ak=∑j=0nAjlk2(xj)=In(lk2)=∫ablk2(x)ρ(x)dx&gt;0A_{k} = \\sum\\limits_{j = 0}^{n}A_jl_k^2(x_j) = I_n(l_k^2) = \\int_a^bl_k^2(x)\\rho(x)dx &gt; 0 Ak​=j=0∑n​Aj​lk2​(xj​)=In​(lk2​)=∫ab​lk2​(x)ρ(x)dx&gt;0 最后一个等号是因为 lk(x)∈P2n+1l_k(x) \\in \\mathbb{P}_{2n + 1}lk​(x)∈P2n+1​ Gauss Legendre 公式 使用 Legendre 递推式得到正交多项式，利用这组多项式得到 Gauss 点，进而求出 Gauss 求积公式的方法 Gauss-Legendre积分表 上表是使用 Legendre 多项式得到的积分节点与积分系数的表格，由于 Legendre 多项式是定义在 [−1,1][-1, 1][−1,1] 上的，因此对于一般区间 [a,b][a, b][a,b] 上的积分，直接变量代换即可 数值微分 指在未知函数表达式的情况下，利用数值方法计算函数在某一点处的导数值 基本的有限差分公式为： Df(x)=f(x+h)−f(x)hDb(x)=f(x)−f(x−h)hDc(x)=f(x+h)−f(x−h)2h\\begin{align*} D_f(x) &amp;= \\frac{f(x + h) - f(x)}{h} \\\\ D_b(x) &amp;= \\frac{f(x) - f(x - h)}{h} \\\\ D_c(x) &amp;= \\frac{f(x + h) - f(x - h)}{2h} \\end{align*} Df​(x)Db​(x)Dc​(x)​=hf(x+h)−f(x)​=hf(x)−f(x−h)​=2hf(x+h)−f(x−h)​​ 利用 Taylor 展开可以得到： Dc(x)=f′(x)+f′′′(ξ)6h2=f′(x)+O(h2)D_c(x) = f&#x27;(x) + \\frac{f&#x27;&#x27;&#x27;(\\xi)}{6}h^2 = f&#x27;(x) + O(h^{2}) Dc​(x)=f′(x)+6f′′′(ξ)​h2=f′(x)+O(h2) 因此 Dc(x)D_c(x)Dc​(x) 的准确度为 2 阶 令 M=max⁡∣f′′′(x)∣M = \\max|f&#x27;&#x27;&#x27;(x)|M=max∣f′′′(x)∣，则可以得到总误差限为： εtot=Mh26+εh\\varepsilon_{\\text{tot}} = \\frac{Mh^{2}}{6} + \\frac{\\varepsilon}{h} εtot​=6Mh2​+hε​ 其中 ε\\varepsilonε 是单次计算 fff 的舍入误差，由于分母上有个 2，因此总舍入误差最后是 2ε/2h=ε/h2\\varepsilon / 2h = \\varepsilon / h2ε/2h=ε/h 因此，中心差分公式的最小误差为： εtot=Mh26+ε2h+ε2h≥39Mε283\\varepsilon_{\\text{tot}} = \\frac{Mh^{2}}{6} + \\frac{\\varepsilon}{2h} + \\frac{\\varepsilon}{2h} \\geq 3\\sqrt[3]{\\frac{9M\\varepsilon^{2}}{8}} εtot​=6Mh2​+2hε​+2hε​≥3389Mε2​​ 当且仅当 h=3ε/M3h = \\sqrt[3]{3\\varepsilon / M}h=33ε/M​ 时取到 同理，我们可以利用差商计算二阶导数，乃至更高阶的导数： Gc(h)≈2f[x−h,x,x+h]=f(x+h)−2f(x)+f(x−h)h2G_c(h) \\approx 2f[x - h, x, x + h] = \\frac{f(x + h) - 2f(x) + f(x - h)}{h^2} Gc​(h)≈2f[x−h,x,x+h]=h2f(x+h)−2f(x)+f(x−h)​ 同样 Taylor 可以证明这个公式的准确度也是 2 阶 这两种方法实际上都是插值求导的特例，即先根据函数值进行插值，之后对插值得到的函数求导，来近似原函数的导数，即： f(i)(xj)=∑k=0nf(xk)lk(i)(xj)f^{(i)}(x_j) = \\sum\\limits_{k = 0}^{n}f(x_k)l_k^{(i)}(x_j) f(i)(xj​)=k=0∑n​f(xk​)lk(i)​(xj​) 理查德外推法 一种通过将步长减半，组合后得到更准确近似表达式的方法，可以利用在数值积分和微分上，下面以数值微分为例介绍 令： f′(x)−Dc(h)=α1h2+α2h4+⋯+αkh2k+⋯f&#x27;(x) - D_c(h) = \\alpha_1 h^2 + \\alpha_2 h^4 + \\cdots + \\alpha_k h^{2k} + \\cdots f′(x)−Dc​(h)=α1​h2+α2​h4+⋯+αk​h2k+⋯ 其中 αk\\alpha_kαk​ 是与 hhh 无关的常数，则： f′(x)−Dc(h2)=α14h2+α216h2+⋯+αk2kh2k+⋯f&#x27;(x) - D_c(\\frac{h}{2}) = \\frac{\\alpha_1}{4} h^2 + \\frac{\\alpha_2}{16} h^2 + \\cdots + \\frac{\\alpha_k}{2^k} h^{2k} + \\cdots f′(x)−Dc​(2h​)=4α1​​h2+16α2​​h2+⋯+2kαk​​h2k+⋯ 通过这两个表达式可以消除 h2h^{2}h2 这一项，得到： f′(x)−4Dc(h2)−Dc(h)3=O(h4)f&#x27;(x) - \\frac{4D_c(\\frac{h}{2}) - D_c(h)}{3} = O(h^{4}) f′(x)−34Dc​(2h​)−Dc​(h)​=O(h4) 因此，4Dc(h2)−Dc(h)3\\dfrac{4D_c(\\frac{h}{2}) - D_c(h)}{3}34Dc​(2h​)−Dc​(h)​ 则是一个准确度阶数更高的估计表达式 并且这种方法是可以不断进行下去的，可以递推的不断增加精度","tags":["笔记","数值微分","数值积分"],"categories":["数值分析"]},{"title":"数值分析 - 函数逼近与函数插值","path":"/2025/05/02/数值分析6/","content":"数值分析 笔记 6 函数逼近与函数插值 这两种方法本质上都是在用简单函数去近似复杂函数的过程，不同的是： 逼近要求整体上误差最小 插值要求在一些点上简单函数与原函数的值相等 函数逼近 函数逼近是指，对于给定函数 f(x)f(x)f(x)，希望在某个函数空间 Φ\\varPhiΦ 中找到一个函数 p(x)p(x)p(x)，使得在某种度量意义下，误差函数 p(x)−f(x)p(x) - f(x)p(x)−f(x) 达到最小 通常 f(x)f(x)f(x) 是一个有表达式的复杂函数或者表格函数，而 Φ\\varPhiΦ 通常有：多项式、有理分式、指数函数、三角函数、分段多项式等简单函数类 函数逼近的例子有很多，例如常见的 Taylor 展开、Fourier 变换、数据点拟合等等 我们通常使用函数空间上的范数来度量误差，C[a,b]C[a, b]C[a,b] 上常见的范数包括： ∣∣f(x)∣∣∞=max⁡x∈[a,b]∣f(x)∣∣∣f(x)∣∣1=∫ab∣f(x)∣dx∣∣f(x)∣∣2=[∫abf2(x)dx]1/2\\begin{align*} ||f(x)||_{\\infty} &amp;= \\max\\limits_{x\\in[a, b]}|f(x)| \\\\ ||f(x)||_{1} &amp;= \\int_{a}^{b}|f(x)|\\mathrm{d}x \\\\ ||f(x)||_{2} &amp;= \\Big[\\int_{a}^{b}f^{2}(x)\\mathrm{d}x\\Big]^{1/2} \\\\ \\end{align*} ∣∣f(x)∣∣∞​∣∣f(x)∣∣1​∣∣f(x)∣∣2​​=x∈[a,b]max​∣f(x)∣=∫ab​∣f(x)∣dx=[∫ab​f2(x)dx]1/2​ 其中 2-范数又称内积范数，定义见下方 在这些范数中，使用 ∞\\infty∞-范数来度量误差是最优的，因为他规定了在整个定义域上两个函数都非常接近，这种逼近方式被称为最佳一致逼近 但是最佳一致逼近非常难以求解，而 1-范数实际上是考察两个函数图像之间的面积，误差较大，因此通常使用 2-范数来度量逼近误差，这被称为最佳平方（最小二乘）逼近 函数内积 函数内积定义为： ⟨u,v⟩=∫abu(x)v(x)‾dx\\langle u, v\\rangle = \\int_a^b u(x)\\overline{v(x)}\\mathrm{d}x ⟨u,v⟩=∫ab​u(x)v(x)​dx 对于内积有 Cauthy-Schwarz 不等式： ∣⟨u,v⟩∣2≤⟨u,u⟩⟨v,v⟩|\\langle u, v\\rangle|^{2} \\leq \\langle u, u\\rangle\\langle v, v\\rangle ∣⟨u,v⟩∣2≤⟨u,u⟩⟨v,v⟩ 对于实内积空间 SSS 中的 nnn 个函数 u1,…,unu_1, \\dots, u_nu1​,…,un​，其线性无关的充要条件是 Gram 矩阵 G\\boldsymbol{G}G 非奇异，Gram 矩阵定义为： Gij=⟨ui,uj⟩\\boldsymbol{G}_{ij} = \\langle u_i, u_j\\rangle Gij​=⟨ui​,uj​⟩ 由内积的对称性和正定性可以得到，非奇异的 Gram 矩阵是对称正定的 上述内积定义中，两个函数的地位是等价的，也就是内积的对称性，但是有的时候这并不是想要的，内积本质上是一种广义上的求和操作，因此根据加权求和的思想，引入加权内积 权函数 ρ(x)\\rho(x)ρ(x) 定义为满足以下条件的函数： ∀x∈[a,b],ρ(x)≥0\\forall x\\in [a, b],\\quad\\rho(x) \\geq 0∀x∈[a,b],ρ(x)≥0 ∀k∈N,∫abxkρ(x)dx\\forall k\\in \\mathbb{N},\\quad \\int_a^b x^{k}\\rho(x)\\mathrm{d}x∀k∈N,∫ab​xkρ(x)dx 是存在的 对于任意非负连续函数 g(x)g(x)g(x)，若 ∫abg(x)ρ(x)dx=0\\int_a^b g(x)\\rho(x)\\mathrm{d}x = 0∫ab​g(x)ρ(x)dx=0，则 g(x)≡0g(x) \\equiv 0g(x)≡0，即ρ(x)\\rho(x)ρ(x) 没有局部恒为 000 的情况 则定义加权内积为： ⟨u,v⟩=∫abρ(x)u(x)v(x)‾dx\\langle u, v\\rangle = \\int_a^b \\rho(x)u(x)\\overline{v(x)}\\mathrm{d}x ⟨u,v⟩=∫ab​ρ(x)u(x)v(x)​dx 最佳平方逼近 考虑函数类 Φ=span{φ1,…,φn}\\varPhi = \\text{span}\\{\\varphi_{1}, \\dots, \\varphi_{n}\\}Φ=span{φ1​,…,φn​}，则我们需要找到 S(t)=∑i=1nxiφi(t)S(t) = \\sum\\limits_{i=1}^{n}x_i\\varphi_{i}(t)S(t)=i=1∑n​xi​φi​(t)，使得 ∣∣S(t)−f(t)∣∣22||S(t) - f(t)||_{2}^{2}∣∣S(t)−f(t)∣∣22​ 最小 根据内积的双线性性与对称性，有： F=∣∣S(t)−f(t)∣∣22=⟨∑i=1nxiφi−f,∑i=1nxiφi−f⟩=∑i=1n∑j=1nxixj⟨φi,φj⟩−2∑i=1nxi⟨f,φi⟩+⟨f,f⟩\\begin{align*} F &amp;= ||S(t) - f(t)||_{2}^{2} \\\\ &amp;= \\langle\\sum\\limits_{i=1}^{n}x_i\\varphi_{i} - f, \\sum\\limits_{i=1}^{n}x_i\\varphi_{i} - f\\rangle \\\\ &amp;= \\sum\\limits_{i=1}^{n}\\sum\\limits_{j=1}^{n}x_{i}x_{j}\\langle\\varphi_{i}, \\varphi_{j}\\rangle - 2\\sum\\limits_{i=1}^{n}x_i\\langle f, \\varphi_{i}\\rangle + \\langle f, f\\rangle \\end{align*} F​=∣∣S(t)−f(t)∣∣22​=⟨i=1∑n​xi​φi​−f,i=1∑n​xi​φi​−f⟩=i=1∑n​j=1∑n​xi​xj​⟨φi​,φj​⟩−2i=1∑n​xi​⟨f,φi​⟩+⟨f,f⟩​ 因此： ∂F∂xk=2∑i=1nxi⟨φi,φk⟩−2⟨f,φk⟩\\begin{align*} \\frac{\\partial F}{\\partial x_{k}} = 2\\sum\\limits_{i = 1}^{n}x_{i}\\langle \\varphi_{i}, \\varphi_{k}\\rangle - 2\\langle f, \\varphi_{k}\\rangle \\end{align*} ∂xk​∂F​=2i=1∑n​xi​⟨φi​,φk​⟩−2⟨f,φk​⟩​ 令所有的偏导数等于 000，可以得到一个线性方程组 Gx=b\\boldsymbol{Gx = b}Gx=b，其中 G\\boldsymbol{G}G 是 Gram 矩阵，b=[⟨f,φ1⟩,…,⟨f,φn⟩]T\\boldsymbol{b} = [\\langle f, \\varphi_{1}\\rangle, \\dots, \\langle f, \\varphi_{n}\\rangle]^{T}b=[⟨f,φ1​⟩,…,⟨f,φn​⟩]T 如果这些函数线性无关，那么 G\\boldsymbol{G}G 是对称正定的，这个线性方程组有唯一解，并且可以证明这个解可以让误差度量达到最小值，几何意义上来说，这代表： S∗−f⊥ΦS^{*} - f \\perp \\Phi S∗−f⊥Φ 基函数线性无关时，最佳平方逼近算法计算 Gram 矩阵 G\\boldsymbol{G}G作 Cholesky 分解 G=LLT\\boldsymbol{G} = \\boldsymbol{LL}^{T}G=LLT解方程得到 x\\boldsymbol{x}x 多项式最佳平方逼近 可以取：Φ=Pn−1\\Phi = \\mathbb{P}_{n - 1}Φ=Pn−1​，即次数不超过 n−1n - 1n−1 的所有多项式的集合 对于 [0,1][0, 1][0,1] 区间，此时有： ⟨φi,φj⟩=∫01ti+j−2dt=1i+j−1\\langle\\varphi_{i}, \\varphi_{j}\\rangle = \\int_0^1 t^{i + j - 2} \\mathrm{d}t = \\frac{1}{i + j - 1} ⟨φi​,φj​⟩=∫01​ti+j−2dt=i+j−11​ 即 G=Hn\\boldsymbol{G} = \\boldsymbol{H}_{n}G=Hn​ 根据 Weierstrass 定理，多项式可以对连续函数进行任意好的逼近，但是根据上述结论，其 Gram 矩阵会随着次数增大而极具病态，并且是稠密的，计算复杂度高 如果我们将基函数取成一组正交基，那根据正交的特性很容易得到，Gram 矩阵会变成对角阵！这种情况下解方程是非常容易的 此处的正交需要两两之间加权内积为 000，权函数选取不同可能会得出不同的结果，最 naive 的权函数是 ρ(x)≡1\\rho(x) \\equiv 1ρ(x)≡1 可以通过 Gram-Schmidt 正交化的方式从 {1,t,…,tn−1}\\{1, t, \\dots, t^{n - 1}\\}{1,t,…,tn−1} 得到一组正交多项式，具体来说： φ1(t)=1φk(t)=tk−1−∑i=1k−1⟨tk−1,φi(t)⟩⟨φi(t),φi(t)⟩φi(t)\\begin{align*} \\varphi_{1}(t) &amp;= 1 \\\\ \\varphi_{k}(t) &amp;= t^{k - 1} - \\sum\\limits_{i = 1}^{k - 1}\\frac{\\langle t^{k - 1}, \\varphi_{i}(t)\\rangle}{\\langle \\varphi_{i}(t), \\varphi_{i}(t)\\rangle}\\varphi_{i}(t) \\\\ \\end{align*} φ1​(t)φk​(t)​=1=tk−1−i=1∑k−1​⟨φi​(t),φi​(t)⟩⟨tk−1,φi​(t)⟩​φi​(t)​ 对于正交基，可以很方便地求出逼近结果： S∗=∑k=1n⟨f(t),φk(t)⟩⟨φk(t),φk(t)⟩φk(t)S^{*} = \\sum\\limits_{k = 1}^{n}\\frac{\\langle f(t), \\varphi_{k}(t)\\rangle}{\\langle \\varphi_{k}(t), \\varphi_{k}(t)\\rangle}\\varphi_{k}(t) S∗=k=1∑n​⟨φk​(t),φk​(t)⟩⟨f(t),φk​(t)⟩​φk​(t) 在选取不同的定义域与不同的权函数时，Gram-Schmidt 正交化的结果可以表示成不同的递推形式，如下表： 表中的递推式可以帮助我们方便的求出 φk\\varphi_{k}φk​ 如果定义域不满足上表中的条件，可以使用线性映射的方式修改，例如对于 Legendre 多项式，从 [−1,1][-1, 1][−1,1] 映射到 [a,b][a, b][a,b]： s=b−a2t+b+a2s = \\frac{b - a}{2} t + \\frac{b + a}{2} s=2b−a​t+2b+a​ 因此映射后的 Legendre 多项式为： Pk~(s)=Pk(2s−(b+a)b−a)\\tilde{P_{k}}(s) = P_{k}(\\frac{2s - (b + a)}{b - a}) Pk​~​(s)=Pk​(b−a2s−(b+a)​) 注意在求和的时候计算系数与基函数都应该是映射后的 可以证明使用多项式来逼近的时候，逼近误差一致不大于 εn\\frac{\\varepsilon}{\\sqrt{n}}n​ε​ 在 nnn 充分大的时候度量方式为 2-范数，如果原函数二阶导连续，则可以扩展为 无穷范数 最小二乘法 与最佳平方逼近的思路大致相同，不同的是这种方法通常用于给定数据点对的表格，需要最优化的函数不再是内积范数，而是： ∑i=1m[S(ti)−f(ti)]2\\sum\\limits_{i=1}^{m}[S(t_{i}) - f(t_{i})]^{2} i=1∑m​[S(ti​)−f(ti​)]2 本质上来说，定义在离散点处的表格函数也构成了一个线性空间，离散情况下，从连续区间上的函数变成了离散的向量，范数也从积分变成了求和，因此最小二乘是一种最佳平方逼近 法方程法 将表格函数定义为向量 f=[f(t1),…,f(tm)]T\\boldsymbol{f} = [f(t_{1}), \\dots, f(t_{m})]^{T}f=[f(t1​),…,f(tm​)]T，则需要找到向量 x\\boldsymbol{x}x 使得 ∣∣Ax−f∣∣2||\\boldsymbol{Ax - f}||_{2}∣∣Ax−f∣∣2​ 最小，其中 A∈Rm×n\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}A∈Rm×n 定义为： Aij=φj(ti)\\boldsymbol{A}_{ij} = \\varphi_{j}(t_{i}) Aij​=φj​(ti​) A\\boldsymbol{A}A 的每一列代表的是一个基函数，每一行代表的是某一个输入在不同基函数下的函数值，因此可以写成： A=[φ1,…,φn]\\boldsymbol{A} = [\\boldsymbol{\\varphi}_{1}, \\dots, \\boldsymbol{\\varphi}_{n}] A=[φ1​,…,φn​] 考虑到离散函数可以用向量来表示，而向量的范数就是对应下标元素求和的形式，因此： G=ATAb=ATf\\begin{align*} \\boldsymbol{G = A}^{T}\\boldsymbol{A} \\\\ \\boldsymbol{b = A}^{T}\\boldsymbol{f} \\end{align*} G=ATAb=ATf​ 也即我们将最小二乘法转换为了最佳平方逼近的 Gx=b\\boldsymbol{Gx = b}Gx=b，如果表格基函数线性无关，也即 A\\boldsymbol{A}A 是列满秩的，那 Gx=b\\boldsymbol{Gx = b}Gx=b 一定存在唯一解 然而，通常最小二乘的使用场景都是拟合大量数据点，即 m&gt;&gt;nm &gt;&gt; nm&gt;&gt;n 时，但是这种情况下就会导致 Gx=b\\boldsymbol{Gx = b}Gx=b 并不等价于 Ax=f\\boldsymbol{Ax = f}Ax=f，甚至在列满秩的情况下很容易后者无解，不过可以证明的是 Gx=b\\boldsymbol{Gx = b}Gx=b 的解满足使得 ∣∣Ax−f∣∣2||\\boldsymbol{Ax - f}||_{2}∣∣Ax−f∣∣2​ 最小 因此得到 表格基函数线性无关时，最小二乘法计算系数矩阵 A\\boldsymbol{A}A解方程 ATAx=ATf\\boldsymbol{A}^{T}\\boldsymbol{Ax = }\\boldsymbol{A}^{T}\\boldsymbol{f}ATAx=ATf 对于连续函数来说，是否线性无关与输入没有关系，而对于表格函数来说，是否线性无关是与观测点的值有关的，并且观测点可能出现相同的（即一对多），有 Haar 条件： 若 tit_{i}ti​ 中至少有 nnn 个不同的值，则 Pn−1\\mathbb{P}_{n - 1}Pn−1​ 对应的表格基函数是线性无关的 正交变换法 由于法方程法会面临最佳平方逼近的同样问题，因此我们仍然需要选取正交的表格基函数，一种可行的方法是 A\\boldsymbol{A}A 的 QR 变换： 由于正交变换不改变 2-范数，因此： ∣∣f−Ax∣∣2=∣∣QTf−Rx∣∣2||\\boldsymbol{f - Ax}||_{2} = ||\\boldsymbol{Q}^{T}\\boldsymbol{f - Rx}||_{2} ∣∣f−Ax∣∣2​=∣∣QTf−Rx∣∣2​ 对于 A∈Rm×n\\boldsymbol{A} \\in \\mathbb{R}^{m\\times n}A∈Rm×n，其对应的 QR 分解可以分块为： Q=[Q1,Q2],R=[R1O]\\boldsymbol{Q} = \\begin{bmatrix} \\boldsymbol{Q}_{1}, \\boldsymbol{Q}_{2} \\end{bmatrix}, \\quad \\boldsymbol{R} = \\begin{bmatrix} \\boldsymbol{R}_{1} \\\\ \\boldsymbol{O} \\end{bmatrix} Q=[Q1​,Q2​​],R=[R1​O​] 其中 Q1∈Rm×n\\boldsymbol{Q}_{1} \\in \\mathbb{R}^{m \\times n}Q1​∈Rm×n，R1∈Rn×n\\boldsymbol{R}_{1} \\in \\mathbb{R}^{n \\times n}R1​∈Rn×n 则有： ∣∣QTf−Rx∣∣2=∣∣Q1Tf−R1x∣∣2+∣∣Q2Tf∣∣2≥∣∣Q2Tf∣∣2\\begin{align*} ||\\boldsymbol{Q}^{T}\\boldsymbol{f - Rx}||_{2} &amp;= ||\\boldsymbol{Q}_{1}^{T}\\boldsymbol{f} - \\boldsymbol{R}_{1}\\boldsymbol{x}||_{2} + ||\\boldsymbol{Q}_{2}^{T}\\boldsymbol{f}||_{2} \\\\ &amp;\\geq ||\\boldsymbol{Q}_{2}^{T}\\boldsymbol{f}||_{2} \\end{align*} ∣∣QTf−Rx∣∣2​​=∣∣Q1T​f−R1​x∣∣2​+∣∣Q2T​f∣∣2​≥∣∣Q2T​f∣∣2​​ 当且仅当 Q1Tf=R1x\\boldsymbol{Q}_{1}^{T}\\boldsymbol{f} = \\boldsymbol{R}_{1}\\boldsymbol{x}Q1T​f=R1​x 时取等 因此得到 表格基函数线性无关时，最小二乘法计算系数矩阵 A\\boldsymbol{A}A正交三角化 A\\boldsymbol{A}A 得到 R\\boldsymbol{R}R，同时变换 f\\boldsymbol{f}f 得到 QTf\\boldsymbol{Q}^{T}\\boldsymbol{f}QTf取前 nnn 行，解方程 R1x=QTf[1..n]\\boldsymbol{R}_{1}\\boldsymbol{x} =\\boldsymbol{Q}^{T}\\boldsymbol{f}[1..n]R1​x=QTf[1..n] 由于 R\\boldsymbol{R}R 是三角阵，因此解方程快速且稳定 函数插值 本质上是一种假设数据没有误差的时候做的函数拟合，我们用 P(x)P(x)P(x) 代表插值结果，则需要满足 P(xi)=yiP(x_i) = y_iP(xi​)=yi​ 常见的插值函数包括多项式、三角函数、有理分式、分段函数等 多项式插值 对于有 n+1n + 1n+1 个数据点的插值条件，我们可以使用 nnn 次多项式来进行插值，有代数基本定理可以知道，一定可以找到唯一的一个多项式满足条件 最直接的方式是求解线性方程组： {a0+a1x0+⋯+anx0n=y0a0+a1x1+⋯+anx1n=y1⋮a0+a1xn+⋯+anxnn=yn\\begin{cases} a_0 + a_1 x_0 &amp;+ \\dots + a_n x_0^n = y_0 \\\\ a_0 + a_1 x_1 &amp;+ \\dots + a_n x_1^n = y_1 \\\\ &amp;\\vdots \\\\ a_0 + a_1 x_n &amp;+ \\dots + a_n x_n^n = y_n \\\\ \\end{cases} ⎩⎨⎧​a0​+a1​x0​a0​+a1​x1​a0​+a1​xn​​+⋯+an​x0n​=y0​+⋯+an​x1n​=y1​⋮+⋯+an​xnn​=yn​​ 系数矩阵为 Vandermonde 矩阵： A=[1x0⋯x0n1x1⋯x1n⋮⋮⋱⋮1xn⋯xnn]\\boldsymbol{A} = \\begin{bmatrix} 1 &amp; x_0 &amp; \\cdots &amp; x_0^n \\\\[0.5em] 1 &amp; x_1 &amp; \\cdots &amp; x_1^n \\\\[0.5em] \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\[0.5em] 1 &amp; x_n &amp; \\cdots &amp; x_n^n \\\\[0.5em] \\end{bmatrix} A=​11⋮1​x0​x1​⋮xn​​⋯⋯⋱⋯​x0n​x1n​⋮xnn​​​ 但是这个矩阵是稠密的，并且使用这种方法不利于分析，因此引入 Lagrange 插值法 Lagrange 插值 考虑 n=1n = 1n=1 的情况，也就是使用一维方程（直线）去插值两个节点，我们可以使用经典的两点式直线方程得到结果： y=x−x1x0−x1y0+x−x0x1−x0y1y = \\frac{x - x_1}{x_0 - x_1}y_0 + \\frac{x - x_0}{x_1 - x_0}y_1 y=x0​−x1​x−x1​​y0​+x1​−x0​x−x0​​y1​ 这实际上可以看成是一些基函数的线性组合，系数为给定的函数值，即： y=y0l0(x)+y1l1(x)y = y_0l_0(x) + y_1l_1(x) y=y0​l0​(x)+y1​l1​(x) 其中 l0(x)l_0(x)l0​(x) 与 l1(x)l_1(x)l1​(x) 都是一次函数，并且满足 l0(x0)=l1(x1)=1,l0(x1)=l1(x0)=0l_0(x_0) = l_1(x_1) = 1, l_0(x_1) = l_1(x_0) = 0l0​(x0​)=l1​(x1​)=1,l0​(x1​)=l1​(x0​)=0 这就是最基础的 Lagrange 插值 扩展到更高维的形式，则插值函数为： Ln(x)=∑k=0nyklk(x)L_n(x) = \\sum\\limits_{k = 0}^{n}y_kl_k(x) Ln​(x)=k=0∑n​yk​lk​(x) 基函数 lk(x)l_k(x)lk​(x) 的次数也为 nnn，并且满足： lk(xi)={1i=k0i≠kl_k(x_i) = \\begin{cases} 1 &amp; i = k \\\\ 0 &amp; i eq k \\end{cases} lk​(xi​)={10​i=ki=k​ 确定基函数最简单的方式是利用给定的 nnn 个零点，这可以得到一个成比例的函数簇，之后根据 xkx_kxk​ 处的函数值求出系数即可 具体来说，令：ωn+1(x)=∏i=0n(x−xi)\\omega_{n + 1}(x) = \\prod\\limits_{i = 0}^{n}(x - x_i)ωn+1​(x)=i=0∏n​(x−xi​)则有ωn+1(xi)≡0\\omega_{n + 1}(x_i) \\equiv 0ωn+1​(xi​)≡0对其求导：ωn+1′(x)=∑j=0n(∏i=0i≠jn(x−xi))\\omega^{&#x27;}_{n + 1}(x) = \\sum\\limits_{j=0}^{n}\\Bigg(\\prod\\limits_{\\substack{i = 0 \\\\ i eq j}}^{n}(x - x_i)\\Bigg)ωn+1′​(x)=j=0∑n​(i=0i=j​∏n​(x−xi​))因此：ωn+1′(xk)=∏i=0i≠kn(xk−xi)=ωn+1(x)(x−xk)∣x=xk\\omega^{&#x27;}_{n + 1}(x_k) = \\prod\\limits_{\\substack{i = 0 \\\\ i eq k}}^{n}(x_k - x_i) = \\frac{\\omega_{n + 1}(x)}{(x - x_k)}\\bigg|_{x = x_k}ωn+1′​(xk​)=i=0i=k​∏n​(xk​−xi​)=(x−xk​)ωn+1​(x)​​x=xk​​遂得到基函数表达式：lk(x)=ωn+1(x)(x−xk)ωn+1′(xk)l_k(x) = \\frac{\\omega_{n + 1}(x)}{(x - x_k)\\omega^{&#x27;}_{n + 1}(x_k)}lk​(x)=(x−xk​)ωn+1′​(xk​)ωn+1​(x)​ 我们定义 Rn(x)≡f(x)−Pn(x)R_{n}(x) \\equiv f(x) - P_{n}(x)Rn​(x)≡f(x)−Pn​(x) 为插值余项，则 Lagrange 插值的余项为： Rn(x)=f(n+1)(ξ(x))(n+1)!ωn+1(x)R_{n}(x) = \\frac{f^{(n + 1)}(\\xi(x))}{(n + 1)!}\\omega_{n + 1}(x) Rn​(x)=(n+1)!f(n+1)(ξ(x))​ωn+1​(x) 其中 ξ(x)∈(a,b)\\xi(x) \\in (a, b)ξ(x)∈(a,b) 证明方法是根据 Rn(x)R_{n}(x)Rn​(x) 在所有的插值点上的值为 000，则其可以写成 Rn(x)=g(x)ωn+1(x)R_{n}(x) = g(x)\\omega_{n + 1}(x)Rn​(x)=g(x)ωn+1​(x) 的形式为了求出 g(x)g(x)g(x)，取一个无关辅助变量 ttt，构造函数φ(t)=f(t)−Ln(t)−g(x)ωn+1(t)\\varphi(t) = f(t) - L_{n}(t) - g(x)\\omega_{n + 1}(t)φ(t)=f(t)−Ln​(t)−g(x)ωn+1​(t)则 φ(t)\\varphi(t)φ(t) 有 n+2n + 2n+2 个根 x,xi (i=0,…,n)x, x_{i} \\,(i = 0, \\dots, n)x,xi​(i=0,…,n)，不断使用罗尔定理，可以得到：φ(n+1)(ξ)=f(n+1)(ξ)−g(x)(n+1)!\\varphi^{(n + 1)}(\\xi) = f^{(n + 1)}(\\xi) - g(x)(n + 1)!φ(n+1)(ξ)=f(n+1)(ξ)−g(x)(n+1)!即得到：g(x)=f(n+1)(ξ)(n+1)!g(x) = \\frac{f^{(n + 1)}(\\xi)}{(n + 1)!}g(x)=(n+1)!f(n+1)(ξ)​ 但是 Lagrange 插值有一个巨大的问题，即在插值点有变动的时候，插值函数的变动非常巨大，开销太大，因此引入 Newton 插值 Newton 插值 Newton 插值的主要思想是逐步增加插值点的数目，逐步增加高次项，而不是每一个插值点都使用同样次数的基函数 扩展方式为： Pn(x)=Pn−1(x)+cnωn(x)P_n(x) = P_{n - 1}(x) + c_{n}\\omega_n(x) Pn​(x)=Pn−1​(x)+cn​ωn​(x) 最终公式为： Nn(x)=∑i=0nciωi(x)N_{n}(x) = \\sum\\limits_{i = 0}^{n}c_{i}\\omega_i(x) Nn​(x)=i=0∑n​ci​ωi​(x) 为了求出系数 cic_ici​，我们引入函数差商的概念，函数的 kkk 阶差商是如下递归定义出来的： f[x0]=f(x0)f[x0,x1,…,xk]=f[x0,…,xk−2,xk]−f[x0,x1,…,xk−1]xk−xk−1\\begin{align*} f[x_{0}] &amp;= f(x_{0}) \\\\ f[x_{0}, x_{1}, \\dots, x_{k}] &amp;= \\frac{f[x_0, \\dots, x_{k - 2}, x_k] - f[x_0, x_1, \\dots, x_{k - 1}]}{x_k - x_{k - 1}} \\end{align*} f[x0​]f[x0​,x1​,…,xk​]​=f(x0​)=xk​−xk−1​f[x0​,…,xk−2​,xk​]−f[x0​,x1​,…,xk−1​]​​ 可以归纳证明出： f[x0,…,xk]=∑i=0kf(xi)ωk+1′(xi)f[x_0, \\dots, x_k] = \\sum\\limits_{i = 0}^{k}\\frac{f(x_i)}{\\omega^{&#x27;}_{k + 1}(x_i)} f[x0​,…,xk​]=i=0∑k​ωk+1′​(xi​)f(xi​)​ 直接取 ck=f[x0,…,xk]c_k = f[x_0, \\dots, x_k]ck​=f[x0​,…,xk​] 即可，此时余项为： Rn(x)=f[x,x0,…,xn]ωn+1(x)R_{n}(x) = f[x, x_0, \\dots, x_n]\\omega_{n + 1}(x) Rn​(x)=f[x,x0​,…,xn​]ωn+1​(x) 根据该式以及余项的定义，可以证明差商的性质： f[x,x0,…,xn]=f(n+1)(ξ)(n+1)!f[x, x_0, \\dots, x_n] = \\frac{f^{(n + 1)}(\\xi)}{(n + 1)!}f[x,x0​,…,xn​]=(n+1)!f(n+1)(ξ)​由 xxx 的任意性可以推出：f[x0,…,xn]=f(n)(ξ)n!f[x_0, \\dots, x_n] = \\frac{f^{(n)}(\\xi)}{n!}f[x0​,…,xn​]=n!f(n)(ξ)​ 在使用 Newton 插值的过程中，可以使用 Nk+1(x)−Nk(x)N_{k + 1}(x) - N_{k}(x)Nk+1​(x)−Nk​(x) 或者余项来判断是否需要使用新的插值点 分段多项式插值 对于上述的多项式插值有一些很显著的问题： 数值稳定性差，容易被异常数据影响 无法保证曲线的单调性和凸性 容易出现过拟合（Runge 现象：nnn越高对曲线的拟合效果不一定越好） 可以采用分段多项式插值的方式来修改 分段线性插值 定义 x−1=x0&lt;x1&lt;⋯&lt;xn=xn+1x_{-1} = x_0 &lt; x_{1} &lt; \\cdots &lt; x_n = x_{n + 1}x−1​=x0​&lt;x1​&lt;⋯&lt;xn​=xn+1​ 则基函数定义为： li(x)={x−xi−1xi−xi−1xi−1≤x≤xix−xi+1xi−xi+1xi≤x≤xi+10othersl_i(x) = \\begin{cases} \\dfrac{x - x_{i - 1}}{x_i - x_{i - 1}} &amp; x_{i - 1} \\leq x \\leq x_{i} \\\\[1em] \\dfrac{x - x_{i + 1}}{x_i - x_{i + 1}} &amp; x_{i} \\leq x \\leq x_{i + 1} \\\\[1em] 0 &amp; \\text{others} \\end{cases} li​(x)=⎩⎨⎧​xi​−xi−1​x−xi−1​​xi​−xi+1​x−xi+1​​0​xi−1​≤x≤xi​xi​≤x≤xi+1​others​ 也即每两个数据点之间是线性的 令 Ih(x)=∑i=0nyili(x)I_h(x) = \\sum\\limits_{i =0}^{n}y_il_i(x) Ih​(x)=i=0∑n​yi​li​(x) 为分段线性插值结果，则每个小区间上的余项都是一个二阶的 Lagrange 余项，则可以证明： 若 f(x)∈C2[a,b]f(x) \\in C^{2}[a, b]f(x)∈C2[a,b]，则：lim⁡h→0Ih(x)=f(x)\\lim\\limits_{h \\to 0}I_{h}(x) = f(x)h→0lim​Ih​(x)=f(x)其中 h=max⁡1≤i≤n(xi+1−xi)h = \\max\\limits_{1 \\leq i \\leq n}(x_{i + 1} - x_{i})h=1≤i≤nmax​(xi+1​−xi​) 分段 Hermite 插值 Hermite 插值不仅保证每个点处的函数值相同，还保证了每个点处的导数值也相同，即插值目标为： H(xi)=f(xi)H′(xi)=f′(xi)\\begin{align*} H(x_i) &amp;= f(x_i) \\\\ H&#x27;(x_i) &amp;= f&#x27;(x_i) \\end{align*} H(xi​)H′(xi​)​=f(xi​)=f′(xi​)​ 可以证明 Hermite 多项式一定有解且唯一，结果为： H(x)=∑j=0n[fjαj(x)+fj′βj(x)]H(x) = \\sum\\limits_{j=0}^{n}[f_j\\alpha_j(x) + f&#x27;_j\\beta_j(x)] H(x)=j=0∑n​[fj​αj​(x)+fj′​βj​(x)] 其中 αj,βj\\alpha_j, \\beta_jαj​,βj​ 是基函数，满足： αj′(xi)=βj(xi)=0αj(xi)=βj′(xi)={1i=j0i≠j\\begin{align*} \\alpha_j&#x27;(x_i) = \\beta_j(x_i) &amp;= 0 \\\\ \\alpha_j(x_i) = \\beta_j&#x27;(x_i) &amp;= \\begin{cases} 1 &amp; i = j \\\\ 0 &amp; i eq j \\end{cases} \\end{align*} αj′​(xi​)=βj​(xi​)αj​(xi​)=βj′​(xi​)​=0={10​i=ji=j​​ 他们可以从 Lagrange 插值的基函数推出来： αj(x)=[1−2(x−xj)lj′(xj)]lj2(x)βj(x)=(x−xj)lj2(x)\\begin{align*} \\alpha_j(x) &amp;= [1 - 2(x - x_j)l&#x27;_j(x_j)]l_j^2(x) \\\\ \\beta_j(x) &amp;= (x - x_j)l_j^2(x) \\end{align*} αj​(x)βj​(x)​=[1−2(x−xj​)lj′​(xj​)]lj2​(x)=(x−xj​)lj2​(x)​ 如果是特殊的 Hermite 插值，例如只用保证在一个点处的导数值相同，则可以用 Newton 或 Lagrange 插值之后，再在后面添加一项 Cωn+1(x)C\\omega_{n + 1}(x)Cωn+1​(x) ，求出常数 CCC 即可 当 n=1n = 1n=1 的时候，Hermite 实际上是在用一条三次曲线去插两个点，这杯称为两点三次插值，利用这种方法可以引出分段 Hermite 插值，即每一段都用两点三次的方法去插，公式很简单，只需要把分段线性插值的基函数代入到上述 αj,βj\\alpha_j, \\beta_jαj​,βj​ 的表达式中即可 保形分段插值 在 Hermite 中我们需要知道插值点处的导数值，但是这在很多情况下是几乎不可能的，例如一组统计数据基本上无法得知其导数是如何的，因此这种情况下我们需要通过某种方法来认为的“设置”导数值，进而得到一个光滑并且保凸的曲线 一种常见的方式是利用数据点与邻近数据点的割线来估计该数据点处的导数，具体来说对于 xkx_kxk​ 处的导数： 首先计算两侧割线斜率： dk−1=f(xk)−f(xk−1)xk−xk−1dk=f(xk+1)−f(xk)xk+1−xk\\begin{align*} d_{k - 1} = \\frac{f(x_k) - f(x_{k - 1})}{x_k - x_{k - 1}} \\\\ d_{k} = \\frac{f(x_{k + 1}) - f(x_{k})}{x_{k + 1} - x_{k}} \\\\ \\end{align*} dk−1​=xk​−xk−1​f(xk​)−f(xk−1​)​dk​=xk+1​−xk​f(xk+1​)−f(xk​)​​ 如果 dk−1dk≤0d_{k - 1}d_{k} \\leq 0dk−1​dk​≤0 即两侧单调性不同，则认为 fk′=0f&#x27;_k = 0fk′​=0，反之对两侧的割线斜率用区间长度做加权平均： wk−1+wkfk′=wk−1dk−1+wkdk\\frac{w_{k - 1} + w_{k}}{f&#x27;_k} = \\frac{w_{k - 1}}{d_{k - 1}} + \\frac{w_{k}}{d_{k}} fk′​wk−1​+wk​​=dk−1​wk−1​​+dk​wk​​ 其中： wk−1=hk−1+2hkwk=2hk−1+hkhk−1=xk−xk−1hk=xk+1−xk\\begin{align*} w_{k - 1} = h_{k - 1} + 2h_k&amp;\\quad w_{k} = 2h_{k - 1} +h_{k} \\\\[1em] h_{k - 1} = x_{k} - x_{k - 1}&amp;\\quad h_{k} = x_{k + 1} - x_{k} \\end{align*} wk−1​=hk−1​+2hk​hk−1​=xk​−xk−1​​wk​=2hk−1​+hk​hk​=xk+1​−xk​​ 而端点处的函数值可以做单侧分析得到 样条插值 上述的分段插值有一个显而易见的问题，它只保证了每个插值点处的一阶导数连续，更高阶的导数则无法保证，而我们知道在物理上，如果这条插值曲线的势能达到最小，那曲线一定是二阶导数连续的 满足在整体区间上二阶导函数连续的插值函数称为样条插值函数，如果每个小区间上都是三次函数，则称为三次样条插值函数 每个区间上 sj(x)s_j(x)sj​(x) 是三次多项式，需要 444 个方程才能唯一确定系数，因此一共需要 4n4n4n 个方程，而良定义的方程为： sj(xj)=fjj=0,…,n−1sj(xj+1)=fj+1j=0,…,n−1sj−1′(xj)=sj′(xj)j=1,…,n−1sj−1′′(xj)=sj′′(xj)j=1,…,n−1\\begin{align*} s_j(x_j) &amp;= f_j \\quad j = 0, \\dots, n - 1 \\\\ s_j(x_{j + 1}) &amp;= f_{j + 1} \\quad j = 0, \\dots, n - 1 \\\\ s_{j - 1}&#x27;(x_j) &amp;= s_j&#x27;(x_j) \\quad j = 1, \\dots, n - 1 \\\\ s_{j - 1}&#x27;&#x27;(x_j) &amp;= s_j&#x27;&#x27;(x_j) \\quad j = 1, \\dots, n - 1 \\\\ \\end{align*} sj​(xj​)sj​(xj+1​)sj−1′​(xj​)sj−1′′​(xj​)​=fj​j=0,…,n−1=fj+1​j=0,…,n−1=sj′​(xj​)j=1,…,n−1=sj′′​(xj​)j=1,…,n−1​ 一共 2n+2(n−1)=4n−22n + 2(n - 1) = 4n - 22n+2(n−1)=4n−2 个，因此还需要从端点处设置两个方程才够，有很多不同的设置方法，包括但不限于： 设置端点处的一阶导数值 设置端点处的二阶导数值（如果端点处的二阶导数为 000 则称为自然样条插值） 假设 xn−x0x_n - x_0xn​−x0​ 是函数的周期 给定第一个区间和最后一个区间的表达式 在给定足量的方程之后，就需要想办法确定处插值函数了，直接解方程比较复杂，有两种可行的方式： 假设每个插值点的一阶导数已知，于是可以用分段 Hermite 插值法，之后再根据二次导数连续的特性来反解出参数 假设每个插值点的二阶导数已知，先利用插值条件解出表达式，之后反解出参数 假设 S′′(xj)=MjS&#x27;&#x27;(x_j) = M_jS′′(xj​)=Mj​，并认为二次导数在区间是线性的，则：S′′(x)=Mj(x−xj+1xj−xj+1)+Mj+1(x−xjxj+1−xj)S&#x27;&#x27;(x) = M_j\\Big(\\frac{x - x_{j + 1}}{x_j - x_{j + 1}}\\Big) + M_{j + 1}\\Big(\\frac{x - x_{j}}{x_{j + 1} - x_{j}}\\Big)S′′(x)=Mj​(xj​−xj+1​x−xj+1​​)+Mj+1​(xj+1​−xj​x−xj​​)积分两次可以得到：S(x)=−Mj6hj(x−xj+1)3+Mj+16hj(x−xj)3+ajx+bj,x∈[xj,xj+1]S(x) = -\\frac{M_j}{6h_j}(x - x_{j + 1})^{3} + \\frac{M_{j +1}}{6h_j}(x - x_{j})^{3} + a_j x + b_j,\\quad x\\in[x_j, x_{j + 1}]S(x)=−6hj​Mj​​(x−xj+1​)3+6hj​Mj+1​​(x−xj​)3+aj​x+bj​,x∈[xj​,xj+1​]根据插值点处的函数值可以解出 aj,bja_j, b_jaj​,bj​ 的值：aj=fj+1−fjhj−Mj+1−Mj6hjbj=fjxj+1−fj+1xjhj−Mj+1xj−Mjxj+16hj\\begin{align*}a_j &amp;= \\frac{f_{j + 1} - f_j}{h_j} - \\frac{M_{j + 1} - M_{j}}{6}h_j \\\\b_j &amp;= \\frac{f_{j}x_{j + 1} - f_{j + 1}x_j}{h_j} - \\frac{M_{j + 1}x_{j} - M_{j}x_{j + 1}}{6}h_j\\end{align*}aj​bj​​=hj​fj+1​−fj​​−6Mj+1​−Mj​​hj​=hj​fj​xj+1​−fj+1​xj​​−6Mj+1​xj​−Mj​xj+1​​hj​​代入之后，可以得到：S(x)=−Mj6hj(x−xj+1)3+Mj+16hj(x−xj)3+(fjhj−Mjhj6)(xj+1−x)+(fj+1hj−Mj+1hj6)(x−xj)\\begin{align*}S(x) = &amp;-\\frac{M_j}{6h_j}(x - x_{j + 1})^{3} + \\frac{M_{j +1}}{6h_j}(x - x_{j})^{3}\\\\ &amp;+ (\\frac{f_j}{h_j} - \\frac{M_jh_j}{6})(x_{j + 1} - x)+ (\\frac{f_{j + 1}}{h_j} - \\frac{M_{j + 1}h_j}{6})(x - x_j)\\end{align*}S(x)=​−6hj​Mj​​(x−xj+1​)3+6hj​Mj+1​​(x−xj​)3+(hj​fj​​−6Mj​hj​​)(xj+1​−x)+(hj​fj+1​​−6Mj+1​hj​​)(x−xj​)​再根据一阶导数连续可以求出 MjM_{j}Mj​ 的值，在两个相邻区间上，使用 S′(xj−0)=S′(xj+0)S&#x27;(x_j - 0) = S&#x27;(x_j + 0)S′(xj​−0)=S′(xj​+0) 可以化简出：μjMj−1+2Mj+λjMj+1=dj,j=1,…,n−1\\mu_jM_{j - 1} + 2M_j + \\lambda_jM_{j + 1} = d_j,\\quad j = 1, \\dots, n - 1μj​Mj−1​+2Mj​+λj​Mj+1​=dj​,j=1,…,n−1其中：μj=hj−1hj−1+hjλj=hjhj−1+hjdj=6hj−1+hj[fj−1−fjhj−1+fj+1−fjhj]\\begin{align*}\\mu_j &amp;= \\frac{h_{j - 1}}{h_{j - 1} + h_{j}} \\\\\\lambda_j &amp;= \\frac{h_{j}}{h_{j - 1} + h_{j}} \\\\d_j &amp;= \\frac{6}{h_{j - 1} + h_{j}}\\Big[\\frac{f_{j - 1} - f_{j}}{h_{j - 1}} +\\frac{f_{j + 1} - f_{j}}{h_{j}}\\Big] \\\\\\end{align*}μj​λj​dj​​=hj−1​+hj​hj−1​​=hj−1​+hj​hj​​=hj−1​+hj​6​[hj−1​fj−1​−fj​​+hj​fj+1​−fj​​]​再根据端点值得到两个方程，一共是 n+1n + 1n+1 个方程，可以解出 n+1n + 1n+1 个二阶导数值，在力学上求解二阶导数的方程被称为弯矩方程，次数每个方程最多含有三个变量，因此称为三弯矩方程，并且这种方法最后可以使用追赶法求解，在效率和稳定性上都要优于直接求解 4n4n4n 个方程假设端点值的处理方式是已知端点处的一阶导数值，则上述方法写成矩阵的形式为：[21μ12λ1⋱⋱⋱μn−12λn−112][M0M1⋮Mn−1Mn]=[d0d1⋮dn−1dn]\\begin{bmatrix}2 &amp; 1 &amp; &amp; &amp; &amp; \\\\[0.5em]\\mu_1 &amp; 2 &amp; \\lambda_1 &amp; &amp; &amp; \\\\[0.5em] &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; &amp; \\\\[0.5em] &amp; &amp; \\mu_{n - 1} &amp; 2 &amp; \\lambda_{n - 1} &amp; \\\\[0.5em] &amp; &amp; &amp; 1 &amp; 2\\end{bmatrix}\\begin{bmatrix}M_0 \\\\[0.5em]M_1 \\\\[0.5em]\\vdots \\\\[0.5em]M_{n - 1} \\\\[0.5em]M_{n}\\end{bmatrix} = \\begin{bmatrix}d_0 \\\\[0.5em]d_1 \\\\[0.5em]\\vdots \\\\[0.5em]d_{n - 1} \\\\[0.5em]d_{n}\\end{bmatrix}​2μ1​​12⋱​λ1​⋱μn−1​​⋱21​λn−1​2​​​​M0​M1​⋮Mn−1​Mn​​​=​d0​d1​⋮dn−1​dn​​​其中 d0,dnd_0, d_nd0​,dn​ 是由端点处的一阶导数确定的，具体来说：d0=6h0(f1−f0h0−f0′)dn=6hn(fn′−fn−fn−1hn)\\begin{align*}d_0 &amp;= \\frac{6}{h_0}(\\frac{f_1 - f_0}{h_0} - f&#x27;_0) \\\\d_n &amp;= \\frac{6}{h_n}(f&#x27;_n - \\frac{f_n - f_{n - 1}}{h_n}) \\\\\\end{align*}d0​dn​​=h0​6​(h0​f1​−f0​​−f0′​)=hn​6​(fn′​−hn​fn​−fn−1​​)​","tags":["笔记","函数逼近","函数插值"],"categories":["数值分析"]},{"title":"数值分析 - 特征值","path":"/2025/04/09/数值分析5/","content":"数值分析 笔记 5 矩阵特征值的计算 特征值的概念 矩阵 A\\boldsymbol{A}A 的特征值是指满足： Ax=λxx≠0\\boldsymbol{Ax} = \\lambda\\boldsymbol{x}\\quad \\boldsymbol{x eq 0} Ax=λxx=0 的标量 λ\\lambdaλ 关于特征值有以下结论： det(A)=∏λi(A)\\mathrm{det}(\\boldsymbol{A}) = \\prod\\lambda_{i}(\\boldsymbol{A})det(A)=∏λi​(A)λ(A)=λ(AT)\\lambda(\\boldsymbol{A}) = \\lambda(\\boldsymbol{A}^{T})λ(A)=λ(AT)对于对角阵或三角阵，特征值为对角元对于分块对角阵或对角块为方阵的分块三角阵，特征值为对角块特征值的并集相似矩阵的特征值相等，即 λ(A)=λ(V−1AV)\\lambda(\\boldsymbol{A}) = \\lambda(\\boldsymbol{V}^{-1}\\boldsymbol{AV})λ(A)=λ(V−1AV)对矩阵做运算可以直接对应到特征值上 定义： 代数重数为 λ\\lambdaλ 作为方程 det⁡(λI−A)=0\\det(\\lambda\\boldsymbol{I - A}) = 0det(λI−A)=0 的解的重数，几何重数代表 λ\\lambdaλ 对应的特征子空间的维数，可以证明 几何重数不大于代数重数 且不同 λ\\lambdaλ 对应的特征向量都是线性无关的，但是不一定能张成整个空间（即几何重数之和可能小于 nnn ），如果几何重数和几何重数恒定相等，这种矩阵称为 非亏损阵，反之为亏损阵，非亏损阵的 nnn 个特征向量一定是全空间的一组基 有如下定理： ∃Xs.t.X−1AX=Λ⇔A非亏损\\exist \\boldsymbol{X}\\quad \\text{s.t.} \\boldsymbol{X}^{-1}\\boldsymbol{AX} = \\boldsymbol{\\Lambda} \\Leftrightarrow \\boldsymbol{A} \\text{非亏损}∃Xs.t.X−1AX=Λ⇔A非亏损其中 Λ\\boldsymbol{\\Lambda}Λ 是对角阵自然可以证明实对称矩阵一定是非亏损的，并且其特征值一定是实数，可正交对角化，即 X\\boldsymbol{X}X 是正交矩阵 通过重数，可以定义强有力但是我不会的 Jordan 分解： A=XJX−1J=[J1⋱Jp]Js=[λs1λs⋱⋱1λs]\\boldsymbol{A} = \\boldsymbol{XJX}^{-1} \\quad \\boldsymbol{J} = \\begin{bmatrix} \\boldsymbol{J}_{1} &amp; &amp; \\\\[0.6em] &amp; \\ddots &amp; \\\\[0.6em] &amp; &amp; \\boldsymbol{J}_{p} \\\\ \\end{bmatrix} \\quad \\boldsymbol{J}_{s} = \\begin{bmatrix} \\lambda_{s} &amp; 1 &amp; &amp; \\\\[0.6em] &amp; \\lambda_{s} &amp; \\ddots &amp; \\\\[0.6em] &amp; &amp; \\ddots &amp; 1 \\\\[0.6em] &amp; &amp; &amp; \\lambda_{s} \\\\ \\end{bmatrix} A=XJX−1J=​J1​​⋱​Jp​​​Js​=​λs​​1λs​​⋱⋱​1λs​​​ 其中每个 λ\\lambdaλ 对应几何重数个 Jordan 块，阶数之和为代数重数 特征值的分布 很多时候我们关心的是矩阵特征值的极值，例如谱半径是矩阵特征值绝对值的最大值，2-范数、2-条件数也与特征值有关 定义矩阵 A∈Cn×n\\boldsymbol{A} \\in \\mathbb{C}^{n\\times n}A∈Cn×n 的 Gerschgorin 圆盘为：圆心为 aiia_{ii}aii​，半径 ri=(∑j=1n∣aij∣)−∣aii∣r_{i} = \\Big(\\sum\\limits_{j = 1}^{n}|a_{ij}|\\Big) - |a_{ii}|ri​=(j=1∑n​∣aij​∣)−∣aii​∣，则有： A\\boldsymbol{A}A 的特征值一定在 nnn 个圆盘的并集上如果有 mmm 个圆盘组成了独立的连通支，则这 mmm 个圆盘中恰好有 mmm 个特征值 幂法与反幂法 幂法的作用是为了求主特征值与主特征向量，即模最大的特征值与其对应的向量 幂法的定义为：取几乎任意的非零向量 v0\\boldsymbol{v}_{0}v0​，通过以下方式计算向量序列： vk=Avk−1\\boldsymbol{v}_{k} = \\boldsymbol{Av}_{k - 1} vk​=Avk−1​ 设主特征值为 λ1\\lambda_{1}λ1​，其对应的特征向量为 x1\\boldsymbol{x}_{1}x1​，则有，当 A\\boldsymbol{A}A 有唯一主特征时： lim⁡k→∞vk=λ1lim⁡k→∞vk−1=Cx1\\lim\\limits_{k\\to\\infty}\\boldsymbol{v}_{k} = \\lambda_{1}\\lim\\limits_{k\\to\\infty}\\boldsymbol{v}_{k - 1} = C\\boldsymbol{x}_{1} k→∞lim​vk​=λ1​k→∞lim​vk−1​=Cx1​ 我们针对非亏损阵 A\\boldsymbol{A}A 进行证明： 设 A\\boldsymbol{A}A 线性无关的特征向量为 x^1,⋯ ,x^n\\hat{\\boldsymbol{x}}_{1}, \\cdots, \\hat{\\boldsymbol{x}}_{n}x^1​,⋯,x^n​，v0=∑i=1nαix^i\\boldsymbol{v}_{0} = \\sum\\limits_{i=1}^{n}\\alpha_{i}\\hat{\\boldsymbol{x}}_{i}v0​=i=1∑n​αi​x^i​，其中 α1≠0\\alpha_{1} eq 0α1​=0，这也是 几乎随机 的原因，则有：vk=Akv0=∑i=1nαiλikx^i=λ1k[∑i=1sαix^i+∑i=s+1nαi(λiλ1)kx^i]\\begin{align*}\\boldsymbol{v}_{k} &amp;= \\boldsymbol{A}^{k}\\boldsymbol{v}_{0} \\\\&amp;= \\sum\\limits_{i=1}^{n}\\alpha_{i}\\lambda_{i}^{k}\\hat{\\boldsymbol{x}}_{i} \\\\&amp;= \\lambda_{1}^{k}\\Bigg[\\sum\\limits_{i=1}^{s}\\alpha_{i}\\hat{\\boldsymbol{x}}_{i} + \\sum\\limits_{i=s+1}^{n}\\alpha_{i}(\\frac{\\lambda_{i}}{\\lambda_{1}})^{k}\\hat{\\boldsymbol{x}}_{i}\\Bigg]\\end{align*}vk​​=Akv0​=i=1∑n​αi​λik​x^i​=λ1k​[i=1∑s​αi​x^i​+i=s+1∑n​αi​(λ1​λi​​)kx^i​]​其中，sss 为 λ1\\lambda_{1}λ1​ 的代数重数由于 ∣λi/λ1∣&lt;1|\\lambda_i / \\lambda_1 | &lt; 1∣λi​/λ1​∣&lt;1，因此当 kkk 充分大的时候：lim⁡k→∞vk≈λ1k(∑i=1sαix^i)\\lim\\limits_{k\\to\\infty}\\boldsymbol{v}_{k} \\approx \\lambda_{1}^{k}\\Big(\\sum\\limits_{i=1}^{s}\\alpha_{i}\\hat{\\boldsymbol{x}}_{i}\\Big)k→∞lim​vk​≈λ1k​(i=1∑s​αi​x^i​)证毕 规格化 幂法的主要问题在于，当 kkk 很大的时候，可能在收敛之前就已经发生了溢出现象 解决溢出的一种方式为规格化，即在每一步计算完成之后除以向量的模最大的元素 max⁡‾(vk)\\overline{\\max}(\\boldsymbol{v}_{k})max(vk​)，即： uk=vkmax⁡‾(vk)vk+1=Auk\\begin{align*} \\boldsymbol{u}_{k} &amp;= \\frac{\\boldsymbol{v}_{k}}{\\overline{\\max}(\\boldsymbol{v}_{k})} \\\\ \\boldsymbol{v}_{k + 1} &amp;= \\boldsymbol{Au}_{k}\\\\ \\end{align*} uk​vk+1​​=max(vk​)vk​​=Auk​​ 这样的话有： lim⁡k→∞uk=x1max⁡‾(x1)lim⁡k→∞∣∣vk∣∣∞=λ1\\begin{align*} \\lim\\limits_{k\\to\\infty}\\boldsymbol{u}_{k} &amp;= \\frac{\\boldsymbol{x}_{1}}{\\overline{\\max}(\\boldsymbol{x}_{1})} \\\\ \\lim\\limits_{k\\to\\infty}||\\boldsymbol{v}_{k}||_{\\infty} &amp;= \\lambda_{1}\\\\ \\end{align*} k→∞lim​uk​k→∞lim​∣∣vk​∣∣∞​​=max(x1​)x1​​=λ1​​ 其中 x1\\boldsymbol{x}_{1}x1​ 是某个主特征向量 幂法加速 原点位移： 幂法的收敛速度取决于次大特征值与最大值的模长之比，而特征值的运算是线性的，因此考虑 B=A−sI\\boldsymbol{B} = \\boldsymbol{A} - s\\boldsymbol{I}B=A−sI，则可以选取合适的 sss，使得 λ1−s\\lambda_{1} - sλ1​−s 仍然是 B\\boldsymbol{B}B 的主特征值，且： ∣λ2(B)λ1−s∣\\Big|\\frac{\\lambda_{2}(\\boldsymbol{B})}{\\lambda_{1} - s}\\Big| ​λ1​−sλ2​(B)​​ 尽可能小，其中 λ2(B)\\lambda_{2}(\\boldsymbol{B})λ2​(B) 代表模次大的特征值 Rayleigh 商加速： 实对称矩阵 A\\boldsymbol{A}A 对应向量 x≠0\\boldsymbol{x} eq \\boldsymbol{0}x=0 的 Rayleigh 商定义为： R(x)=⟨Ax,x⟩⟨x,x⟩=xTAxxTxR(\\boldsymbol{x}) = \\frac{\\lang\\boldsymbol{Ax}, \\boldsymbol{x}\\rang}{\\lang\\boldsymbol{x}, \\boldsymbol{x}\\rang} = \\frac{\\boldsymbol{x}^{T}\\boldsymbol{Ax}}{\\boldsymbol{x}^{T}\\boldsymbol{x}} R(x)=⟨x,x⟩⟨Ax,x⟩​=xTxxTAx​ 可以证明： λn≤R(x)≤λ1\\lambda_{n} \\leq R(\\boldsymbol{x}) \\leq \\lambda_{1} λn​≤R(x)≤λ1​ 其中 λ1,λn\\lambda_{1}, \\lambda_{n}λ1​,λn​ 为最大和最小特征值 可以证明规格化幂法满足： R(uk)=λ1+O((λ2λ1)2k)max⁡‾(uk)=λ1+O((λ2λ1)k−1)\\begin{align*} R(\\boldsymbol{u}_{k}) &amp;= \\lambda_{1} + O\\Big(\\Big(\\frac{\\lambda_{2}}{\\lambda_{1}}\\Big)^{2k}\\Big) \\\\ \\overline{\\max}(\\boldsymbol{u}_{k}) &amp;= \\lambda_{1} + O\\Big(\\Big(\\frac{\\lambda_{2}}{\\lambda_{1}}\\Big)^{k - 1}\\Big) \\end{align*} R(uk​)max(uk​)​=λ1​+O((λ1​λ2​​)2k)=λ1​+O((λ1​λ2​​)k−1)​ 因此 Rayleigh 商可以比最大值更快收敛 反幂法 即通过求 A−1\\boldsymbol{A}^{-1}A−1 模最小的特征值，取倒数后得到 A\\boldsymbol{A}A 的主特征值 QR 分解 Householder 变换 对于 w∈Rn\\boldsymbol{w} \\in \\mathbb{R}^{n}w∈Rn, wTw=1\\boldsymbol{w}^T\\boldsymbol{w} = 1wTw=1，称 H(w)=I−2wwT\\boldsymbol{H(w)} = \\boldsymbol{I} - 2\\boldsymbol{ww}^{T}H(w)=I−2wwT 为 Householder 矩阵，Hx\\boldsymbol{Hx}Hx 被称为 Householder 变换 定义 v=wwTx=(wTx)w\\boldsymbol{v} = \\boldsymbol{ww}^{T}\\boldsymbol{x} = (\\boldsymbol{w}^{T}\\boldsymbol{x})\\boldsymbol{w}v=wwTx=(wTx)w ，几何上来看 v\\boldsymbol{v}v 为 x\\boldsymbol{x}x 在 w\\boldsymbol{w}w 方向上的投影 显然 H\\boldsymbol{H}H 是正交矩阵，因此 Householder 变换不会改变向量的二范数，并且可以证明以下定理： 对于 x≠y∈Rn\\boldsymbol{x} eq \\boldsymbol{y} \\in \\mathbb{R}^{n}x=y∈Rn, 且 ∣∣x∣∣2=∣∣y∣∣2||\\boldsymbol{x}||_{2} = ||\\boldsymbol{y}||_{2}∣∣x∣∣2​=∣∣y∣∣2​，则存在 Householder 矩阵 H\\boldsymbol{H}H 使得 Hx=y\\boldsymbol{Hx = y}Hx=y 取 y=−σe1\\boldsymbol{y} = -\\sigma\\boldsymbol{e}_{1}y=−σe1​，其中 σ=sgn(x1)∣∣x∣∣2\\sigma = \\text{sgn}(x_1)||\\boldsymbol{x}||_{2}σ=sgn(x1​)∣∣x∣∣2​，则构造 H\\boldsymbol{H}H 时，满足 v=x+σe1,w=v/∣∣v∣∣2\\boldsymbol{v = x} + \\sigma\\boldsymbol{e_{1}}, \\boldsymbol{w = v} / \\boldsymbol{||v||_{2}}v=x+σe1​,w=v/∣∣v∣∣2​ 这实际上和矩阵消元的过程是一样的，而且由于 H\\boldsymbol{H}H 是正交的，因此可以连续左乘 householder 矩阵，以达到正交三角化的效果 矩阵的 QR 分解 可以证明，任意实矩阵都一定存在 QR 分解，即 A=QR\\boldsymbol{A = QR}A=QR，其中 Q\\boldsymbol{Q}Q 为正交阵，如果 A\\boldsymbol{A}A 非奇异且 R\\boldsymbol{R}R 对角元全正，则分解唯一 下面利用 Householder 变换构造 QR 分解 令： Hk⋯H2H1A=R\\boldsymbol{H_{k}\\cdots\\boldsymbol{H}_{2}\\boldsymbol{H}_{1}A = R} Hk​⋯H2​H1​A=R 则 A=H1H2⋯HkR=QRA = \\boldsymbol{H_{1}\\boldsymbol{H}_{2}\\cdots\\boldsymbol{H}_{k}R = QR} A=H1​H2​⋯Hk​R=QR QR 分解的直接构造是简单的，大致思路为： 构造 H1\\boldsymbol{H}_{1}H1​ 给第一列消元 考虑右下角的 (n−1)×(n−1)(n - 1) \\times (n - 1)(n−1)×(n−1) 阶子阵，构造H2′\\boldsymbol{H}_{2}&#x27;H2′​ 用于消除子阵第一列，对应原矩阵中的第二列，之后即有：H2=[I10T0H2′]\\boldsymbol{H_{2}} = \\begin{bmatrix} \\boldsymbol{I}_{1} &amp; \\boldsymbol{0}^{T} \\\\ \\boldsymbol{0} &amp; \\boldsymbol{H}_{2}&#x27; \\end{bmatrix} H2​=[I1​0​0TH2′​​] 以此类推即可 可以使用算法构造每一个 H\\boldsymbol{H}H 对应的 v\\boldsymbol{v}v，需要的乘法次数为 O(mn2)O(mn^{2})O(mn2)，可减少为 nm2−n3/3nm^{2} - n^{3} / 3nm2−n3/3，如果生成 Q\\boldsymbol{Q}Q 则需要额外 O(mn2)O(mn^{2})O(mn2) Givens 旋转变换 正交变换的另一种方式，通过旋转矩阵来做到 二维平面上的旋转矩阵为： G=[cos⁡θsin⁡θ−sin⁡θcos⁡θ]\\boldsymbol{G} = \\begin{bmatrix} \\cos \\theta &amp; \\sin\\theta \\\\ -\\sin\\theta &amp; \\cos\\theta \\end{bmatrix} G=[cosθ−sinθ​sinθcosθ​] 这代表顺时针旋转 θ\\thetaθ 角 如果想旋转 nnn 维 空间中的两个元素xi,xjx_i, x_jxi​,xj​，则只需要将这个矩阵嵌入 I\\boldsymbol{I}I 的 {i,j}×{i,j}\\{i, j\\}\\times \\{i, j\\}{i,j}×{i,j} 这四个位置即可 如果取： G=1α[x1x2−x2x1],x12+x22=α2\\boldsymbol{G} = \\frac{1}{\\alpha}\\begin{bmatrix} x_1 &amp; x_2 \\\\ -x_2 &amp; x_1 \\end{bmatrix},\\quad x_1^2 + x_2^2 = \\alpha^2 G=α1​[x1​−x2​​x2​x1​​],x12​+x22​=α2 则 G[x1x2]=[α0]\\boldsymbol{G}\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} \\alpha \\\\ 0 \\end{bmatrix} G[x1​x2​​]=[α0​] 这也就实现了消元，并且嵌入到 nnn 维之后仍然每次只影响两行，可以通过不断旋转第 (1,i)(1, i)(1,i) 两个元素来给向量消元，之后按照 QR 分解同样的算法可以构造另一种 QR QR 分解的迭代算法 仍然是矩阵求特征值的问题，考虑我们已知 A\\boldsymbol{A}A 的一个特征向量 x\\boldsymbol{x}x，并且通过正交变换将其消元：Hx=σe1\\boldsymbol{Hx} = \\sigma\\boldsymbol{e}_{1}Hx=σe1​，则： HAHTe1=HA1σx=1σHλx=λσσe1=λe1\\boldsymbol{HAH}^{T}\\boldsymbol{e}_{1} = \\boldsymbol{HA}\\frac{1}{\\sigma}\\boldsymbol{x} = \\frac{1}{\\sigma}\\boldsymbol{H}\\lambda\\boldsymbol{x} = \\frac{\\lambda}{\\sigma}\\sigma\\boldsymbol{e}_{1} = \\lambda\\boldsymbol{e}_{1} HAHTe1​=HAσ1​x=σ1​Hλx=σλ​σe1​=λe1​ 根据单位向量的特性，可以得到： HAHT=[λrT0A1]\\boldsymbol{HAH}^{T} = \\begin{bmatrix} \\lambda &amp; \\boldsymbol{r}^{T} \\\\ \\boldsymbol{0} &amp; \\boldsymbol{A}_{1} \\end{bmatrix} HAHT=[λ0​rTA1​​] 于是我们只需要求 (n−1)×(n−1)(n - 1) \\times (n - 1)(n−1)×(n−1) 维矩阵的特征值即可，这种技术被称为 收缩技术 迭代算法 首先介绍实 Schur 分解： 对于任意实方阵 A\\boldsymbol{A}A，存在正交阵 Q\\boldsymbol{Q}Q，使得 QTAQ=S\\boldsymbol{Q}^{T}\\boldsymbol{AQ} = \\boldsymbol{S}QTAQ=S 为实 Schur 型，或称为拟上三角阵实 Schur 型是指对角块为 1 阶或 2 阶 的分块上三角阵，并且满足 2 阶分块阵的特征值是 A\\boldsymbol{A}A 的两个共轭复特征值 则利用 QR 分解求特征值的一种迭代算法为： Ak=QkRkAk+1=RkQk\\begin{align*} \\boldsymbol{A}_{k} &amp;= \\boldsymbol{Q}_{k}\\boldsymbol{R}_{k} \\\\ \\boldsymbol{A}_{k + 1} &amp;= \\boldsymbol{R}_{k}\\boldsymbol{Q}_{k} \\\\ \\end{align*} Ak​Ak+1​​=Qk​Rk​=Rk​Qk​​ 可以证明：若矩阵 A\\boldsymbol{A}A 的等模的特征值为实重特征值或复共轭特征值, 则QR迭代所得矩阵序列 {Ak}\\{\\boldsymbol{A}_{k}\\}{Ak​} 基本收敛于拟上三角阵，而拟上三角阵是方便求特征值的 对于实对称阵，其迭代的极限也为对角阵 实用的 QR 算法 QR 算法的不足之处： 计算量很大（化简为上 Hessenberg 阵） 手链可能很慢（带原点位移的 QR） 上 Hessenberg 阵是指仅有上三角、主对角线旁边的副对角线有元素的矩阵，如下： [1234567898765]\\begin{bmatrix} 1&amp; 2&amp; 3&amp; 4 \\\\ 5&amp; 6&amp; 7&amp; 8 \\\\ &amp; 9&amp; 8&amp; 7 \\\\ &amp; &amp; 6&amp; 5 \\end{bmatrix} ​15​269​3786​4875​​ 对于上 Hessenberg 型矩阵，可以应用 Givens 旋转的 QR 分解，每步的计算量为 O(n2)O(n^{2})O(n2)，而普通矩阵 QR 分解的计算量为 O(n3)O(n^{3})O(n3)，并且可以证明迭代过程中仍然是保持 Hessenberg 的 对于任意矩阵，都可以用 Householder 变换将其正交相似为上 Hessenberg 矩阵，思路是将矩阵二分块为 1×11 \\times 11×1 与 (n−1)×(n−1)(n - 1)\\times(n - 1)(n−1)×(n−1)，这样只用将第一列第 2∼n2\\sim n2∼n 行进行消元，即得到了 hessenberg 的形式 具体来说： 用Householder变正交相似约化为上Hessenberg矩阵 而实对称阵的带原点位移迭代是指： Ak=QkRk−skIAk+1=RkQk+skI\\begin{align*} \\boldsymbol{A}_{k} &amp;= \\boldsymbol{Q}_{k}\\boldsymbol{R}_{k} - s_k\\boldsymbol{I} \\\\ \\boldsymbol{A}_{k + 1} &amp;= \\boldsymbol{R}_{k}\\boldsymbol{Q}_{k} + s_k\\boldsymbol{I} \\\\ \\end{align*} Ak​Ak+1​​=Qk​Rk​−sk​I=Rk​Qk​+sk​I​ 如果是非对称阵，则可能有复特征值，因此需要做二维平面上的平移","tags":["笔记","特征值"],"categories":["数值分析"]},{"title":"数值分析 - 迭代解方程组","path":"/2025/04/02/数值分析4/","content":"数值分析 笔记 4 线性方程组的迭代解法 迭代解法指的是通过构造一个向量序列来逼近准确解，类似不动点迭代法，为了保证迭代的计算量较小，则： x(k+1)=Bx(k)+f\\boldsymbol{x}^{(k + 1)} = \\boldsymbol{B}\\boldsymbol{x}^{(k)} + \\boldsymbol{f} x(k+1)=Bx(k)+f 对于 Ax=b\\boldsymbol{Ax} = \\boldsymbol{b}Ax=b，使用矩阵分裂法，令 A=M−N\\boldsymbol{A} = \\boldsymbol{M} - \\boldsymbol{N}A=M−N，则可以化简为： x=M−1Nx+M−1b\\boldsymbol{x} = \\boldsymbol{M}^{-1}\\boldsymbol{Nx} + \\boldsymbol{M}^{-1}\\boldsymbol{b} x=M−1Nx+M−1b 这也就是一个迭代表达式，因此分裂需要满足： M\\boldsymbol{M}M非奇异，且解方程快 收敛快 Jacobi 迭代法 令D=diag(A)\\boldsymbol{D} = \\mathrm{diag}(\\boldsymbol{A})D=diag(A)，则令M=D\\boldsymbol{M} = \\boldsymbol{D}M=D，N=D−A\\boldsymbol{N} = \\boldsymbol{D - A}N=D−A 迭代式为： xk+1=D−1(D−A)x+D−1b\\boldsymbol{x}^{k + 1} = \\boldsymbol{D}^{-1}(\\boldsymbol{D - A})\\boldsymbol{x} + \\boldsymbol{D}^{-1}\\boldsymbol{b} xk+1=D−1(D−A)x+D−1b 由于 D−1\\boldsymbol{D}^{-1}D−1 是方便计算的，只用做 nnn 次除法即可，因此每次迭代的计算量相当于是做一次 MV 运算，如果是 SpMV，则计算量降为 O(nnz(A))O(\\mathrm{nnz}(\\boldsymbol{A}))O(nnz(A)) 算法为： 1234while not stop: y = x for i in range(1, n + 1): x[i] = (b[i] - sum(1, i, a[i][j] * y[j]) - sum(i + 1, n + 1, a[i][j] * y[j])) / a[i][i] Gauss-Seidel 迭代法 与 Jacobi 迭代法很类似，不同的是取 M\\boldsymbol{M}M 为 A\\boldsymbol{A}A 的下三角子阵而不是对角阵，但这时候对迭代法的顺序有要求，当求出 xi(k+1)\\boldsymbol{x}^{(k + 1)}_{i}xi(k+1)​ 之后，需要用它直接求 xi+1(k+1)\\boldsymbol{x}^{(k + 1)}_{i + 1}xi+1(k+1)​ 因此对应算法为： 123while not stop: for i in range(1, n + 1): x[i] = (b[i] - sum(1, i, a[i][j] * x[j]) - sum(i + 1, n + 1, a[i][j] * x[j])) / a[i][i] 当然也可以逆向计算，从 nnn 算到 111 事实上，上述的逻辑其实是推到的逻辑的逆向，我们是先给出分裂法对应的矩阵，之后再给出算法，但其实这不太符合逻辑，我们应该是先给出迭代的算法，再推导出其分裂法的矩阵，并据此分析其收敛性等性质 例如，Jacobi 和 GS 的算法来源应该是下面两张图： Jacobi原始迭代式 Gauss-Seidel原始迭代式 SOR 迭代法 在 GS 迭代法的基础上增加了松弛因子 ω\\omegaω，计算完 xi(k+1)x_{i}^{(k + 1)}xi(k+1)​ 之后将其与 xi(k)x_{i}^{(k)}xi(k)​ 加权平均得到最终结果，具体来说： SOR原始迭代式 对应的矩阵计算为： x(k+1)=(1−ω)x(k)+ωD−1[L~x(k+1)+U~x(k)+b]\\boldsymbol{x}^{(k + 1)} = (1 - \\omega) \\boldsymbol{x}^{(k)} + \\omega\\boldsymbol{D}^{-1}\\Big[\\tilde{\\boldsymbol{L}}\\boldsymbol{x}^{(k + 1)} + \\tilde{\\boldsymbol{U}}\\boldsymbol{x}^{(k)} + \\boldsymbol{b} \\Big] x(k+1)=(1−ω)x(k)+ωD−1[L~x(k+1)+U~x(k)+b] 对应分裂法，M=1ωD−L~\\boldsymbol{M} = \\dfrac{1}{\\omega}\\boldsymbol{D} - \\tilde{L}M=ω1​D−L~，其中： L~={−aiji&gt;j0othersU~={−aiji&lt;j0others\\begin{align*} \\tilde{\\boldsymbol{L}} = \\begin{cases} - a_{ij} &amp; i &gt; j \\\\ 0 &amp; \\text{others} \\end{cases} \\\\ \\tilde{\\boldsymbol{U}} = \\begin{cases} - a_{ij} &amp; i &lt; j \\\\ 0 &amp; \\text{others} \\end{cases} \\end{align*} L~={−aij​0​i&gt;jothers​U~={−aij​0​i&lt;jothers​​ 因此对应算法为： 123while not stop: for i in range(1, n + 1): x[i] = (1 - ω)* x[i] + ω * (b[i] - sum(1, i, a[i][j] * x[j]) - sum(i + 1, n + 1, a[i][j] * x[j])) / a[i][i] 收敛性分析 类似非线性方程求解的判据，我们定义： e(k)=x(k)−x∗\\boldsymbol{e}^{(k)} = \\boldsymbol{x}^{(k)} - \\boldsymbol{x}^{*} e(k)=x(k)−x∗ 则容易得到 e(k+1)=Be(k)⇒e(k)=Bke(0)\\boldsymbol{e}^{(k + 1)} = \\boldsymbol{B}\\boldsymbol{e}^{(k)} \\Rightarrow \\boldsymbol{e}^{(k)} = \\boldsymbol{B}^{k}\\boldsymbol{e}^{(0)} e(k+1)=Be(k)⇒e(k)=Bke(0) 因此对于任意一个初始误差，如果要保证迭代法收敛，则需要保证 lim⁡k→∞Bk=O\\lim\\limits_{k \\to \\infty}\\boldsymbol{B}^{k} = \\boldsymbol{O}k→∞lim​Bk=O 对于矩阵的极限，我们有如下定理： lim⁡k→∞A(k)=A⇔∀xlim⁡k→∞A(k)x=Ax\\lim\\limits_{k\\to\\infty}\\boldsymbol{A}^{(k)} = \\boldsymbol{A} \\Leftrightarrow \\forall \\boldsymbol{x} \\quad \\lim\\limits_{k\\to\\infty}\\boldsymbol{A}^{(k)}\\boldsymbol{x} = \\boldsymbol{Ax}k→∞lim​A(k)=A⇔∀xk→∞lim​A(k)x=Ax 定义矩阵的谱半径为ρ(A)=max⁡∣λ(A)∣\\rho(\\boldsymbol{A}) = \\max |\\lambda(\\boldsymbol{A})|ρ(A)=max∣λ(A)∣，使用谱分解或 Jordan 分解可以证明，lim⁡k→∞Bk=O\\lim\\limits_{k \\to \\infty}\\boldsymbol{B}^{k} = \\boldsymbol{O}k→∞lim​Bk=O 等价与 ρ(B)&lt;1\\rho(\\boldsymbol{B}) &lt; 1ρ(B)&lt;1 正式给出定理： 若：x(k+1)=Bx(k)+f\\boldsymbol{x}^{(k + 1)} = \\boldsymbol{B}\\boldsymbol{x}^{(k)} + \\boldsymbol{f}x(k+1)=Bx(k)+f且 I−B\\boldsymbol{I - B}I−B 非奇异，则迭代法对于任意初始值收敛的充要条件是 ρ(B)&lt;1\\rho(\\boldsymbol{B}) &lt; 1ρ(B)&lt;1，且非奇异保证了收敛值是唯一解 类比之前对收敛阶的定义，可以证明当 B\\boldsymbol{B}B 可对角化的时候，该迭代法 1 阶收敛，且常数 c=ρ(B)c = \\rho(\\boldsymbol{B})c=ρ(B) 对于上述的三种迭代法，有充分条件： 对于 Jacobi 的迭代矩阵 B=D−1(D−A)\\boldsymbol{B} = \\boldsymbol{D}^{-1}\\boldsymbol{(D - A)}B=D−1(D−A)，若 ∣∣B∣∣1&lt;1||\\boldsymbol{B}||_{1} &lt; 1∣∣B∣∣1​&lt;1 或 ∣∣B∣∣∞&lt;1||\\boldsymbol{B}||_{\\infty} &lt; 1∣∣B∣∣∞​&lt;1，则 Jacobi 和 G-S 收敛 对于一个矩阵 A\\boldsymbol{A}A，如果存在排列阵 PPP，使得： PTAP=[A11A120A22]\\boldsymbol{P}^{T}\\boldsymbol{AP} = \\begin{bmatrix} \\boldsymbol{A}_{11} &amp; \\boldsymbol{A}_{12} \\\\ \\boldsymbol{0} &amp; \\boldsymbol{A}_{22} \\end{bmatrix} PTAP=[A11​0​A12​A22​​] 其中 A11\\boldsymbol{A}_{11}A11​ 与 A22\\boldsymbol{A}_{22}A22​ 是方阵，则称 A\\boldsymbol{A}A 是可约矩阵 给出一些针对系数矩阵是对角占优和正定阵时，收敛的条件： 严格对角占优矩阵、不可约的弱对角占优矩阵，都是非奇异的对于 1 中的系数矩阵，其 Jacobi 和 G-S 都收敛，并且若 0&lt;ω≤10 &lt; \\omega \\leq 10&lt;ω≤1，则 SOR 也收敛对于系数为对称正定矩阵，Jacobi在对角元全正，且 2D−A2\\boldsymbol{D} - \\boldsymbol{A}2D−A 也正定的时候收敛，G-S 一定收敛，并且若 0&lt;ω&lt;20 &lt; \\omega &lt; 20&lt;ω&lt;2，则 SOR 也收敛SOR 收敛的必要条件是 0&lt;ω&lt;20 &lt; \\omega &lt; 20&lt;ω&lt;2 最速下降法 将解线性方程组转化为在高维空间中求函数极值的问题，例如对于函数： φ(x)=12xTAx−bTx\\varphi(\\boldsymbol{x}) = \\frac{1}{2}\\boldsymbol{x}^{T}\\boldsymbol{Ax} - \\boldsymbol{b}^{T}\\boldsymbol{x} φ(x)=21​xTAx−bTx 可以证明其极值点就是 Ax=b\\boldsymbol{Ax = b}Ax=b 的解，如果 A\\boldsymbol{A}A 是正定矩阵，则这个极值点一定是最小值 求极值最简单的方法是最速下降法，也就是梯度下降，每一步沿着负梯度方向前进，步长保证得到的结果最小，对于上述的 φ\\varphiφ，我们有： ∇φ(x(k))=Ax(k)−b=−r(k) abla\\varphi(\\boldsymbol{x}^{(k)}) = \\boldsymbol{Ax}^{(k)} - \\boldsymbol{b} = -\\boldsymbol{r}^{(k)} ∇φ(x(k))=Ax(k)−b=−r(k) 则步长为： αk=(r(k))Tr(k)(r(k))TAr(k)\\alpha_{k} = \\frac{(\\boldsymbol{r}^{(k)})^{T}\\boldsymbol{r}^{(k)}}{(\\boldsymbol{r}^{(k)})^{T}\\boldsymbol{Ar}^{(k)}} αk​=(r(k))TAr(k)(r(k))Tr(k)​ 每次迭代为： x(k+1)=x(k)+αkr(k)r(k+1)=r(k)−αkAr(k)\\begin{align} \\boldsymbol{x}^{(k + 1)} &amp;= \\boldsymbol{x}^{(k)} + \\alpha_{k}\\boldsymbol{r}^{(k)} \\\\ \\boldsymbol{r}^{(k + 1)} &amp;= \\boldsymbol{r}^{(k)} - \\alpha_{k}\\boldsymbol{Ar}^{(k)} \\end{align} x(k+1)r(k+1)​=x(k)+αk​r(k)=r(k)−αk​Ar(k)​​ 等式 (2) 是因为 Δr=Δ(b−Ax)=−AΔx=−αAr\\Delta\\boldsymbol{r} = \\Delta(\\boldsymbol{b - Ax}) = -\\boldsymbol{A}\\Delta\\boldsymbol{x} = -\\alpha\\boldsymbol{Ar}Δr=Δ(b−Ax)=−AΔx=−αAr 每步迭代的计算量是一次 MV，与 SOR 相同 由于 φ\\varphiφ 是凸二次函数，因此一定收敛，对于一般的优化问题，可以扩展为随机梯度下降法 但是梯度下降的收敛速度很慢，并且可能会遇到局部最优解 共轭梯度法 不沿着最速下降方向，沿着最速下降方向和上一步搜索方向张成的平面移动，设搜索方向为 p(k)\\boldsymbol{p}^{(k)}p(k)，则： βk−1=−(r(k))TAp(k−1)(p(k−1))TAp(k−1)p(k)=r(k)+βk−1p(k−1)αk=(r(k))Tp(k)(p(k))TAp(k)\\begin{align*} \\beta_{k - 1} &amp;= -\\frac{(\\boldsymbol{r}^{(k)})^{T}\\boldsymbol{Ap}^{(k - 1)}}{(\\boldsymbol{p}^{(k - 1)})^{T}\\boldsymbol{Ap}^{(k - 1)}} \\\\ \\boldsymbol{p}^{(k)} &amp;= \\boldsymbol{r}^{(k)} + \\beta_{k - 1}\\boldsymbol{p}^{(k - 1)} \\\\ \\alpha_{k} &amp;= \\frac{(\\boldsymbol{r}^{(k)})^{T}\\boldsymbol{p}^{(k)}}{(\\boldsymbol{p}^{(k)})^{T}\\boldsymbol{Ap}^{(k)}} \\end{align*} βk−1​p(k)αk​​=−(p(k−1))TAp(k−1)(r(k))TAp(k−1)​=r(k)+βk−1​p(k−1)=(p(k))TAp(k)(r(k))Tp(k)​​ 每轮迭代需要一次 MV 两次 VV，但是可以保证如果收敛，则收敛步数不大于 nnn 对于病态矩阵，舍入误差严重，可能收敛很慢甚至不收敛，因此可以做一些处理，例如对于病态矩阵 A\\boldsymbol{A}A： Ax=b⇔M−1Ax=M−1b\\boldsymbol{Ax = b} \\Leftrightarrow \\boldsymbol{M}^{-1}\\boldsymbol{Ax} = \\boldsymbol{M}^{-1}\\boldsymbol{b} Ax=b⇔M−1Ax=M−1b 如果想保证系数矩阵是对称正定的，则取 M=LLT\\boldsymbol{M} = \\boldsymbol{LL}^{T}M=LLT 是对称正定的，并且令 y=LTx\\boldsymbol{y} = \\boldsymbol{L}^{T}\\boldsymbol{x}y=LTx，则： Ax=b⇔L−1AL−Ty=L−1b\\boldsymbol{Ax = b} \\Leftrightarrow \\boldsymbol{L}^{-1}\\boldsymbol{A}\\boldsymbol{L}^{-T}\\boldsymbol{y} = \\boldsymbol{L}^{-1}\\boldsymbol{b} Ax=b⇔L−1AL−Ty=L−1b 这样 L−1ALT\\boldsymbol{L}^{-1}\\boldsymbol{A}\\boldsymbol{L}^{T}L−1ALT 就是对称正定的","tags":["笔记","线性方程组","线性代数"],"categories":["数值分析"]},{"title":"数值分析 - 线性方程组","path":"/2025/03/12/数值分析3/","content":"数值分析 笔记 3 线性方程组 线性代数相应内容复习 对于一个线性方程组，当方程数和变元数不等时，其解的数量通常是无穷或零，因此在本课程中基本不考虑 相应的，我们考虑实方阵A∈Rn×n\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}A∈Rn×n作为方程系数的情况，且为了方程有解，我们考虑非奇异矩阵（即可逆矩阵） 几种特殊矩阵： 对称正定矩阵：A=AT\\boldsymbol{A} = \\boldsymbol{A}^{T}A=AT，∀x≠0,xTAx&gt;0\\forall \\boldsymbol{x} eq \\boldsymbol{0}, \\quad \\boldsymbol{x}^{T}\\boldsymbol{Ax} &gt; 0∀x=0,xTAx&gt;0 正交矩阵：AAT=I\\boldsymbol{AA}^{T} = \\boldsymbol{I}AAT=I 范数 向量的范数 一般的，我们定义满足如下条件的算子∣∣⋅∣∣||\\cdot||∣∣⋅∣∣为范数： 正定性：∀x∈Rn,∣∣x∣∣≥0\\forall \\boldsymbol{x} \\in \\mathbb{R}^{n}, ||\\boldsymbol{x}|| \\geq 0∀x∈Rn,∣∣x∣∣≥0，等号成立当且仅当x=0\\boldsymbol{x} = \\boldsymbol{0}x=0正齐次性：∀α∈R,∣∣αx∣∣=∣α∣⋅∣∣x∣∣\\forall \\alpha \\in \\mathbb{R}, ||\\alpha \\boldsymbol{x}|| = |\\alpha|\\cdot||\\boldsymbol{x}||∀α∈R,∣∣αx∣∣=∣α∣⋅∣∣x∣∣三角不等式 ∀x,y∈Rn,∣∣x+y∣∣≤∣∣x∣∣+∣∣y∣∣\\forall \\boldsymbol{x}, \\boldsymbol{y} \\in \\mathbb{R}^{n}, ||\\boldsymbol{x} + \\boldsymbol{y}|| \\leq ||\\boldsymbol{x}|| + ||\\boldsymbol{y}||∀x,y∈Rn,∣∣x+y∣∣≤∣∣x∣∣+∣∣y∣∣ 范数一定是以向量元素为变元的nnn元连续函数 p-范数和内积范数是两种常见的范数： p-范数:∣∣x∣∣p=(∑i=1n∣xi∣p)1p||\\boldsymbol{x}||_{p} = \\Big(\\sum\\limits_{i=1}^{n}|x_{i}|^{p} \\Big)^{\\frac{1}{p}} ∣∣x∣∣p​=(i=1∑n​∣xi​∣p)p1​ 内积范数（也就是2-范数）：∣∣x∣∣=⟨x,x⟩=xTx||\\boldsymbol{x}|| = \\sqrt{\\langle \\boldsymbol{x}, \\boldsymbol{x} \\rangle} = \\sqrt{\\boldsymbol{x}^{T}\\boldsymbol{x}} ∣∣x∣∣=⟨x,x⟩​=xTx​ 对于p-范数，通常使用几种特例，包括1-范数，2-范数与无穷范数（也可以分别成为曼哈顿范数、欧式范数、最大范数），公式分别为： ∣∣x∣∣1=∑i=1n∣xi∣∣∣x∣∣2=∑i=1nxi2∣∣x∣∣∞=max⁡1≤i≤n∣xi∣\\begin{align*} ||\\boldsymbol{x}||_{1} &amp;= \\sum\\limits_{i=1}^{n} |x_{i}| \\\\ ||\\boldsymbol{x}||_{2} &amp;= \\sqrt{\\sum\\limits_{i=1}^{n}x_{i}^{2}} \\\\ ||\\boldsymbol{x}||_{\\infty} &amp;= \\max\\limits_{1\\leq i \\leq n} |x_{i}| \\end{align*} ∣∣x∣∣1​∣∣x∣∣2​∣∣x∣∣∞​​=i=1∑n​∣xi​∣=i=1∑n​xi2​​=1≤i≤nmax​∣xi​∣​ 针对范数有如下定理： 等价性：对于任意两种范数s,ts, ts,t，存在常数c1,c2c_{1}, c_{2}c1​,c2​，使得：c1∣∣x∣∣s≤∣∣x∣∣t≤c2∣∣x∣∣sc_{1}||\\boldsymbol{x}||_{s} \\leq ||\\boldsymbol{x}||_{t} \\leq c_{2}||\\boldsymbol{x}||_{s}c1​∣∣x∣∣s​≤∣∣x∣∣t​≤c2​∣∣x∣∣s​极限性：对于向量序列{x(k)}\\{\\boldsymbol{x}^{(k)}\\}{x(k)}对于任意一种范数，有：lim⁡k→∞x(k)=x∗⇔lim⁡k→∞∣∣x−x∗∣∣=0\\lim_{k\\to \\infty}\\boldsymbol{x}^{(k)} = \\boldsymbol{x}^{*} \\Leftrightarrow \\lim_{k\\to\\infty}||\\boldsymbol{x} - \\boldsymbol{x}^{*}|| = 0k→∞lim​x(k)=x∗⇔k→∞lim​∣∣x−x∗∣∣=0可以先由无穷范数证明，再使用范数的等价性扩展到其他范数 矩阵范数 在向量范数的定义上进行扩张，增加两个条件： ∣∣AB∣∣≤∣∣A∣∣⋅∣∣B∣∣||\\boldsymbol{A}\\boldsymbol{B}|| \\leq ||\\boldsymbol{A}||\\cdot||\\boldsymbol{B}||∣∣AB∣∣≤∣∣A∣∣⋅∣∣B∣∣相容性：∣∣Ax∣∣≤∣∣A∣∣⋅∣∣x∣∣||\\boldsymbol{A}\\boldsymbol{x}|| \\leq ||\\boldsymbol{A}||\\cdot||\\boldsymbol{x}||∣∣Ax∣∣≤∣∣A∣∣⋅∣∣x∣∣ 我们还可以使用向量的范数∣∣⋅∣∣v||\\cdot||_{v}∣∣⋅∣∣v​来定义矩阵的范数，这种定义称为向量诱导范数 ∣∣A∣∣v=max⁡x≠0∣∣Ax∣∣v∣∣x∣∣v||\\boldsymbol{A}||_{v} = \\max\\limits_{\\boldsymbol{x} eq \\boldsymbol{0}} \\frac{||\\boldsymbol{Ax}||_{v}}{||\\boldsymbol{x}||_{v}} ∣∣A∣∣v​=x=0max​∣∣x∣∣v​∣∣Ax∣∣v​​ 可以证明，向量诱导范数符合前述的定义 利用向量的p-范数进行诱导，我们可以得到几种矩阵的p-范数： ∣∣A∣∣1=max⁡1≤j≤n∑i=1n∣aij∣∣∣A∣∣∞=max⁡1≤i≤n∑j=1n∣aij∣∣∣A∣∣2=λmax⁡(ATA)\\begin{align*} ||\\boldsymbol{A}||_{1} &amp;= \\max\\limits_{1\\leq j\\leq n}\\sum\\limits_{i=1}^{n}|a_{ij}| \\\\ ||\\boldsymbol{A}||_{\\infty} &amp;= \\max\\limits_{1\\leq i\\leq n}\\sum\\limits_{j=1}^{n}|a_{ij}| \\\\ ||\\boldsymbol{A}||_{2} &amp;= \\sqrt{\\lambda_{\\max}(\\boldsymbol{A}^{T}\\boldsymbol{A})} \\\\ \\end{align*} ∣∣A∣∣1​∣∣A∣∣∞​∣∣A∣∣2​​=1≤j≤nmax​i=1∑n​∣aij​∣=1≤i≤nmax​j=1∑n​∣aij​∣=λmax​(ATA)​​ 此外还有常用的Frobenius范数： ∣∣A∣∣F=∑i=1n∑j=1naij2=tr(ATA)||\\boldsymbol{A}||_{F} = \\sqrt{\\sum\\limits_{i=1}^{n}\\sum\\limits_{j=1}^{n}a_{ij}^{2}} = \\sqrt{\\mathrm{tr}(\\boldsymbol{A}^{T}\\boldsymbol{A})} ∣∣A∣∣F​=i=1∑n​j=1∑n​aij2​​=tr(ATA)​ 矩阵条件数 下面讨论解线性方程组问题的敏感性 考虑右端发生小扰动，形式为： Ax=b⇒A(x+Δx)=b+Δb\\boldsymbol{Ax}=\\boldsymbol{b} \\Rightarrow \\boldsymbol{A}(\\boldsymbol{x} + \\Delta\\boldsymbol{x}) = \\boldsymbol{b} + \\Delta\\boldsymbol{b} Ax=b⇒A(x+Δx)=b+Δb 这种情况下解的扰动是Δx\\Delta\\boldsymbol{x}Δx，因此根据条件数的定义： cond=∣∣Δx∣∣/∣∣x∣∣∣∣Δb∣∣/∣∣b∣∣=∣∣Δx∣∣⋅∣∣b∣∣∣∣Δb∣∣⋅∣∣x∣∣\\mathrm{cond} = \\frac{||\\Delta\\boldsymbol{x}|| / ||\\boldsymbol{x}||}{||\\Delta\\boldsymbol{b}||/||\\boldsymbol{b}||} = \\frac{||\\Delta\\boldsymbol{x}||\\cdot||\\boldsymbol{b}||}{||\\Delta\\boldsymbol{b}||\\cdot||\\boldsymbol{x}||} cond=∣∣Δb∣∣/∣∣b∣∣∣∣Δx∣∣/∣∣x∣∣​=∣∣Δb∣∣⋅∣∣x∣∣∣∣Δx∣∣⋅∣∣b∣∣​ 根据范数的定义，可以有如下的推导： ∣∣Δx∣∣=∣∣A−1Δb∣∣≤∣∣A−1∣∣⋅∣∣Δb∣∣∣∣b∣∣=∣∣Ax∣∣≤∣∣A∣∣⋅∣∣x∣∣⇒∣∣b∣∣⋅∣∣Δx∣∣≤∣∣A−1∣∣⋅∣∣Δb∣∣⋅∣∣A∣∣⋅∣∣x∣∣\\begin{align*} ||\\Delta\\boldsymbol{x}|| &amp;= ||\\boldsymbol{A}^{-1}\\Delta\\boldsymbol{b}|| \\leq ||\\boldsymbol{A}^{-1}||\\cdot||\\Delta\\boldsymbol{b}|| \\\\ ||\\boldsymbol{b}|| &amp;= ||\\boldsymbol{Ax}|| \\leq ||\\boldsymbol{A}||\\cdot||\\boldsymbol{x}|| \\\\ \\Rightarrow\\qquad\\qquad ||\\boldsymbol{b}||\\cdot||\\Delta\\boldsymbol{x}|| &amp;\\leq ||\\boldsymbol{A}^{-1}||\\cdot||\\Delta\\boldsymbol{b}||\\cdot||\\boldsymbol{A}||\\cdot||\\boldsymbol{x}|| \\\\ \\end{align*} ∣∣Δx∣∣∣∣b∣∣⇒∣∣b∣∣⋅∣∣Δx∣∣​=∣∣A−1Δb∣∣≤∣∣A−1∣∣⋅∣∣Δb∣∣=∣∣Ax∣∣≤∣∣A∣∣⋅∣∣x∣∣≤∣∣A−1∣∣⋅∣∣Δb∣∣⋅∣∣A∣∣⋅∣∣x∣∣​ 代入有： cond≤∣∣A∣∣⋅∣∣A−1∣∣\\mathrm{cond} \\leq ||\\boldsymbol{A}||\\cdot||\\boldsymbol{A}^{-1}|| cond≤∣∣A∣∣⋅∣∣A−1∣∣ 于是我们定义这个上界为矩阵的条件数，即其代表了解线性方程问题敏感性的上界： cond(A)=∣∣A∣∣⋅∣∣A−1∣∣\\mathrm{cond}(\\boldsymbol{A}) = ||\\boldsymbol{A}||\\cdot||\\boldsymbol{A}^{-1}||cond(A)=∣∣A∣∣⋅∣∣A−1∣∣ 可以证明的是，如果发生扰动的并非b\\boldsymbol{b}b而是A\\boldsymbol{A}A，也可以近似到上述上界 条件数越大，矩阵越病态，而对于奇异矩阵，我们定义期条件数为正无穷大 例如对于Hilbert矩阵，其可以计算出其条件数随着nnn的增大会急剧增大，因此会变得越来越病态 Hn=[112⋯1n1213⋯1n+1⋮⋮⋱⋮1n1n+1⋯12n−1]\\boldsymbol{H}_{n} = \\begin{bmatrix} 1 &amp; \\dfrac{1}{2} &amp; \\cdots &amp; \\dfrac{1}{n} \\\\[1em] \\dfrac{1}{2} &amp; \\dfrac{1}{3} &amp; \\cdots &amp; \\dfrac{1}{n+1} \\\\[1em] \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\[1em] \\dfrac{1}{n} &amp; \\dfrac{1}{n + 1} &amp; \\cdots &amp; \\dfrac{1}{2n - 1} \\end{bmatrix} Hn​=​121​⋮n1​​21​31​⋮n+11​​⋯⋯⋱⋯​n1​n+11​⋮2n−11​​​ 一些定理 对于任意向量范数意义下的矩阵范数，有如下定理： cond(A)=(max⁡x≠0∣∣Ax∣∣∣∣x∣∣) / (min⁡x≠0∣∣Ax∣∣∣∣x∣∣)≥1\\mathrm{cond}(\\boldsymbol{A}) = \\Big(\\max\\limits_{\\boldsymbol{x} eq \\boldsymbol{0}}\\frac{||\\boldsymbol{Ax}||}{||\\boldsymbol{x}||}\\Big)\\,\\Big/\\,\\Big(\\min\\limits_{\\boldsymbol{x} eq \\boldsymbol{0}}\\frac{||\\boldsymbol{Ax}||}{||\\boldsymbol{x}||}\\Big) \\geq 1cond(A)=(x=0max​∣∣x∣∣∣∣Ax∣∣​)/(x=0min​∣∣x∣∣∣∣Ax∣∣​)≥1 同时，根据定义很容易推导出矩阵条件数满足的性质： cond(A−1)=cond(cA)=cond(A)\\mathrm{cond}(\\boldsymbol{A}^{-1}) = \\mathrm{cond}(c\\boldsymbol{A}) = \\mathrm{cond}(\\boldsymbol{A})cond(A−1)=cond(cA)=cond(A) cond(I)\\mathrm{cond}(\\boldsymbol{I})cond(I) = 1 对于一个对角阵D\\boldsymbol{D}D，有 cond(D)≥max⁡∣dii∣min⁡∣dii∣\\mathrm{cond}(\\boldsymbol{D})\\geq \\dfrac{\\max|d_{ii}|}{\\min|d_{ii}|}cond(D)≥min∣dii​∣max∣dii​∣​，其中等号在p-范数下取到 正交变换不改变2-范数下的条件数 LU分解 LU分解即为将一个矩阵拆分成一个下三角与一个上三角矩阵的乘积的形式，分为两种： Doolittle分解：LLL为单位下三角阵，UUU为上三角阵 Crout分解：LLL为下三角阵，UUU为单位上三角阵 本章讨论Doolittle分解 LU分解的存在性有定理： 对于方程Ax=b\\boldsymbol{Ax} = \\boldsymbol{b}Ax=b，其中A∈Rn×n\\boldsymbol{A} \\in \\mathbb{R}^{n\\times n}A∈Rn×n，则执行高斯消元过程中的主元 akk(k)≠0a_{kk}^{(k)} eq 0akk(k)​=0 等价于 A\\boldsymbol{A}A有唯一LU分解其中 akk(k)a_{kk}^{(k)}akk(k)​ 代表消除kkk步之后的元素 LU分解的计算很简单，不再赘述，其主要用途在解方程 选主元 可以看出，LU分解的计算与主元的选取有关，而这是可以通过对换矩阵来进行的，并且对换操作不会改变方程的解（可以想象若干方程以任意的顺序排列，它的解当然是不会变的） 有定理： 对于矩阵 A∈Rn×n\\boldsymbol{A} \\in \\mathbb{R}^{n\\times n}A∈Rn×n，执行高斯消元过程中的主元 akk(k)a_{kk}^{(k)}akk(k)​均不为零 等价于 A\\boldsymbol{A}A 的前 n−1n - 1n−1 个顺序主子式均不为零 因此对称正定或负定矩阵一定可以LU分解 如果在高斯消去的过程中，遇到了零主元的情况，可以从该行下方的行中取一行，满足 ajk(k)≠0(j&gt;k)a_{jk}^{(k)} eq 0\\quad (j &gt; k)ajk(k)​=0(j&gt;k) 与这一行交换，之后就可以正常进行下去了，可以证明的是，如果 A\\boldsymbol{A}A 非奇异，那么一定可以完成这个交换的操作 同时，可以选择绝对值尽量大的主元，这样可以有效避免误差的扩大传播 部分主元 这种方法是为了满足上述 可以选择绝对值尽量大的主元，这样可以有效避免误差的扩大传播 的操作，具体做法是在每一步消元的时候，将第 iki_kik​ 行与第 kkk 行交换，其中，ik=argmaxk≤i≤n∣aik(k)∣i_{k} = \\mathop{\\mathrm{argmax}}\\limits_{k\\leq i\\leq n} |a_{ik}^{(k)}|ik​=k≤i≤nargmax​∣aik(k)​∣ 下面推导部分主元的LU分解： 假设 Pk\\boldsymbol{P}_{k}Pk​ 代表第 kkk 步消元过程中的交换过程，即交换第 iki_{k}ik​ 行与第 kkk 行的对换矩阵，则消去过程可以表示为：Mn−1Pn−1⋯M2P2M1P1A=U\\boldsymbol{M}_{n-1}\\boldsymbol{P}_{n-1}\\cdots\\boldsymbol{M}_{2}\\boldsymbol{P}_{2}\\boldsymbol{M}_{1}\\boldsymbol{P}_{1}\\boldsymbol{A} = \\boldsymbol{U}Mn−1​Pn−1​⋯M2​P2​M1​P1​A=U由于对换矩阵的逆是自身，因此我们令：M‾k=(∏i=n−1k+1Pi)Mk(∏i=k+1n−1Pi)\\overline{\\boldsymbol{M}}_{k} = \\Big(\\prod_{i=n-1}^{k+1}\\boldsymbol{P}_{i}\\Big)\\boldsymbol{M}_{k}\\Big(\\prod_{i=k+1}^{n-1}\\boldsymbol{P}_{i}\\Big)Mk​=(i=n−1∏k+1​Pi​)Mk​(i=k+1∏n−1​Pi​)这样原始消去可以变换为：(∏i=n−11M‾k)(∏i=n−11Pk)A=U\\Big(\\prod_{i=n-1}^{1}\\overline{\\boldsymbol{M}}_{k}\\Big)\\Big(\\prod_{i=n-1}^{1}\\boldsymbol{P}_{k}\\Big)\\boldsymbol{A} = \\boldsymbol{U}(i=n−1∏1​Mk​)(i=n−1∏1​Pk​)A=U记：L=(∏i=n−11M‾k)−1P=(∏i=n−11Pk)\\begin{align*} \\boldsymbol{L} &amp;= \\Big(\\prod_{i=n-1}^{1}\\overline{\\boldsymbol{M}}_{k}\\Big)^{-1} \\\\ \\boldsymbol{P} &amp;= \\Big(\\prod_{i=n-1}^{1}\\boldsymbol{P}_{k}\\Big)\\end{align*}LP​=(i=n−1∏1​Mk​)−1=(i=n−1∏1​Pk​)​则部分主元的LU分解为：PA=LU\\boldsymbol{PA} = \\boldsymbol{LU}PA=LU 实际计算过程中，我们并不需要按照推导式中的方法，求出如此多的 M‾k\\overline{\\boldsymbol{M}}_{k}Mk​ ，相反我们只需要正常的进行 LU 分解，但是在需要交换的时候，记录对换矩阵 Pk\\boldsymbol{P}_{k}Pk​ ，这样最终求出的分解结果就是所需的 LU\\boldsymbol{LU}LU ，而 P\\boldsymbol{P}P 是容易求出的 全选主元 在上述过程中，由于我们只是选取了列中最大的元素，因此这个方法称为部分选主元，相应的，可以在第 kkk 步选取右下角(n−k+1)×(n−k+1)(n - k + 1) \\times (n - k + 1)(n−k+1)×(n−k+1) 维矩阵中的绝对值最大元素，通过一次行变换与一次列变换将其挪到主元位置，这种方法称为全选主元，得到的分解结果为： PAQ=LU\\boldsymbol{PAQ} = \\boldsymbol{LU} PAQ=LU 应用 可以方便的通过 LU 分解来进行解方程、矩阵乘的计算，假设我们知道了矩阵的 LU 分解，尽管这个计算的复杂度是O(n3)O(n^{3})O(n3)的，但是我们可以通过这个操作来将矩阵乘的计算降到 O(n2)O(n^{2})O(n2) 例如我们需要计算 (A+B−1)x(\\boldsymbol{A} + \\boldsymbol{B}^{-1})\\boldsymbol{x}(A+B−1)x，我们可以按如下方式计算： PAx=LAUAx⇒Ax=P−1LAUAxB−1x=UB−1LB−1Px\\begin{align*} \\boldsymbol{PAx} = \\boldsymbol{L}_{A}\\boldsymbol{U}_{A}\\boldsymbol{x} &amp;\\Rightarrow \\boldsymbol{Ax} = \\boldsymbol{P}^{-1}\\boldsymbol{L}_{A}\\boldsymbol{U}_{A}\\boldsymbol{x} \\\\ \\boldsymbol{B}^{-1}\\boldsymbol{x} &amp;= \\boldsymbol{U}_{B}^{-1}\\boldsymbol{L}_{B}^{-1}\\boldsymbol{P}\\boldsymbol{x} \\end{align*} PAx=LA​UA​xB−1x​⇒Ax=P−1LA​UA​x=UB−1​LB−1​Px​ 其中，计算逆可以转换成解方程，例如： LB−1Px=y⇒LB y=Px\\boldsymbol{L}_{B}^{-1}\\boldsymbol{Px} = \\boldsymbol{y} \\Rightarrow \\boldsymbol{L}_{B}\\,\\boldsymbol{y} = \\boldsymbol{Px} LB−1​Px=y⇒LB​y=Px 由于LU\\boldsymbol{LU}LU都是三角阵，因此解这个方程是 O(n2)O(n^{2})O(n2) 的，如果需要进行大量计算，我们可以对 LU 分解的结果做记忆化，这样可以显著减少后续计算的计算量 稳定性 对于 LU 分解算法，有结论： ∣∣ΔA∣∣∞∣∣A∣∣∞≲nρεmach\\frac{||\\Delta\\boldsymbol{A}||_{\\infty}}{||\\boldsymbol{A}||_{\\infty}} \\lesssim n\\rho\\varepsilon_{\\text{mach}} ∣∣A∣∣∞​∣∣ΔA∣∣∞​​≲nρεmach​ 增长因子 ρ\\rhoρ 定义为： ρ=max⁡∣uij∣max⁡∣aij∣\\rho = \\frac{\\max |u_{ij}|}{\\max |a_{ij}|} ρ=max∣aij​∣max∣uij​∣​ Cholesky 分解 对于一个可无需交换主元的对称矩阵，首先将其 LU 分解扩展为 LDU 分解，满足其中的 LU\\boldsymbol{LU}LU 都是单位三角阵，D\\boldsymbol{D}D 是对角阵，这样的话： A=LDU=AT=UTDLT\\boldsymbol{A} = \\boldsymbol{LDU} = \\boldsymbol{A}^{T} = \\boldsymbol{U}^{T}\\boldsymbol{DL}^{T} A=LDU=AT=UTDLT 因此 L=UT\\boldsymbol{L} = \\boldsymbol{U^{T}}L=UT，即 A=LDLT\\boldsymbol{A} = \\boldsymbol{LDL}^{T}A=LDLT 就此引入 Cholesky 分解： 对于一个对称正定矩阵 A\\boldsymbol{A}A，分解 A=LDLT\\boldsymbol{A} = \\boldsymbol{LDL}^{T}A=LDLT 满足 D\\boldsymbol{D}D 也是对称正定的，因此我们可以令：D=diag(d11,d22,…,dnn)\\sqrt{\\boldsymbol{D}} = \\mathrm{diag}(\\sqrt{d_{11}}, \\sqrt{d_{22}}, \\dots, \\sqrt{d_{nn}})D​=diag(d11​​,d22​​,…,dnn​​)这样的话：A=LDDTLT=L1L1T\\boldsymbol{A} = \\boldsymbol{L}\\sqrt{\\boldsymbol{D}}\\sqrt{\\boldsymbol{D}}^{T}\\boldsymbol{L}^{T} = \\boldsymbol{L}_{1}\\boldsymbol{L}_{1}^{T}A=LD​D​TLT=L1​L1T​这就是 Cholesky 分解 其具体算法两层遍历，但是只用遍历矩阵的半角（因为是对称的） 1234for j in range(1, n + 1): (1) for i in range(j + 1, n + 1): (2) 其中： ajj=ajj−∑k=1j−1ajk2aij=1ajj(aij−∑k=1j−1aikajk)\\begin{align} a_{jj} &amp;= \\sqrt{a_{jj} - \\sum\\limits_{k=1}^{j-1}a_{jk}^{2}} \\\\ a_{ij} &amp;= \\frac{1}{a_{jj}}\\Big(a_{ij} - \\sum\\limits_{k=1}^{j-1}a_{ik}a_{jk}\\Big) \\end{align} ajj​aij​​=ajj​−k=1∑j−1​ajk2​​=ajj​1​(aij​−k=1∑j−1​aik​ajk​)​​ 可以证明其增长因子 ρ≤1\\rho \\leq 1ρ≤1 带状矩阵 定义： 若矩阵 A\\boldsymbol{A}A 满足：∀i,j,∣i−j∣&gt;β⇒aij=0\\forall i, j, |i-j|&gt;\\beta \\Rightarrow a_{ij} = 0∀i,j,∣i−j∣&gt;β⇒aij​=0∃k,ak(k−β)2+ak(k+β)2≠0\\exists k, a_{k(k-\\beta)}^{^2} + a_{k(k+\\beta)}^{2} eq 0∃k,ak(k−β)2​+ak(k+β)2​=0则称 A\\boldsymbol{A}A 是半带宽为 β\\betaβ 的带状矩阵 可以证明带状矩阵的 LU 分解结果满足，其非零元仍然在原始带宽内 考虑三对角矩阵，即β=1\\beta = 1β=1的带状矩阵，例如： [12345678910]\\begin{bmatrix} 1 &amp; 2 &amp; &amp; \\\\ 3 &amp; 4 &amp; 5 &amp; \\\\ &amp; 6 &amp; 7 &amp; 8 \\\\ &amp; &amp; 9 &amp; 10 \\\\ \\end{bmatrix} ​13​246​579​810​​ 三对角矩阵的 LU 分解算法是 O(n)O(n)O(n) 的，令： A=[b1c1a2b2c2⋱⋱⋱an−1bn−1cn−1anbn]\\boldsymbol{A} = \\begin{bmatrix} b_{1} &amp; c_{1} &amp; &amp; &amp; \\\\[1em] a_{2} &amp; b_{2} &amp; c_{2} &amp; &amp; \\\\[1em] &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\\\[1em] &amp; &amp; a_{n-1} &amp; b_{n-1} &amp; c_{n-1} \\\\[1em] &amp; &amp; &amp; a_{n} &amp; b_{n} \\end{bmatrix} A=​b1​a2​​c1​b2​⋱​c2​⋱an−1​​⋱bn−1​an​​cn−1​bn​​​ 则其不选主元的 LU 分解一定是： L=[1m21⋱⋱mn−11mn1]U=[d1c1d2c2⋱⋱dn−1cn−1dn]\\boldsymbol{L} = \\begin{bmatrix} 1 &amp; &amp; &amp; &amp; \\\\[1em] m_{2} &amp; 1 &amp; &amp; &amp; \\\\[1em] &amp; \\ddots &amp; \\ddots &amp; &amp; \\\\[1em] &amp; &amp; m_{n-1} &amp; 1 &amp; \\\\[1em] &amp; &amp; &amp; m_{n} &amp; 1 \\end{bmatrix} \\quad \\boldsymbol{U} = \\begin{bmatrix} d_{1} &amp; c_{1} &amp; &amp; &amp; \\\\[1em] &amp; d_{2} &amp; c_{2} &amp; &amp; \\\\[1em] &amp; &amp; \\ddots &amp; \\ddots &amp; \\\\[1em] &amp; &amp; &amp; d_{n-1} &amp; c_{n-1} \\\\[1em] &amp; &amp; &amp; &amp; d_{n} \\end{bmatrix} L=​1m2​​1⋱​⋱mn−1​​1mn​​1​​U=​d1​​c1​d2​​c2​⋱​⋱dn−1​​cn−1​dn​​​ 其中： d1=b1mi=ai/di−1di=bi−mici−12≤i≤n\\begin{align*} d_{1} &amp;= b_{1} \\\\ m_{i} &amp;= a_{i}/d_{i - 1} \\\\ d_{i} &amp;= b_{i} - m_{i}c_{i - 1} \\\\ 2 &amp;\\leq i \\leq n \\end{align*} d1​mi​di​2​=b1​=ai​/di−1​=bi​−mi​ci−1​≤i≤n​ 这可以很方便由直接 LU 分解得到 而解决三对角矩阵为系数的线性方程组也是很高效的，算法称为追赶法，具体来说，针对上述定义的A\\boldsymbol{A}A和方程Ax⃗=f⃗\\boldsymbol{A}\\vec{x}=\\vec{f}Ax=f​： 2≤i≤nn−1≥j≥1mi=ai/bi−1bi=bi−mici−1fi=fi−mifi−1xn=fn/bnxj=(fj−cjxj+1)/bj\\begin{align*} 2\\leq i\\leq n&amp;\\quad n - 1 \\geq j \\geq 1 \\\\ m_{i} &amp;= a_{i} / b_{i - 1} \\\\ b_{i} &amp;= b_{i} - m_{i}c_{i - 1} \\\\ f_{i} &amp;= f_{i} - m_{i}f_{i - 1} \\\\ x_{n} &amp;= f_{n} / b_{n} \\\\ x_{j} &amp;= (f_{j} - c_{j}x_{j + 1}) / b_{j} \\end{align*} 2≤i≤nmi​bi​fi​xn​xj​​n−1≥j≥1=ai​/bi−1​=bi​−mi​ci−1​=fi​−mi​fi−1​=fn​/bn​=(fj​−cj​xj+1​)/bj​​ 一般带状矩阵的 LU 分解时间复杂度为 O(β2n)O(\\beta^{2}n)O(β2n)，空间复杂度为 O(βn)O(\\beta n)O(βn)，这说明 β&lt;&lt;n\\beta &lt;&lt; nβ&lt;&lt;n 时甚至是线性的，这是由带状矩阵的稀疏特性决定的，而带状矩阵的逆是稠密的，因此应该尽量避免求逆 可以证明，对称正定矩阵与严格对角占有矩阵是可以不选主元进行稳定 LU 分解的，如果使用部分选主元，LU\\boldsymbol{LU}LU矩阵的带宽不会超过 2β2\\beta2β","tags":["笔记","线性方程组","线性代数"],"categories":["数值分析"]},{"title":"数值分析 - 非线性方程","path":"/2025/03/05/数值分析2/","content":"数值分析 笔记 2 非线性方程解法 非线性方程的含义很广泛，常见的特例为nnn次多项式方程，对于任一非线性方程，如果其某一实根x∗x^{*}x∗满足： f(x∗)=f′(x∗)=⋯=f(m−1)(x∗)=0f(x^{*}) = f&#x27;(x^{*}) = \\cdots = f^{(m - 1)}(x^{*}) = 0 f(x∗)=f′(x∗)=⋯=f(m−1)(x∗)=0 则称x∗x^{*}x∗为mmm重根 对于解方程这个问题，输入为函数值yyy，解为自变量xxx，因此其绝对条件数为： ∣ΔxΔy∣≈∣1f′(x)∣\\Big| \\frac{\\Delta x}{\\Delta y} \\Big| \\approx \\Big| \\frac{1}{f&#x27;(x)} \\Big| ​ΔyΔx​​≈​f′(x)1​​ 因此对于多重根即f′(x)=0f&#x27;(x) = 0f′(x)=0，问题是很敏感的 二分法 二分法的成立基于以下充分条件： 若f(x)∈C[a,b]f(x) \\in C[a, b]f(x)∈C[a,b]，且f(a)f(b) &lt; 0，则f(x)f(x)f(x)在(a,b)(a, b)(a,b)内至少有一个实根 二分法的算法很简单，不再赘述，注意其中ε\\varepsilonε代表区间长度阈值 如果使用计算机进行二分法求解，那其最小的有根区间长度为2E+1εmach2^{E + 1}\\varepsilon_{\\text{mach}}2E+1εmach​，其中EEE为准确根x∗x^{*}x∗对应的浮点数指数，即E=⌊log⁡2∣x∗∣⌋E = \\lfloor \\log_{2}|x^{*}| \\rfloorE=⌊log2​∣x∗∣⌋，因此其最大相对误差为2εmach2\\varepsilon_{\\text{mach}}2εmach​ 二分法总能收敛，但是收敛速度慢，且初始区间难以确定 不动点迭代法 首先将方程f(x)=0f(x) = 0f(x)=0变形为x=g(x)x = g(x)x=g(x)，从而将求f(x)f(x)f(x)零点问题转化为求g(x)g(x)g(x)不动点的问题，而不动点可以通过迭代来实现： x0=Cxk+1=g(xk)\\begin{align*} x_{0} &amp;= C \\\\ x_{k + 1} &amp;= g(x_{k}) \\end{align*} x0​xk+1​​=C=g(xk​)​ 如果最终序列xkx_{k}xk​收敛到x∗x^{*}x∗，则x∗x^{*}x∗为原方程的根 关键问题是，对于同一个函数f(x)f(x)f(x)可能会有多种变形方式，在这种情况下，不同变形的收敛性可能并不相同，例如对于x4−x−2=0x^{4} - x - 2 = 0x4−x−2=0： x=x4−2x=x+24\\begin{align} x &amp;= x^{4} - 2 \\\\ x &amp;= \\sqrt[4]{x + 2} \\end{align} xx​=x4−2=4x+2​​​ 其中式(1)(1)(1)是发散的，但是式(2)(2)(2)是收敛的 全局收敛 针对不动点迭代法的收敛性，有如下定理： 对于g(x)∈C[a,b]g(x) \\in C[a, b]g(x)∈C[a,b]，若有：∀x∈[a,b],a≤g(x)≤b∃L∈(0,1),∀x1,x2∈[a,b],∣g(x1)−g(x2)∣≤L∣x1−x2∣\\begin{align} &amp;\\forall x\\in [a, b],\\quad a\\leq g(x) \\leq b \\\\ &amp;\\exist L\\in (0, 1), \\forall x_{1}, x_{2} \\in [a, b],\\quad |g(x_{1}) - g(x_{2})| \\leq L|x_{1} - x_{2}|\\end{align}​∀x∈[a,b],a≤g(x)≤b∃L∈(0,1),∀x1​,x2​∈[a,b],∣g(x1​)−g(x2​)∣≤L∣x1​−x2​∣​​则g(x)g(x)g(x)在[a,b][a, b][a,b]内有唯一不动点，并且∀x0∈[a,b]\\forall x_{0} \\in [a, b]∀x0​∈[a,b]，不动点迭代法都收敛到这个唯一的不动点x∗x^{*}x∗，误差满足：∣xk−x∗∣≤Lk1−L∣x1−x0∣|x_{k} - x^{*}| \\leq \\frac{L^{k}}{1 - L} |x_{1} - x_{0}|∣xk​−x∗∣≤1−LLk​∣x1​−x0​∣如果仅需要判断收敛性，而不需要知道绝对误差的范围，则条件(4)(4)(4)可以简化为：∀x∈[a,b],∣g′(x)∣&lt;1\\begin{align} \\forall x \\in [a, b], \\quad |g&#x27;(x)| &lt; 1\\end{align}∀x∈[a,b],∣g′(x)∣&lt;1​​这可以由Lagrange中值定理推出 局部收敛 上述全局收敛是求出了迭代式在一整个区间上的行为，而在不动点周围的邻域内，同样可以定义局部收敛：如果g(x)g(x)g(x)有不动点x∗x^{*}x∗，∃D=[x∗−δ,x∗+δ]\\exist D = [x^{*} - \\delta, x^{*} + \\delta]∃D=[x∗−δ,x∗+δ]，使得∀x0∈D\\forall x_{0} \\in D∀x0​∈D，迭代法都收敛到x∗x^{*}x∗，则称该方法局部收敛 设x∗x^{*}x∗是g(x)g(x)g(x)的不动点，若∣g′(x∗)∣&lt;1|g&#x27;(x^{*})| &lt; 1∣g′(x∗)∣&lt;1，且g′(x)g&#x27;(x)g′(x)在x∗x^{*}x∗某个邻域，则迭代法局部收敛 证明略 稳定性与收敛阶 若非线性方程进行数值解时，得到的解序列xnx_{n}xn​收敛，并且误差项$e(x_{k}) = x_{k} - x^{*} $满足： lim⁡k→∞∣e(xk+1)∣∣e(xk)∣p=c∈(0,∞)\\lim_{k\\to \\infty} \\frac{|e(x_{k + 1})|}{|e(x_{k})|^{p}} = c \\in (0, \\infty) k→∞lim​∣e(xk​)∣p∣e(xk+1​)∣​=c∈(0,∞) 则称其为ppp阶收敛，即收敛阶为ppp，对于一个收敛的方法，其收敛阶是唯一的，例如二分法的收敛阶大体上是1 收敛阶越高，迭代法收敛的越快 判断收敛阶的充要条件是： 若g(x)g(x)g(x)在x∗x^{*}x∗附近 p≥2p\\geq 2p≥2 阶连续可导，则收敛阶为 ppp 的充要条件是：g′(x∗)=g′′(x∗)=⋯=g(p−1)(x∗)=0g(p)(x∗)≠0\\begin{align*} g&#x27;(x^{*}) = g&#x27;&#x27;(x^{*}) &amp;= \\cdots = g^{(p - 1)}(x^{*}) = 0 \\\\ g^{(p)}(x^{*}) &amp; eq 0\\end{align*}g′(x∗)=g′′(x∗)g(p)(x∗)​=⋯=g(p−1)(x∗)=0=0​ 其证明方法较简单，如下 充分性：由Lagrange余项Taylor展开可知：e(xk+1)=g(xk)−g(x∗)=g(p)(xk)p!(xk−x∗)p=g(p)(xk)p!e(xk)pe(x_{k + 1}) = g(x_{k}) - g(x^{*}) = \\frac{g^{(p)}(x_{k})}{p!}(x_{k} - x^{*})^{p} = \\frac{g^{(p)}(x_{k})}{p!}e(x_{k})^{p} e(xk+1​)=g(xk​)−g(x∗)=p!g(p)(xk​)​(xk​−x∗)p=p!g(p)(xk​)​e(xk​)p 之后直接按照收敛阶的定义即可 必要性，假设其直到q≠pq eq pq=p阶导数不为0，之前所有阶均为0，同样由Taylor可以证明其qqq阶收敛，这与收敛阶的唯一性矛盾 牛顿法 原理很简单，利用切线近似曲线 在点(xk,f(xk))(x_{k}, f(x_{k}))(xk​,f(xk​))处，函数的切线方程为： f(xk)+f′(xk)(x−xk)=0f(x_{k}) + f&#x27;(x_{k})(x - x_{k}) = 0 f(xk​)+f′(xk​)(x−xk​)=0 转化形式后可以得到迭代式： xk+1=g(xk)=xk−f(xk)f′(xk)x_{k + 1} = g(x_{k}) = x_{k} - \\frac{f(x_{k})}{f&#x27;(x_{k})} xk+1​=g(xk​)=xk​−f′(xk​)f(xk​)​ 保证f′(xk)≠0f&#x27;(x_{k}) eq 0f′(xk​)=0，求导易知对于f(x)f(x)f(x)的单根 x∗x^{*}x∗ 有 g′(x∗)=0g&#x27;(x^{*}) = 0g′(x∗)=0，因此有： 对于f(x)=0f(x) = 0f(x)=0的单根x∗x^{*}x∗，若f(x)f(x)f(x)在x∗x^{*}x∗附近有连续二阶导数，则牛顿法至少局部二阶收敛 例如计算机中使用的平方根的方式即为对f(x)=x2−cf(x) = x^{2} - cf(x)=x2−c利用牛顿法求根： xk+1=12(xk+cxk)x_{k + 1} = \\frac{1}{2}(x_{k} + \\frac{c}{x_{k}}) xk+1​=21​(xk​+xk​c​) 可以证明这种方法是在R+\\mathbb{R}^{+}R+上全局收敛的 判停准则 迭代法的停止条件通常有： ∣f(xk)∣≤ε1|f(x_{k})| \\leq \\varepsilon_{1}∣f(xk​)∣≤ε1​：残差判据，但这可能说明我们找到了另一个根，而非期望收敛的值 ∣xk−xk−1∣≤ε2|x_{k} - x_{k - 1}| \\leq \\varepsilon_{2}∣xk​−xk−1​∣≤ε2​，误差判据 ∣xk−xk−1∣≤ε3∣xk∣|x_{k} - x_{k - 1}| \\leq \\varepsilon_{3}|x_{k}|∣xk​−xk−1​∣≤ε3​∣xk​∣，相对误差判据 通常将从残差判据与下面两种或其中一种结合使用 问题 牛顿法是局部收敛的，依赖于初值的选取 牛顿法对连续性的要求较高，因为g′(x)g&#x27;(x)g′(x)中涉及到了f′′(x)f&#x27;&#x27;(x)f′′(x) 例如f(x)=sgn(x−a)x−af(x) = \\text{sgn}(x - a)\\sqrt{x - a}f(x)=sgn(x−a)x−a​则对任意初值都无法收敛，原因是f′(x)f&#x27;(x)f′(x)在x=ax = ax=a处并不连续 割线法与抛物线法 割线法是为了规避牛顿法中的求导问题，使用过xk,xk−1x_{k}, x_{k - 1}xk​,xk−1​的割线来代替切线，其迭代方程为： xk+1=xk−xk−xk−1f(xk)−f(xk−1)f(xk)x_{k + 1} = x_{k} - \\frac{x_{k} - x_{k - 1}}{f(x_{k}) - f(x_{k - 1})}f(x_{k}) xk+1​=xk​−f(xk​)−f(xk−1​)xk​−xk−1​​f(xk​) 这是一种广义的迭代法（同时由前两项进行迭代）其收敛阶满足： 若f(x)f(x)f(x)在根x∗x^{*}x∗某邻域内二阶连续可导且一阶导不为0，当 x0,x1x_{0}, x_{1}x0​,x1​ 充分接近 x∗x^{*}x∗ 时，割线法按 p≈1.618p \\approx 1.618p≈1.618 阶收敛 如果我们能够从前三项推导，这样的方法称之为抛物线法，但是开口向上的抛物线不一定与x轴有交点，因此我们可以构建一个x=P(y)x = P(y)x=P(y)的抛物线，之后用xk,xk−1,xk−2x_{k}, x_{k - 1}, x_{k - 2}xk​,xk−1​,xk−2​待定系数 这个方法同样称为逆二次插值法，局部收敛阶 p≈1.839p\\approx 1.839p≈1.839 实用求根技术 牛顿下山法 防止牛顿法迭代过程发散的一种有效思路，定义一个比例因子序列λi∈(0,1]\\lambda_{i}\\in (0, 1]λi​∈(0,1]，迭代方程为： xk+1=xk−λif(xk)f′(xk)x_{k + 1} = x_{k} - \\lambda_{i}\\frac{f(x_{k})}{f&#x27;(x_{k})} xk+1​=xk​−λi​f′(xk​)f(xk​)​ 算法为： 牛顿下山法","tags":["笔记","非线性方程"],"categories":["数值分析"]},{"title":"高性能计算导论 - 并行计算","path":"/2025/03/04/高性能计算导论1/","content":"高性能计算导论 笔记 1 并行计算 并行计算硬件模型 Flynn分类法，按照指令流(Instrcution Stream)与数据流(Data Stream)进行分类，其中指令流是指处理器操作指令的流水线数量，数据流是指一条指令操作的数据数量： SISD：单指令流，单数据流 SIMD：单指令流，多数据流（例如Intel CPU上的大位宽算数指令） MISD：多指令流，单数据流 MIMD：多指令流，多数据流 对于NVIDIA GPU，其中每一个计算流称为一个Streaming Multiprocessor(SM)，每一个SM中包含若干个Warp，Warp是变成可操作的最小计算单元，每个Warp中包含32个Core，其中的每一个Core可以操作不同的数据，也就是说其规定了操作数的个数，这被称为SIMT（Single Instruction Multiple Threads） 同样我们还能按照其他的方式对硬件进行分类 内存视角 共享内存：所有处理器都与共享内存相连，处于同一个地址空间下，任何处理器可以访问任意内存位置，还可以细分为： 均匀内存访问架构（UMA）：性能均等，难以扩展 非均匀内存访问架构（NUMA）：每个单元有局部内存，跨单元代价高 分布式内存：每个处理器有自己的地址空间，需要显示通信来访问其他单元的内存 共享内存的两种类型 处理器视角","tags":["笔记","并行计算"],"categories":["高性能计算导论"]},{"title":"数值分析 - 误差分析","path":"/2025/02/26/数值分析1/","content":"数值分析 笔记 1 误差分析 通常来说，误差的来源包括： 计算前的误差： 模型误差：例如物理中常见的“忽略空气阻力” 数据误差：已知常数、测量值、前序结果的误差等 计算中的误差 截断误差：计算方法本身的近似带来的误差，例如有限阶的泰勒展开计算非多项式函数 舍入误差：计算时对数据进行舍入，默认为四舍五入 误差及其分类 我们通常使用xxx表示真实值，使用x^\\hat{x}x^表示近似值，那么绝对误差和相对误差分别定义为 e(x)=x^−xer(x)=x^−xx\\begin{align*} e(x) &amp;= \\hat{x} - x \\\\ e_{r}(x) &amp;= \\frac{\\hat{x} - x}{x} \\end{align*} e(x)er​(x)​=x^−x=xx^−x​​ 因此当真实值为000的时候，讨论相对误差没有意义 在很多情况下（例如测量、舍入计算时）我们无法获取真实值，因此无法计算真实误差，这种情况下会估计误差上限，绝对误差限和相对误差限分别定义为： ε(x)=max⁡(e(x))εr(x)=max⁡(er(x))\\begin{align*} \\varepsilon(x) &amp;= \\max(e(x)) \\\\ \\varepsilon_{r}(x) &amp;= \\max(e_{r}(x)) \\end{align*} ε(x)εr​(x)​=max(e(x))=max(er​(x))​ 在误差很小的情况下，相对误差可以近似为 er(x)≈e(x)x^e_{r}(x) \\approx \\frac{e(x)}{\\hat{x}} er​(x)≈x^e(x)​ 关于有效数字的定理 将xxx保留ppp位有效数字得到近似值x^\\hat{x}x^，其中第一位有效数字为d0d_{0}d0​，则相对误差满足：∣er(x)∣≤5d0×10−p|e_{r}(x)| \\leq \\frac{5}{d_{0}}\\times 10^{-p}∣er​(x)∣≤d0​5​×10−p 如果xxx与x^\\hat{x}x^的相对误差满足∣er(x)∣≤5d0+1×10−p|e_{r}(x)| \\leq \\frac{5}{d_{0} + 1}\\times 10^{-p}∣er​(x)∣≤d0​+15​×10−p则：x^\\hat{x}x^的前ppp位有效数字与xxx的相同，或保留ppp位有效数字之后二者相等这可以认为是x^\\hat{x}x^对xxx的估计有ppp位是正确的由于d0≤9d_{0} \\leq 9d0​≤9，因此如果相对误差小于12×10−p\\frac{1}{2}\\times 10^{-p}21​×10−p，则保留ppp位有效值后估计是正确的 数据传递误差与计算误差 在计算函数f(x)f(x)f(x)的过程中，误差的来源是两部分： f^(x^)−f(x)=(f^(x^)−f(x^))+(f(x^)−f(x))\\hat{f}(\\hat{x}) - f(x) = \\big(\\hat{f}(\\hat{x}) - f(\\hat{x}) \\big) + \\big(f(\\hat{x}) - f(x) \\big) f^​(x^)−f(x)=(f^​(x^)−f(x^))+(f(x^)−f(x)) 前者是单纯的计算误差，fff无法精确计算导致，而后者是数据传递误差，即自变量的误差影响到因变量 考虑使用差商近似微分： f′(x)≈f(x+h)−f(x)hf&#x27;(x) \\approx \\frac{f(x + h) - f(x)}{h} f′(x)≈hf(x+h)−f(x)​ 由带拉格朗日余项的泰勒公式： f(x+h)=f(x)+f′(x)h+f′′(ξ)2h2ξ∈(x,x+h)f(x + h) = f(x) + f&#x27;(x)h + \\frac{f&#x27;&#x27;(\\xi)}{2}h^{2}\\quad \\xi \\in (x, x + h) f(x+h)=f(x)+f′(x)h+2f′′(ξ)​h2ξ∈(x,x+h) 因此使用差商会带来截断误差，设f′′(x)f&#x27;&#x27;(x)f′′(x)的上界为MMM，则截断误差误差限为： εT=Mh2\\varepsilon_{T} = \\frac{Mh}{2} εT​=2Mh​ 而舍入误差限为： εR=2εh\\varepsilon_{R} = \\frac{2\\varepsilon}{h} εR​=h2ε​ 其中ε\\varepsilonε是每一次计算fff带来的舍入误差限 因此总误差限为 εtot=Mh2+2εh\\varepsilon_{\\text{tot}} = \\frac{Mh}{2} + \\frac{2\\varepsilon}{h} εtot​=2Mh​+h2ε​ 容易得到，当h=2ε/Mh = 2\\sqrt{\\varepsilon / M}h=2ε/M​的时候，总误差限最小 问题的敏感性 我们使用条件数来反应问题的敏感性： cond=∣∣解的相对误差∣∣∣∣输入的相对误差∣∣\\text{cond} = \\frac{||解的相对误差||}{||输入的相对误差||} cond=∣∣输入的相对误差∣∣∣∣解的相对误差∣∣​ 以函数求值问题为例，我们有： cond=∣[f(x^)−f(x)]/f(x)(x^−x)/x∣≈∣xf′(x)f(x)∣\\text{cond} = \\Big|\\frac{[f(\\hat{x}) - f(x)]/f(x)}{(\\hat{x} - x)/x}\\Big| \\approx \\Big|\\frac{xf&#x27;(x)}{f(x)}\\Big| cond=​(x^−x)/x[f(x^)−f(x)]/f(x)​​≈​f(x)xf′(x)​​ 类似的，我们可以使用绝对误差定义绝对条件数 对于简单多元运算y=f(x1,…,xn)y = f(x_{1}, \\dots, x_{n})y=f(x1​,…,xn​)，近似值为y^=f(x^1,…,x^n)\\hat{y} = f(\\hat{x}_{1}, \\dots, \\hat{x}_{n})y^​=f(x^1​,…,x^n​)我们可以使用Taylor来近似估计相对误差限 y−y^≈∑i=1n∂f∂xi(x^1,…,x^n)(xi−x^i)y - \\hat{y} \\approx \\sum\\limits_{i=1}^{n}\\frac{\\partial f}{\\partial x_{i}}(\\hat{x}_{1}, \\dots, \\hat{x}_{n})(x_{i} - \\hat{x}_{i}) y−y^​≈i=1∑n​∂xi​∂f​(x^1​,…,x^n​)(xi​−x^i​) 因此 ε(y^)=∣∑i=1n∂f∂xi(x^1,…,x^n)∣ε(x^i)\\varepsilon(\\hat{y}) = \\Big|\\sum\\limits_{i=1}^{n}\\frac{\\partial f}{\\partial x_{i}}(\\hat{x}_{1}, \\dots, \\hat{x}_{n})\\Big|\\varepsilon(\\hat{x}_{i}) ε(y^​)=​i=1∑n​∂xi​∂f​(x^1​,…,x^n​)​ε(x^i​) 算法稳定性 对于一个算法，其稳定性可以定义为： 对计算过程中的扰动（四舍五入、保存数据精度等）不敏感的算法更稳定 对包含一系列计算步的过程, 若中间步结果的（相对）误差不放大或放大不严重, 则该过程对应的算法更稳定 例如在计算黄金分割率ϕ\\phiϕ的幂次时，如果采用下列递推式： ϕn+1=ϕn−1−ϕn(n≥2)ϕ0=1,ϕ1=ϕ^\\begin{align*} \\phi^{n + 1} &amp;= \\phi ^{n - 1} - \\phi^{n} \\quad (n \\geq 2) \\\\ \\phi^{0} &amp;= 1, \\phi^{1} = \\hat{\\phi} \\end{align*} ϕn+1ϕ0​=ϕn−1−ϕn(n≥2)=1,ϕ1=ϕ^​​ 其绝对误差也满足： en+1=en−1−en(n≥2)e0=0,e1=ϕ−ϕ^\\begin{align*} e_{n + 1} &amp;= e_{n - 1} - e_{n} \\quad (n \\geq 2) \\\\ e_{0} &amp;= 0, e_{1} = \\phi - \\hat{\\phi} \\end{align*} en+1​e0​​=en−1​−en​(n≥2)=0,e1​=ϕ−ϕ^​​ 可以计算得知，∣en∣=cn∣e1∣|e_{n}| = c_{n}|e_{1}|∣en​∣=cn​∣e1​∣，其中cnc_{n}cn​为Fibonacci序列，显然当nnn较大时，绝对误差的放大非常严重，相对误差亦然 向后误差 向后误差是一种分析舍入误差的方法，在函数求值的过程中，fff的计算会有误差f(x)→f^(x)f(x) \\to \\hat{f}(x)f(x)→f^​(x)，这种舍入误差可能是隐含在每一步的计算过程中的，分析过程较为复杂，因此考虑将其转化为输入扰动带来的误差，即： 找到x^\\hat{x}x^，使得f(x^)=y^f(\\hat{x}) = \\hat{y}f(x^)=y^​，则Δx=x^−x\\Delta x = \\hat{x} - xΔx=x^−x称为向后误差 计算机浮点数 计算机浮点数系统 我们定义机器精度为εmach=2−p\\varepsilon_{\\text{mach}} = 2^{-p}εmach​=2−p 则有如下定理： 实数xxx与其浮点数表示fl(x)\\text{fl}(x)fl(x)的误差满足：∣fl(x)−xx∣≤εmach\\Big|\\frac{\\text{fl}(x) - x}{x}\\Big|\\leq \\varepsilon_{\\text{mach}}​xfl(x)−x​​≤εmach​两个实数x1,x2x_{1}, x_{2}x1​,x2​，若∣x2/x1∣≤12εmach|x_{2}/x_{1}|\\leq \\frac{1}{2}\\varepsilon_{\\text{mach}}∣x2​/x1​∣≤21​εmach​，则x2x_{2}x2​的数值对浮点运算x1+x2x_{1} + x_{2}x1​+x2​无影响 抵消现象 指在计算过程中有效位数下降的过程，例如x=1.02305×103,y=1.92137×103x = 1.02305 \\times 10^{3}, y = 1.92137 \\times 10^{3}x=1.02305×103,y=1.92137×103，则精确计算得到x−y=1.68x - y = 1.68x−y=1.68，有效位数降至3位，可能导致相对误差的放大与准确度的下降 例如在一元二次方程求根公式中，其中一个根为： x1=−b+b2−4ac2ax_{1} = \\frac{-b + \\sqrt{b^{2} - 4ac}}{2a} x1​=2a−b+b2−4ac​​ 如果∣4ac∣&lt;&lt;b2|4ac| &lt;&lt; b^{2}∣4ac∣&lt;&lt;b2，那bbb与b2−4ac\\sqrt{b^{2} - 4ac}b2−4ac​的值非常接近，可能会出现抵消现象，解决方法为修改求根公式： x1=2c−b−b2−4acx_{1} = \\frac{2c}{-b - \\sqrt{b^{2} - 4ac}} x1​=−b−b2−4ac​2c​ 总结 误差简单总结","tags":["笔记","误差分析"],"categories":["数值分析"]},{"title":"拼尽全力 战胜torch","path":"/2025/01/11/拼尽全力战胜torch/","content":"集群配置torch踩雷记录 随着期末考试结束，本人重启了被四大原理stall了很久很久的复现工程，首先便是我们最喜欢的配环境啦 第一次尝试 环境环境，conda create，往里塞能看得见的requirements.txt，大胜，于是乎开始下载学长写的代码pip install -e .，再次大胜，遂骄傲，开始复现，大败 定睛一看，TypeError:unsupported operand type(s) for |: ... ？什么玩意，或运算符用错了吗？进调用栈一看，椅子电脑虾，怎么把类型标注里面的|当成或运算符了啊 上网一查，发现是python版本过低导致的，直接升版本，干到3.10，再次复现，依旧大败 定睛一看，哎哟老熟人deepspeed找不到卡，开始翻找之前的博客，找到啦！ https://ywang22thu.github.io/2024/11/02/%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/#%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98https://ywang22thu.github.io/2024/11/02/%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/#%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98 解决之后开始井喷ModuleNotFound，于是疯狂pip，直到…… 被apex打败 遇到了报错No module named 'apex.multi_tensor_apply'，我一条pip install apex，毫无作用 上网查询，告诉我apex需要从源码手动编译下载，而不能直接下载，于是clone下来一切顺利，跟着readme走呀走呀走呀，还剩最后一步之时，报错啦Torch did not find available GPUs on this system ？怎么又找不到卡，你**** 研究torch 研究一顿之后发现，我的torch是在某一个requirements.txt里面被偷偷安装的，然后下成了cpu的版本，这一项可以通过以下几种方式来确定： pip list查看torch的版本，如果后面没有+cuxxx则是CPU，反之其中的xxx则为CUDA版本（这个不是说加粗！） python -c &quot;import torch; print(torch.cuda.is_available())&quot;，如果是False则代表是CPU版本的 python -c &quot;import torch; print(torch.version.cuda)&quot;，如果是None则代表是CPU版本的 既然如此，由于我现在的这个环境断断续续往里拉了好几天（中间经历了美妙的信号处理原理考试和编译原理考试），我决定直接开一个新环境来装 在脚本中首先通过module load加载cuda/12.1，再按照官网指示运行命令 1conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia 之后确实开始下载了，恰逢我腹中绞痛，头晕脑胀，只能休息等待（没想到这窜窜病持续了两天半呜呜呜） 一天之后，待到身体略微恢复了些力气的时候，上服务器看了一下节点状态，懵了 ？不是你一个conda install跑了28小时？源在火星吗？ 遂鲨掉这个进程，开始询问学长，在学长的悉心指导下，终于弄明白了torch的安装流程 战胜torch 首先需要知道的是，这个服务器是由slurm集群管理的，同时是linux_aarch64架构，因此很多情况下，直接pip install并不能够安装带有cuda版本的包，或者根本不能安装到包，可能因为： 登录节点上没有GPU资源 pip install没法指定包兼容的处理器版本 因此这种情况下，我们需要下载whl文件之后手动编译，whl文件可以理解为一个python安装包的压缩包，直接利用pip install xxx.whl就可以编译安装对应的包，通常whl文件的文件名有以下规范： 1torch-2.3.0+cu121-cp310-cp310-linux_aarch64.whl 按照-来进行划分，从前到后分别为：包名、包版本、python版本（cpxxx表示包含了C语言扩展的Python）、ABI标签（代表二进制兼容性）、支持的平台架构 仔细查看集群使用手册之后发现，这个集群已经帮助我们下好了很多很多版本的轮子，于是直接跑到对应文件夹下开始下载，下载完成后测试，大败 报错为 1libcudart.so.12: cannot open shared object file: No such file or directory 上网查询，发现是没有cuda或者版本不对，于是通过module load加载对应版本的cuda，解决了这个问题，结果出现： 1ImportError: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.29&#x27; not found (required by xxx/lib/python3.10/site-packages/torch/lib/libtorch_python.so) 和学长一起奋力思考之后决定，重装一遍！ 这次留了个心眼，在pip install和测试之前，分别跑了module load对应版本的cuda cudnn gcc，大胜利！ 终于成功装上了带cuda的torch了呜呜呜 注 注意每次import torch之前都需要module load","tags":["环境配置"],"categories":["科研"]},{"title":"信号处理原理期末复习","path":"/2024/12/31/信号处理原理期末复习/","content":"信号处理原理 笔记 A 复习笔记 四种卷积 连续线卷积 f(t)∗g(t)=∫−∞∞f(τ)g(t−τ)dτ=∫−∞∞f(t−τ)g(τ)dτf(t) * g(t) = \\int_{-\\infty}^{\\infty}f(\\tau)g(t - \\tau)\\mathrm{d}\\tau = \\int_{-\\infty}^{\\infty}f(t - \\tau)g(\\tau)\\mathrm{d}\\tau f(t)∗g(t)=∫−∞∞​f(τ)g(t−τ)dτ=∫−∞∞​f(t−τ)g(τ)dτ 连续圆卷积 f(t)⊗g(t)=∫tt+Tf(τ)g(t−τ)dτ=∫tt+Tf(t−τ)g(τ)dτf(t) \\otimes g(t) = \\int_{t}^{t + T}f(\\tau)g(t - \\tau)\\mathrm{d}\\tau = \\int_{t}^{t + T}f(t - \\tau)g(\\tau)\\mathrm{d}\\tau f(t)⊗g(t)=∫tt+T​f(τ)g(t−τ)dτ=∫tt+T​f(t−τ)g(τ)dτ 离散线卷积 f(n)∗g(n)=∑k=−∞∞f(k)g(n−k)=∑k=−∞∞f(n−k)g(k)f(n) * g(n) = \\sum\\limits_{k=-\\infty}^{\\infty}f(k)g(n - k) = \\sum\\limits_{k = -\\infty}^{\\infty}f(n - k)g(k) f(n)∗g(n)=k=−∞∑∞​f(k)g(n−k)=k=−∞∑∞​f(n−k)g(k) 离散圆卷积 f(n)⊗g(n)=∑k=0N−1f(k)g(n−k)=∑k=0N−1f(n−k)g(k)f(n) \\otimes g(n) = \\sum\\limits_{k=0}^{N - 1}f(k)g(n - k) = \\sum\\limits_{k = 0}^{N - 1}f(n - k)g(k) f(n)⊗g(n)=k=0∑N−1​f(k)g(n−k)=k=0∑N−1​f(n−k)g(k) 性质 四种卷积都满足： 交换律、结合律、分配率 对卷积求导/积分等价于对某一个运算函数求导/积分后再卷积 (f∗g)(n)=f(m)∗g(n−m)(f * g)^{(n)} = f^{(m)}*g^{(n - m)}(f∗g)(n)=f(m)∗g(n−m)，这是第二条的推广，上标(n)(n)(n)代表求nnn次微分，当n&lt;0n &lt; 0n&lt;0的时候代表积分 四种FT对比 包括FT, FS, DTFT, DFT，其中WN=exp⁡(−j2πN)W_{N} = \\exp(-j\\dfrac{2\\pi}{N})WN​=exp(−jN2π​) FT FS DTFT DFT 公式 F(ω)=∫Rf(t)e−jωtdtF(\\omega) = \\int_{\\mathbb{R}}f(t)e^{-j\\omega t}\\mathrm{d}tF(ω)=∫R​f(t)e−jωtdt Fn=1T1∫T1f(t)e−jnω1tdtF_{n} = \\frac{1}{T_{1}}\\int_{T_{1}}f(t)e^{-jn\\omega_{1}t}\\mathrm{d}tFn​=T1​1​∫T1​​f(t)e−jnω1​tdt X(ω)=∑n=−∞∞x(n)e−jnωX(\\omega) = \\sum\\limits_{n=-\\infty}^{\\infty}x(n)e^{-jn\\omega}X(ω)=n=−∞∑∞​x(n)e−jnω X(k)=∑n=0L−1x(n)WNnkX(k) = \\sum\\limits_{n=0}^{L - 1}x(n)W_{N}^{nk}X(k)=n=0∑L−1​x(n)WNnk​ 逆变换 f(t)=12π∫RF(ω)ejωtdωf(t) = \\frac{1}{2\\pi}\\int_{\\mathbb{R}}F(\\omega)e^{j\\omega t}\\mathrm{d}\\omegaf(t)=2π1​∫R​F(ω)ejωtdω f(t)=∑n=−∞∞Fnejnω1tf(t) = \\sum\\limits_{n=-\\infty}^{\\infty}F_{n}e^{jn\\omega_{1}t}f(t)=n=−∞∑∞​Fn​ejnω1​t x(n)=12π∫−ππX(ω)ejnωdωx(n) = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}X(\\omega)e^{jn\\omega}\\mathrm{d}\\omegax(n)=2π1​∫−ππ​X(ω)ejnωdω x~(n)=1N∑k=0L−1WN−nkX(k)\\tilde{x}(n) = \\frac{1}{N}\\sum\\limits_{k=0}^{L-1}W_{N}^{-nk}X(k)x~(n)=N1​k=0∑L−1​WN−nk​X(k) 连续/周期 时域连续，频域连续 时域周期连续，频域离散 时域离散，频域连续周期 时域离散，频域离散 其中，FE, DTFT, DFT的性质总结如下： 着重关注其中的系数和系数的位置！ FT DTFT DFT 奇异信号 F[ejω0t]=2πδ(ω−ω0)\\mathscr{F}[e^{j\\omega_{0}t}] = 2\\pi\\delta(\\omega - \\omega_{0})F[ejω0​t]=2πδ(ω−ω0​)F[Gτ(ω)]=τ⋅Sa(τ2ω)\\mathscr{F}[G_{\\tau}(\\omega)] = \\tau\\cdot \\mathrm{Sa}(\\frac{\\tau}{2}\\omega)F[Gτ​(ω)]=τ⋅Sa(2τ​ω)F[δ(t)]=1\\mathscr{F}[\\delta(t)] = 1F[δ(t)]=1（频谱称为白色谱） - x(n)x(n)x(n)为实序列的时候X(k)=X∗(N−k)X(k) = X^{*}(N - k)X(k)=X∗(N−k) 线性 ✓\\checkmark✓ ✓\\checkmark✓ ✓\\checkmark✓ 压扩 F[f(at)]=1∣a∣F(ωa)\\mathscr{F}[f(at)] = \\frac{1}{|a|}F(\\frac{\\omega}{a})F[f(at)]=∣a∣1​F(aω​) DTFT[x(a)(n)]=X(aω)a∈Z/{0}\\mathrm{DTFT}[x_{(a)}(n)] = X(a\\omega)\\quad a\\in \\mathbb{Z} / \\{0\\}DTFT[x(a)​(n)]=X(aω)a∈Z/{0} - 反褶与共轭 F[f(−t)]=F(−ω)\\mathscr{F}[f(-t)] = F(-\\omega)F[f(−t)]=F(−ω)F[f∗(t)]=F∗(−ω)\\mathscr{F}[f^{*}(t)] = F^{*}(-\\omega)F[f∗(t)]=F∗(−ω) DTFT[x(−n)]=X(−ω)\\mathrm{DTFT}[x(-n)] = X(-\\omega)DTFT[x(−n)]=X(−ω)DTFT[x∗(n)]=X∗(−ω)\\mathrm{DTFT}[x^{*}(n)] = X^{*}(-\\omega)DTFT[x∗(n)]=X∗(−ω) DFT[x(−n)]=X(−k)\\mathrm{DFT}[x(-n)] = X(-k)DFT[x(−n)]=X(−k)DFT[x∗(n)]=X∗(−k)\\mathrm{DFT}[x^{*}(n)] = X^{*}(-k)DFT[x∗(n)]=X∗(−k) 时移与频移 F[f(t−t0)]=e−jωt0F(ω)\\mathscr{F}[f(t - t_{0})] = e^{-j\\omega t_{0}}F(\\omega)F[f(t−t0​)]=e−jωt0​F(ω)F[ejωt0f(t)]=F(ω−ω0)\\mathscr{F}[e^{j\\omega t_{0}}f(t)] = F(\\omega - \\omega_{0})F[ejωt0​f(t)]=F(ω−ω0​) DTFT[x(n−n0)]=e−jωn0X(ω)\\mathrm{DTFT}[x(n - n_{0})] = e^{-j\\omega n_{0}}X(\\omega)DTFT[x(n−n0​)]=e−jωn0​X(ω)DTFT[ejω0nx(n)]=X(ω−ω0)\\mathrm{DTFT}[e^{j\\omega_{0} n}x(n)] = X(\\omega - \\omega_{0})DTFT[ejω0​nx(n)]=X(ω−ω0​) DFT[x(n−m)]=WNmkX(ω)\\mathrm{DFT}[x(n - m)] = W_{N}^{mk}X(\\omega)DFT[x(n−m)]=WNmk​X(ω)DFT[WN−nlx(n)]=X(k−l)\\mathrm{DFT}[W_{N}^{-nl}x(n)] = X(k-l)DFT[WN−nl​x(n)]=X(k−l) 卷积定理 F[f1(t)⋅f2(t)]=12πF1(ω)∗F2(ω)\\mathscr{F}[f_{1}(t)\\cdot f_{2}(t)] = \\frac{1}{2\\pi}F_{1}(\\omega)* F_{2}(\\omega)F[f1​(t)⋅f2​(t)]=2π1​F1​(ω)∗F2​(ω)F[f1(t)∗f2(t)]=F1(ω)⋅F2(ω)\\mathscr{F}[f_{1}(t)* f_{2}(t)] = F_{1}(\\omega)\\cdot F_{2}(\\omega)F[f1​(t)∗f2​(t)]=F1​(ω)⋅F2​(ω) DTFT[x1(n)⋅x2(n)]=12πX1(ω)⊗X2(ω)\\mathrm{DTFT}[x_{1}(n)\\cdot x_{2}(n)] = \\frac{1}{2\\pi}X_{1}(\\omega)\\otimes X_{2}(\\omega)DTFT[x1​(n)⋅x2​(n)]=2π1​X1​(ω)⊗X2​(ω)DTFT[x1(n)∗x2(n)]=X1(ω)⋅X2(ω)\\mathrm{DTFT}[x_{1}(n)* x_{2}(n)] = X_{1}(\\omega)\\cdot X_{2}(\\omega)DTFT[x1​(n)∗x2​(n)]=X1​(ω)⋅X2​(ω) DFT[x1(n)⋅x2(n)]=1NX1(k)⊗X2(k)\\mathrm{DFT}[x_{1}(n)\\cdot x_{2}(n)] = \\frac{1}{N}X_{1}(k)\\otimes X_{2}(k)DFT[x1​(n)⋅x2​(n)]=N1​X1​(k)⊗X2​(k)DFT[x1(n)∗x2(n)]=X1(k)⋅X2(k)\\mathrm{DFT}[x_{1}(n)* x_{2}(n)] = X_{1}(k)\\cdot X_{2}(k)DFT[x1​(n)∗x2​(n)]=X1​(k)⋅X2​(k)IDFT[X1(k)⋅X2(k)]=x1(n)⊗x2(n)\\mathrm{IDFT}[X_{1}(k)\\cdot X_{2}(k)] = x_{1}(n)\\otimes x_{2}(n)IDFT[X1​(k)⋅X2​(k)]=x1​(n)⊗x2​(n) Parseval ∫R∣f(t)∣2dt=12π∫R∣F(ω)∣2dω\\int_{\\mathbb{R}}|f(t)|^{2}\\mathrm{d}t = \\frac{1}{2\\pi}\\int_{\\mathbb{R}}|F(\\omega)|^{2}\\mathrm{d}\\omega∫R​∣f(t)∣2dt=2π1​∫R​∣F(ω)∣2dω ∑n=−∞∞∣x(n)∣2=12π∫−ππ∣X(ω)∣2\\sum\\limits_{n=-\\infty}^{\\infty}|x(n)|^{2} = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}|X(\\omega)|^{2}n=−∞∑∞​∣x(n)∣2=2π1​∫−ππ​∣X(ω)∣2 ∑n=0N−1∣x(n)∣2=1N∑k=0N−1∣X(ω)∣2\\sum\\limits_{n=0}^{N-1}|x(n)|^{2} = \\frac{1}{N}\\sum\\limits_{k=0}^{N-1}|X(\\omega)|^{2}n=0∑N−1​∣x(n)∣2=N1​k=0∑N−1​∣X(ω)∣2 FT与FS关系 对于一个非周期函数f(t)f(t)f(t)，其傅里叶变换的系数记为F(ω)F(\\omega)F(ω)，将f(t)f(t)f(t)做周期延拓得到f~(t)\\tilde{f}(t)f~​(t)，且f~(t)\\tilde{f}(t)f~​(t)的傅里叶系数为FnF_{n}Fn​，则其满足： Fn=1T1F(nω1)F_{n} = \\frac{1}{T_{1}}F(n\\omega_{1}) Fn​=T1​1​F(nω1​) DTFT模拟频率和数字频率的关系 在DTFT中，我们对真实采样得到的结果f(nT)f(nT)f(nT)进行了归一化，将采样周期TTT归一化为111，在这种情况下： 归一化前的频率为模拟频率，为 Ω=2πT\\,\\Omega = \\frac{2\\pi}{T}Ω=T2π​ 归一化后的频率为数字频率，为 ω=2π\\,\\omega = 2\\piω=2π Nyquist区间从[−πT,πT][-\\frac{\\pi}{T}, \\frac{\\pi}{T}][−Tπ​,Tπ​]变为了[−π,π][-\\pi, \\pi][−π,π] 模拟频率与数字频率的关系为ω=TΩ\\omega = T\\Omegaω=TΩ 有限长DTFT 实际中我们只能得到长度为LLL的离散时间信号，而DTFT要求x(n)x(n)x(n)是在整数域上定义的，因此我们可以考虑对x(n)x(n)x(n)加一个长度为LLL的窗：w(n)=10≤n≤L−1w(n) = \\mathbf{1}_{0\\leq n \\leq L - 1}w(n)=10≤n≤L−1​，得到xL(n)=x(n)w(n)x_{L}(n) = x(n)w(n)xL​(n)=x(n)w(n)，根据DTFT的特性，有： XL(ω)=12πX(ω)⊗W(ω)X_{L}(\\omega) = \\frac{1}{2\\pi}X(\\omega) \\otimes W(\\omega) XL​(ω)=2π1​X(ω)⊗W(ω) 而： W(ω)=∑n=−∞∞w(n)e−jωn=∑n=0L−1e−jωn=sin⁡(Lω2)sin⁡(ω2)e−j(L−1)ω2\\begin{align*} W(\\omega) &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}w(n)e^{-j\\omega n} \\\\ &amp;= \\sum\\limits_{n = 0}^{L - 1}e^{-j\\omega n} = \\frac{\\sin(\\frac{L\\omega}{2})}{\\sin(\\frac{\\omega}{2})}e^{-\\frac{j(L - 1)\\omega}{2}} \\end{align*} W(ω)​=n=−∞∑∞​w(n)e−jωn=n=0∑L−1​e−jωn=sin(2ω​)sin(2Lω​)​e−2j(L−1)ω​​ 定义主瓣宽度为ΔωW=2πL\\Delta\\omega_{W} = \\frac{2\\pi}{L}ΔωW​=L2π​，绝对值在这个宽度之外的为旁瓣，其导致了频率泄露 DFT的注意事项 最重要的是，IDFT得到的不是唯一结果，而是原来序列的回绕，这是因为序列回绕之后的DFT与原序列的DFT相同，证明参考： https://ywang22thu.github.io/2024/11/19/%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E5%8E%9F%E7%90%866/#Appendix-Ahttps://ywang22thu.github.io/2024/11/19/%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E5%8E%9F%E7%90%866/#Appendix-A FFT 如果希望计算x(n)x(n)x(n)的DFT，序列长度为N=2RN = 2RN=2R，则我们考虑将序列拆分为两组g(r)=x(2r)g(r) = x(2r)g(r)=x(2r)与h(r)=x(2r+1)h(r) = x(2r + 1)h(r)=x(2r+1)，设其对应的DFT序列分别为X(k),G(k),H(k)X(k), G(k), H(k)X(k),G(k),H(k)，长度分别为N,R,RN, R, RN,R,R，则计算X(k)X(k)X(k)的快速方法为： X(k)={G(k)+WNkH(k)k=0,1,…,N2−1G(k−N2)−WNk−N2H(k−N2)k=N2,N2+1,…,N−1\\begin{align*} X(k) = \\begin{cases} G(k) + W_{N}^{k}H(k) &amp; k = 0, 1, \\dots, \\frac{N}{2} - 1 \\\\ G(k - \\frac{N}{2}) - W_{N}^{k - \\frac{N}{2}}H(k - \\frac{N}{2}) &amp; k = \\frac{N}{2}, \\frac{N}{2} + 1, \\dots, N - 1 \\end{cases} \\end{align*} X(k)={G(k)+WNk​H(k)G(k−2N​)−WNk−2N​​H(k−2N​)​k=0,1,…,2N​−1k=2N​,2N​+1,…,N−1​​ 对应时间复杂度为O(Nlog⁡N)O(N\\log N)O(NlogN) 从DFT到FT/FS 从DFT计算FT 假设f(t)f(t)f(t)经过TsT_{s}Ts​采样后，得到的DTFT为X(ω)X(\\omega)X(ω)，再经过频域采样后得到的DFT为X(k)X(k)X(k)，则： X(k)=X(ωk)=X(2πNk)X(k) = X(\\omega_{k}) = X(\\frac{2\\pi}{N}k) X(k)=X(ωk​)=X(N2π​k) 而我们有，时域采样实际上是频域上压扩后的周期扩展，因此： X(ω)=(F(ω)/Ts)ωsX(\\omega) = (F(\\omega)/T_{s})_{\\omega_{s}} X(ω)=(F(ω)/Ts​)ωs​​ 在满足Nyquist条件的情况下，ωk\\omega_{k}ωk​都位于一个Nyquist区间内，并且周期重复不会产生混叠现象，因此： X(k)=X(ωk)=F(ωk)/TsX(k) = X(\\omega_{k}) = F(\\omega_{k})/T_{s} X(k)=X(ωk​)=F(ωk​)/Ts​ 化简后得到： F(ωk)=TsX(k)F(\\omega_{k}) = T_{s}X(k) F(ωk​)=Ts​X(k) 也即我们可以对DFT的图像进行扩压并连线后得到F(ω)F(\\omega)F(ω)的近似图像 从IDFT计算IFT 对F(ω)F(\\omega)F(ω)按照ωs\\omega_{s}ωs​进行周期重复，得到DTFT序列，再次N点采样得到F(k)F(k)F(k)，现在希望根据F(k)F(k)F(k)计算出f(t)f(t)f(t) IDFT[F(k)]=IDTFT[(F(ωk))ωs]=Ts⋅IDTFT[(F(ωk/Ts))ωs]=Tsf(n)\\begin{align*} \\mathrm{IDFT}[F(k)] &amp;= \\mathrm{IDTFT}[(F(\\omega_{k}))_{\\omega_{s}}] \\\\ &amp;= T_{s}\\cdot \\mathrm{IDTFT}[(F(\\omega_{k} / T_{s}))_{\\omega_{s}}] \\\\ &amp;= T_{s}f(n) \\end{align*} IDFT[F(k)]​=IDTFT[(F(ωk​))ωs​​]=Ts​⋅IDTFT[(F(ωk​/Ts​))ωs​​]=Ts​f(n)​ 即： f(n)=1TsIDFT[F(k)]f(n) = \\frac{1}{T_{s}}\\mathrm{IDFT}[F(k)] f(n)=Ts​1​IDFT[F(k)] 因此我们可以根据IDFT的图像压扩后连线得到f(t)f(t)f(t)的近似图像 从DFT计算FS 对于一个周期信号f(t)f(t)f(t)，我们希望得到其采样后的N点DFT与其FS的关系，假设这个采样满足Nyquist定理，并且一个周期内恰好有NNN个采样点，即Ts=TNT_{s} = \\frac{T}{N}Ts​=NT​ 由于周期信号进行周期重复之后，频谱幅度会发生变化，因此不能使用第一种情况中的思路来做，相应的，我们需要使用： Fn=1TF(nω)F_{n} = \\frac{1}{T}F(n\\omega) Fn​=T1​F(nω) 其中F(ω)F(\\omega)F(ω)为对f(t)f(t)f(t)截取一个周期后得到的非周期信号计算FT后的结果，此时满足第一种情况，即： F(kω)=TsX(k)F(k\\omega) = T_{s}X(k) F(kω)=Ts​X(k) 因此： Fn=TsTX(k)=1NX(k)F_{n} = \\frac{T_{s}}{T}X(k) = \\frac{1}{N}X(k) Fn​=TTs​​X(k)=N1​X(k) 采样 时域采样 对时域上的串x(t)x(t)x(t)，用p(t)=∑n=−∞∞δ(t−nTs)p(t) = \\sum\\limits_{n = -\\infty}^{\\infty} \\delta(t - nT_{s})p(t)=n=−∞∑∞​δ(t−nTs​)对其进行采样，得到的结果相当于在频域上以ωs\\omega_{s}ωs​为周期进行延拓，之后幅度乘以系数，即： xp(t)=x(t)p(t)=∑n=−∞∞x(nTs)δ(t−nTs)Xp(ω)=12πX(ω)∗P(ω)=1Ts∑n=−∞∞X(ω−nωs)\\begin{align*} x_{p}&amp;(t) = x(t)p(t) = \\sum\\limits_{n=-\\infty}^{\\infty}x(nT_{s})\\delta(t - nT_{s}) \\\\ X_{p}(\\omega) &amp;= \\frac{1}{2\\pi}X(\\omega)*P(\\omega) = \\frac{1}{T_{s}}\\sum\\limits_{n = -\\infty}^{\\infty}X(\\omega - n\\omega_{s}) \\end{align*} xp​Xp​(ω)​(t)=x(t)p(t)=n=−∞∑∞​x(nTs​)δ(t−nTs​)=2π1​X(ω)∗P(ω)=Ts​1​n=−∞∑∞​X(ω−nωs​)​ Nyquist采样定理为，满足以下两个条件的采样信号序列可以恢复原信号： x(t)x(t)x(t)在频域是带限的，即频域上分布在∣ω∣≤ωM|\\omega| \\leq \\omega_M∣ω∣≤ωM​内 采样频率满足ωs&gt;2ωM\\omega_{s} &gt; 2\\omega_{M}ωs​&gt;2ωM​ 采样后在频域恢复只需要用窗函数H(ω)H(\\omega)H(ω)来截取，得到X(ω)X(\\omega)X(ω)，因此对应到时域，就相当于是用窗函数的IFT，即理想滤波器的单位冲激响应h(t)h(t)h(t)，对采样结果进行卷积 H(ω)=e−jωt0∣ω∣&lt;ωsX(ω)=H(ω)Xp(ω)x(t)=F−1[X(ω)]=h(t)∗xp(t)\\begin{align*} H(\\omega) &amp;= \\mathbf{e^{-j\\boldsymbol{\\omega} t_{0}}}_{|\\omega| &lt; \\omega_{s}} \\\\ X(\\omega) &amp;= H(\\omega)X_{p}(\\omega) \\\\ x(t) &amp;= \\mathscr{F}^{-1}\\bigl[X(\\omega)\\bigr] \\\\ &amp;= h(t) * x_{p}(t) \\end{align*} H(ω)X(ω)x(t)​=e−jωt0​∣ω∣&lt;ωs​​=H(ω)Xp​(ω)=F−1[X(ω)]=h(t)∗xp​(t)​ 频域采样 在频域上以ω0\\omega_{0}ω0​采样相当于在时域以2πω0\\frac{2\\pi}{\\omega_{0}}ω0​2π​以周期进行周期延拓 P(ω)=∑n=−∞∞δ(ω−nω0)Xp(ω)=∑n=−∞∞X(nω0)δ(ω−nω0)xp(t)=1ω0∑n=−∞∞x(t−2πω0n)\\begin{align*} P(\\omega) &amp;= \\sum\\limits_{n = -\\infty}^{\\infty}\\delta(\\omega - n\\omega_{0}) \\\\ X_{p}(\\omega) &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}X(n\\omega_{0})\\delta(\\omega - n\\omega_{0}) \\\\ x_{p}(t) &amp;= \\frac{1}{\\omega_{0}}\\sum\\limits_{n = -\\infty}^{\\infty}x(t - \\frac{2\\pi}{\\omega_{0}}n) \\end{align*} P(ω)Xp​(ω)xp​(t)​=n=−∞∑∞​δ(ω−nω0​)=n=−∞∑∞​X(nω0​)δ(ω−nω0​)=ω0​1​n=−∞∑∞​x(t−ω0​2π​n)​ 同样，时域恢复的时候也是利用举行信号进行截取，频域需要内插，内插函数为W(ω)=2π Sa(ω/ω0)W(\\omega) = 2\\pi\\,\\mathrm{Sa}(\\omega/\\omega_{0})W(ω)=2πSa(ω/ω0​) Z变换 在Fourier变换中，变换核为ejωe^{j\\omega}ejω，我们考虑将其泛化为任意复数z∈Cz\\in \\mathbb{C}z∈C，此即Z变换，但是Z变换不一定是恒收敛的，需要考虑其收敛域ROC 对于右边序列，ROC为模最大的极点所在圆以外的部分 对于左边序列，ROC为模最小的极点所在圆以内的部分 对于双边序列，我们将其拆分为左右边序列的和，ROC为圆环 000与+∞+\\infty+∞需要单独讨论 重要的性质 由于ZT是FT的扩展，所以FT的性质，例如线性、时移、压扩等，ZT都能保持 Z[anu(n)]=11−az−1Z[−anu(−n−1)]={11−az−10&lt;∣a∣&lt;∣z∣0z=0\\begin{align*} \\mathscr{Z}[a^{n}u(n)] &amp;= \\frac{1}{1 - az^{-1}} \\\\ \\mathscr{Z}[-a^{n}u(-n-1)] &amp;= \\begin{cases} \\frac{1}{1 - az^{-1}} &amp; 0 &lt; |a| &lt; |z| \\\\ 0 &amp; z = 0 \\end{cases} \\end{align*} Z[anu(n)]Z[−anu(−n−1)]​=1−az−11​={1−az−11​0​0&lt;∣a∣&lt;∣z∣z=0​​","tags":["信原","笔记","数学基础"],"categories":["信号处理原理"]},{"title":"信号处理原理 9","path":"/2024/12/24/信号处理原理9/","content":"信号处理原理 笔记 9 滤波器的设计 我们以低通滤波器的设计为例，其他类型的滤波器可以转换成低通的来计算 低通FIR滤波器的设计过程 公式中，fsf_{s}fs​为采样频率 其中的窗函数表如下，其中第一项为窗函数ω(n)\\omega(n)ω(n)，第二项用于计算窗长NNN，NNN为大于表中第二项的最小奇数： 低通FIR滤波器设计过程中的窗函数表 带通与高通 带通与高通的算法：首先将中心频率挪到零点，当成低通算，算完之后需要再额外乘cos⁡(ω0n)\\cos(\\omega_{0}n)cos(ω0​n)，其中ω0=2πf0/fs\\omega_{0} = 2\\pi f_{0} / f_{s}ω0​=2πf0​/fs​，f0f_{0}f0​为中心频率 其实这相当于低通滤波器的中心频率是0Hz0\\rm Hz0Hz，于是乎我们就忽略了其中的cos⁡(0)=1\\cos(0) = 1cos(0)=1这一项 带阻和带通 带阻可以看成是高通和低通的并联 带通可以看成是高通和低通的串联 因此根据单位冲激响应的串并联特性来计算： 并联时：hn=h1(n)+h2(n)h_{n} = h_{1}(n) + h_{2}(n)hn​=h1​(n)+h2​(n) 串联时：hn=h1(n)∗h2(n)h_{n} = h_{1}(n) * h_{2}(n)hn​=h1​(n)∗h2​(n) 带阻FIR滤波器 带通FIR滤波器","tags":["信原","笔记","数学基础"],"categories":["信号处理原理"]},{"title":"传输层与应用层安全协议","path":"/2024/12/17/传输层与应用层安全协议/","content":"计算机网络安全技术 笔记 4 传输层与网络层安全协议 传输层安全协议 SSL IPsec可以提供端到端的安全传输，但是不能处理同一端系统中不同应用之间的安全需求，因此需要传输层的安全协议：基于传输层的安全服务，保证两个应用之间的保密性和安全性，为应用层提供安全服务 常见协议包括 SP4：从属于安全数据网络系统SDNS，由NSA与NIST开发 SSH：通过 强制认证+数据加密 实现 安全登陆+安全传输 TLSP：ISO开发和标准化的协议，通信加密+完整性验证 SSL：安全套接层安全机制 我们主要讨论SSL，它是一个工作在TCP之上、对应用层透明的协议，可以为端到端的应用提供保密性、完整性和身份认证等安全服务 体系结构 两个实体：客户机 + 服务器，基于证书在双方之间完成身份认证 两个概念：会话 + 连接，会话是虚拟连接，连接是特定通道 两层协议：握手协议 + 记录协议 SSL协议 会话与连接 会话是客户端与服务器之间的虚拟连接，通过握手协议建立，用以协商密码算法、主密钥等 连接是特定的通信信道（例如一次HTTPS访问可能需要多次连接），通常映射成是一次TCP连接 会话 - 连接是一对多的关系 会话参数包括： 会话标识符 对等实体证书 压缩方法 加密规格（例如加密算法等） 主控密钥 是否可以恢复 连接参数 服务器和客户随机数 服务器写MAC密钥：服务器发送数据进行MAC操作的密钥 客户机写MAC密钥：客户机发送数据进行MAC操作的密钥 服务器写密钥：服务器加密 - 客户解密的对称密钥 客户机写密钥：服务器解密 - 客户加密的对称密钥 初始化向量 序列号 SSL记录协议 为SSL连接提供两种服务： 保密性：使用握手协议定义的共享密钥，对payload进行加密 完整性：用握手协议定义的共享密钥计算MAC 记录协议的操作过程为： 分片：将应用层数据分成若干片，每片不超过2142^{14}214字节 压缩：握手协议约定了压缩算法 加密：包括添加MAC码、载荷加密、添加SSL记录头 SSL记录协议数据单元 SSL握手协议 功能包括： 协商密码算法与主会话密钥 client和server相互认证 握手协议通过若干次报文交换完成，每个报文包括三个字段： 类型：1 B 长度：3 B 内容：&gt;= 1 B SSL握手协议消息类型 一共需要四个阶段来完成，大体上为建立通道 - 验证身份 - 交换密钥 建立安全能力： client发送client_hello报文，其中密码参数包括密钥交换算法、加密算法、MAC算法 server发送server_hello报文 server认证、密钥交换 server发送其SSL数字证书 如果需要client认证，则server发送certificate_request server发送server_hello_done，等待client相应 client认证、密钥交换 client收到server_hello_done，验证证书 如果收到了certificate_request，则发送数字证书，如果没有可用数字证书则发送一个alert，但是此时如果client的认证是强制的将导致会话失败 client发送client_key_exchange，如果发送过数字证书则会用密钥进行签名 结束阶段 client利用发送过去的密钥派生出所有算法需要的密钥 client发送change_cipher_spec server转换为新密码对 client发送新算法、密钥的finished报文 server发送change_cipher_spec server发送finished SSL告警协议与修改密码规约协议 告警协议alert用于向peer传递SSL相关的晶胞，其报文只有两个字节： 第一个字节标识告警 / 致命错误 第二个字节标识特定告警信息 修改密码规约协议chaneg_cipher_spec，在握手协议的结束阶段发送，通知接收方，以后的记录将使用刚才协商的密码算法和密钥进行加密/认证 只有一个字节，只有一个有效值 SSL安全性分析 SSL为每次安全连接产生一个128位长的随机序号，可以防范重放攻击 保密性建立在算法安全性基础之上 SSL对应用层不透明，只能提供交易中客户与服务器间的双方认证，在涉及多方的电子交易中，SSL协议并不能协调各方间的安全传输和信任关系 应用层安全协议 HTTPS Web的安全问题 Web的安全性需要三个方向： server数据存储安全 client的计算机安全 双方之间通信安全 针对Web的攻击可以按照威胁位置分为如上三类，也可以根据威胁方式分类： 主动攻击，包括伪装成其它用户、篡改客户和服务器之间的消息或者篡改Web站点的信息等 被动攻击，包括在浏览器和服务器通信窃听、获得原来被限制使用的权限等 提供Web安全的方法包括： IP级安全，如IPsec TCP级安全，如SSL 应用级安全，为应用定制安全协议，例如安全电子交易SET 针对HTTP的攻击 应用最为广泛的应用层协议是HTTP，但是它是明文传输，没有完整性校验和状态连接 常见的攻击有： 监听嗅探：直接嗅探到明文信息 篡改劫持：直接劫持并修改通信数据包 伪造服务器：ARP欺骗、DNS欺骗、钓鱼等 中间人攻击 攻击者与通讯双方建立独立的联系，由于HTTP不会进行认证且明文传输，因此这个操作是无法被防御的，一种常见的攻击手段是ARP欺骗 ARP是建立IP-MAC映射表的协议，但是其也没有进行任何验证，因此攻击者可以伪造ARP报文，从而将双方的通信打断（将通信目标节点的MAC改成攻击者的MAC），从而能够窃取信息、篡改信息 在ARP欺骗成功之后，可以继续实现DNS欺骗 HTTPS 是HTTP与SSL的合并，相当于在HTTP与TCP之间增加了一个SSL层，对数据进行加密，实现了保密性、完整性和身份认证 HTTPS与HTTP的区别 HTTPS仍然无法避免ARP欺骗，但是嗅探到的只能是密文，因此可以在一定程度上进行防范，但是如果攻击者使用自己的证书替换掉服务器的证书，那通信过程对于攻击者来说就是明文 但是HTTPS仍然可能被攻击，例如SSLStrip： 先进行中间人攻击来拦截 HTTP 流量 将出现的 HTTPS 链接全部替换为 HTTP，同时记下所有改变的链接 使用 HTTP 与受害者机器连接 同时与合法的服务器建立 HTTPS 受害者与合法服务器之间的全部通信经过了代理转发 出现的图标被替换成为用户熟悉的“小黄锁”图标，以建立信任 中间人攻击就成功骗取了密码、账号等信息，而受害者一无所知 电子商务安全 电子商务安全应该包括： 基本加密算法 以基本加密算法为基础的证书认证体系CA(Certificate Authority)以及数字信封、数字签名等基本安全技术 以基本加密算法、安全技术、CA体系为基础的各种安全应用协议 其对安全的基本要求有： 授权合法性 信息的保密性 信息的完整性 身份的真实性 不可抵赖性 存储信息的安全性 电子商务安全体系包括网络系统安全、网络信息安全、网络交易安全等 电子商务安全体系 安全电子交易协议 SET 参与方包括： 持卡人(cardholder) 网上商家(merchant) 发卡银行(issuer) 收款银行(acquirer) 支付网关(Payment Gateway) 证书授权(CA) SET交易过程 SET交易前的认证技术 购买请求 持卡人向商家发送支付信息和订购信息，二者之间有一定联系（防止商家篡改），但是要分开签名和加密，即分别加密后拼接再次加密，之后用持卡人私钥签名 商家向收款银行发送支付信息 支付授权 商家通过支付网关和发卡行时得到授权，才能发货 支付授权交换由授权请求和授权响应组成，授权请求报文包括支付信息、双签名、授权公钥、双方证书，授权响应是与请求对应的回复 支付网关对授权请求的处理是： 验证所有证书的合法性 解密数字信封，获得会话密钥，解密authorization block 验证商家对authorization block 的数字签名 解密Payment Block的数字信封，解密支付信息 验证双签名 验证transiaction ID 与PI中的是否一致 从发卡行申请支付 支付获取 商家只有通过支付获取，才能完成银行的转帐业务 获取请求报文由以下几部分组成：支付的数量、交易ID、获取权标、商人的签名密钥、证书 支付获取由获取请求和获取响应报文组成 获取响应报文由以下几部分组成：网关的签名、加密获取相应数据块、网关签名密钥证书 客户生成购买请求 商家验证用户订单","tags":["笔记","网安","传输层","网络层","安全协议"],"categories":["计算机网络安全技术"]},{"title":"目标代码生成及代码优化基础","path":"/2024/12/16/目标代码生成/","content":"编译原理 笔记 6 目标代码生成及代码优化基础 编译器整体逻辑 基本概念 基本块 对应实验中的：basicblock 一个顺序执行的语句序列，只有一个入口和一个出口，只有入口可能是label，只有出口可能是跳转或halt语句，具体来说： 入口可能是： 整个程序的第一条语句 某条跳转语句的目标 紧跟条件跳转语句的语句 出口可能是： 跳转语句 halt 其他 划分基本块算法： 求出所有入口语句 由入口语句构造对应基本块： 到下一入口（不包含） 到跳转或halt（包含） 之后，不在基本块的语句都是不可到达的 流图 对应实验中的：cfg 表示程序的控制流信息，以基本块为点集，节点0一定是含有首条语句的基本块，存在有向边i -&gt; j当且仅当： i的出口是跳到j的入口 i的出口不是无条件跳转或停并且j紧跟i 循环 首先定义支配节点： 如果去除节点m后，从首节点出发不能到达节点n，则称m是n的支配节点，即为m DOM n，节点n的所有支配节点集合成为支配节点集，即为D(n) 之后定义回边： 对于一条有向边n -&gt; d，其为回边当且仅当d DOM n 每一个回边n -&gt; d对应一个自然循环为下面这些点构成的集合： n和d 去除d后仍可到达n的节点 数据流分析基础 常用的手段是建立和求解数据流方程，例如： out(S)=gen(S)∪(in(S)−kill(S))\\mathrm{out}(S) = \\mathrm{gen}(S) \\cup (\\mathrm{in}(S) - \\mathrm{kill}(S)) out(S)=gen(S)∪(in(S)−kill(S)) 到达-定值数据流分析 对于变量A的定值是指一条TAC语句赋值或可能赋值给A，最普通的例如直接对A赋值或读值到A，这种语句的位置成为A的定值点 如果变量A的定值点d可以到达另一点p，要求d -》 p连通且路径上没有其他定值 对于基本块BBB，我们定义： P[B]P[B]P[B]为BBB的所有前驱 GEN[B]\\mathrm{GEN}[B]GEN[B]为B中定值并且到达了出口处的定值点集合 KILL[B]\\mathrm{KILL}[B]KILL[B]为到达B入口、其定值的变量在B内被重新定值的定值点集合 IN[B]\\mathrm{IN}[B]IN[B]为B入口处各变量所有定值点的集合 OUT[B]\\mathrm{OUT}[B]OUT[B]为B出口处各变量所有定值点的集合 则其数据流方程为： IN[B]=∪b∈P[B]OUT[B]OUT[B]=GEN[B]∪(IN[B]−KILL[B])\\begin{align*} \\mathrm{IN}[B] &amp;= \\mathop{\\cup}\\limits_{b\\in P[B]} \\mathrm{OUT}[B] \\\\ \\mathrm{OUT}[B] &amp;= \\mathrm{GEN}[B] \\cup (\\mathrm{IN}[B] - \\mathrm{KILL}[B]) \\end{align*} IN[B]OUT[B]​=b∈P[B]∪​OUT[B]=GEN[B]∪(IN[B]−KILL[B])​ 计算的算法为： IN[Bi]=∅\\mathrm{IN}[B_{i}] = \\emptyIN[Bi​]=∅，OUT[Bi]=GEN[Bi]\\mathrm{OUT}[B_{i}] = \\mathrm{GEN}[B_{i}]OUT[Bi​]=GEN[Bi​] 循环使用上述方程计算直到IN[B]\\mathrm{IN}[B]IN[B]保持稳定 到达定值数据流为一种典型的向前流，即信息流和控制流同向 活跃变量数据流分析 对应实验中的：livenessanalyzer 变量A在点p活跃表示存在从p开始的某条通路需要引用A在p处的值 对于基本块BBB，我们定义： P[B]P[B]P[B]为BBB的所有后继 LiveUse[B]\\mathrm{LiveUse}[B]LiveUse[B]为B中定值前要引用的变量集合 Def[B]\\mathrm{Def}[B]Def[B]为B中定值、且定值前未被引用的变量集合 LiveIn[B]\\mathrm{LiveIn}[B]LiveIn[B]为B入口处活跃变量的集合 LiveOut[B]\\mathrm{LiveOut}[B]LiveOut[B]为B出口处活跃变量的集合 LiveIn[B]=LiveUse[B]∪(LiveOut[B]−Def[B])LiveOut[B]=∪s∈S[B]LiveIn[s]\\begin{align*} \\mathrm{LiveIn}[B] &amp;= \\mathrm{LiveUse}[B] \\cup (\\mathrm{LiveOut}[B] - \\mathrm{Def}[B])\\\\ \\mathrm{LiveOut}[B] &amp;= \\mathop{\\cup}\\limits_{s\\in S[B]} \\mathrm{LiveIn}[s] \\end{align*} LiveIn[B]LiveOut[B]​=LiveUse[B]∪(LiveOut[B]−Def[B])=s∈S[B]∪​LiveIn[s]​ 计算的算法为： LiveIn[Bi]=LiveUse[Bi]\\mathrm{LiveIn}[B_{i}] = \\mathrm{LiveUse}[B_{i}]LiveIn[Bi​]=LiveUse[Bi​]，LiveOut[Bi]=∅\\mathrm{LiveOut}[B_{i}] = \\emptyLiveOut[Bi​]=∅ 循环使用上述方程计算直到LiveOut[B]\\mathrm{LiveOut}[B]LiveOut[B]保持稳定 活跃变量数据流为一种典型的向后流，即信息流和控制流反向 UD链和DU链 变量A在点u处的引用定值链（UD链）是指到达u的A的定值点全体，算法为： 如果A在基本块中被定值，定值点为d，且d在u之前，则A在u的UD链就是[d] 如果A在基本块中的u点之前没有被定值，A在u的UD链就是IN[B] 变量A在定值点u处的定值引用链（DU链）是指u处对变量A定的值被使用的引用点全体 DU链的一种算法为扩充活跃变量数据流： LiveUse[B]\\mathrm{LiveUse}[B]LiveUse[B]为(s, A)的集合，其中s在BBB中且引用了A，并且s之前没有给A定值 Def[B]\\mathrm{Def}[B]Def[B]为(s, A)的集合，其中s不在BBB中且引用了A，并且A在B中被重新定值 待用信息与活跃信息 待用信息：基本块内某定值点下一次被使用的地方 活跃信息：基本块中的活跃信息链体现了以语句为单位的活跃变量信息，即如果i定值A、j引用A、i -&gt; j之间没有重新定值，则i -&gt; j之间A是活跃的 算法为倒序扫描，对于每一个A=B op CA = B \\,\\mathrm{op}\\, CA=BopC： A 非待用，非活跃 B和C 待用信息为i，活跃 基本块的DAG 有向无圈图，叶节点代表名字初值，内部节点由运算符号标记 基本块的DAG DAG生成算法大概就是： 常数直接生成（包括可以计算出的常数） 动态计算按照图中规则生成 尽可能复用 很简单！（不是我懒得抄） 可以使用DAG优化基本块 基本块优化DAG 目标代码生成 目标代码生成需要考虑： 指令选择：优先保证语义一致性，之后考虑效率 寄存器分配 指令调度 高效使用寄存器 Ershov数代表表达式求值时所需要寄存器数目的最小值，计算算法为： 12345678910def ershov(tree): for node in tree.backwardIterator(): if node.ls is None and node.rs is None: node.ershov = 1 elif node.rs is None: node.ershov = node.ls.ershov elif node.ls.ershov == node.rs.ershov: node.ershov = node.ls.ershov + 1 else: node.ershov = max(node.ls.ershov, node.rs.ershov) 即： 叶节点的ershov数为1 如果只有一个孩子，则为孩子的ershov 如果左右儿子的ershov相同，则取孩子的ershov+1 如果左右儿子的ershov不同，则取较大者 表达式树的求值使用Sethi-Ullman算法，一种简略的算法为先递归计算孩子中ershov数更大的子树 两遍的寄存器分配和指派算法（实验框架中的做法）： 第一次分配给通用寄存器 第二次将通用寄存器绑定到物理寄存器 图分配算法 基于寄存器相干图的图着色寄存器分配算法 寄存器相干图定义为： 节点为伪寄存器 如果在某条语句中，节点i被定值，节点j是活跃的，则i, j之间有一条边 语句的活跃变量集合可以倒序遍历语句得到，算法为： 123live = bb.liveOutfor instr in bb.instrs[::-1]: instr.live = live - instr.def + instr.use 之后用kkk（kkk为物理寄存器数目）种颜色对相干图进行着色即可，但是k着色是一个NPC问题，因此有一种简单的启发式算法： 依次删除所有度小于kkk的节点，这些点满足：我们可以在分配完其所有邻居之后为其分配一个新颜色 如果能到达空图，则代表可以k着色，反之不可以k着色，这代表我们需要把一个节点放到内存中（删除之），再继续分配 代码优化技术 按照优化范围分 窥孔优化：几条指令 局部优化：基本块 全局优化：流图 过程间：程序 按照对象分 目标代码优化 中间代码优化 源级优化 按照优化方式分 指令调度 寄存器分配 存储层次优化 存储布局优化 循环优化 控制流优化 过程优化等 窥孔优化 在目标指令序列上滑动一个包含若干条指令的窗口（即窥孔），如果发现不好的指令序列则优化 删除冗余内存操作 合并已知量 常量传播（可能使得更多的指令不可达从而被删除） 代数化简（删除x = x + 0这种） 控制流优化（减少跳转次数） 死代码删除（if(false) ...） 强度削弱（乘法变加法，除法变乘法或移位） 使用目标机惯用指令 循环优化 外提循环不变量，即循环中不变的代码可能可以放到循环外，可以利用UD来判断 循环不变量的外提 对于归纳变量（在每一次迭代都有新值的变量，例如循环下标），可以削弱计算强度，删除冗余归纳变量","tags":["笔记","编原","目标代码","代码优化"],"categories":["编译原理"]},{"title":"网络层安全协议","path":"/2024/12/13/网络层安全协议/","content":"计算机网络安全技术 笔记 3 网络层安全协议 协议栈与每一层的安全协议 IPsec 现有IP协议无认证、无完整性保证、无保密保证、访问控制不完备，可能面临窃听、伪造IP地址、篡改和重发等 而IPsec保障了IP级的安全性，包括： 认证：确保收到的包是从包头标识的源端发出的，而且该包在传输过程中未被篡改 保密：将报文加密后传输，防止第三方窃听 密钥管理：密钥管理机制与密钥的安全交换相关 其用途包括： 分支机构通过互联网安全互联（VPN） 远程安全访问互联网 与合作者建立外联网和内联网联系 加强电子商务安全性 IPsec的实施方式非常多样： 在主机上实施，与操作系统集成，对用户是透明的 在防火墙上实施，不需要修改操作系统 在路由器上实施，如VPN的实现 IPsec文档 重要的文档是1998年发布的RFC系列 RFC 2401：安全结构概述 RFC 2402：IP扩展的包认证描述（IPv4和IPv6） RFC 2406：IP扩展的包加密描述（IPv4和IPv6） RFC 2408：特定加密机制 IPv6必须支持这些特性而IPv4可选 包认证的扩展报头成为认证头（AH），用于提供数据的源发认证和完整性保护 包加密的扩展报头成为封装安全载荷（ESP），用于提供数据保密、源发认证和完整性保护 IPsec文档 IPsec服务 IPsec服务 安全关联SA SA是IPsec通信双方之间对某些要素的一组安全信息参数集合，包括但不限于协议、操作模式、密码算法、认证算法、密钥、密钥生存期 关联是发送方和接收方之间的单向关系，如果需要是双向的，则需要两个SA SA仅可由AH或ESP之中的一方提供 SA由三个参数唯一确定： 安全参数索引SPI 与SA相关的位串，仅在本地有意义 由AH与ESP携带，使得接收方能够选择合适的SA IP目的地址IPDA 表示SA的目的地址 安全标识协议 表明是AH还是ESP 每一个IPsec的实施中都有一个数据库SADB，定义了与每个SA相关联的参数元组 对于需要处理的数据包，首先从其中解析出SPI、IPDA、Protocol，之后查找SADB： DB命中，则比对SA的参数，一致则处理，不一致则丢弃 DB不命中，则根据数据包的方向，输入包丢弃，输出包创建新SADB并存入 而SA的使用有SPDB即安全策略数据库决定，其中的每一项定义了要保护的数据包及操作，操作包括： Discard bypass IPsec apply IPsec 最后一种操作会认为接收的数据包已经经过安全服务 SA选择子 用于过滤输出流量，并将其映射到某个特定的SA，定义为IP集合与上层协议 对于每个要输出的IP包，首先在SPDB中比较相应域的值，寻找匹配的入口，如果存在对应的选择子，则通过对应的SA进行处理 SPDB的入口选择子包括： 目的IP地址、源IP地址 用户标识 数据敏感性级别 传输层协议 IPsec协议 源端口和目的端口 IPv6报类 IPv6报流标签 IPv6报服务类型 SA参数 默认情况下，参数是两种协议都必须实现的 序列号计数器：每用一次SA保护包自增1，溢出后重新协商 序列号溢出标记：计数器溢出时置为1，阻止下一次发包并重新协商 反重放窗口：决定输入报文是否是重放，32位计数器 AH信息组（AH需要实现）：认证算法，密钥，密钥生存期和AH的相关参数 ESP信息组（ESP需要实现）：加密和认证算法，密钥，初始值，密钥生存期和ESP的相关参数 SA生存期：计时器，生存期结束的时候必须终止 协议模式：隧道模式或传输模式 Path MTU：任何遵从的最大传送单位路径和迟滞变量 SA组合 由于单个SA只能实现AH或ESP中的一种，因此如果需要对曾读物，则需要指定一个SA序列，包括两种方式： 传输邻接：对一个IP包使用多个安全协议，而组合AH与ESP的方法仅允许一级组合（因为传输模式不改变IP头） 隧道迭代：通过隧道模式应用多层安全协议 协议模式 AH和ESP均支持传输模式和隧道模式 传输模式 对上层协议与IP包载荷提供保护 传输模式ESP加载和认证（可选）IP载荷，不包括报头 传输模式AH认证IP载荷和报头的选中部分 传输模式通常用于主机之间的端到端通信 IPsec传输模式 隧道模式 对整个IP包提供保护 整个数据包和安全域被当作一个新的IP载荷，并拥有一个新的外部IP报头 途中经过的路由器不能检查内部IP报头 隧道模式ESP加密和认证（可选）整个内部IP包，包括内部IP报头 隧道模式AH=】认证整个内部IP包和外部IP报头的选中部分 IPsec隧道模式 AH 支持数据完整性与IP包的认证，认证是基于MAC码进行的 AH认证头包括： Next header：标识数据载荷中的封装方式或者协议，8 bits Payload length：有效载荷长度，8 bits Reserved：16 bits SPI：伪随机值，全0代表没有SA，32 bits Seqence Number：计数器，防止重放攻击，32 bits Authentication Data：变长，包含完整性校验值ICV或包的MAC，32*n bits AH认证头 AH处理输入数据包 AH处理输出数据报 处理数据报的过程可能需要加入滑动窗口，以防范重放攻击 反重放攻击 避免攻击者反复发送经过认证的包，这个在发送方由报头中的序列号保证，但是由于IP是无连接的，因此接收方需要使用滑动窗口 窗口的右边界NNN为最大的可接受的序号，窗口大小为WWW 在窗口中且新包，则验证MAC，通过则标记位置 超过右边界且新包，则验证MAC，通过则更新右边界并标记位置 如果在左边界之外、该序列号已被标记或包未通过验证，则丢弃 ICV 完整性校验值，是一种MAC或MAC的截断 规范有： HMAC-MD5-96 HMAC-SHA-1-96 计算MAC的过程中，我们令： 在IP报头中，传输过程中不变的部分和AH SA终点可预测的部分，其他部分全部置零 AH报头不计算认证数据域，其被置零 IPv4报头中的可变部分 协议模式 当服务器提供传输模式认证时，可以直接使用传输模式 反之，工作站向防火墙证明自己身份，可以使用隧道模式 ESP ESP报文头 大部分与AH相同，其中Padding的作用是： 保证明文长度与加密算法要求的一致 保证对齐 隐藏payload的实际长度 假设源报文为IP_head-payload，则： 传输模式：IP_head-ESP_head-payload-ESP_tail-MAC 隧道模式：new_IP_head-ESP_head-IP_head-payload-ESP_tail-MAC 对于数据包的处理也基本和AH相同，不同点在于SA中会指定加密方式及加密参数，需要额外进行加解密的操作 ESP处理输入数据包 ESP处理输出数据报 IKE 即Internet Key Exchange，为IPsec提供了自动协商交换密钥、建立安全关联SA的服务，还可以扩展到其他网络保密协议的安全参数协商过程中 核心技术为DH密钥交换算法，使得IKE具备了完善的前向安全性（指一个密钥被破解，并不影响其他密钥的安全性，这些密钥间没有派生关系） IKE的作用为：IKE不但可自动地为参与通信的实体协商安全关联SA，还可以维护安全关联数据库SADB 降低手工配置复杂度 安全关联SA定时更新 密钥定时更新 允许IPsec提供反重放服务 允许在端与端之间动态认证 报文格式 继承自ISAKMP，因此也称ISAKMP格式，利用UDP的500端口进行传输，每个ISAKMP报文由一个定长的报文头和不定数量的载荷构成 IKE报文格式 报文头包括： Initiator Cookie：发起者Cookie，32 bits Responder Cookie：应答者Cookie，32 bits Next Payload：第一个载荷类型，8 bits MjVer：主版本号，4 bits MnVer：次版本号，4 bits Exchange Type：密钥交换类型，8 bits Flags：属性定义，只定义了最低三位，其余位全0，8 bits [0]：加密位，表示载荷是否加密 [1]：约束位，用于同步密钥交换 [2]：认证位，表示载荷是否有认证 Message ID：标志第二阶段密钥协商对话，由对话发起者生成的随机数，32 bits Total Message Length：报文总长度，32 bits 每一个载荷的载荷头包括： Next Payload：后继载荷类型，最后一个载荷对应0，8 bits Reserverd：保留字，置零，8 bits Payload Length：包括头的载荷长，16 bits 不同类型的载荷为： SA载荷，用来协商安全属性，指明解释域和状态 Proposal载荷，包含在SA载荷中 Transform载荷，总是包含在Proposal载荷内 Key Exchange载荷，传送密钥的各类信息，可为Oakley/DH等所用 Identification身份认证载荷，传送身份信息 Certificate证书认证载荷，传送证书和相关信息 Certificate Request证书请求载荷，向对方要求证书和相关信息 Hash载荷，传送Hash函数的结果 Signature签名载荷，传送数字签名信息 Nonce载荷，传送大随机数，可以防止重放攻击 Notification通知载荷 Delete删除载荷，通知对方删除某个或多个SA Vendor ID供应商载荷，提供了一种扩展手段 体系结构 使用了两个阶段的ISAKMP框架 创建一个通信信道，并进行验证，为IKE SA 主模式：6次交互 快速模式：3次交互 使用第一阶段的IKE SA建立IPsec SA 快速模式：3次交互 第一阶段 建立一个经过验证的安全通道，为后续的协商提供机密性和完整性保护 其中，主模式提供了对通信双方的身份保护，当身份保护不必要的时候，可以使用积极模式减少信息传输，提高效率 IKE第一阶段主模式 消息1/2：双方就散列函数、加密算法、认证方法、IKE SA协商的时间限制等进行了协商 消息3/4：双方采用DH密钥交换算法计算共享密钥，计算方法见下图 消息5/6：双方发送自己的标识信息、IP地址与主机名，并对其DH密钥交换过程中得到的三个密钥进行hash，如果hash结果一样则认证成功 DH密钥交换算法 如果其中一方的IP地址是动态的，或者要求更高的效率，可以采用快速模式 IKE第一阶段快速模式 相当于将主模式重组为：(1, 3) - (2, 4, 6) - (5) 最终建立了IKE SA 第二阶段 基于IKE SA建立IPsec SA，一个IKE SA可以为多个IPsec SA建立服务，一次第二阶段协商可以建立多个安全关联，需要协商的参数有： 加密算法：包括DES、IDEA、Blowfish、3DES、CAST等 哈希算法：包括MD5、SHA、Tiger等 验证方法：包括共享密钥、RSA签名、DSS签名、RSA加密、RSA加密等 DH组 存活周期类型及长度：包括秒、千字节等 密钥长度 工作模式 端到端通常使用传输模式 网关到网关通常使用隧道模式 其他情况可以采用这两种模式的组合，例如端到网关可以采用隧道模式包裹传输模式的方法 工作过程 以守护进程的方式在后台运行，两个守护进程通过500端口的UDP协议来传递消息，其使用SADB和SPDB，和IPsec的工作方式基本相同 当需要应用IPsec但是没有SA的时候，会向IKE守护进程发送创建SA请求，守护进程查SPDB得到参数之后发出请求，开始协商，协商完成则将新SA增加到SADB中，反之由管理员配置SPDB 当需要删除SA的时候，守护进程会从SADB中删除SA，并向远程守护进程发消息，远程守护进程可以： 删除SA 保留SA但是除去该SA的通信权","tags":["笔记","网安","网络层","安全协议"],"categories":["计算机网络安全技术"]},{"title":"信号处理原理 8","path":"/2024/12/10/信号处理原理8/","content":"信号处理原理 笔记 8 Z变换 Z变换是Fourier变换的扩展，将其中的变换核从单位根变换为任意复数，而我们考虑离散时间的情况，对应的公式为： X(ω)=∑n=−∞∞x(n)e−jnω=∑n=−∞∞x(n)(ejω)−nX(z)=Z[x(n)]=∑n=−∞∞x(n)z−n\\begin{align*} X(\\omega) &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}x(n)e^{-jn\\omega} = \\sum\\limits_{n=-\\infty}^{\\infty}x(n)(e^{j\\omega})^{-n} \\\\ X(z) &amp;= \\mathscr{Z}\\bigl[x(n)\\bigr] = \\sum\\limits_{n=-\\infty}^{\\infty}x(n)z^{-n} \\end{align*} X(ω)X(z)​=n=−∞∑∞​x(n)e−jnω=n=−∞∑∞​x(n)(ejω)−n=Z[x(n)]=n=−∞∑∞​x(n)z−n​ 既然涉及到了复变函数，那就一定需要讨论收敛域，我们将所有使X(z)X(z)X(z)收敛的zzz的取值范围称为X(z)X(z)X(z)的收敛域，记为ROC 一些结论： ROC通常是复平面圆环 极点通常为ROC边界 ZT是ROC内的解析函数 特定序列的ROC 有限长序列 x(n)={∈Cn∈[n1,n2]0else\\begin{align*} x(n) = \\begin{cases} \\in \\mathbb{C} &amp; n \\in [n_{1}, n_{2}] \\\\ 0 &amp; \\rm else \\end{cases} \\end{align*} x(n)={∈C0​n∈[n1​,n2​]else​​ 此时收敛域只有可能不包括原点和无穷远点，具体来说： n1&lt;0&lt;n2⇒0&lt;∣z∣&lt;∞n1&lt;n2≤0⇒0≤∣z∣&lt;∞0≤n1&lt;n2⇒0&lt;∣z∣≤∞\\begin{align*} n_{1} &lt; 0 &lt; n_{2}&amp;\\Rightarrow 0 &lt; |z| &lt; \\infty \\\\ n_{1} &lt; n_{2} \\leq 0 &amp;\\Rightarrow 0 \\leq |z| &lt; \\infty \\\\ 0 \\leq n_{1} &lt; n_{2} &amp;\\Rightarrow 0 &lt; |z| \\leq \\infty \\end{align*} n1​&lt;0&lt;n2​n1​&lt;n2​≤00≤n1​&lt;n2​​⇒0&lt;∣z∣&lt;∞⇒0≤∣z∣&lt;∞⇒0&lt;∣z∣≤∞​ 右边序列 x(n)={∈Cn∈[n1,+∞)0else\\begin{align*} x(n) = \\begin{cases} \\in \\mathbb{C} &amp; n \\in [n_{1}, +\\infty) \\\\ 0 &amp; \\rm else \\end{cases} \\end{align*} x(n)={∈C0​n∈[n1​,+∞)else​​ 由lim⁡n→∞∣x(n)z−n∣n&lt;1\\lim\\limits_{n\\to \\infty}\\sqrt[n]{|x(n)z^{-n}|} &lt; 1n→∞lim​n∣x(n)z−n∣​&lt;1，ROC至少为lim⁡n→∞∣x(n)∣n=Rx1&lt;∣z∣&lt;∞\\lim\\limits_{n\\to \\infty}\\sqrt[n]{|x(n)|} = R_{x1} &lt; |z| &lt; \\inftyn→∞lim​n∣x(n)∣​=Rx1​&lt;∣z∣&lt;∞ 如果不满足前置条件，则Z级数不一定收敛，并且Rx1R_{x1}Rx1​可能 不存在 无穷远处的收敛性取决于n1n_{1}n1​正负号，具体来说： n1&lt;0⇒Rx1&lt;∣z∣&lt;∞n1≥0⇒Rx1&lt;∣z∣≤∞\\begin{align*} n_{1} &lt; 0 &amp;\\Rightarrow R_{x1} &lt; |z| &lt; \\infty \\\\ n_{1} \\geq 0 &amp;\\Rightarrow R_{x1} &lt; |z| \\leq \\infty \\end{align*} n1​&lt;0n1​≥0​⇒Rx1​&lt;∣z∣&lt;∞⇒Rx1​&lt;∣z∣≤∞​ 也即模最大的有限极点所在圆周的外侧，不包括圆周 左边序列 x(n)={∈Cn∈(−∞,n2]0else\\begin{align*} x(n) = \\begin{cases} \\in \\mathbb{C} &amp; n \\in (-\\infty, n_{2}] \\\\ 0 &amp; \\rm else \\end{cases} \\end{align*} x(n)={∈C0​n∈(−∞,n2​]else​​ 有lim⁡n→∞∣x(−n)zn∣n&lt;1\\lim\\limits_{n\\to \\infty}\\sqrt[n]{|x(-n)z^{n}|} &lt; 1n→∞lim​n∣x(−n)zn∣​&lt;1，ROC至多为0≤∣z∣&lt;Rx2=(lim⁡n→∞∣x(−n)∣n)−10 \\leq |z| &lt; R_{x2} = (\\lim\\limits_{n\\to \\infty}\\sqrt[n]{|x(-n)|})^{-1}0≤∣z∣&lt;Rx2​=(n→∞lim​n∣x(−n)∣​)−1 无穷远处的收敛性取决于n1n_{1}n1​正负号，具体来说： n2&gt;0⇒0&lt;∣z∣&lt;Rx2n2≤0⇒0≤∣z∣&lt;Rx2\\begin{align*} n_{2} &gt; 0 &amp;\\Rightarrow 0 &lt; |z| &lt; R_{x2} \\\\ n_{2} \\leq 0 &amp;\\Rightarrow 0 \\leq |z| &lt; R_{x2} \\end{align*} n2​&gt;0n2​≤0​⇒0&lt;∣z∣&lt;Rx2​⇒0≤∣z∣&lt;Rx2​​ 也即模最小的非零极点所在圆周的内侧，不包括圆周 双边序列 x(n)x(n)x(n)在整个序列上都有定义，处理方式是将其拆分成左边序列和右边序列的和： X(z)=∑n=0∞x(n)z−n+∑n=−∞−1x(n)z−nX(z) = \\sum\\limits_{n=0}^{\\infty}x(n)z^{-n} + \\sum\\limits_{n=-\\infty}^{-1}x(n)z^{-n} X(z)=n=0∑∞​x(n)z−n+n=−∞∑−1​x(n)z−n 于是双边序列的Z变换存在当且仅当Rx1R_{x1}Rx1​和Rx2R_{x2}Rx2​都存在且Rx1&lt;Rx2R_{x1} &lt; R_{x2}Rx1​&lt;Rx2​，对应的ROC为Rx1&lt;∣z∣&lt;Rx2R_{x1} &lt; |z| &lt; R_{x2}Rx1​&lt;∣z∣&lt;Rx2​ 常见序列ZT 单位冲击序列 Z[δ(n)]=∑n=−∞∞δ(n)z−n=δ(0)=1\\mathscr{Z}[\\delta(n)] = \\sum\\limits_{n=-\\infty}^{\\infty}\\delta(n)z^{-n} = \\delta(0) = 1 Z[δ(n)]=n=−∞∑∞​δ(n)z−n=δ(0)=1 ROC为全复平面 单位阶跃序列 Z[u(n)]=∑n=0∞z−n=11−z−1\\mathscr{Z}[u(n)] = \\sum\\limits_{n=0}^{\\infty}z^{-n} = \\frac{1}{1 - z^{-1}} Z[u(n)]=n=0∑∞​z−n=1−z−11​ ROC为∣z∣&gt;1|z| &gt; 1∣z∣&gt;1 矩形脉冲序列 Z[GN(n)]=∑n=0N−1z−n=1−z−N1−z−1\\mathscr{Z}[G_{N}(n)] = \\sum\\limits_{n=0}^{N - 1}z^{-n} = \\frac{1 - z^{-N}}{1 - z^{-1}} Z[GN​(n)]=n=0∑N−1​z−n=1−z−11−z−N​ ROC为0&lt;∣z∣≤∞0 &lt; |z| \\leq \\infty0&lt;∣z∣≤∞ 单位指数序列 Z[anu(n)]=∑n=0∞anz−n=11−az−1\\mathscr{Z}[a^{n}u(n)] = \\sum\\limits_{n=0}^{\\infty}a^{n}z^{-n} = \\frac{1}{1 - az^{-1}} Z[anu(n)]=n=0∑∞​anz−n=1−az−11​ ROC为∣z∣&gt;∣a∣|z| &gt; |a|∣z∣&gt;∣a∣ 如果没有要求是因果序列，即可能在n&lt;0n &lt; 0n&lt;0的时候也有值，则例如 Z[anu(−n−1)]=∑n=−∞−1(anz−n)={11−az−1∣z∣&lt;∣a∣0z=0\\begin{align*} \\mathscr{Z}[a^{n}u(-n - 1)] &amp;= \\sum\\limits_{n=-\\infty}^{-1}(a^{n}z^{-n}) \\\\ &amp;= \\begin{cases} \\dfrac{1}{1 - az^{-1}} &amp; |z| &lt; |a| \\\\ 0 &amp; z = 0 \\end{cases} \\end{align*} Z[anu(−n−1)]​=n=−∞∑−1​(anz−n)=⎩⎨⎧​1−az−11​0​∣z∣&lt;∣a∣z=0​​ ROC为0≤∣z∣&lt;∣a∣0 \\leq |z| &lt; |a|0≤∣z∣&lt;∣a∣ ZT的性质 线性性 Z[∑k=1Kakxk(n)]=∑k=1KakXk(z)\\mathscr{Z}\\Bigg[\\sum\\limits_{k=1}^{K}a_{k}x_{k}(n)\\Bigg] = \\sum\\limits_{k=1}^{K}a_{k}X_{k}(z) Z[k=1∑K​ak​xk​(n)]=k=1∑K​ak​Xk​(z) 时域平移 Z[x(n+m)]=zmX(z)\\mathscr{Z}\\bigl[x(n + m)\\bigr] = z^{m}X(z) Z[x(n+m)]=zmX(z) 时域扩展 x(a)(n)={x(na)na∈Z0na∉Z\\begin{align*} x_{(a)}(n) = \\begin{cases} x(\\frac{n}{a}) &amp; \\frac{n}{a} \\in Z \\\\ 0 &amp; \\frac{n}{a} otin Z \\end{cases} \\end{align*} x(a)​(n)={x(an​)0​an​∈Zan​∈/Z​​ 其中要求：0≠a∈Z0 eq a \\in Z0=a∈Z 在几何上，这相当于首先根据aaa的符号决定 是否需要反褶，之后插入∣a∣−1|a| - 1∣a∣−1个0 则扩展之后的ZT为： Z[x(a)(n)]=X[za]\\mathscr{Z}\\bigl[x_{(a)}(n)\\bigr] = X[z^{a}] Z[x(a)​(n)]=X[za] ROC变化是等价的，即为：R1&lt;∣za∣&lt;R2R_{1} &lt; |z^{a}| &lt; R_{2}R1​&lt;∣za∣&lt;R2​ 对称性 如果序列是偶对称的，则： X(z)=Z[x(n)]=Z[x(−n)]=∑n=−∞∞x(−n)z−n=∑n=−∞∞x(n)(1z)−n=X(1z)\\begin{align*} X(z) &amp;= \\mathscr{Z}\\bigl[x(n)\\bigr] = \\mathscr{Z}\\bigl[x(-n)\\bigr] \\\\ &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}x(-n)z^{-n} \\\\ &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}x(n)(\\frac{1}{z})^{-n} = X(\\frac{1}{z}) \\end{align*} X(z)​=Z[x(n)]=Z[x(−n)]=n=−∞∑∞​x(−n)z−n=n=−∞∑∞​x(n)(z1​)−n=X(z1​)​ 同理如果序列是奇对称的，那么： X(z)=−X(1z)X(z) = -X(\\frac{1}{z}) X(z)=−X(z1​) 时域共轭 Z[x∗(n)]=X∗(z∗)\\mathscr{Z}\\bigl[x^{*}(n)\\bigr] = X^{*}(z^{*}) Z[x∗(n)]=X∗(z∗) 因此对于实序列，我们有： X(z)=Z[x(n)]=Z[x∗(n)]=X∗(z∗)X(z) = \\mathscr{Z}\\bigl[x(n)\\bigr] = \\mathscr{Z}\\bigl[x^{*}(n)\\bigr] = X^{*}(z^{*}) X(z)=Z[x(n)]=Z[x∗(n)]=X∗(z∗) Z域尺度变换 Z[anx(n)]=X(za)Rx1&lt;∣za∣&lt;Rx2Z[a−nx(n)]=X(az)Rx1&lt;∣az∣&lt;Rx2Z[(−1)nx(n)]=X(−z)Rx1&lt;∣z∣&lt;Rx2Z[ejnω0x(n)]=X(e−jω0z)Rx1&lt;∣z∣&lt;Rx2\\begin{align*} \\mathscr{Z}\\bigl[a^{n}x(n)\\bigr] &amp;= X(\\frac{z}{a}) \\quad R_{x1} &lt; |\\frac{z}{a}| &lt; R_{x2} \\\\ \\mathscr{Z}\\bigl[a^{-n}x(n)\\bigr] &amp;= X(az) \\quad R_{x1} &lt; |az| &lt; R_{x2}\\\\ \\mathscr{Z}\\bigl[(-1)^{n}x(n)\\bigr] &amp;= X(-z) \\quad R_{x1} &lt; |z| &lt; R_{x2}\\\\ \\mathscr{Z}\\bigl[e^{jn\\omega_{0}}x(n)\\bigr] &amp;= X(e^{-j\\omega_{0}}z) \\quad R_{x1} &lt; |z| &lt; R_{x2}\\\\ \\end{align*} Z[anx(n)]Z[a−nx(n)]Z[(−1)nx(n)]Z[ejnω0​x(n)]​=X(az​)Rx1​&lt;∣az​∣&lt;Rx2​=X(az)Rx1​&lt;∣az∣&lt;Rx2​=X(−z)Rx1​&lt;∣z∣&lt;Rx2​=X(e−jω0​z)Rx1​&lt;∣z∣&lt;Rx2​​ Z域微分 Z[nx(n)]=−zddzZ[x(n)]Z[nmx(n)]=[−zddz]mZ[x(n)]\\begin{align*} \\mathscr{Z}\\bigl[nx(n)\\bigr] &amp;= -z\\frac{d}{dz}\\mathscr{Z}\\bigl[x(n)\\bigr] \\\\ \\mathscr{Z}\\bigl[n^{m}x(n)\\bigr] &amp;= \\Bigg[-z\\frac{d}{dz}\\Bigg]^{m}\\mathscr{Z}\\bigl[x(n)\\bigr] \\\\ \\end{align*} Z[nx(n)]Z[nmx(n)]​=−zdzd​Z[x(n)]=[−zdzd​]mZ[x(n)]​ ROC只可能在零或无穷远点处变化 初值定理与终值定理 x(0)=lim⁡z→∞X(z)lim⁡n→∞x(n)=lim⁡z→1(z−1)X(z)\\begin{align*} x(0) &amp;= \\lim\\limits_{z\\to\\infty}X(z) \\\\ \\lim\\limits_{n\\to\\infty} x(n) &amp;= \\lim\\limits_{z\\to 1}(z - 1)X(z) \\end{align*} x(0)n→∞lim​x(n)​=z→∞lim​X(z)=z→1lim​(z−1)X(z)​ 要求极限存在，即： X(z)X(z)X(z)的极点必须在单位圆内，或 极点位于单位圆上，且为一阶极点 卷积定理 Z[x(n)∗y(n)]=Z[x(n)]Z[y(n)]\\mathscr{Z}\\big[x(n) * y(n)\\big] = \\mathscr{Z}\\big[x(n)\\big]\\mathscr{Z}\\big[y(n)\\big] Z[x(n)∗y(n)]=Z[x(n)]Z[y(n)] 其ROC至少为原序列ROC的交集，如果出现零极点相抵则可能会扩大 Parseval ∑n=−∞∞x(n)y∗(n)=12πj∮CX(z)Y∗(1z∗)z−1dz\\sum\\limits_{n = -\\infty}^{\\infty} x(n)y^{*}(n) = \\frac{1}{2\\pi j}\\oint_{C}X(z)Y^{*}(\\frac{1}{z^{*}})z^{-1}dz n=−∞∑∞​x(n)y∗(n)=2πj1​∮C​X(z)Y∗(z∗1​)z−1dz 逆Z变换 仅考虑X(z)X(z)X(z)为只有一阶极点的有理分式 我们将X(z)X(z)X(z)写成N(z)/D(z)N(z) / D(z)N(z)/D(z)的形式，考虑其化简之后的形式，分为两种情况 X(z)=N(z)D(z)=∑k=1MAk1−pkz−1X(z)=N(z)D(z)=A0+∑k=1MAk1−pkz−1X(z)=N(z)D(z)=Q(z)D(z)+R(z)D(z)=Q(z)+R(z)D(z)X(z)=N(z)D(z)=N(z)(1D(z))=N(z)W(z)\\begin{align} X(z) &amp;= \\frac{N(z)}{D(z)} = \\sum\\limits_{k = 1}^{M}\\frac{A_{k}}{1 - p_{k}z^{-1}} \\\\ X(z) &amp;= \\frac{N(z)}{D(z)} = A_{0} + \\sum\\limits_{k = 1}^{M}\\frac{A_{k}}{1 - p_{k}z^{-1}} \\\\ X(z) &amp;= \\frac{N(z)}{D(z)} = \\frac{Q(z)D(z) + R(z)}{D(z)} = Q(z) + \\frac{R(z)}{D(z)} \\\\ X(z) &amp;= \\frac{N(z)}{D(z)} = N(z)(\\frac{1}{D(z)}) = N(z)W(z) \\end{align} X(z)X(z)X(z)X(z)​=D(z)N(z)​=k=1∑M​1−pk​z−1Ak​​=D(z)N(z)​=A0​+k=1∑M​1−pk​z−1Ak​​=D(z)N(z)​=D(z)Q(z)D(z)+R(z)​=Q(z)+D(z)R(z)​=D(z)N(z)​=N(z)(D(z)1​)=N(z)W(z)​​ (1)(2)(1)(2)(1)(2)式中，我们有： A0=[X(z)]∣z=0Ak=[(1−pkz−1)X(z)]∣z=pkD(z)=∏k=1M(1−pkz−1)\\begin{align*} \\quad A_{0} &amp;= [X(z)]|_{z = 0} \\\\ A_{k} &amp;= [(1 - p_{k}z^{-1})X(z)]|_{z = p_{k}}\\\\ D(z) &amp;= \\prod\\limits_{k=1}^{M}(1 - p_{k}z^{-1}) \\end{align*} A0​Ak​D(z)​=[X(z)]∣z=0​=[(1−pk​z−1)X(z)]∣z=pk​​=k=1∏M​(1−pk​z−1)​ 也即AkA_{k}Ak​为所有一阶极点处的留数 (3)(4)(3)(4)(3)(4)式代表分子次数绝对值更高的情况，这种情况可以首先降次再进行处理（转化成(1)(2)(1)(2)(1)(2)的形式），也可以拆成两个多项式的乘积，之后利用ZT的线性性和平移特性求出 所以最终需要求出的是形如(1−pkz−1)−1(1 - p_{k}z^{-1})^{-1}(1−pk​z−1)−1的形式的IIR，而这恰好是单位指数序列的IR： Z[anu(n)]=∑n=0∞anz−n=11−az−1∣z∣&gt;∣a∣Z[anu(−n−1)]=∑n=−∞−1(anz−n)={11−az−1∣z∣&lt;∣a∣0z=0\\begin{align*} \\mathscr{Z}[a^{n}u(n)] &amp;= \\sum\\limits_{n=0}^{\\infty}a^{n}z^{-n} = \\frac{1}{1 - az^{-1}} \\quad |z| &gt; |a|\\\\ \\mathscr{Z}[a^{n}u(-n - 1)] &amp;= \\sum\\limits_{n=-\\infty}^{-1}(a^{n}z^{-n}) = \\begin{cases} \\dfrac{1}{1 - az^{-1}} &amp; |z| &lt; |a| \\\\ 0 &amp; z = 0 \\end{cases} \\end{align*} Z[anu(n)]Z[anu(−n−1)]​=n=0∑∞​anz−n=1−az−11​∣z∣&gt;∣a∣=n=−∞∑−1​(anz−n)=⎩⎨⎧​1−az−11​0​∣z∣&lt;∣a∣z=0​​ 因果序列与稳定性 如果需要我们求出因果序列（n&lt;0n &lt; 0n&lt;0的时候无值），则需要使用第一种形式，即收敛域为∣z∣&gt;∣a∣|z| &gt; |a|∣z∣&gt;∣a∣ 对于一个系统，其是稳定的当且仅当收敛域包含单位圆，这由上一章的BIBO系统保证 因此： 因果系统是稳定的当且仅当其所有极点在单位圆内 反因果系统是稳定的当且仅当其所有极点在单位圆外 逆Z变换与差分方程 在上一章中，我们求出了如下关系式： H(ω)=Y(ω)X(ω)H(\\omega) = \\frac{Y(\\omega)}{X(\\omega)} H(ω)=X(ω)Y(ω)​ 我们将FT泛化为ZT，可以得到： H(z)=Y(z)X(z)H(z) = \\frac{Y(z)}{X(z)} H(z)=X(z)Y(z)​ 将H(z)H(z)H(z)成为LTI系统的传递函数，也称系统函数，其实际上是系统单位冲激响应h(n)h(n)h(n)的Z变换 但是计算h(n)=Z−1H(z)h(n) = \\mathscr{Z}^{-1}{H(z)}h(n)=Z−1H(z)非常复杂，因此我们希望能够想到一种办法，能够直接从H(z)H(z)H(z)求出差分方程 考虑下述的差分方程： ∑k=0Nbky(n−k)=∑r=0Marx(n−r)\\sum\\limits_{k=0}^{N}b_{k}y(n-k) = \\sum\\limits_{r=0}^{M}a_{r}x(n-r) k=0∑N​bk​y(n−k)=r=0∑M​ar​x(n−r) 则我们对两边做ZT，由平移特性可得： Y(z)∑k=0Nbkz−k=X(z)∑r=0Marz−rY(z)\\sum\\limits_{k=0}^{N}b_{k}z^{-k} = X(z)\\sum\\limits_{r=0}^{M}a_{r}z^{-r} Y(z)k=0∑N​bk​z−k=X(z)r=0∑M​ar​z−r 因此 H(z)=Y(z)X(z)=∑r=0Marz−r∑k=0Nbkz−kH(z) = \\frac{Y(z)}{X(z)} = \\frac{\\sum\\limits_{r=0}^{M}a_{r}z^{-r}}{\\sum\\limits_{k=0}^{N}b_{k}z^{-k}} H(z)=X(z)Y(z)​=k=0∑N​bk​z−kr=0∑M​ar​z−r​ 这说明，H(z)\\boldsymbol{H(z)}H(z)有理分式表达式和差分方程可以直接进行转换","tags":["信原","笔记","数学基础"],"categories":["信号处理原理"]},{"title":"运行时存储组织","path":"/2024/12/04/运行时存储组织/","content":"编译原理 笔记 5 运行时存储组织 运行时存储组织的作用与任务是，在代码生成前安排目标机存储资源的使用，主要问题有： 数据表示：如何表示基本类型、指针、数组、结构体、对象等数据 表达式计算：在栈上计算还是在其他地方（一些机器会有运算栈） 存储分配策略 过程（函数）实现 程序运行时存储空间的布局 会根据机器的不同而不同，典型的一种布局为（从高地址开始）： 保留区 栈（地址往低扩展） 堆（地址往高扩展） 共享库和分别编译模块 静态数据区 代码区 保留区 存储分配策略 静态存储分配：在编译期就确定要分配的空间，但是适用范围很小 栈式存储分配：有效实现可动态嵌套的程序结构，我们将运行栈中的数据单元称为活动记录 堆式存储记录：从堆空间为数据对象分配或释放存储，分为显式和隐式两种 活动记录 即栈帧，栈帧基址位于 fp中，栈顶指针位于sp中 典型的过程活动记录 动态链与静态链 对于嵌套定义的函数，例如下面这段： 12345678def P(): x = 1 def Q(): y = 2 def R(): P() R() Q() 我们需要使用动态链和静态链来帮助内层函数访问非局部数据： 动态链：指向调用此函数前最新的栈帧基地址 静态链：指向此函数直接外层函数最新栈帧的基地址，如果是全局函数则指向0 例如在前面的函数中，调用P()之后的栈帧显然是PQRPQR，此时R的DL会指向其caller，也就是其前一个Q，而SL会指向定义R的函数的最新栈帧，在这个例子里面同样是前一个Q Display表 Display表是一个K+1维的数组，其中K是当前嵌套层数，D[i]代表当前函数、直接外层、……、最外层这条嵌套定义链条上每一个函数的栈帧基地址 Display表可以直接存储在栈帧中，这样每次调用或恢复函数的时候只需要从caller或callee的栈帧中读取Display表并作处理即可 但是这会导致栈帧过大，因此我们采用增量法：也即利用每次调用或恢复嵌套函数其实只会影响表中特定一项，在全局记录一个Display表，每次调用函数对表的影响（被移除的表项）记录在callee的栈帧中，恢复时根据callee的嵌套深度对相应的表项进行恢复 动态/静态作用域 动态作用域与静态作用域（很抽象）实际上和实现方式强相关，也即在全局和局部重复出现的重名变量，应该如何处理 考虑这段代码： 1234567891011121314var xfunction show()&#123; console.log(x)&#125;function showSmall()&#123; var x x = 1 show()&#125;function main()&#123; x = 2 show() showSmall()&#125; 如果是静态作用域，也即show函数中x的地址应该为为全局x的地址，也即从show函数开始，在作用域栈中寻找，因此输出的结果应该为： 12 2 但是如果是动态处理，则在showSmall中调用show时，其中的x应该为在showSmall函数中定义的局部变量，也即从这一次调用的show函数开始，在函数调用栈中寻找，也即因此输出的结果应该为： 12 1 在JavaScript V8 13.1.201.9中，这段代码运行的结果为2, 2 静态和动态的定义为： 静态：从函数开始，在作用域栈中寻找 动态：从函数调用开始，在函数调用栈中寻找 函数参数传递 两种方式： call-by-value call-by-reference 如果允许嵌套函数，则会出现将外层函数局部变量作为函数参数的过程，这是一个较为复杂的过程，一种解决方法是在存储函数实参的时候添加SL，如下图： 允许嵌套定义函数时的参数传递","tags":["笔记","编原","语义分析"],"categories":["编译原理"]},{"title":"信号处理原理 7","path":"/2024/12/03/信号处理原理7/","content":"信号处理原理 笔记 7 滤波器 从数学上来说，滤波器其实就是频域上的窗函数，分类为： 高通滤波器(HP) 低通滤波器(LP) 带通滤波器(BP) 带阻滤波器(BS) 全通滤波器(AP) 不同种类滤波器图像 由于滤波器要求是偶函数，因此我们只需要研究 ω∈[0,π]\\omega \\in [0, \\pi]ω∈[0,π] 的情况即可 滤波特性参数 假设滤波器为W(ω)W(\\omega)W(ω)，由于不同种类的滤波器的数学表达式不相同，因此下面讨论低通滤波器的参数特性 通带容限：dp=max⁡ω∈[0,π](W(ω)−1)d_{p} = \\max\\limits_{\\omega\\in [0, \\pi]} (W(\\omega) - 1)dp​=ω∈[0,π]max​(W(ω)−1) 阻带容限：dsd_{s}ds​定义为所有旁瓣的最大值 通带：{ω ∣ abs(W(ω)−1)≤dp}\\{\\omega \\,|\\, \\mathrm{abs}\\big(W(\\omega) - 1\\big) \\leq d_{p} \\}{ω∣abs(W(ω)−1)≤dp​}，其边缘频率定义为ωp\\omega_{p}ωp​ 阻带：{ω ∣ W(ω)≤ds}\\{\\omega \\,|\\, W(\\omega) \\leq d_{s} \\}{ω∣W(ω)≤ds​}，其边缘频率定义为ωs\\omega_{s}ωs​ 过渡带：通带和阻带之外的部分 实际滤波器截止频率：W−1(12)W^{-1}\\big(\\dfrac{1}{\\sqrt{2}}\\big)W−1(2​1​) 理想滤波器截止频率：ωc=W−1(12)\\omega_{c} = W^{-1}\\big(\\dfrac{1}{2}\\big)ωc​=W−1(21​) 低通滤波器特性参数 注意，图中是低通滤波器，其他类型的滤波器图像并不一定这样，例如显然高通滤波器中，ωp&gt;ωs\\omega_{p} &gt; \\omega_{s}ωp​&gt;ωs​ 滤波器的数学表示 差分方程 一个阶段的输出是本阶段输入、上阶段输入、上阶段输出的线性组合 y(n)=1b0[a0x(n)+a1x(n−1)−b1y(n−1)]y(n) = \\frac{1}{b_{0}}\\bigl[a_{0}x(n) + a_{1}x(n-1) - b_{1}y(n-1) \\bigr] y(n)=b0​1​[a0​x(n)+a1​x(n−1)−b1​y(n−1)] 一般形式，扩展为其之前所有状态输入输出的线性组合： ∑k=0Nbky(n−k)=∑r=0Marx(n−r)\\sum\\limits_{k=0}^{N}b_{k}y(n-k) = \\sum\\limits_{r=0}^{M}a_{r}x(n-r) k=0∑N​bk​y(n−k)=r=0∑M​ar​x(n−r) 其中NNN称之为滤波器的阶数 所有符号是约定俗成的，严禁替换 流图 课程中，规范的流图绘制为： 流图规范 流图只有这几个单元，每个单元内部是可替换的，绘制时注意： 箭头 箭头上的文字 每个块的形状 流图绘制示例 对单位冲激响应的解释 在采样一章中，我们提出了一个概念： 以理想低通滤波器（频域矩形脉冲）的单位冲激响应作为内插函数 现在，我们解释一下其中单位冲激响应的含义 在一个系统中，我们将输入称之为激励，将输出称之为响应，因此滤波器的冲激响应是指激励为脉冲信号时的响应，而单位冲激信号为： δ(n)={1n=00n≠0\\begin{align*} \\delta(n) = \\begin{cases} 1 &amp; n = 0 \\\\ 0 &amp; n eq 0 \\end{cases} \\end{align*} δ(n)={10​n=0n=0​​ 当我们需要求滤波器单位冲激响应的时候，我们将差分方程的输入x(n)x(n)x(n)替换为δ(n)\\delta(n)δ(n)即可 课程规定：此时同样需要把y(n)y(n)y(n)替换为h(n)h(n)h(n) 分类 根据每个阶段的输出是否和之前的输出有关，我们将滤波器分为有限脉冲响应（FIR）滤波器和无限脉冲响应（IIR）滤波器 FIR： y(n)=∑k=0Makx(n−k)y(n) = \\sum\\limits_{k=0}^{M}a_{k}x(n-k) y(n)=k=0∑M​ak​x(n−k) IIR： y(n)=∑k=0Makx(n−k)+∑k=1Nbky(n−k)y(n) = \\sum\\limits_{k=0}^{M}a_{k}x(n-k) + \\sum\\limits_{k=1}^{N}b_{k}y(n-k) y(n)=k=0∑M​ak​x(n−k)+k=1∑N​bk​y(n−k) 流图的变换 对于一个IIR，其流图有两种形式，即先递归后递推或先递推后递归，而通常情况下为了更好的内存效率，我们使用先递归后递推的方式，因此我们需要将另一种进行变换，变换方式为： 流图的变换 可以证明，这种变换之后得到的响应是一致的，详细证明见Appendix A 在这样的变化后，中间的Z−1Z^{-1}Z−1块可以共用，因此减少了内存 滤波器与卷积 通常来说，滤波器的输入为一系列脉冲信号，即： x(n)=∑k=−∞∞x(k)δ(n−k)x(n) = \\sum\\limits_{k=-\\infty}^{\\infty}x(k)\\delta(n - k) x(n)=k=−∞∑∞​x(k)δ(n−k) 而我们知道，当输入为单位冲激信号即x(n)=δ(n)x(n) = \\delta(n)x(n)=δ(n)时，得到的响应应该为单位冲激响应h(n)h(n)h(n)，因此由线性可得： y(n)=∑k=−∞∞x(k)h(n−k)=x(n)∗h(n)y(n) = \\sum\\limits_{k=-\\infty}^{\\infty}x(k)h(n - k) = x(n) * h(n) y(n)=k=−∞∑∞​x(k)h(n−k)=x(n)∗h(n) 也即输出就是输入与单位冲激响应的卷积 我们有，这个LTI系统是稳定系统（稳定系统：输入有界 -&gt; 输出有界）当且仅当： ∑n=−∞∞∣h(n)∣=P&lt;∞\\sum\\limits_{n=-\\infty}^{\\infty}|h(n)| = P &lt; \\infty n=−∞∑∞​∣h(n)∣=P&lt;∞ 证明详见Appendix B 如果系统串联，那么等价系统的响应函数做卷积 如果系统并联，那么等价系统的响应函数做加法 系统的频率响应 系统的频率响应即为h(n)h(n)h(n)的DTFT，得到的通常为一个复值函数，即： H(ω)=∑n=−∞∞h(n)e−jnω=∣H(ω)∣ejφ(ω)H(\\omega) = \\sum\\limits_{n=-\\infty}^{\\infty}h(n)e^{-jn\\omega} = |H(\\omega)|e^{j\\varphi(\\omega)} H(ω)=n=−∞∑∞​h(n)e−jnω=∣H(ω)∣ejφ(ω) 根据输出的卷积表达式，我们有： Y(ω)=DTFT(y(n))=DTFT(x(n)∗h(n))=X(ω)H(ω)\\begin{align*} Y(\\omega) &amp;= \\mathrm{DTFT}(y(n)) \\\\ &amp;= \\mathrm{DTFT}(x(n) * h(n)) \\\\ &amp;= X(\\omega)H(\\omega) \\end{align*} Y(ω)​=DTFT(y(n))=DTFT(x(n)∗h(n))=X(ω)H(ω)​ 而根据滤波器的差分方程表达形式： ∑k=0Nbky(n−k)=∑r=0Marx(n−r)\\sum\\limits_{k=0}^{N}b_{k}y(n-k) = \\sum\\limits_{r=0}^{M}a_{r}x(n-r) k=0∑N​bk​y(n−k)=r=0∑M​ar​x(n−r) 我们对这个式子两边求DTFT，根据DTFT在时域上的平移特性，有： Y(ω)∑k=0Nbke−jkω=X(ω)∑r=0Mare−jrωY(\\omega)\\sum\\limits_{k=0}^{N}b_{k}e^{-jk\\omega} = X(\\omega)\\sum\\limits_{r=0}^{M}a_{r}e^{-jr\\omega} Y(ω)k=0∑N​bk​e−jkω=X(ω)r=0∑M​ar​e−jrω 于是得到H(ω)H(\\omega)H(ω)的表达式： H(ω)=Y(ω)X(ω)=∑r=0Mare−jrω∑k=0Nbke−jkωH(\\omega) = \\frac{Y(\\omega)}{X(\\omega)} = \\frac{\\sum\\limits_{r=0}^{M}a_{r}e^{-jr\\omega}}{\\sum\\limits_{k=0}^{N}b_{k}e^{-jk\\omega}} H(ω)=X(ω)Y(ω)​=k=0∑N​bk​e−jkωr=0∑M​ar​e−jrω​ 如果系统串联，那么等价系统的响应函数做乘法 如果系统并联，那么等价系统的响应函数做加法 Appendix Appendix A 原有的表达式为： y(n)=∑r=0Marx(n−r)+∑k=1Nbky(n−k)y(n) = \\sum\\limits_{r=0}^{M}a_{r}x(n - r) + \\sum\\limits_{k=1}^{N}b_{k}y(n - k) y(n)=r=0∑M​ar​x(n−r)+k=1∑N​bk​y(n−k) 变换后的表达式为： z(n)=x(n)+∑k=1Nbkz(n−k)y(n)=∑r=0Marz(n−r)\\begin{align*} z(n) &amp;= x(n) + \\sum\\limits_{k=1}^{N}b_{k}z(n - k) \\\\ y(n) &amp;= \\sum\\limits_{r=0}^{M}a_{r}z(n - r) \\end{align*} z(n)y(n)​=x(n)+k=1∑N​bk​z(n−k)=r=0∑M​ar​z(n−r)​ 因此变换之后： y(n)=∑r=0Marz(n−r)=∑r=0Marx(n−r)+∑r=0M∑k=1Narbkz(n−r−k)=∑r=0Marx(n−r)+∑k=1Nbk∑r=0Marz((n−k)−r)=∑r=0Marx(n−r)+∑k=1Nbky(n−k)\\begin{align*} y(n) &amp;= \\sum\\limits_{r=0}^{M}a_{r}z(n - r) \\\\ &amp;= \\sum\\limits_{r=0}^{M}a_{r}x(n - r) + \\sum\\limits_{r=0}^{M}\\sum\\limits_{k=1}^{N}a_{r}b_{k}z(n-r-k) \\\\ &amp;= \\sum\\limits_{r=0}^{M}a_{r}x(n - r) + \\sum\\limits_{k=1}^{N}b_{k}\\sum\\limits_{r=0}^{M}a_{r}z((n-k)-r) \\\\ &amp;= \\sum\\limits_{r=0}^{M}a_{r}x(n - r) + \\sum\\limits_{k=1}^{N}b_{k}y(n - k) \\end{align*} y(n)​=r=0∑M​ar​z(n−r)=r=0∑M​ar​x(n−r)+r=0∑M​k=1∑N​ar​bk​z(n−r−k)=r=0∑M​ar​x(n−r)+k=1∑N​bk​r=0∑M​ar​z((n−k)−r)=r=0∑M​ar​x(n−r)+k=1∑N​bk​y(n−k)​ 也即是等价的","tags":["信原","笔记","数学基础"],"categories":["信号处理原理"]},{"title":"静态语义分析与中间代码生成","path":"/2024/12/01/静态语义分析/","content":"编译原理 笔记 4 静态语义分析与中间代码生成 静态语义分析 本章可以对应实验中的：namer与typer 静态语义检查指在编译期间所进行的语义检查，包括但不限于： 静态类型检查 符号的作用域分析 控制流检查 唯一性检查 符号的上下文相关性检查 类型检查 验证语言结构是否匹配上下文所期望的类型，实现某个类型系统，分为静态和动态两大类， 类型系统的严格定义较为复杂，在此不做赘述，可以简单理解为C语言等强类型语言中类型定义的部分 我们可以借助翻译模式来设计类型检查程序，将类型表达式作为属性值赋给程序的各个部分（如实验中的Expression基类所拥有的type成员），利用类型系统的给出的形式化定义来设计相应的翻译模式 借助翻译模式描述类型检查算法举例 当然，如果语法上有一些修改，那么相应的翻译模式也需要进行修改，例如如果规定break和continue只能出现在循环体内，则需要添加一个继承属性用来记录当前语句是在在循环内 作用域分析 静态作用域：通过符号表来实现 动态作用域：通过运行时活动记录实现，下一讲会详细介绍 中间代码生成 本章可以对应实验中的：tacgen及其相关部分 中间代码的作用是： 对源语言和目标语言进行语义上的过渡 有利于重定向和机器无关优化 在实验中，一共有AST和TAC两种中间代码，AST由yacc库生成，TAC由tacgen包生成 详细的利用翻译模式重写python的结果参考pdf 对于数组类型，在处理的过程中通常会将其有关的信息记录在一些单元中，称之为数组的内情向量，例如数组的维度、每一维的大小等等 对于布尔表达式，我们可以直接使用bool值进行计算，也可以通过转移到程序中的位置来表示表达式的求值结果 ，也即E = (a &lt; b) or ((c &lt; d) and (e &lt; f))类似： 12345678 if (a &lt; b) goto E.true goto label1label1: if (c &lt; d) goto label2 goto E.falselabel2: if (e &lt; f) goto E.true goto E.false 利用控制流对布尔表达式进行短路翻译 同理，我们可以将tacgen中生成条件语句的代码也写成类似的形式，详细写法参考ppt 拉链与代码回填 显然，上面的翻译模式是L-翻译模式，那如果我们希望使用S-翻译模式甚至S-属性文法是否可以做到呢 我们定义真链与假链，分别代表当布尔表达式为真/假时，需要跳转到的标号，这样我们在处理布尔表达式的时候只需要维护着两条链 S-翻译模式的bool表达式 通过这两条链，我们可以将条件语句、循环语句等写成S-翻译模式，如： S-翻译模式的if条件语句 但是在上述的布尔表达式中，我们可以看出其实生成的goto语句是不完整的，这是因为我们在利用综合属性处理布尔表达式的时候，我们没有办法得知当这个式子为真/假的时候究竟要跳到哪里，也即我们不知道E.true和E.false所代表的具体标号，而这个过程需要通过backpatch(p, i)函数完成，这个函数会将链p中每一条跳转语句的目的标号置为i 我认为，这个通常用于处理布尔表达式用于跳转的情况，例如if(a) &#123;&#125; else &#123;&#125;，但是这个正好是布尔表达式最常用的情况","tags":["笔记","编原","语义分析"],"categories":["编译原理"]},{"title":"信号处理原理 6","path":"/2024/11/19/信号处理原理6/","content":"信号处理原理 笔记 6 离散Fourier变换 DFT DTFT用于将时域上的内容离散化，但得到的结果在频域上仍然是一个连续的函数，仍然是计算机无法存储和计算的值，因此我们需要将其在频域上也进行离散化，得到离散Fourier变换DFT 由于我们有： X(ω)=X(ω+2π)X(\\omega) = X(\\omega + 2\\pi) X(ω)=X(ω+2π) 因此我们取一个Nyquist周期[0,2π][0, 2\\pi][0,2π]，将其划分为NNN份，只保留这些特定点上的频谱： ωk=0+k2πNk=0,1,…,N−1\\omega_{k} = 0 + k\\frac{2\\pi}{N}\\quad k = 0, 1, \\dots, N - 1 ωk​=0+kN2π​k=0,1,…,N−1 得到： X(ωk)=∑n=0L−1x(n)e−jωkn=∑n=0L−1x(n)e−j2πNnkX(\\omega_{k}) = \\sum\\limits_{n=0}^{L-1}x(n)e^{-j\\omega_{k}n} = \\sum\\limits_{n=0}^{L-1}x(n)e^{-j\\frac{2\\pi}{N}nk} X(ωk​)=n=0∑L−1​x(n)e−jωk​n=n=0∑L−1​x(n)e−jN2π​nk 为了将上述公式写成只与kkk有关的形式，我们记WN=exp⁡(−j2πN)W_{N} = \\exp({-j\\frac{2\\pi}{N}})WN​=exp(−jN2π​)，则有： X(k)=∑n=0L−1x(n)WNnkX(k) = \\sum\\limits_{n=0}^{L-1}x(n)W_{N}^{nk} X(k)=n=0∑L−1​x(n)WNnk​ 于是我们可以定义矩阵W∈RN×L\\mathbf{W}\\in \\mathbb{R}^{N\\times L}W∈RN×L，满足Wnk=WNnk\\mathbf{W}_{nk} = W_{N}^{nk}Wnk​=WNnk​，则我们对于时域序列xT=[x(0),…,x(L−1)]\\mathbf{x}^{T} = [x(0), \\dots, x(L-1)]xT=[x(0),…,x(L−1)]与频域序列XT=[X(0),⋯ ,X(N−1)]\\mathbf{X}^{T} = [X(0), \\cdots, X(N - 1)]XT=[X(0),⋯,X(N−1)]，我们有： X=Wx\\mathbf{X} = \\mathbf{W}\\mathbf{x} X=Wx N与L的关系 LLL为在时域上采样的数量，在处理数据的过程中可以认为是常数，NNN是我们主动在频域上采样的数量，通常情况下，我们期待L=NL = NL=N，如果不等，则我们可以做如下变换： L&lt;NL &lt; NL&lt;N：时域序列较短，此时直接在其后方补零即可： xD=[x,0N−L−1]\\mathbf{x}_{D} = [\\mathbf{x}, \\mathbf{0}_{N - L - 1}] xD​=[x,0N−L−1​] 显然这个序列做DFT得到的结果和x\\mathbf{x}x是一致的 L&gt;NL &gt; NL&gt;N：时域序列较长，此时对于时域采样序列做回绕： x~(n)=∑m=0∞x(mN+n)n=0,1,…,N−1\\tilde{x}(n) = \\sum\\limits_{m=0}^{\\infty}x(mN + n)\\quad n = 0, 1, \\dots, N - 1 x~(n)=m=0∑∞​x(mN+n)n=0,1,…,N−1 不容易证明，回绕之后得到的DFT和原序列的DFT是相同的，证明过程见附录 但是这导致，内容完全不同但是回绕相同的序列，其DFT完全相同 因此，我们在处理过程中，一般取N=LN = LN=L IDFT 有了DFT，我们同样也需要构造IDFT，但是这是简单的，因为DFT的本质是矩阵变换，因此我们只需要对矩阵求逆即可，我们直接给出结果： x~(n)=1N∑k=0L−1WN−nkX(k)\\tilde{x}(n) = \\frac{1}{N}\\sum\\limits_{k=0}^{L-1}W_{N}^{-nk}X(k) x~(n)=N1​k=0∑L−1​WN−nk​X(k) 注意到，我们求出的是x~(n)\\tilde{x}(n)x~(n)而并非精确的x(n)x(n)x(n)，这是因为回绕相同的所有序列求出的DFT都是相同的 性质 根据上述讨论，我们在研究性质的过程中，默认L=NL = NL=N 显然性质 DFT是离散的、周期的、线性的 实序列的共轭对称性 如果x(n)x(n)x(n)是实序列，那么有： X(k)=X∗(N−k)X(k) = X^{*}(N - k) X(k)=X∗(N−k) Parsval定理 ∑n=0N−1∣x(n)∣2=1N∑k=0N−1∣X(k)∣2\\sum\\limits_{n=0}^{N-1}|x(n)|^{2} = \\frac{1}{N}\\sum\\limits_{k=0}^{N-1}|X(k)|^{2} n=0∑N−1​∣x(n)∣2=N1​k=0∑N−1​∣X(k)∣2 奇偶性与虚实性 奇/偶函数的DFT是奇/偶函数 实/虚函数的DFT，实部是偶/奇函数，虚部是奇/偶函数，模是偶函数，相位是奇函数 偶函数DFT不改变虚实性，奇函数DFT改变虚实性 反褶与共轭 x(n)⇔X(k)x(−n)⇔X(−k)x∗(n)⇔X∗(−k)\\begin{align*} x(n) &amp;\\Leftrightarrow X(k) \\\\ x(-n) &amp;\\Leftrightarrow X(-k) \\\\ x^{*}(n) &amp;\\Leftrightarrow X^{*}(-k) \\end{align*} x(n)x(−n)x∗(n)​⇔X(k)⇔X(−k)⇔X∗(−k)​ 对称性 DFT[X(n)]=Nx~(−k)\\mathrm{DFT}\\bigl[X(n)\\bigr] = N\\tilde{x}(-k) DFT[X(n)]=Nx~(−k) 频移与时移 DFT[x(n)WN−nl]=X(k−l)DFT[x(n−m)]=WNmkX(k)\\begin{align*} \\mathrm{DFT}\\bigl[x(n)W_{N}^{-nl}\\bigr] &amp;= X(k - l) \\\\ \\mathrm{DFT}\\bigl[x(n - m)\\bigr] &amp;= W_{N}^{mk}X(k) \\end{align*} DFT[x(n)WN−nl​]DFT[x(n−m)]​=X(k−l)=WNmk​X(k)​ 对这两个性质的证明详见Appendix B 卷积特性 离散序列的线卷积定义详见笔记5，圆卷积定义为： x(n)⊗y(n)=∑m=0N−1x(m)y((n−m) mod N)x(n)\\otimes y(n) = \\sum\\limits_{m=0}^{N-1}x(m)y((n - m) \\text{ mod } N) x(n)⊗y(n)=m=0∑N−1​x(m)y((n−m) mod N) 则有： DFT[x(n)∗y(n)]=X(k)⋅Y(k)DFT[x(n)⋅y(n)]=1NX(k)⊗Y(k)IDFT[X(k)⋅Y(k)]=x(n)⊗y(n)\\begin{align*} \\mathrm{DFT}\\bigl[x(n) * y(n)\\bigr] &amp;= X(k)\\cdot Y(k) \\\\ \\mathrm{DFT}\\bigl[x(n)\\cdot y(n)\\bigr] &amp;= \\frac{1}{N}X(k)\\otimes Y(k) \\\\ \\mathrm{IDFT}\\bigl[X(k) \\cdot Y(k)\\bigr] &amp;= x(n) \\otimes y(n) \\end{align*} DFT[x(n)∗y(n)]DFT[x(n)⋅y(n)]IDFT[X(k)⋅Y(k)]​=X(k)⋅Y(k)=N1​X(k)⊗Y(k)=x(n)⊗y(n)​ 需要注意的是，DFT和IDFT并不严格一一对应，这是因为回绕的DFT都相同 DFT的快速算法 按照定义式： X(k)=DFT[x(n)]=∑n=0N−1x(n)WNnkX(k) = \\mathrm{DFT}\\bigl[x(n)\\bigr] = \\sum\\limits_{n=0}^{N-1}x(n)W_{N}^{nk} X(k)=DFT[x(n)]=n=0∑N−1​x(n)WNnk​ 假设我们已经预先计算好了所有的WNnkW_{N}^{nk}WNnk​，则计算X\\mathbf{X}X复杂度为O(N2)O(N^{2})O(N2) 根据定义式，WN=exp⁡(−j2πN)W_{N} = \\exp(-j\\frac{2\\pi}{N})WN​=exp(−jN2π​)，因此我们有以下两条性质： WNnk=WN(nk) mod NWNnk+N2=−WNnk\\begin{align*} W_{N}^{nk} &amp;= W_{N}^{(nk)\\text{ mod }N} \\\\ W_{N}^{nk + \\frac{N}{2}} &amp;= -W_{N}^{nk} \\end{align*} WNnk​WNnk+2N​​​=WN(nk) mod N​=−WNnk​​ 于是采用快速Fouier变换（FFT）的计算过程进行加速，具体过程如下： 假设N=2RN = 2RN=2R为偶数，首先将定义式按照奇偶项拆分开 X(k)=∑r=0R−1x(2r)WN2rk+∑r=0R−1x(2r+1)WN(2r+1)k=∑r=0R−1x(2r)WN2rk+WNk∑r=0R−1x(2r+1)WN2rk\\begin{align*} X(k) &amp;= \\sum\\limits_{r=0}^{R - 1}x(2r)W_{N}^{2rk} + \\sum\\limits_{r=0}^{R - 1}x(2r + 1)W_{N}^{(2r + 1)k} \\\\ &amp;= \\sum\\limits_{r=0}^{R - 1}x(2r)W_{N}^{2rk} + W_{N}^{k}\\sum\\limits_{r=0}^{R - 1}x(2r + 1)W_{N}^{2rk} \\\\ \\end{align*} X(k)​=r=0∑R−1​x(2r)WN2rk​+r=0∑R−1​x(2r+1)WN(2r+1)k​=r=0∑R−1​x(2r)WN2rk​+WNk​r=0∑R−1​x(2r+1)WN2rk​​ 并且我们有： WN2rk=exp⁡(−j2πN2rk)=exp⁡(−j2πRrk)=WRrk\\begin{align*} W_{N}^{2rk} &amp;= \\exp(-j\\frac{2\\pi}{N}2rk) \\\\ &amp;= \\exp(-j\\frac{2\\pi}{R}rk) \\\\ &amp;= W_{R}^{rk} \\end{align*} WN2rk​​=exp(−jN2π​2rk)=exp(−jR2π​rk)=WRrk​​ 可以看出，这和DFT变换矩阵的元素形式是一样的，这说明XkX_{k}Xk​的奇偶项分别对应的一个DFT 于是我们可以记g(r)=x(2r)g(r) = x(2r)g(r)=x(2r)，h(r)=x(2r+1)h(r) = x(2r+1)h(r)=x(2r+1)，有： X(k)=∑r=0R−1x(2r)WN2rk+WNk∑r=0R−1x(2r+1)WN2rk=∑r=0R−1g(r)WRrk+WNk∑r=0R−1h(r)WRrk=DFT[g(r)]+WNkDFT[h(r)]=G(k)+WNkH(k)\\begin{align*} X(k) &amp;= \\sum\\limits_{r=0}^{R - 1}x(2r)W_{N}^{2rk} + W_{N}^{k}\\sum\\limits_{r=0}^{R - 1}x(2r + 1)W_{N}^{2rk} \\\\ &amp;= \\sum\\limits_{r=0}^{R - 1}g(r)W_{R}^{rk} + W_{N}^{k}\\sum\\limits_{r=0}^{R-1}h(r)W_{R}^{rk} \\\\ &amp;= \\mathrm{DFT}\\bigl[g(r)\\bigr] + W_{N}^{k}\\mathrm{DFT}\\bigl[h(r)\\bigr] \\\\ &amp;= G(k) + W_{N}^{k}H(k) \\end{align*} X(k)​=r=0∑R−1​x(2r)WN2rk​+WNk​r=0∑R−1​x(2r+1)WN2rk​=r=0∑R−1​g(r)WRrk​+WNk​r=0∑R−1​h(r)WRrk​=DFT[g(r)]+WNk​DFT[h(r)]=G(k)+WNk​H(k)​ 注意，上式的定义区间是[0,R)[0, R)[0,R)而不是[0,N)[0, N)[0,N)，因为其中使用的变换核的周期（即WWW的下标）是RRR而非NNN，因此应该写作： X(k)=G(k)+WNkH(k)k=0,1,…N2−1X(k) = G(k) + W_{N}^{k}H(k) \\quad k = 0, 1, \\dots \\frac{N}{2} - 1 X(k)=G(k)+WNk​H(k)k=0,1,…2N​−1 后半个序列的计算过程为： X(k+N2)=∑r=0R−1x(2r)WN2r(k+N2)+WNk+N2∑r=0R−1x(2r+1)WN2r(k+N2)=∑r=0R−1g(r)WRrkWNrN+WNk+N2∑r=0R−1h(r)WRrkWNrN=∑r=0R−1g(r)WRrk−WNk∑r=0R−1h(r)WRrk=DFT[g(r)]−WNkDFT[h(r)]=G(k)−WNkH(k)\\begin{align*} X(k + \\frac{N}{2}) &amp;= \\sum\\limits_{r=0}^{R - 1}x(2r)W_{N}^{2r(k + \\frac{N}{2})} + W_{N}^{k + \\frac{N}{2}}\\sum\\limits_{r=0}^{R - 1}x(2r + 1)W_{N}^{2r(k + \\frac{N}{2})} \\\\ &amp;= \\sum\\limits_{r=0}^{R - 1}g(r)W_{R}^{rk}W_{N}^{rN} + W_{N}^{k + \\frac{N}{2}}\\sum\\limits_{r=0}^{R-1}h(r)W_{R}^{rk}W_{N}^{rN} \\\\ &amp;= \\sum\\limits_{r=0}^{R - 1}g(r)W_{R}^{rk} - W_{N}^{k}\\sum\\limits_{r=0}^{R-1}h(r)W_{R}^{rk} \\\\ &amp;= \\mathrm{DFT}\\bigl[g(r)\\bigr] - W_{N}^{k}\\mathrm{DFT}\\bigl[h(r)\\bigr] \\\\ &amp;= G(k) - W_{N}^{k}H(k) \\end{align*} X(k+2N​)​=r=0∑R−1​x(2r)WN2r(k+2N​)​+WNk+2N​​r=0∑R−1​x(2r+1)WN2r(k+2N​)​=r=0∑R−1​g(r)WRrk​WNrN​+WNk+2N​​r=0∑R−1​h(r)WRrk​WNrN​=r=0∑R−1​g(r)WRrk​−WNk​r=0∑R−1​h(r)WRrk​=DFT[g(r)]−WNk​DFT[h(r)]=G(k)−WNk​H(k)​ 这说明我们可以通过G(k)\\boldsymbol{G(k)}G(k)与H(k)\\boldsymbol{H(k)}H(k)计算出全部的X(k)\\boldsymbol{X(k)}X(k)，并且复杂度是O(1)O(1)O(1)的 假设按照FFT计算X\\mathbf{X}X的时间复杂度为T(N)T(N)T(N)，则有： T(N)=2T(N2)+N⋅O(1)=2T(N2)+O(N)T(N) = 2T(\\frac{N}{2}) + N\\cdot O(1) = 2T(\\frac{N}{2}) + O(N) T(N)=2T(2N​)+N⋅O(1)=2T(2N​)+O(N) 因此我们有最终复杂度为T(N)=O(Nlog⁡N)T(N) = O(N\\log N)T(N)=O(NlogN) Appendix Appendix A 对回绕性质的证明 证明：X=X~\\mathbf{X} = \\tilde{\\mathbf{X}}X=X~设L=qN+rL = qN + rL=qN+r，则我们可以将x\\mathbf{x}x对应的变换矩阵WWW按列分为q+1q + 1q+1块，前qqq块为N×NN\\times NN×N，最后一块为N×rN \\times rN×r，同样我们可以这样对应的划分xT=[x0x1⋯xq−1xq]\\mathbf{x}^{T} = \\begin{bmatrix} \\mathbf{x}_{0} &amp; \\mathbf{x}_{1} &amp; \\cdots &amp; \\mathbf{x}_{q-1} &amp; \\mathbf{x}_{q} \\end{bmatrix}xT=[x0​​x1​​⋯​xq−1​​xq​​]，其中xmn=x(mN+n)\\mathbf{x}_{mn} = x(mN + n)xmn​=x(mN+n)，则显然，x~(n)=∑m=0qxmn\\tilde{x}(n) = \\sum\\limits_{m=0}^{q}\\mathbf{x}_{mn}x~(n)=m=0∑q​xmn​，于是有：X=Wx=[W0W1⋯Wq−1Wq][x0x1⋮xq−1xq]=W0[INWNNIN⋯WN(q−1)NINM][x0x1⋮xq−1xq]=W0[ININ⋯INM][x0x1⋮xq−1xq]=W0(∑i=0⌊L/N⌋−1xi+Mxq)=X~\\begin{align*} \\mathbf{X} &amp;= \\mathbf{W}\\mathbf{x} \\\\ &amp;= \\begin{bmatrix} \\mathbf{W}_{0} &amp; \\mathbf{W}_{1} &amp; \\cdots &amp; \\mathbf{W}_{q-1} &amp; \\mathbf{W}_{q} \\end{bmatrix}\\begin{bmatrix} \\mathbf{x}_{0} \\\\ \\mathbf{x}_{1} \\\\ \\vdots \\\\ \\mathbf{x}_{q-1} \\\\ \\mathbf{x}_{q} \\\\ \\end{bmatrix} \\\\ &amp;= \\mathbf{W}_{0}\\begin{bmatrix} \\mathbf{I}_{N} &amp; W_{N}^{N}\\mathbf{I}_{N} &amp; \\cdots &amp; W_{N}^{(q - 1)N}\\mathbf{I}_{N} &amp; \\mathbf{M} \\end{bmatrix}\\begin{bmatrix} \\mathbf{x}_{0} \\\\ \\mathbf{x}_{1} \\\\ \\vdots \\\\ \\mathbf{x}_{q-1} \\\\ \\mathbf{x}_{q} \\\\ \\end{bmatrix} \\\\ &amp;= \\mathbf{W}_{0}\\begin{bmatrix} \\mathbf{I}_{N} &amp; \\mathbf{I}_{N} &amp; \\cdots &amp; \\mathbf{I}_{N} &amp; \\mathbf{M} \\end{bmatrix}\\begin{bmatrix} \\mathbf{x}_{0} \\\\ \\mathbf{x}_{1} \\\\ \\vdots \\\\ \\mathbf{x}_{q-1} \\\\ \\mathbf{x}_{q} \\\\ \\end{bmatrix} \\\\ &amp;= \\mathbf{W}_{0}\\Big(\\sum\\limits_{i = 0}^{\\lfloor L / N\\rfloor - 1}\\mathbf{x}_{i} + \\mathbf{M}\\mathbf{x}_{q}\\Big) \\\\ &amp;= \\tilde{\\mathbf{X}}\\end{align*}X​=Wx=[W0​​W1​​⋯​Wq−1​​Wq​​]​x0​x1​⋮xq−1​xq​​​=W0​[IN​​WNN​IN​​⋯​WN(q−1)N​IN​​M​]​x0​x1​⋮xq−1​xq​​​=W0​[IN​​IN​​⋯​IN​​M​]​x0​x1​⋮xq−1​xq​​​=W0​(i=0∑⌊L/N⌋−1​xi​+Mxq​)=X~​其中，M\\mathbf{M}M是一个N×rN \\times rN×r的矩阵，满足M=[Ir0(N−r−1)×N]\\mathbf{M} = \\begin{bmatrix} \\mathbf{I}_{r} \\\\ \\mathbf{0}_{(N - r - 1)\\times N}\\end{bmatrix}M=[Ir​0(N−r−1)×N​​] Appendix B TODO","tags":["信原","笔记","数学基础"],"categories":["信号处理原理"]},{"title":"语义计算基础","path":"/2024/11/09/语义计算基础/","content":"编译原理 笔记 3 语法制导的语义计算基础 以上下文无关文法为基础，有两种分类： 属性文法：侧重语义计算规则 翻译模式：侧重语义计算过程 属性文法 基于CFG的改进： 为每个文法符号关联多个属性（类的成员） 为每个产生式关联一个语义规则集合（或称为语义动作） 语义动作就是使用当前产生式的时候，需要调用某个函数，或需要对产生式中出现的某个文法符号的某个属性进行赋值 如果产生式A→αA\\to \\alphaA→α关联了语义规则b≔f(c1,…,ck)b\\coloneqq f(c_{1}, \\dots, c_{k})b:=f(c1​,…,ck​) 如果bbb是AAA的属性，则称bbb是AAA的综合属性 如果bbb是B∈αB\\in\\alphaB∈α的属性，则称bbb是BBB的继承属性 基于属性文法的语义计算 计算方法分为两类： 树遍历方法 单遍的方法 基于树遍历方法的语义计算 构造输入串的语法分析树 构造依赖图 如果依赖图无圈，则可以按照该图的任何一种拓扑排序（排序中不改变有向边的关系）计算所有属性值 如果依赖图有圈，则不可以按照这种方法进行计算 依赖图的构造需要遍历两遍分析树，按照如下方法： 123456789101112131415graph = DependencyGraph()for node in tree.internal_nodes: # create nodes for all attributes of this non-terminator graph.create_nodes(node.productions.attributes) # create nodes for those functions instead of an assignment graph.create_nodes(node.productions.functions, virtual==True)for node in tree.internal_nodes: for rule in node.productions: # the vertex on behalf of this production vertex = rule.vertex parameters = rule.rhs.parameters if isinstance(rule, Assignment) else rule.parameters for para in parameters: graph.add_edge(vertex, para.vertex) 在计算完成后，我们可以得到一个完整的、已知每个节点的所有属性值的语法分析树，这棵树被称为带标注的语法分析树 基于单遍方法的语义计算 可以看出，树遍历分析需要遍历两次语法分析树，并且会有非良定义的情况，因此提出另一种基于单遍的方法，分为自下而上和自上而下两种，只适用于特定的两类文法，我们讨论两种： S-属性文法：只包含综合属性 L-属性文法：对于产生式右端的任意符号，其继承属性的计算只依赖于其左边符号的属性，因此如果涉及到产生式左端文法符号，则只能是继承属性 S-属性文法的语义计算 通常采用自下而上的方法进行 如果采用LR分析方法，则多加一个语义栈，存放综合属性的值 由于S-属性文法只包含有综合属性，因此在需要通过产生式来规约的时候，产生式右端的各个符号所包含的，出现在该产生式所关联的语义规则右端的属性值，应当已经计算完成 利用LR分析进行S-属性文法语义计算的例子 L-属性文法的语义计算 采用DFS后序遍历的方法进行，首先遍历每一个产生式右端所需要的参数，计算其值之后再计算左端的值 利用LL分析进行L-属性文法语义计算的例子 基于翻译模式的语义计算 与基于属性文法的语义计算类似，但是允许语义规则集合出现在产生式右端的任何位置，显式地表示动作和属性计算的次序 因此我们需要限制每个属性值在被访问到的时候已经存在： 类S-属性文法：仅包含综合属性的情形，直接将语义规则集合放在产生式右端的末尾即可 类L-属性文法：右端符号的继承属性的计算必须位于该符号之前，并且其只能依赖于产生式左边符号的属性；计算产生式左端非终结符相应的语义规则置于产生式的尾部 翻译模式文法举例 我们只使用单遍的方法 自上而下 处理比较简单，在每一个ParseX函数中，将对应的语义规则集合加入到合适的位置即可，注意此时ParseX函数可能有参数了，参数即为X的继承属性 如果原来文法含有左递归，则需要在消除左递归的同时对翻译模式中的语义规则进行变换，变换方式为： 将： A→A1Y{A.a≔g(A1.a,Y.y)}A→X{A.a≔f(X.x)}\\begin{align*} A &amp;\\to A_{1}Y\\{A.a \\coloneqq g(A_{1}.a, Y.y)\\} \\\\ A &amp;\\to X\\{A.a \\coloneqq f(X.x)\\} \\end{align*} AA​→A1​Y{A.a:=g(A1​.a,Y.y)}→X{A.a:=f(X.x)}​ 变为： A→X{R.i≔f(X.x)}R{A.a≔R.s}R→Y{R1.i≔g(R.i,Y.y)}R1{R.s≔R1.s}R→ε{R.s≔R.i}\\begin{align*} A &amp;\\to X\\{R.i \\coloneqq f(X.x)\\}R\\{A.a \\coloneqq R.s\\} \\\\ R &amp;\\to Y\\{R_{1}.i \\coloneqq g(R.i, Y.y)\\}R_{1}\\{R.s\\coloneqq R_{1}.s\\} \\\\ R &amp;\\to \\varepsilon\\{R.s\\coloneqq R.i\\} \\end{align*} ARR​→X{R.i:=f(X.x)}R{A.a:=R.s}→Y{R1​.i:=g(R.i,Y.y)}R1​{R.s:=R1​.s}→ε{R.s:=R.i}​ 可以理解为，RRR的综合属性R.iR.iR.i用于计算，代替了原文法中A.aA.aA.a的作用，但是由于我们的计算现在是递归进行但是文法没有递归，所以我们需要增加一个继承属性R.sR.sR.s用于从下往上传递信息 详情请参考： sygl233的博客https://sygl233.github.io/2024/11/08/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86-8/ 自下而上 类S-属性文法的计算是相似的，核心是类L-属性文法的自下而上计算（非常复杂，仅做简介） 从翻译模式中去掉嵌在产生式中间的语义规则集： 若规则集合中未关联任何属性，则引入新终结符NNN与N→ε{⋯ }N\\to \\varepsilon\\{\\cdots\\}N→ε{⋯}，后方跟随规则集合 若规则集合中关联了一些属性，则引入新终结符NNN与N→ε{⋯ }N\\to \\varepsilon\\{\\cdots\\}N→ε{⋯}，后方跟随规则集合，并在适当的地方增加复写规则 继承属性的访问：产生式右端的符号串中，靠左符号的综合属性可以替代靠右符号的继承属性 例如A→XYA\\to XYA→XY中，如果关联的语义规则需要用到继承属性Y.iY.iY.i，并且存在复写规则Y.i≔X.sY.i\\coloneqq X.sY.i:=X.s则可以用XXX的综合属性X.sX.sX.s来代替 TODO 详情请参考： sygl233的博客https://sygl233.github.io/2024/11/08/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86-8/ （皂基导致的，可不是我懒噢）","tags":["笔记","编原","语义计算"],"categories":["编译原理"]},{"title":"消息验证","path":"/2024/11/06/消息验证/","content":"计算机网络安全技术 笔记 2 消息验证 在网络中，攻击手段包括： 伪装：攻击者产生非法信息或欺诈应答 内容修改：修改内容 顺序修改：对双方发送消息的顺序进行修改 计时修改：对消息的延时和重放 发送方否认：发送方否认发送过消息 接收方否认：接收方否认接受过消息 消息验证的主要目的是验证收到的消息确实来自真正的发送方并且未被修改，认证的过程通过认证符进行，产生认证符的函数称为认证函数，认证函数可以分为三类： 消息加密：直接加密整个消息 消息认证码MAC：通过MAC函数处理消息，将结果作为认证符 HASH函数：将hash函数当成认证符 主要使用的是Hash 消息加密 对称加密 例如对每个消息附加一个错误检测码，或称之为帧校验序列FCS 利用FCS进行对称加密 实际应用：TCP/IP协议 公钥加密 可以提供保密性，如果需要提供认证（数字签名），则发送方需要首先利用自身的私钥进行加密，再利用接收方的公钥进行加密 消息验证码MAC MAC类似于一个加密函数，但是不要求可逆性，它利用密码生成一个固定长度的短数据块，并将该数据块附加在消息之后 发送方与接收方共享一个密钥K，发送方将消息的MAC附在消息之后，接收方也对消息计算MAC，判断是否被修改 当然我们也可以将携带了MAC的消息进行加密，或者将加密后的消息计算MAC，来达到认证+保密的效果 将同一消息广播给很多接受者 在信息交换中，接受者随机对消息进行认证 对明文形式的计算机程序进行认证 只需要认证而不需要保密：如SNMPv3 需要将认证和保密性分开处理 肉丁土豆 hash码也称为消息摘要(Message Digest, MD) 用于认证的方法 将消息hash之后连接，再用对称密码加密，对称密码用于认证，hash用于保密 将消息hash之后用对称密码加密，再附在消息后，本质上就是一种MAC 将消息hash之后用发送方的私钥加密，再附在消息后，提供了数字签名与认证能力 将消息hash之后用发送方的私钥加密，附在消息后，再使用对称密码加密，提供了签名、认证与保密性 发送方与接收方共享秘密值SSS，将SSS附在消息后再hash，而不直接通信SSS 发送方与接收方共享秘密值SSS，将SSS附在消息后再hash，得到的结果用对称密码加密 hash特点 H:M→HH: \\mathcal{M} \\to \\mathcal{H}H:M→H是满足如下条件的映射： M=Σ∗\\mathcal{M} = \\Sigma^{*}M=Σ∗ H={w ∣ len(w)≡n(const)}\\mathcal{H} = \\{w\\,|\\,\\mathrm{len}(w) \\equiv n\\rm(const)\\}H={w∣len(w)≡n(const)} ∀m∈MH(m)\\forall m \\in \\mathcal{M}\\quad H(m)∀m∈MH(m)是可计算的 ∀h∈HH−1(h)\\forall h \\in \\mathcal{H}\\quad H^{-1}(h)∀h∈HH−1(h)是不可计算的 给定mmm，找到m′≠mm&#x27; eq mm′=m使得H(m)=H(m′)H(m) = H(m&#x27;)H(m)=H(m′)是不可计算的，称为抗弱碰撞 找到任何x≠yx eq yx=y使得H(x)=H(y)H(x) = H(y)H(x)=H(y)是不可计算的，称为抗强碰撞 一般结构 一般迭代地进行计算，给定一个初始值CV0\\mathrm{CV}_{0}CV0​，将输入分为等长的LLL组，最后一组如果长度不足则padding： H(m)=CVLCVi=f(CVi−1,Yi−1)\\begin{align*} H(m) &amp;= \\mathrm{CV}_{L} \\\\ \\mathrm{CV}_{i} &amp;= f(\\mathrm{CV}_{i-1}, Y_{i-1}) \\end{align*} H(m)CVi​​=CVL​=f(CVi−1​,Yi−1​)​ fff称之为压缩函数，本质上我们需要找到合适的fff MD5 一种针对32位，倾向于小端机的算法 输入：任意长度 分组长度：512比特 输出长度：128比特 增加填充位 直接在整个消息之后填充10∗10^{*}10∗，使得填充后消息的长度lll满足：l≡448 mod 512l \\equiv 448 \\text{ mod } 512 l≡448 mod 512 填充长度 设第一步之后的报文长度为lll，则用64位二进制数表示l mod 264l\\text{ mod } 2^{64}l mod 264，并将结果附在最后，得到总长度是512倍数的消息 初始化缓存 初始化用于存储CV\\mathrm{CV}CV的128位缓冲区，使用4个32位寄存器表示，初始值为： 32'h01234567 32'h89abcdef 32'hfedcba98 32'h76543210 迭代计算MD5迭代过程 每次迭代即为：c,d,a←b,c,db←a+((a+gcd(b,c,d)+XK+Ti)&lt;&lt;&lt;3)\\begin{align*} c, d, a &amp;\\leftarrow b, c, d \\\\ b &amp;\\leftarrow a + ((a + gcd(b, c, d) + X_{K} + T_{i}) &lt;&lt;&lt; 3) \\end{align*} c,d,ab​←b,c,d←a+((a+gcd(b,c,d)+XK​+Ti​)&lt;&lt;&lt;3)​ 逻辑函数为： F(b,c,d)=(b⊕c)∨(¬b⊕d)F(b, c, d) = (b\\oplus c)\\vee( eg b \\oplus d)F(b,c,d)=(b⊕c)∨(¬b⊕d) G(b,c,d)=(b⊕d)∨(c⊕¬d)G(b, c, d) = (b\\oplus d)\\vee(c \\oplus eg d)G(b,c,d)=(b⊕d)∨(c⊕¬d) H(b,c,d)=b⊕c⊕dH(b, c, d) = b\\oplus c\\oplus dH(b,c,d)=b⊕c⊕d I(b,c,d)=c⊕(b∨¬d)I(b, c, d) = c\\oplus (b\\vee eg d)I(b,c,d)=c⊕(b∨¬d) 输出 SHA SHA即Secure Hash Algorithm，其基于MD4算法，因此大部分环节和MD算法是类似的 SHA-1输入少于2642^{64}264位，输出为160位，分组长度512位 增加填充位 填充长度 初始化MD缓存 迭代计算，十轮压缩分为两组，每轮执行16迭代20步 输出 SHA压缩函数 RIPEMD-160 RIPEMD-160输入任意长（这里和后面的表冲突了），输出为160位，分组长度512位 增加填充位 填充长度 初始化MD缓存 迭代计算，每轮16步迭代 输出 Hash函数比较 数字签名算法DSS 消息认证可以保证通信双方不收第三方的攻击，但是不能处理通信双方伪造消息或否认发送过消息，这个操作需要使用数字签名来完成，数字签名可以分为直接数字签名和仲裁数字签名 直接数字签名：在加密之前首先利用发送方的私钥对数据或hash进行签名，这样解密后的数据就可以通过发送方的公钥验证签名 仲裁数字签名：发送方将签名之后的消息发送给仲裁者，仲裁者验证签名之后，将消息加上日期与通过验证的标志，再发送给接收方 经典的数字签名标准DSS使用SHA-1算法 DSS算法 其中各个参数的含义为： (p,q,g)(p, q, g)(p,q,g)为全局公钥： ppp是LLL位素数，LLL满足512≤L≤1024512 \\leq L \\leq 1024512≤L≤1024且64 ∣ L64 \\,|\\, L64∣L qqq是160位的素数，并且是p−1p-1p−1的因子 g=(h(p−1)/q) mod pg = (h^{(p-1)/q})\\text{ mod }pg=(h(p−1)/q) mod p，其中hhh满足1&lt;h&lt;p−11 &lt; h &lt; p - 11&lt;h&lt;p−1，且hhh需要使得g&gt;1g &gt; 1g&gt;1 用户私钥xxx：(0,q−1)(0, q - 1)(0,q−1)之间的随机整数 用户公钥yyy：y=gx mod py = g^{x}\\text{ mod }py=gx mod p 签名私钥kkk：(0,q)(0, q)(0,q)之间的随机整数，每次签名随机一次","tags":["笔记","网安","消息验证"],"categories":["计算机网络安全技术"]},{"title":"集群使用问题记录","path":"/2024/11/02/集群使用记录/","content":"集群开发过程中遇到的一些问题的记录 由于科研需求，我需要在一个集群上完成一些实验，这也是本人第一次接触集群与HPC，所以遇到了很多问题，在此作简要记录，以便后期需要 注：集群是aarch64架构 复现WebRL WebRL是一个基于现有模型，为其添加一个RL来实现更好效果的WebAgent，我的工作是复现这篇文章，由于这个仓库并没有在github上开源，因此缺少了很多community的帮助，并且其README写的非常高屋建瓴，如果直接跟随的话会报大错，经过了大概7h的研究，现在能够在这个集群上初始化了 在写这些文字的时候，llama模型的权限还没申请到，因此还不能确保开始train之后没问题鸣鸣鸣别骂我 Update：数据集没开源🤡 服务器登录 用ssh即可，登录没什么要说的，不过服务器是有权限ban掉免密登录操作的，建议在遇到一直无法免密的时候先询问一下负责人 SLURM指令 Slurm基础指令https://blog.csdn.net/lejun_wang1984/article/details/135180652 Slurm详细教程https://wiki.cheng-group.net/ikkem-hpc-manual/slurm/sbatch/ 由于我们一开始登录到集群的时候是到了登录节点，这个节点下是没有卡的，因此查看会显示没卡，我们需要先进入一个计算节点 12srun --pty --gres=gpu:1 bash # 进入交互模式，拿到一张卡nvidia-smi # 或gpustat等命令 注：--gres=gpu:1是旧版语法，表示申请1个gpu计算资源，新版语法写为--gpus=1 环境配置 如果需要使用NVIDIA的显卡，则需要使用对应的编程语言CUDA，CUDA对应的编译器为nvcc(NVIDIA CUDA Compiler)，用于将CUDA程序编译成可以在NVIDIA GPU上运行的代码 可以类比C语言和gcc的关系 在conda环境下安装nvcc非常简单，例如： 1conda install nvidia/label/cuda-12.1.0::cuda-nvcc 这代表会通过nvidia渠道，在当前环境下安装CUDA 12.1.0版本的nvcc编译器。 之后可以根据仓库中的README进行操作，上述步骤基本不会在任何README中出现 有的README中会让我们使用pip install -e .的命令，这条命令的本意就是往当前环境下安装一堆python包，其详细含义是： .代表当前路径，也即会在当前路径下开始搜索，将所有的python包安装到环境中 -e代表采用editable模式，也即不会将路径下的所有包都下载到环境中，而是建立了一个软连接，我的理解是在环境中存了一个引用，这样我们可以直接修改路径下的代码，而不需要反复的pip install 通常采用这个方式的原因是，我们希望将当前的包更够更方便的被使用，避免使用繁杂的路径或跨根目录导入 环境变量 这个任务中，我使用的是LLama-Factory这个库的某个版本来train一个baseline，根据README，我需要使用llamafactory-cli来train，遇到的第一个问题是环境变量问题，报错如下 1ValueError: Please use `FORCE TORCHRUN=1` to launch Deepspeed training 因此按照其指示设置全局变量即可，在sbatch提交的脚本中添加 1export FORCE_TORCHRUN=1 即可 随后遇见一个AssertError，排查（直接看源码）后发现同样是环境变量没设置好，添加： 1export NPROC_PER_NODE=$SLURM_NTASKS_PER_NODE 后面的环境变量由Slurm提供 版本问题 最终我们遇到了版本问题，在解决后发现是torch版本与deepspeed版本不兼容导致的 首先，deepspeed版本过高会导致无法检测到集群中的CUDA，遂降版本0.15.3-&gt;0.13.5 检测不到CUDA会导致其去编译一些xx/deepspeed/ops/csrc/cpu/路径下的文件，但是由于本集群是aarch64架构，因此出现了C++编译失败的问题，可以参考下面这个issue https://github.com/microsoft/DeepSpeed/issues/5640https://github.com/microsoft/DeepSpeed/issues/5640 降版本之后，出现了ImportError，参考下面的issue，简略来说就是把torch旧版本的代码复制过来（异术） https://github.com/microsoft/DeepSpeed/issues/5603https://github.com/microsoft/DeepSpeed/issues/5603","tags":["Slurm","DeepSpeed","CUDA"],"categories":["科研"]},{"title":"DLRM","path":"/2024/11/01/DLRM/","content":"DLRM 总结 DLRM AdaEmbed 提出了In-training pruning system AdaEmbed，动态优化embedding table 应用了VHDI AdaEmbed Overview 具体算法为： AdaEmbed Algorithm 包含了三个主要模块： AdaEmbed Coordinator: 从Agents处收集importance，决定prune strategy，协调prune的执行 Memory Manager：每一个Agent会内置一个，用于管理Embedding table的物理内存 Embedding Monitor：决定importance，向Coordinator通信 同一个table内，每一个embedding row会有一个EI(i)EI(i)EI(i)来决定其重要性，更新方法为： EI(i)=freqt(i)+∣∣∇gt(i)∣∣+EI(i−1)EI(i) = freq_{t}(i) + || abla_{g_{t}}(i)|| + EI(i-1) EI(i)=freqt​(i)+∣∣∇gt​​(i)∣∣+EI(i−1) 并且每TTT次迭代进行一定比例的衰减 不同table之间，首先对每个table的importance，利用这个特征的分布的下95%分位数做归一化，之后将embedding vector dim相同的feature划分成一个group，在group内做prune，每个组结果的embedding table大小由总大小按比例分配得到 决定prune的时机需要判断embedding vectors中importance变化足够剧烈的有多少，但是全部判断overhead太大，因此在每一个agent中sample一小部分出来判断，并据此估计全局 为了避免过多的内存开销，引入VHDI（感觉很像页表） VHDI Overview 重分配一个embedding的时候直接zero-initialization FIITED 基于以下观察： 不同特征之间的重要性不同 每个特征对应嵌入表中，行的重要性不同 每一个嵌入向量的维度重要性不同 重要性会随着时间发生改变 FIIT Overview 将嵌入表中的每一个嵌入向量分成了多个chunk，嵌入表的store与prune是基于chunk进行的，减少了内存使用 FIIT Overview 当一个prune了的chunk需要重新keep的时候，其值会被重新初始化 在做训练的过程中，对于不等长的embedding vector，采用zero-padding的方式 每次迭代的过程中，更新chunk utility value的方法是： u(i+1)=γu(i)+a(i)g(i)u(i + 1) = \\gamma u(i) + a(i)g(i) u(i+1)=γu(i)+a(i)g(i) 其中a(i)a(i)a(i)是访问次数，g(i)g(i)g(i)是梯度的2-范数 chunk的pruning ratio可以指定也可以训 同时也可以prune某一些dimension，相当于将不同embedding tables的同一个维度当成一个样本，决定其importance并决定是否prune 如果直接实现这个算法，会导致有大量的内存碎块，因此使用AdmEmbed中提出的VHDI算法，并添加一个chunk manager FIIT with VHDI 优化了四个方面的开销： hash表查找 Embedding table查找 更新每一个chunk的utility value Prune 方法是： 并行计算每一个chunk的utility value与并行prune 将前一个batch的utility value update放在后一个batch的forward过程中并行完成 采用pre-fetching技术优化两次查表"},{"title":"信号处理原理 5","path":"/2024/10/29/信号处理原理5/","content":"信号处理原理 笔记 5 离散时间信号的Fourier变换 DTFT 离散时间傅里叶变换 由于真实信号一般没有解析表达式，因此需要通过抽样值来计算出理想抽样信号的频谱密度函数： F(ω)=TF^(ω)=T∑n=−∞∞f(nT)e−jnωT,ω∈[−ωs2,ωs2]F(\\omega) = T\\hat{F}(\\omega) = T\\sum\\limits_{n=-\\infty}^{\\infty}f(nT)e^{-jn\\omega T} ,\\quad \\omega\\in[-\\frac{\\omega_{s}}{2}, \\frac{\\omega_{s}}{2}]F(ω)=TF^(ω)=Tn=−∞∑∞​f(nT)e−jnωT,ω∈[−2ωs​​,2ωs​​] 上式在满足奈奎斯特采样定理的时候严格成立，如果不满足则会导致混叠现象的发生，此时第一个等于号改为≈\\approx≈ 从中可以看出，f(nT)f(nT)f(nT)实际上是F^(ω)\\hat{F}(\\omega)F^(ω)的FS系数，因此有： f(nT)=1ωs∫−ωs/2ωs/2F^(ω)ejnωTdωf(nT) = \\frac{1}{\\omega_{s}}\\int_{-\\omega_{s}/2}^{\\omega_{s}/2} \\hat{F}(\\omega)e^{jn\\omega T}d\\omega f(nT)=ωs​1​∫−ωs​/2ωs​/2​F^(ω)ejnωTdω 注意指数上的符号 频率归一化 为了方便，将采样频率归一，也即将f(nT)f(nT)f(nT)中的TTT在数学上化简为1，将频率归一化的离散信号称为数字信号，将数字信号DTFT归一化频谱为数字频谱 在归一化之后，采样频率为ωs=2πT=2π\\omega_{s} = \\frac{2\\pi}{T} = 2\\piωs​=T2π​=2π 代入公式有： X(ω)=DTFT[x(n)]=∑n=−∞∞x(n)e−jnωx(n)=12π∫−ππX(ω)ejnωdω\\begin{align*} X(\\omega) = \\mathrm{DTFT}[x(n)] = \\sum\\limits_{n=-\\infty}^{\\infty}x(n)e^{-jn\\omega} \\\\ x(n) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi}X(\\omega)e^{jn\\omega}d\\omega \\end{align*} X(ω)=DTFT[x(n)]=n=−∞∑∞​x(n)e−jnωx(n)=2π1​∫−ππ​X(ω)ejnωdω​ 我们将抽样时的真实频率（又称为模拟频率）记为Ω\\OmegaΩ，引入归一化时间之后的数字频率为ω\\omegaω，则： 模拟频率的Nyquist区间为：[−Ωs2,Ωs2][-\\dfrac{\\Omega_{s}}{2}, \\dfrac{\\Omega_{s}}{2}][−2Ωs​​,2Ωs​​] 数字频率的Nyquist区间为[−π,π][-\\pi, \\pi][−π,π] 二者的关系为ω=ΩTs\\omega = \\Omega T_{s}ω=ΩTs​ 性质 周期性 X(ω)=X(ω+2π)X(\\omega) = X(\\omega + 2\\pi) X(ω)=X(ω+2π) 证明是显然的 线性 DTFT(∑kakxk)=∑kakDTFT(xk)\\mathrm{DTFT}(\\sum\\limits_{k} a_{k}x_{k}) = \\sum\\limits_{k} a_{k}\\mathrm{DTFT}(x_{k}) DTFT(k∑​ak​xk​)=k∑​ak​DTFT(xk​) 原因是DTFT本质上其实是一种特殊频率的采样 平移特性 DTFT[x(n−n0)]=e−jωn0X(ω)DTFT[ejω0nx(n)]=X(ω−ω0)\\begin{align*} \\mathrm{DTFT}[x(n-n_{0})] &amp;= e^{-j\\omega n_{0}}X(\\omega) \\\\ \\mathrm{DTFT}[e^{j\\omega_{0} n}x(n)] &amp;= X(\\omega - \\omega_{0}) \\end{align*} DTFT[x(n−n0​)]DTFT[ejω0​nx(n)]​=e−jωn0​X(ω)=X(ω−ω0​)​ 证明和FT的证明是类似的 反褶与共轭 DTFT[x(−n)]=X(−ω)DTFT[x∗(n)]=X∗(−ω)\\begin{align*} \\mathrm{DTFT}[x(-n)] &amp;= X(-\\omega) \\\\ \\mathrm{DTFT}[x^{*}(n)] &amp;= X^{*}(-\\omega) \\end{align*} DTFT[x(−n)]DTFT[x∗(n)]​=X(−ω)=X∗(−ω)​ 证明和FT的证明是类似的 频域与时域变化 DTFT[nxn]=j[ddωX(ω)]DTFT[xa(n)]=X(aω)\\begin{align*} \\mathrm{DTFT}[nx_{n}] &amp;= j\\bigl[\\frac{d}{d\\omega}X(\\omega)\\bigr] \\\\ \\mathrm{DTFT}[x_{a}(n)] &amp;= X(a\\omega) \\end{align*} DTFT[nxn​]DTFT[xa​(n)]​=j[dωd​X(ω)]=X(aω)​ 上式中，由于xnx_{n}xn​的定义域为Z\\mathbb{Z}Z，所以我们定义其压缩后的结果为： xa(n)={x(na)na∈Z0na∉Z\\begin{align*} x_{a}(n) = \\begin{cases} x(\\frac{n}{a}) &amp; \\frac{n}{a} \\in \\mathbb{Z} \\\\ 0 &amp; \\frac{n}{a} otin \\mathbb{Z} \\end{cases} \\end{align*} xa​(n)={x(an​)0​an​∈Zan​∈/Z​​ 卷积定理 首先我们需要定义两种新的卷积形式： 离散序列线卷积： x1(n)∗x2(n)=∑k=−∞∞x1(n−k)x2(k)x_{1}(n) * x_{2}(n) = \\sum\\limits_{k=-\\infty}^{\\infty}x_{1}(n-k)x_{2}(k) x1​(n)∗x2​(n)=k=−∞∑∞​x1​(n−k)x2​(k) 连续序列圆卷积： X1(ω)⊗X2(ω)=∫−ππX1(ω′)X2(ω−ω′)dω′X_{1}(\\omega) \\otimes X_{2}(\\omega) = \\int_{-\\pi}^{\\pi}X_{1}(\\omega&#x27;)X_{2}(\\omega - \\omega&#x27;)d\\omega&#x27; X1​(ω)⊗X2​(ω)=∫−ππ​X1​(ω′)X2​(ω−ω′)dω′ 于是： DTFT[x1(n)∗x2(n)]=X1(ω)⋅X2(ω)DTFT[x1(n)⋅x2(n)]=12πX1(ω)⊗X2(ω)\\begin{align*} \\mathrm{DTFT}[x_{1}(n) * x_{2}(n)] &amp;= X_{1}(\\omega)\\cdot X_{2}(\\omega) \\\\ \\mathrm{DTFT}[x_{1}(n) \\cdot x_{2}(n)] &amp;= \\frac{1}{2\\pi}X_{1}(\\omega) \\otimes X_{2}(\\omega) \\\\ \\end{align*} DTFT[x1​(n)∗x2​(n)]DTFT[x1​(n)⋅x2​(n)]​=X1​(ω)⋅X2​(ω)=2π1​X1​(ω)⊗X2​(ω)​ 注意乘法的DTFT\\mathrm{DTFT}DTFT公式右边的12π\\frac{1}{2\\pi}2π1​ Parseval能量定理 ∑n=−∞∞∣x(n)∣2=12π∫−ππ∣X(ω)∣2dω\\sum\\limits_{n=-\\infty}^{\\infty}|x(n)|^{2} = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}|X(\\omega)|^{2}d\\omega n=−∞∑∞​∣x(n)∣2=2π1​∫−ππ​∣X(ω)∣2dω 有限长DTFT 现实中无法获得无限长的时域频谱，于是我们需要一个窗函数进行截取 w(n)={10≤n≤L−10else\\begin{align*} w(n) = \\begin{cases} 1 &amp; 0 \\leq n \\leq L - 1 \\\\ 0 &amp; \\rm else \\end{cases} \\end{align*} w(n)={10​0≤n≤L−1else​​ 截取后的信号为： xL(n)=x(n)w(n)={x(n)0≤n≤L−10else\\begin{align*} x_{L}(n) = x(n)w(n) = \\begin{cases} x(n) &amp; 0\\leq n \\leq L - 1 \\\\ 0 &amp; \\rm else \\end{cases} \\end{align*} xL​(n)=x(n)w(n)={x(n)0​0≤n≤L−1else​​ 对应的频谱变为： XL(ω)=∑n=−∞∞xL(n)e−jωn=∑n=0L−1x(n)e−jωnX_{L}(\\omega) = \\sum\\limits_{n=-\\infty}^{\\infty}x_{L}(n)e^{-j\\omega n} = \\sum\\limits_{n=0}^{L - 1}x(n)e^{-j\\omega n} XL​(ω)=n=−∞∑∞​xL​(n)e−jωn=n=0∑L−1​x(n)e−jωn 另一种理解是，我们利用DTFT的卷积特性来理解 XL(ω)=DTFT[x(n)w(n)]=12πX(ω)⊗W(ω)=12π∫−ππX(ω′)W(ω−ω′)dω′\\begin{align*} X_{L}(\\omega) &amp;= \\mathrm{DTFT}[x(n)w(n)] \\\\ &amp;= \\frac{1}{2\\pi}X(\\omega)\\otimes W(\\omega) \\\\ &amp;= \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}X(\\omega&#x27;)W(\\omega - \\omega&#x27;)d\\omega&#x27; \\end{align*} XL​(ω)​=DTFT[x(n)w(n)]=2π1​X(ω)⊗W(ω)=2π1​∫−ππ​X(ω′)W(ω−ω′)dω′​ 于是乎我们需要首先来求窗函数的频谱： W(ω)=DTFT[w(n)]=∑n=−∞∞w(n)e−jnω=∑n=0L−1e−jnω=1−e−jLω1−e−jω=1−cos⁡(Lω)+jsin⁡(Lω)1−cos⁡(jω)+jsin⁡(jω)=2sin⁡2(Lω2)+2jsin⁡(Lω2)cos⁡Lω22sin⁡2(ω2)+2jsin⁡(ω2)cos⁡ω2=sin⁡(Lω2)sin⁡(ω2)⋅cos⁡(Lω2)−jsin⁡(Lω)cos⁡(ω2)−jsin⁡(ω)=sin⁡(Lω2)sin⁡(ω2)e−j(L−1)ω2\\begin{align*} W(\\omega) &amp;= \\mathrm{DTFT}[w(n)] \\\\ &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}w(n)e^{-jn\\omega} \\\\ &amp;= \\sum\\limits_{n=0}^{L-1}e^{-jn\\omega} \\\\ &amp;= \\frac{1 - e^{-jL\\omega}}{1 - e^{-j\\omega}} \\\\ &amp;= \\frac{1 - \\cos(L\\omega) + j\\sin(L\\omega)}{1 - \\cos(j\\omega) + j\\sin(j\\omega)} \\\\ &amp;= \\frac{2\\sin^{2}(\\frac{L\\omega}{2}) + 2j\\sin(\\frac{L\\omega}{2})\\cos{\\frac{L\\omega}{2}}}{2\\sin^{2}(\\frac{\\omega}{2}) + 2j\\sin(\\frac{\\omega}{2})\\cos{\\frac{\\omega}{2}}} \\\\ &amp;= \\frac{\\sin(\\frac{L\\omega}{2})}{\\sin(\\frac{\\omega}{2})}\\cdot \\frac{\\cos(\\frac{L\\omega}{2}) - j\\sin(L\\omega)}{\\cos(\\frac{\\omega}{2}) - j\\sin(\\omega)} \\\\ &amp;= \\frac{\\sin(\\frac{L\\omega}{2})}{\\sin(\\frac{\\omega}{2})} e^{-\\frac{j(L-1)\\omega}{2}} \\end{align*} W(ω)​=DTFT[w(n)]=n=−∞∑∞​w(n)e−jnω=n=0∑L−1​e−jnω=1−e−jω1−e−jLω​=1−cos(jω)+jsin(jω)1−cos(Lω)+jsin(Lω)​=2sin2(2ω​)+2jsin(2ω​)cos2ω​2sin2(2Lω​)+2jsin(2Lω​)cos2Lω​​=sin(2ω​)sin(2Lω​)​⋅cos(2ω​)−jsin(ω)cos(2Lω​)−jsin(Lω)​=sin(2ω​)sin(2Lω​)​e−2j(L−1)ω​​ 我们来分析窗函数的幅度频谱函数∣W(ω)∣=sin⁡(Lω2)sin⁡(ω2)x∈(−π,π)|W(\\omega)| = \\dfrac{\\sin(\\frac{L\\omega}{2})}{\\sin(\\frac{\\omega}{2})}\\quad x\\in(-\\pi, \\pi)∣W(ω)∣=sin(2ω​)sin(2Lω​)​x∈(−π,π) 窗函数的幅度频谱函数的图像 如上图所示，在(−π,π)(-\\pi, \\pi)(−π,π)内，窗函数的频谱会有2⌊L2⌋2\\lfloor\\dfrac{L}{2}\\rfloor2⌊2L​⌋个零点，其中频谱强度最大的为原点，我们定义主瓣宽度为： ΔωW=2πL\\Delta \\omega_{W} = \\frac{2\\pi}{L} ΔωW​=L2π​ 可以看到，绝对值为主瓣内的频谱占据了所有频谱的绝大部分能量，而旁瓣，也即频率绝对值在(2πL,π)(\\dfrac{2\\pi}{L}, \\pi)(L2π​,π)之间的部分其实相当于能量的损耗，也即出现了频率泄露 分辨率问题 我们考虑下面这个例子： x(n)=A1ejω1n+A2ejω2nx(n) = A_{1}e^{j\\omega_{1}n} + A_{2}e^{j\\omega_{2}n} x(n)=A1​ejω1​n+A2​ejω2​n 很明显其频谱为： X(ω)=A1δ(ω−ω1)+A2δ(ω−ω2)X(\\omega) = A_{1}\\delta(\\omega - \\omega_{1}) + A_{2}\\delta(\\omega - \\omega_{2}) X(ω)=A1​δ(ω−ω1​)+A2​δ(ω−ω2​) 画出图像可以看出，只要ω1≠ω2\\omega_{1} eq \\omega_{2}ω1​=ω2​，这两个冲激函数就不会重叠，因此其实他的分辨率是无限高的 但是我们加窗之后有： xL(n)=A1ejω1n+A2ejω2nn=0,1,…L−1x_{L}(n) = A_{1}e^{j\\omega_{1}n} + A_{2}e^{j\\omega_{2}n} \\quad n = 0, 1, \\dots L-1 xL​(n)=A1​ejω1​n+A2​ejω2​nn=0,1,…L−1 频谱为： XL(ω)=A1W(ω−ω1)+A2W(ω−ω2)X_{L}(\\omega) = A_{1}W(\\omega - \\omega_{1}) + A_{2}W(\\omega - \\omega_{2}) XL​(ω)=A1​W(ω−ω1​)+A2​W(ω−ω2​) 加窗后的频谱函数 也即Δω\\Delta \\omegaΔω越小，分辨的难度越大，我们定义不可分辨的范围是二者的零点进入了对方的主瓣内，也即可以分辨的范围是： Δω≥ΔωW=2πL\\Delta\\omega \\geq \\Delta\\omega_{W} = \\frac{2\\pi}{L} Δω≥ΔωW​=L2π​ 因此在这个例子中，如果希望能清晰分辨，窗的宽度应该满足L≥2π/ΔωL \\geq 2\\pi/\\Delta\\omegaL≥2π/Δω 针对DTFT一题作业的思考 作业原题如下： 已知x(n)x(n)x(n)的DTFT为X(ω)X(\\omega)X(ω)，试求x(2n+1)x(2n+1)x(2n+1)的DTFT 常规做法为： 注意到：X(ω)=∑n=−∞∞x(n)e−jnωX(ω+π)=∑n=−∞∞x(n)e−jn(ω+π)=∑n=−∞∞x(n)e−jnωe−jnπ=∑n=−∞∞(−1)nx(n)e−jnω\\begin{align*} X(\\omega) &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}x(n)e^{-j n\\omega} \\\\ X(\\omega + \\pi) &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}x(n)e^{-j n(\\omega + \\pi)} \\\\ &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}x(n)e^{-j n\\omega}e^{-j n \\pi} \\\\ &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}(-1)^{n}x(n)e^{-j n\\omega}\\end{align*}X(ω)X(ω+π)​=n=−∞∑∞​x(n)e−jnω=n=−∞∑∞​x(n)e−jn(ω+π)=n=−∞∑∞​x(n)e−jnωe−jnπ=n=−∞∑∞​(−1)nx(n)e−jnω​因此我们有：DTFT[x(2n+1)]=∑n=−∞∞x(2n+1)e−jnω=ejω2∑n=−∞∞x(2n+1)e−j(2n+1)ω2=ejω2X(ω/2)−X((ω/2)+π)2\\begin{align*} \\mathrm{DTFT}[x(2n+1)] &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}x(2n+1)e^{-jn\\omega} \\\\ &amp;= e^{j\\frac{\\omega}{2}}\\sum\\limits_{n=-\\infty}^{\\infty}x(2n+1)e^{-j (2n + 1)\\frac{\\omega}{2}} \\\\ &amp;= e^{j\\frac{\\omega}{2}}\\frac{X(\\omega/2) - X((\\omega / 2) + \\pi)}{2}\\end{align*}DTFT[x(2n+1)]​=n=−∞∑∞​x(2n+1)e−jnω=ej2ω​n=−∞∑∞​x(2n+1)e−j(2n+1)2ω​=ej2ω​2X(ω/2)−X((ω/2)+π)​​ 这题让我们不禁开始思考，我们能否求出采样频率经过任意线性变换之后得到的新信号x(an+b)x(an+b)x(an+b)，其中a,b∈Za, b \\in \\mathbb{Z}a,b∈Z，其DTFT与之前的之间有什么关系呢 注意到，我们在上述过程，即a=2a = 2a=2时，利用了X(ω+0)X(\\omega + 0)X(ω+0)与X(ω+π)X(\\omega + \\pi)X(ω+π)两个频谱函数进行叠加，而000和π\\piπ恰好是z(c)=ej⋅(2c)−1z(c) = e^{j\\cdot(2c)} - 1z(c)=ej⋅(2c)−1的两个零点！ 记： ck=2kπaλk=ejckk=0,1,…,a−1\\begin{align*} c_{k} &amp;= \\frac{2k\\pi}{a} \\\\ \\lambda_{k} &amp;= e^{jc_{k}} \\\\ k &amp;= 0, 1, \\dots, a - 1 \\end{align*} ck​λk​k​=a2kπ​=ejck​=0,1,…,a−1​ 则λk\\lambda_{k}λk​为aaa次单位根 此时有： Xk(ω)=X(ω−ck)=∑n=−∞∞x(n)e−jn(ω−ck)=∑n=−∞∞λknx(n)e−jnω\\begin{align*} X_{k}(\\omega) &amp;= X(\\omega - c_{k}) \\\\ &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}x(n)e^{-j n(\\omega - c_{k})} \\\\ &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}\\lambda_{k}^{n}x(n)e^{-jn\\omega} \\end{align*} Xk​(ω)​=X(ω−ck​)=n=−∞∑∞​x(n)e−jn(ω−ck​)=n=−∞∑∞​λkn​x(n)e−jnω​ 我们知道对于MMM次单位根与任意非负整数rrr，存在： ∑m=0M−1(λr)m={1−λrM1−λr=0r&gt;0Mr=0\\begin{align*} \\sum\\limits_{m=0}^{M-1}(\\lambda^{r})^{m} &amp;= \\begin{cases}\\frac{1 - \\lambda^{rM}}{1 - \\lambda^{r}} = 0 &amp; r &gt; 0 \\\\ M &amp; r = 0 \\end{cases} \\end{align*} m=0∑M−1​(λr)m​={1−λr1−λrM​=0M​r&gt;0r=0​​ 记n=qa+rn = qa + rn=qa+r，则Xk(ω)X_{k}(\\omega)Xk​(ω)可变化为： Xk(ωa)=∑n=−∞∞λk(qa+r)x(n)e−j(qa+r)ωa=λkr∑n=−∞∞x(n)e−jqω+rωa\\begin{align*} X_{k}(\\frac{\\omega}{a}) &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}\\lambda_{k}^{(qa + r)}x(n)e^{-j(qa + r)\\frac{\\omega}{a}} \\\\ &amp;= \\lambda_{k}^{r}\\sum\\limits_{n=-\\infty}^{\\infty}x(n)e^{-jq\\omega + \\frac{r\\omega}{a}} \\end{align*} Xk​(aω​)​=n=−∞∑∞​λk(qa+r)​x(n)e−j(qa+r)aω​=λkr​n=−∞∑∞​x(n)e−jqω+arω​​ 于是乎，我们有： ∑k=0a−1Xk(ωa)=∑n=−∞∞((∑k=0a−1λkr)x(n)e−jqω−jrωa)=a∑q=−∞∞x(qa)e−jqω=aDTFT[x(an)]\\begin{align*} \\sum\\limits_{k=0}^{a-1}X_{k}(\\frac{\\omega}{a}) &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}\\bigg(\\Big(\\sum\\limits_{k=0}^{a-1}\\lambda_{k}^{r}\\Big)x(n)e^{-jq\\omega - \\frac{jr\\omega}{a}}\\bigg) \\\\ &amp;= a\\sum\\limits_{q=-\\infty}^{\\infty}x(qa)e^{-jq\\omega} \\\\ &amp;= a\\mathrm{DTFT}[x(an)] \\end{align*} k=0∑a−1​Xk​(aω​)​=n=−∞∑∞​((k=0∑a−1​λkr​)x(n)e−jqω−ajrω​)=aq=−∞∑∞​x(qa)e−jqω=aDTFT[x(an)]​ 我们便得到了DTFT[x(an)]\\mathrm{DTFT}[x(an)]DTFT[x(an)]的表达式 DTFT[x(an)]=1a∑k=0a−1X(ω−2kπa)\\begin{align*} \\mathrm{DTFT}[x(an)] &amp;= \\frac{1}{a}\\sum\\limits_{k=0}^{a-1}X(\\frac{\\omega - 2k\\pi}{a} ) \\\\ \\end{align*} DTFT[x(an)]​=a1​k=0∑a−1​X(aω−2kπ​)​ 那怎么对应的求出DTFT[x(an+b)]\\mathrm{DTFT}[x(an + b)]DTFT[x(an+b)]的表达式呢，显然不能直接套用时移的公式，因为我们不能保证a ∣ ba \\,|\\, ba∣b，我们观察上述推导过程中将Xk(ωa)X_{k}(\\frac{\\omega}{a})Xk​(aω​)求和的一步，这一步通过单位根等比求和筛选出了所有满足a ∣ na \\,|\\, na∣n的n，而我们现在需要的是筛选出n mod b≡an\\text{ mod }b\\equiv an mod b≡a的部分，于是我们可以对前面的等比数列做一个变换： ∑k=0a−1λk−bXk(ωa)=∑n=−∞∞((∑k=0a−1λkr−b)x(n)e−jqω−jrωa)=a∑q=−∞∞x(aq+b)e−jqω−jbωa=ae−jbωaDTFT[x(an+b)]\\begin{align*} \\sum\\limits_{k=0}^{a-1}\\lambda_{k}^{-b}X_{k}(\\frac{\\omega}{a}) &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}\\bigg(\\Big(\\sum\\limits_{k=0}^{a-1}\\lambda_{k}^{r-b}\\Big)x(n)e^{-jq\\omega - \\frac{jr\\omega}{a}}\\bigg) \\\\ &amp;= a\\sum\\limits_{q=-\\infty}^{\\infty}x(aq+b)e^{-jq\\omega-\\frac{jb\\omega}{a}} \\\\ &amp;= ae^{-\\frac{jb\\omega}{a}}\\mathrm{DTFT}[x(an + b)] \\end{align*} k=0∑a−1​λk−b​Xk​(aω​)​=n=−∞∑∞​((k=0∑a−1​λkr−b​)x(n)e−jqω−ajrω​)=aq=−∞∑∞​x(aq+b)e−jqω−ajbω​=ae−ajbω​DTFT[x(an+b)]​ 即得： DTFT[x(an)]=1a∑k=0a−1X(ω−2kπa)DTFT[x(an+b)]=1aejωba∑k=0a−1λk−bX(ω−2kπa)\\begin{align*} \\mathrm{DTFT}[x(an)] &amp;= \\frac{1}{a}\\sum\\limits_{k=0}^{a-1}X(\\frac{\\omega - 2k\\pi}{a} ) \\\\ \\mathrm{DTFT}[x(an + b)] &amp;= \\frac{1}{a}e^{j\\omega \\frac{b}{a}}\\sum\\limits_{k=0}^{a-1}\\lambda_{k}^{-b}X(\\frac{\\omega - 2k\\pi}{a}) \\\\\\end{align*}DTFT[x(an)]DTFT[x(an+b)]​=a1​k=0∑a−1​X(aω−2kπ​)=a1​ejωab​k=0∑a−1​λk−b​X(aω−2kπ​)​","tags":["信原","笔记","数学基础"],"categories":["信号处理原理"]},{"title":"DistriFusion & PipeFusion","path":"/2024/10/26/DistriFusion-PipeFusion/","content":"DistriFusion &amp; PipeFusion 相关内容 多卡并行的两种方式 DistriFusion 针对U-Net架构的Diffusion Model进行改进 DistriFusion概括 传统diffusion缺少多卡并行能力，如果直接将image切分的话，缺少通信的patch产生的图片会不合预期，而使用同步通信则会导致通信时间过长，消除了并行的优势 考虑到diffusion中相近step之间输入具有近似的特点，于是做异步通信： DistriFusion详细架构 第ttt步第lll层会有记录此时的完整输入AtlA_{t}^{l}Atl​，在切分到NNN个设备上后，每个设备仅有Atl(i)A_{t}^{l(i)}Atl(i)​这样一部分的输入，此时At+1lA_{t+1}^{l}At+1l​会异步传到这里（通过AllGather），并做一次scatter分配到每台设备上，使得每台设备只需要自己提供1N\\frac{1}{N}N1​的输入即可，其他的输入都复用上一步的 由于Scatter的结果中只有1N\\frac{1}{N}N1​是新的，因此可以修改FlF_{l}Fl​使其支持稀疏操作： 如果FlF_{l}Fl​是卷积或线性层等，则直接将新的一部分作为输入即可 如果FlF_{l}Fl​是Self-Attention，则将其换为Cross-Attention，即使用新图片的QQQ与全图片的KVKVKV作Attention然而这一步通信$KV$可能导致内存开销过大 但是U-Net需要进行GN，而不完整的图片无法计算GN，新算法： 局部GN更新算法 也即在每台设备上用局部信息来更新并估计全局，并分别作GN，之后通过异步通信将每台设备上的信息整合起来，计算精确的全局信息 最后，在实验的时候，并没有一开始就使用DistriFusion，因为初始的一些步骤主要是构建整体布局和全局语义，随着采样的进行，每一步主要变成了复原局部细节。因此采用了预热步骤，也即先使用了若干轮的传统同步通信 PipeFusion 针对DiT进行改进 DistriFusion有一些不足： 应用于DiT时，需要在每台设备之间对于每一层的KVKVKV矩阵均进行通信，导致通信缓存巨大，造成内存浪费 对带宽要求高，需要将每一层的完整中间激活都在timestep之间进行传递 于是提出了新的方法PipeFusion PipeFusion与DistriFusion的对比 PipeFusion也利用了DistriFusion中观察到的现象，并将其命名为输入临时冗余 PipeFusion的架构 图中，Transformer中的LLL层被划分到NNN台设备上，每台设备只负责其中LN\\frac{L}{N}NL​部分的计算，也即每台设备只需要保存自己负责的层所对应的KVKVKV矩阵即可，避免了这一步带来的通信开销和内存开销 其中每一台设备上有一个buffer用来存储激活，当处理前面的patch时，由于一个device会随着流水线的流动逐步处理所有的patch，因此buffer中是存储每一个patch对应的activation，当计算完成一个patch的时候就将其对应的activation更新，使得其相比DistriFusion来说应用了更多的fresh activation 每台设备上都会有一个Activation Buffer DistriFusion中的新GN算法、预热步骤等都可以应用到PipeFusion中，但是有一些修改： DiT不需要GN 将预热步骤分配在其他计算资源上，减少其开销","tags":["DistriFusion","PipeFusion","Multi GPU"],"categories":["科研"]},{"title":"Sequence-P","path":"/2024/10/26/Sequence-P/","content":"Sequence Parallelism 相关 初版 SP架构 初版符号表 环形计算，devices按行切分QKVQKVQKV矩阵，得到Qn,Kn,Vn∈RL/N×AQ^{n}, K^{n}, V^{n} \\in \\mathbb{R}^{L/N\\times A}Qn,Kn,Vn∈RL/N×A，之后执行N−1N-1N−1轮环形通信，计算Sn=concati=1N(Qn(Ki)T)∈RL/N×LS^{n} = \\mathrm{concat}_{i=1}^{N}\\bigl(Q^{n}(K^{i})^{T}\\bigr)\\in \\mathrm{R}^{L/N\\times L}Sn=concati=1N​(Qn(Ki)T)∈RL/N×L，之后再进行N−1N-1N−1轮环形通信，计算attention输出On=SnV=concati=1N(SinVi)O^{n} = S^{n}V = \\mathrm{concat}_{i=1}^{N}\\bigl(S^{n}_{i}V^{i}\\bigr)On=SnV=concati=1N​(Sin​Vi)，其中SinS^{n}_{i}Sin​代表SnS^{n}Sn按列切分为NNN段 性能比较 SP与TP性能比较1 SP与TP性能比较2 因此若SP&gt;TPSP &gt; TPSP&gt;TP则： BL&gt;32HBL &gt; 32HBL&gt;32H BL&gt;16AZBL &gt; 16 AZBL&gt;16AZ 通信比较 二者相同，都是8(N−1)BZ(L/N)A8(N-1)BZ(L/N)A8(N−1)BZ(L/N)A，详细推导省略 对于TP来说的优势 在与PP结合的时候可以减少一次all-gather，这是因为TP会在进入下一阶段的时候对输入也做split，在计算结束之后在all-gather，但是由于SP在初始阶段就会做split，所以就可以失去这个操作 Ulysses Ulysses架构 沿着head cnt做切分，这样一张卡上是若干个完整的头，可以直接计算Attention，并且可以用一些常规的方法加速，例如FlashAttention等 注意在上图中d=hc×hsd = hc\\times hsd=hc×hs，是将多头的直接concat起来得到的向量 Ring-Attention Ring Attention架构 Flash Attention的并行化版本，利用异步P2P通信，在一个设备上计算局部attention的同时传递K-V块","tags":["Sequence Parallelism"],"categories":["科研"]},{"title":"自底向上语法分析","path":"/2024/10/22/自底向上语法分析/","content":"编译原理 笔记 2 自底向上语法分析 自底向上的思想是从要分析的终结符串开始，每一步规约都是将一个子串用一个产生式替换，直到达到开始符号或报错 基本改进方法 与自顶向下相似，直接分析的版本不确定性太高，因此需要进行限制 选择可规约串 对于一个句型，可规约串定义为该句型的短语 对于文法G=(VN,VT,P,S)G = (V_{N}, V_{T}, P, S)G=(VN​,VT​,P,S)，设α,β,δ∈(VN∪VT)∗,w∈VT∗\\alpha, \\beta, \\delta\\in(V_{N}\\cup V_{T})^{*}, w\\in V_{T}^{*}α,β,δ∈(VN​∪VT​)∗,w∈VT∗​： 若S⇒∗αAδS\\mathop{\\Rightarrow}\\limits^{*}\\alpha A\\deltaS⇒∗αAδ且A⇒+βA\\mathop{\\Rightarrow}\\limits^{+}\\betaA⇒+β，则称β\\betaβ是句型αβδ\\alpha\\beta\\deltaαβδ相对非终结符AAA的短语 若S⇒∗αAδS\\mathop{\\Rightarrow}\\limits^{*}\\alpha A\\deltaS⇒∗αAδ且A⇒βA\\Rightarrow\\betaA⇒β，则称β\\betaβ是句型αβδ\\alpha\\beta\\deltaαβδ相对非终结符AAA的直接短语 若S⇒rm∗αAwS\\mathop{\\Rightarrow}\\limits_{rm}^{*}\\alpha AwSrm⇒∗​αAw且A⇒βA\\Rightarrow\\betaA⇒β，则称β\\betaβ是右句型αβw\\alpha\\beta wαβw相对非终结符AAA的句柄 短语可以理解为可以被规约的子串，直接短语就是可以通过一步就能规约到的子串，而句柄是所有直接短语中最靠左的一个（因为在句柄的定义中要求了最右推导，因此右边的直接短语已经被推导完了） 例如对于文法： S→ABA→aAA→εB→bB→bB\\begin{align*} S &amp;\\to AB \\\\ A &amp;\\to aA \\\\ A &amp;\\to \\varepsilon \\\\ B &amp;\\to b \\\\ B &amp;\\to bB \\end{align*} SAABB​→AB→aA→ε→b→bB​ 则： 句子aaabaaabaaab的短语包括ε,a,aa,aaa,aaab,b\\varepsilon, a, aa, aaa, aaab, bε,a,aa,aaa,aaab,b，直接短语包括ε,b\\varepsilon, bε,b，句柄为ε\\varepsilonε 句型aaAbaaAbaaAb的短语包括aA,aaA,aaAb,baA, aaA, aaAb, baA,aaA,aaAb,b，直接短语包括aA,baA, baA,b，句柄为aAaAaA 如果文法是二义的，则右句型的最右推导可能有多个，则句柄也可能会有多个 最右推导与最左规约 通常采用移进-规约分析 与自顶向下分析比较 功能较强：规约的时候可以获取完整的串信息，而推导只能获得局部信息 利于出错处理 有成熟的自动化技术 移进-规约分析 有一个分析引擎和下推栈，分析引擎能完成的动作包括： Reduce：按照确定的方式对栈顶短语进行规约 Shift：从输入序列移进一个单词到栈顶 Error：发现错误，进行处理或恢复 Accept：分析成功 移进-规约分析例子 上图中的步骤逆向过来就是一种最右推导，称之为规范推导 移进-规约冲突 到达一个既可移进又可规约的状态，例如文法： S→if E then S ∣ if E then S else S\\begin{align*} S &amp;\\to \\text{if } E \\text{ then } S \\,|\\, \\text{if } E \\text{ then } S \\text { else } S \\end{align*} S​→if E then S∣if E then S else S​ 则对于串if E then if E then S else S\\text{if } E \\text{ then if } E \\text{ then } S \\text { else } Sif E then if E then S else S即可移进又可规约 规约-规约冲突 到达了一个状态，可能有多种短语可以用于规约，例如产生式： A→aA ∣ aaAA \\to aA \\,|\\, aaA A→aA∣aaA 则对于aaabaaabaaab时，对于栈中的aaAaaAaaA，无法确定该用哪一个短语 表驱动方法 解决上面两个冲突的方法，即通过一张分析表来决定状态机的下一步行为，常见的表有LR分析中的LR分析表、算符优先分析中的算法优先分析表 LR分析 代表从左（L）到右扫描输入序列，产生最右（R）推导，是一种表驱动的移进-规约分析 LR分析表构造 主要是构造两张表ACTION表和GOTO表： ACTION表：根据栈顶状态和当前输入符号来确定下一步动作 GOTO表：根据栈顶状态和规约用的非终结符决定下一个状态 每一个状态为一个set&lt;pair&gt;，每一个pair代表了在当前状态下，消耗的栈顶符号与去掉这个符号后下一步允许什么串进入，本质上是一个大型状态转移图 LR分析表对应的状态转移图实例 这张表具体的构造方法按照分析方法不同分别讨论 LR分析算法 12345678910111213if (ACTION[i, a] == sj) &#123; // shift PUSH j; // push state j to stack READ w; // read one symbol in the input&#125;else if (ACTION[i, a] == rj) &#123; // reduce // the j-th formula is A -&gt; beta POP len(beta); // pop |beta| states from the tiop of stack PUSH GOTO[k, A]; // k is the current stack top&#125;else if (ACTION[i, a] == acc) &#123; // accept return;&#125;else exit(1); // error 带符号栈的LR分析算法 除了状态栈之外，还有一个符号栈，存储的读入但是没有规约的符号，算法修改为： 12345678910111213if (ACTION[i, a] == sj) &#123; // shift PUSH (j, a); // push state j and symbol a to stack READ w; // read one symbol in the input&#125;else if (ACTION[i, a] == rj) &#123; // reduce // the j-th formula is A -&gt; beta POP len(beta); // pop |beta| states from the tiop of stack PUSH (GOTO[k, A], A); // k is the current stack top&#125;else if (ACTION[i, a] == acc) &#123; // accept return;&#125;else exit(1); // error LR(0)分析 首先引入一些概念 对于文法G=(VN,VT,P,S)G = (V_{N}, V_{T}, P, S)G=(VN​,VT​,P,S)，增加产生式S′→SS&#x27;\\to SS′→S，其中S′∉VN∪VTS&#x27; otin V_{N}\\cup V_{T}S′∈/VN​∪VT​，则得到增广文法G′=(VN,VT,P,S′)G&#x27; = (V_{N}, V_{T}, P, S&#x27;)G′=(VN​,VT​,P,S′) 对于文法G=(VN,VT,P,S)G = (V_{N}, V_{T}, P, S)G=(VN​,VT​,P,S)，以及串α,β∈(VN∪VT)∗,w∈VT∗\\alpha, \\beta\\in(V_{N}\\cup V_{T})^{*}, w\\in V_{T}^{*}α,β∈(VN​∪VT​)∗,w∈VT∗​，其中S⇒∗αβwS \\Rightarrow^{*} \\alpha\\beta wS⇒∗αβw，且β\\betaβ为句柄，则αβ\\alpha\\betaαβ任何前缀γ\\gammaγ称为文法GGG的活前缀对于增广文法，原开始符号SSS是G′G&#x27;G′的活前缀 LR(0) FSM LR(0)分析的主要工具，是一个以VN∪VTV_{N}\\cup V_{T}VN​∪VT​为字母表的DFA，可以通过增广后的文法直接构造 可以证明，GGG的LR(0)FSM对应的语言是G′G&#x27;G′所有活前缀的集合 FSM的状态 LR(0) FSM的状态是一个特殊的LR(0)项集，一个LR(0)项是指在右端某一位置有圆点的产生式，圆点代表着已分析过的串与该产生式匹配的位置 项有如下分类： 移进项：A→α.aβA\\to \\alpha .a\\betaA→α.aβ 待约项：A→α.BβA\\to \\alpha .B\\betaA→α.Bβ 规约项：A→α.A\\to \\alpha .A→α. 接收项：S′→S.S&#x27;\\to S .S′→S. 我们将LR(0) FSM的每一项定义为一个项集的闭包(CLOSURE) 123456789def CLOSURE(I): J = I while (1): for (j, p) in zip(J, P): # P is all the generation formula if j.hasform(&quot;A -&gt; α.Bβ&quot;) and p.hasform(&quot;B -&gt; γ&quot;): J.append(&quot;B -&gt; .γ&quot;) if J.hasNotChanged(): break return J 则其状态转移函数定义为： GO(I,X)=CLOSURE(J)J={A→αX.β ∣ A→α.Xβ∈I}\\begin{align*} GO(I, X) &amp;= \\text{CLOSURE}(J) \\\\ J &amp;= \\{A\\to \\alpha X.\\beta \\,|\\, A\\to \\alpha.X\\beta \\in I \\} \\end{align*} GO(I,X)J​=CLOSURE(J)={A→αX.β∣A→α.Xβ∈I}​ 则构造状态集合的方法就是从{CLOSURE({S′→.S})}\\{\\text{CLOSURE}(\\{S&#x27;\\to .S\\})\\}{CLOSURE({S′→.S})}开始，利用上述的状态转移函数逐步扩展状态集合 LR(0)FSM的构造举例 增广文法的每个活前缀都有唯一与之相对应的状态 LR(0)分析表的构造 令状态集合为C={I0,…,In}C = \\{I_{0} ,\\dots,I_{n}\\}C={I0​,…,In​}，则构造ACTION与GOTO表的方法为： GOTO(k,A)=j⇔GO(Ik,A)=Ij\\mathrm{GOTO}(k, A) = j \\Leftrightarrow \\mathrm{GO}(I_{k}, A) = I_{j}GOTO(k,A)=j⇔GO(Ik​,A)=Ij​ ACTION(k,a)=sj⇔A→α.aβ∈Ik &amp; GO(Ik,a)=Ij\\mathrm{ACTION}(k, a) = sj \\Leftrightarrow A\\to\\alpha.a\\beta \\in I_{k} \\,\\&amp;\\, \\mathrm{GO}(I_{k}, a) = I_{j}ACTION(k,a)=sj⇔A→α.aβ∈Ik​&amp;GO(Ik​,a)=Ij​ ACTION(k,a)=rj⇔A→α.∈Ik\\mathrm{ACTION}(k, a) = rj \\Leftrightarrow A\\to\\alpha.\\in I_{k}ACTION(k,a)=rj⇔A→α.∈Ik​ ACTION(k,#)=acc⇔S′→S.∈Ik\\mathrm{ACTION}(k, \\#) = acc \\Leftrightarrow S&#x27;\\to S. \\in I_{k}ACTION(k,#)=acc⇔S′→S.∈Ik​ LR(0)文法 按照上述定义构造的分析表，如果各表项均没有多重定义，则称为LR(0)文法，等价于要求每个状态满足： 不同时含有移进和规约项（不能有移进-规约冲突） 不含有两个以上规约项（不能有规约-规约冲突） 一个非LR(0)文法的例子为： E→E+T ∣ TT→T∗F ∣ FF→(E) ∣ v ∣ d\\begin{align*} E &amp;\\to E + T \\,|\\, T \\\\ T &amp;\\to T * F \\,|\\, F \\\\ F &amp;\\to (E) \\,|\\, v \\,|\\, d \\end{align*} ETF​→E+T∣T→T∗F∣F→(E)∣v∣d​ 短语TTT即存在移进-规约冲突 SLR(1)分析 由于LR(0)限制非常严格（要求看到栈顶状态就能决定动作），因此做一些条件的放松，常见的是允许向前查看一个符号成为LR(1)，首先来研究其简化版本SLR(1) SLR(1)通过判断下一个输入符号是否属于要规约的非终结符的Follow集合，来解决移进-规约冲突和规约-规约冲突 如果一个状态中规约项的非终结符的Follow集两两无交，则可以解决规约-规约冲突 如果一个状态中所有规约项中要规约的非终结符的Follow集与所有要移进的符号集互不相交，则可以解决移进-规约冲突 SLR(1)分析表 其分析表的构造相对于LR(0)来说只用做简单的修改，也即在填充ACTION(k,a)=rj\\mathrm{ACTION}(k, a) = rjACTION(k,a)=rj时，需要保证a∈Follow(A)a\\in \\mathrm{Follow}(A)a∈Follow(A) 按照上述定义构造的分析表，如果各表项均没有多重定义，则称为SLR(1)文法，等价于要求每个状态满足： 对于任意两项A→α.A\\to \\alpha.A→α.与B→β.B\\to \\beta.B→β.，有Follow(A)∩Follow(B)=∅\\mathrm{Follow}(A) \\cap \\mathrm{Follow}(B) = \\emptysetFollow(A)∩Follow(B)=∅ 对于任意两项A→α.aβA\\to \\alpha.a\\betaA→α.aβ与B→γ.B\\to \\gamma.B→γ.，均有a∉Follow(B)a otin \\mathrm{Follow}(B)a∈/Follow(B) 一个非SLR(1)文法的例子为： E→(L,E) ∣ FL→L,E ∣ EF→(F) ∣ d\\begin{align*} E &amp;\\to (L,E) \\,|\\, F \\\\ L &amp;\\to L,E \\,|\\, E \\\\ F &amp;\\to (F) \\,|\\, d \\end{align*} ELF​→(L,E)∣F→L,E∣E→(F)∣d​ 短语(F)(F)(F)会被错误的规约为(E)(E)(E) LR(1)分析 在SLR(1)的基础上进一步改进，将传统的项增加一个终结符，表示产生式右端完整匹配后所允许留在符号串中的下一个终结符，即项会形如： A→α.β , aA\\to \\alpha.\\beta\\,,\\,a A→α.β,a 其中a∈VT∪{#}a\\in V_{T}\\cup\\{\\#\\}a∈VT​∪{#} 对于形如A→α. , aA\\to \\alpha.\\,,\\,aA→α.,a的项，只有当下一个输入为aaa的时候才能进行规约 LR(1)FSM LR(1)FSM的状态是LR(1)项集的闭包，闭包算法为： 123456789def CLOSURE(I): J = I while (1): for (j, p) in zip(J, P): if j.hasform(&quot;[A -&gt; α.Bβ, a]&quot;) and p.hasform(&quot;B -&gt; γ&quot;): J.append(&quot;[B -&gt; .γ, b]&quot;) for b in First(βa) if J.hasNotChanged(): break return J 初态定义为I0=CLOSURE({[S′→.S,#]})I_{0} = \\mathrm{CLOSURE}(\\{[S&#x27;\\to .S, \\#]\\})I0​=CLOSURE({[S′→.S,#]}) 状态转移函数定义为： GO(I,X)=CLOSURE(J)J={[A→αX.β , a] ∣ [A→α.Xβ , a]∈I}\\begin{align*} GO(I, X) &amp;= \\text{CLOSURE}(J) \\\\ J &amp;= \\{[A\\to \\alpha X.\\beta\\,,\\, a] \\,|\\, [A\\to \\alpha.X\\beta \\,,\\, a] \\in I \\} \\end{align*} GO(I,X)J​=CLOSURE(J)={[A→αX.β,a]∣[A→α.Xβ,a]∈I}​ 从初态开始利用上述转移函数扩展，可以得到项集规范族 在上述非SLR(1)的例子中，E→F.E\\to F.E→F.所期待的下一个输入符号没有)))，因此(F)(F)(F)中的FFF不会被规约为EEE，而是会选择移进 LR(1) 分析表构造 GOTO(k,A)=j⇔GO(Ik,A)=Ij\\mathrm{GOTO}(k, A) = j \\Leftrightarrow \\mathrm{GO}(I_{k}, A) = I_{j}GOTO(k,A)=j⇔GO(Ik​,A)=Ij​ ACTION(k,a)=sj⇔[A→α.aβ , b]∈Ik &amp; GO(Ik,a)=Ij\\mathrm{ACTION}(k, a) = sj \\Leftrightarrow [A\\to\\alpha.a\\beta\\,,\\,b] \\in I_{k} \\,\\&amp;\\, \\mathrm{GO}(I_{k}, a) = I_{j}ACTION(k,a)=sj⇔[A→α.aβ,b]∈Ik​&amp;GO(Ik​,a)=Ij​ ACTION(k,b)=rj⇔[A→α. , b]∈Ik\\mathrm{ACTION}(k, b) = rj \\Leftrightarrow [A\\to\\alpha.\\,,\\, b]\\in I_{k}ACTION(k,b)=rj⇔[A→α.,b]∈Ik​ ACTION(k,#)=acc⇔[S′→S. , #]∈Ik\\mathrm{ACTION}(k, \\#) = acc \\Leftrightarrow [S&#x27;\\to S.\\,,\\, \\#] \\in I_{k}ACTION(k,#)=acc⇔[S′→S.,#]∈Ik​ LR(1)文法 按上述算法构造的分析表若每项都无重复定义，则称为LR(1)文法，其FSM每一个状态都满足： 对于任意两个项目[A→α.aβ , b][A\\to \\alpha.a\\beta\\,,\\, b][A→α.aβ,b]与[B→γ.,c][B\\to \\gamma., c][B→γ.,c]，一定有a≠ca eq ca=c 对于任意两个项目[A→α. , a][A\\to \\alpha.\\,,\\, a][A→α.,a]与[B→β. , b][B\\to \\beta.\\,,\\, b][B→β.,b]，一定有a≠ba eq ba=b LR(k)文法 可以扩展到LR(k)文法，但是状态机的复杂度过高，无实际意义，并且可以证明LR(N+)\\mathrm{LR}(\\mathbb{N}^{+})LR(N+)都是等价的 LALR(1)分析 是一个LR(1)与SLR(1)的折中版本 将LR(1)的项的第一部分称为芯，如果LR(1)FSM的两个状态的芯构成的集合完全相同，那么我们称其为同芯的状态 将LR(1)FSM中的同芯状态合并，如果得到的新状态没有规约-规约冲突，则得到的新文法是LALR(1)文法 LALR(1)FSM 构造方法为brute-force方法： 构造增广文法的LR(1)FSM状态集 合并同芯状态 LALR(1)FSM状态的后继状态是其合并前所有同芯状态的后继状态的并 LALR(1)FSM状态数与LR(0)状态数相同，但是其能力强于SLR(1)","tags":["笔记","编原","自底向上","语法分析"],"categories":["编译原理"]},{"title":"信号处理原理 4","path":"/2024/10/22/信号处理原理4/","content":"信号处理原理 笔记 4 信号的采样 采样：每隔一段时间（等距）在模拟信号波形上抽取一个幅度值，称之为采样 抽样的时间间隔称为采样周期TsT_{s}Ts​，倒数称为采样频率fs=1/Tsf_{s} = 1/T_{s}fs​=1/Ts​，采样角频率（不会混淆的情况下也可称为采样频率）为ωs=2π/Ts\\omega_{s} = 2\\pi / T_{s}ωs​=2π/Ts​ 采样的数学模型 在时域： xp(t)=x(t)p(t)x_{p}(t) = x(t)p(t) xp​(t)=x(t)p(t) 在频域： Xp(ω)=12πX(ω)∗P(ω)X_{p}(\\omega) = \\frac{1}{2\\pi}X(\\omega)*P(\\omega) Xp​(ω)=2π1​X(ω)∗P(ω) 其中p(t)p(t)p(t)为我们的采样公式，理想采样为冲激串采样： p(t)=∑n=−∞∞δ(t−nTs)p(t) = \\sum\\limits_{n=-\\infty}^{\\infty}\\delta(t-nT_{s}) p(t)=n=−∞∑∞​δ(t−nTs​) 这种情况下： xp(t)=∑n=−∞∞x(nTs)δ(t−nTs)x_{p}(t) = \\sum\\limits_{n=-\\infty}^{\\infty}x(nT_{s})\\delta(t-nT_{s}) xp​(t)=n=−∞∑∞​x(nTs​)δ(t−nTs​) 此时p(t)p(t)p(t)的FT为： p(t)⇔P(ω)=2πTs∑n=−∞∞δ(ω−nωs)p(t)\\Leftrightarrow P(\\omega) = \\frac{2\\pi}{T_{s}}\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(\\omega-n\\omega_{s}) p(t)⇔P(ω)=Ts​2π​n=−∞∑∞​δ(ω−nωs​) 于是我们有： Xp(ω)=1Ts∑n=−∞∞X(ω−kωs)X_{p}(\\omega) = \\frac{1}{T_{s}}\\sum\\limits_{n=-\\infty}^{\\infty}X(\\omega - k\\omega_{s}) Xp​(ω)=Ts​1​n=−∞∑∞​X(ω−kωs​) 也即在时域上对时间信号进行理想采样相当于在频域上对连续时间信号的频谱以ωs\\boldsymbol{\\omega_{s}}ωs​为周期做周期延拓，并对幅度除以相应系数 我们来证明上述公式中最重要的一步：p(t)⇔P(ω)=2πTs∑n=−∞∞δ(ω−nωs)p(t)\\Leftrightarrow P(\\omega) = \\frac{2\\pi}{T_{s}}\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(\\omega-n\\omega_{s})p(t)⇔P(ω)=Ts​2π​n=−∞∑∞​δ(ω−nωs​)首先直接套用定义：P(ω)=F[p(t)]=∫−∞∞p(t)e−jωtdt=∑n=−∞∞e−jωnT\\begin{align*} P(\\omega) = \\mathscr{F}[p(t)] &amp;= \\int_{-\\infty}^{\\infty}p(t)e^{-j\\omega t}dt \\\\ &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}e^{-j\\omega nT}\\end{align*}P(ω)=F[p(t)]​=∫−∞∞​p(t)e−jωtdt=n=−∞∑∞​e−jωnT​这个式子并不友好，而且在后续卷积的过程中也没法进行化简，于是我们采用另外一种方法，首先对p(t)p(t)p(t)进行FS，系数：Fn=1Ts∫−Ts/2Ts/2p(t)e−jnωstdt=1Ts∑k=−∞∞∫−Ts/2Ts/2δ(t−kTs)e−jnωstdt=1Ts∫−Ts/2Ts/2δ(t)e−jnωstdt=1Ts\\begin{align*} F_{n} &amp;= \\frac{1}{T_{s}}\\int_{-T_{s}/2}^{T_{s}/2}p(t)e^{-jn\\omega_{s}t}dt \\\\ &amp;= \\frac{1}{T_{s}}\\sum\\limits_{k=-\\infty}^{\\infty}\\int_{-T_{s}/2}^{T_{s}/2}\\delta(t-kT_{s})e^{-jn\\omega_{s}t}dt \\\\ &amp;= \\frac{1}{T_{s}}\\int_{-T_{s}/2}^{T_{s}/2}\\delta(t)e^{-jn\\omega_{s}t}dt \\\\ &amp;= \\frac{1}{T_{s}}\\end{align*}Fn​​=Ts​1​∫−Ts​/2Ts​/2​p(t)e−jnωs​tdt=Ts​1​k=−∞∑∞​∫−Ts​/2Ts​/2​δ(t−kTs​)e−jnωs​tdt=Ts​1​∫−Ts​/2Ts​/2​δ(t)e−jnωs​tdt=Ts​1​​因此有：p(t)=1Ts∑n=−∞∞ejnωstp(t) = \\frac{1}{T_{s}}\\sum\\limits_{n=-\\infty}^{\\infty}e^{jn\\omega_{s}t}p(t)=Ts​1​n=−∞∑∞​ejnωs​t此时我们再利用FT的线性可得：P(ω)=F[p(t)]=1Ts∑n=−∞∞F[ejnωst]=2πTs∑n=−∞∞δ(ω−nωs)\\begin{align*} P(\\omega) = \\mathscr{F}[p(t)] &amp;= \\frac{1}{T_{s}}\\sum\\limits_{n=-\\infty}^{\\infty}\\mathscr{F}[e^{jn\\omega_{s}t}] \\\\ &amp;= \\frac{2\\pi}{T_{s}}\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(\\omega - n\\omega_{s})\\end{align*}P(ω)=F[p(t)]​=Ts​1​n=−∞∑∞​F[ejnωs​t]=Ts​2π​n=−∞∑∞​δ(ω−nωs​)​ 采样示意图 时钟域上的采样代表频率域上的周期延拓 当上图中，ωm&gt;ωs\\omega_{m} &gt; \\omega_{s}ωm​&gt;ωs​时会发生混叠，也即延拓之后会发生相互重叠的现象，因此我们要想从Xp(jω)X_{p}(j\\omega)Xp​(jω)中不失真地分离出X(jω)X(j\\omega)X(jω)，则需要满足： x(t)x(t)x(t)是带限的，最高频率分量为ωM\\omega_{M}ωM​ 采样周期不能是任意的，必须保证采样频率ωs≥2ωM\\omega_{s} \\geq 2\\omega_{M}ωs​≥2ωM​ 此时可以用理想低通滤波器从Xp(jω)X_{p}(j\\omega)Xp​(jω)中不失真地分离出X(jω)X(j\\omega)X(jω) 我们有Nyquist采样定理： 对带限于最高频率ωM\\omega_{M}ωM​对连续时间信号x(t)x(t)x(t)，如果以ωs&gt;2ωM\\omega_{s} &gt; 2\\omega_{M}ωs​&gt;2ωM​的频率进行理想采样，则x(t)x(t)x(t)可以唯一由其样本x(nT)x(nT)x(nT)来确定 而在实际应用中，由于理想滤波器是不可实现的，因此要求ωs&gt;2ωM\\omega_{s} &gt; 2\\omega_{M}ωs​&gt;2ωM​ 内插 内插是由样本值重建某一函数的过程 理想内插 以理想低通滤波器（频域矩形脉冲）的单位冲激响应（定义为函数的IFT）作为内插函数 设内插函数为h(t)=F−1[Gωs(ω)]=1TsSa(πtTs)h(t) = \\mathscr{F}^{-1}[G_{\\omega_{s}}(\\omega)] = \\dfrac{1}{T_{s}}\\mathrm{Sa}(\\dfrac{\\pi t}{T_{s}})h(t)=F−1[Gωs​​(ω)]=Ts​1​Sa(Ts​πt​) 则有： x(t)=xp(t)∗h(t)=∑n=−∞∞x(nT)δ(t−nT)∗h(t)=∑n=−∞∞x(nT)h(t−nT)\\begin{align*} x(t) = x_{p}(t) * h(t) &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}x(nT)\\delta(t-nT)*h(t) \\\\ &amp;= \\sum\\limits_{n=-\\infty}^{\\infty}x(nT)h(t-nT) \\end{align*} x(t)=xp​(t)∗h(t)​=n=−∞∑∞​x(nT)δ(t−nT)∗h(t)=n=−∞∑∞​x(nT)h(t−nT)​ 也即可以通过采样值xp(t)x_{p}(t)xp​(t)和Sa函数来恢复原有信号，并且恢复效果是很理想的 时域为Sa函数，频域为矩形脉冲，也即单位冲激响应为其IFT 理想内插函数的单位冲激响应 零阶保持内插 内插函数为矩形脉冲，对应的频域为Sa函数 所得的结果是采样后的信号在x轴上向正方向扩展，到达下一个采样信号的时候直接跳变 零阶保持内插 一阶保持内插 内插函数为脉高为1的三角脉冲 所得到的结果是通过一次函数连接相邻的采样点 一阶保持内插 欠采样信号的恢复 当不满足采样定理的时候，就会出现频谱混叠的情况，此时有一些结论： 频谱混叠的情况下，时域信号变了，但是抽样点处取值不变，也即通过理想内插也得不到原信号，但抽样点处的取值不变 发生频谱混叠的时候理想内插也得不到正确值 工程应用时，如果采样频率ωs=2ωM\\omega_{s} = 2\\omega_{M}ωs​=2ωM​将不足以恢复原信号，例如x(t)=cos⁡(ω0t+φ)x(t) = \\cos(\\omega_{0}t+\\varphi)x(t)=cos(ω0​t+φ)在ωs=2ω0\\omega_{s} = 2\\omega_{0}ωs​=2ω0​的时候可能被恢复成x1(t)=cos⁡φcos⁡(ω0t)x_{1}(t) = \\cos\\varphi\\cos(\\omega_{0}t)x1​(t)=cosφcos(ω0​t) 频域采样 在频域利用P(ω)=∑k=−∞∞δ(ω−kω0)P(\\omega) = \\sum\\limits_{k=-\\infty}^{\\infty}\\delta(\\omega - k\\omega_{0})P(ω)=k=−∞∑∞​δ(ω−kω0​)进行采样得到Xp(ω)X_{p}(\\omega)Xp​(ω) 在频域采样的结果 可以看出，在频域以ω0\\omega_{0}ω0​采样相当于在时域将信号以2πω0\\boldsymbol{\\frac{2\\pi}{\\omega_{0}}}ω0​2π​为周期无限延拓 如果想在时域截取原信号，只需要利用矩形窗信号进行读取 w(t)={ω0∣t∣≤πω00∣t∣&gt;πω0\\begin{align*} w(t) = \\begin{cases} \\omega_{0} &amp; |t| \\leq \\frac{\\pi}{\\omega_{0}} \\\\ 0 &amp; |t| &gt; \\frac{\\pi}{\\omega_{0}} \\end{cases} \\end{align*} w(t)={ω0​0​∣t∣≤ω0​π​∣t∣&gt;ω0​π​​​ 而在频域截取原信号需要内插，内插函数为W(jω)=2πsinc(ω/ω0)W(j\\omega) = 2\\pi\\mathrm{sinc}(\\omega/\\omega_{0})W(jω)=2πsinc(ω/ω0​) 即： X(jω)=12πXp(jω)∗W(jω)=∑k=−∞∞X(kω0)sinc(ω−kω0ω0)\\begin{align*} X(j\\omega) &amp;= \\frac{1}{2\\pi}X_{p}(j\\omega)*W(j\\omega) \\\\ &amp;= \\sum\\limits_{k=-\\infty}^{\\infty}X(k\\omega_{0})\\mathrm{sinc}(\\frac{\\omega-k\\omega_{0}}{\\omega_{0}}) \\end{align*} X(jω)​=2π1​Xp​(jω)∗W(jω)=k=−∞∑∞​X(kω0​)sinc(ω0​ω−kω0​​)​","tags":["信原","笔记","数学基础"],"categories":["信号处理原理"]},{"title":"DiT","path":"/2024/10/20/DiT/","content":"Diffusion Transformer相关 LDM简介 LDM架构 架构如上，ε\\mathcal{\\varepsilon}ε代表编码器，负责将像素空间的输入映射到潜在空间，D\\mathcal{D}D代表解码器，负责将潜在空间的输出映射到像素空间，中间利用U-Net进行去噪，同时τθ\\tau_\\thetaτθ​是Condition编码后的参数，通过CrossAttention与潜在变量结合起来 DiT 基于LDM的一个模型，将其中原本用于Denoise的U-Net修改为Transfomer架构，称为DiT Block，而VAE则是由已有的部分： DiT Block Patchify 对输入的latent noise做扁平化： 将图像切分成多个大小为 p×pp\\times pp×p 的补丁，然后将其转换为长度为 TTT 的序列作为 Transformer 的输入。这使得 DiT 能够处理不同分辨率、持续时间和长宽比的视频和图像。 其中ppp的大小会影响GFLOP，ppp减半GFLOP乘4，但是对下游参数数量没有影响。 DiT Block 按照对条件信息的处理方式分为三种： In-Context Conditioning 直接把Condition和Image拼接在一起，最终一次迭代不拼接，对GFLOP影响很小 Cross Attention Image做一次Self-Attention之后，再和Condition做一次Cross Attention，会提升15%左右的GFLOP，这个和LDM中使用的方法是很相似的 Adaptive Layer Norm(adaLN) 传统的LayerNorm，在做完归一化之后的线性映射参数是直接训练得到，与输入无关，和adaLN中线性映射的采纳数是输入经过一次MLP部分得到 用Adaptive Layer Norm替换Transfomer中的Layer Norm部分，并且这其中的参数与Image无关得到，而通过Condition经过MLP之后得到，对GFLOP影响最小 adaLN-Zero 先把α\\alphaα输出都初始化为0，这样每一个残差块的初始输出都为恒等映射，训练成本更低 Decoder 用一个线性decoder来做解码，输出一个噪声预测与一个对角协方差预测","tags":["Diffusion","Transformer"],"categories":["科研"]},{"title":"科研内容记录","path":"/2024/10/14/科研内容记录/","content":"记录科研过程中学习的一些内容 Self-Attention &amp; Transformer 李宏毅老师的课程： https://www.bilibili.com/video/BV1Wv411h7kN/https://www.bilibili.com/video/BV1Wv411h7kN/ 一些博客： https://nlp.seas.harvard.edu/annotated-transformer/https://nlp.seas.harvard.edu/annotated-transformer/ https://blog.csdn.net/weixin_42475060/article/details/121101749https://blog.csdn.net/weixin_42475060/article/details/121101749 模型参数量分析https://zhuanlan.zhihu.com/p/624740065 Four kinds of parallelism data-parallelismhttps://juejin.cn/post/7254001262646738981 pipeline-parallelismhttps://juejin.cn/post/7262274383287484476 tensor-parallelismhttps://juejin.cn/post/7269698032655728640 sequence-parallelismhttps://juejin.cn/post/7273680143658287156 Flash Attention 原论文，按照版本升序 https://arxiv.org/pdf/2205.14135https://arxiv.org/pdf/2205.14135 https://arxiv.org/pdf/2307.08691https://arxiv.org/pdf/2307.08691 https://arxiv.org/pdf/2407.08608https://arxiv.org/pdf/2407.08608 博客： https://blog.csdn.net/v_JULY_v/article/details/133619540https://blog.csdn.net/v_JULY_v/article/details/133619540 Sequence Parallelism 一些论文： Sequence Parallelismhttps://arxiv.org/pdf/2105.13120 DeepSpeed-Ulysseshttps://arxiv.org/pdf/2309.14509 Ring-Attentionhttps://arxiv.org/pdf/2310.01889 Unified-Sequence-Parallelismhttps://arxiv.org/pdf/2405.07719 博客： https://zhuanlan.zhihu.com/p/689067888https://zhuanlan.zhihu.com/p/689067888 https://zhuanlan.zhihu.com/p/683714620https://zhuanlan.zhihu.com/p/683714620 Distributed System 通信原语Pytorchhttps://zhuanlan.zhihu.com/p/478953028 通信原语MMEngine库https://mmengine.readthedocs.io/zh-cn/v0.7.2/advanced_tutorials/distributed.html Swin Transformer 论文： Swin Transformerhttps://arxiv.org/pdf/2103.14030 博客： Swin Transformerhttps://zhuanlan.zhihu.com/p/367111046 Relative Positionhttps://blog.csdn.net/weixin_40723264/article/details/127632545 Diffusion 论文： DDPMhttps://arxiv.org/pdf/2006.11239 Diffusion Mathhttps://arxiv.org/pdf/2208.11970 Diffusion Transformerhttps://arxiv.org/pdf/2212.09748 Diffusion Overviewhttps://arxiv.org/pdf/2404.07771 博客： Diffusion Modelhttps://zhuanlan.zhihu.com/p/624221952 Diffusion Transformerhttps://zhuanlan.zhihu.com/p/684125968 Sora技术报告： Sorahttps://openai.com/index/video-generation-models-as-world-simulators/ DiTFastAttn 论文： DiT Fast Attentionhttps://arxiv.org/pdf/2406.08552 xFusion 论文： DistriFusionhttps://arxiv.org/pdf/2402.19481 PipeFusionhttps://arxiv.org/pdf/2405.14430 一些问题 不同的Normalization BN是在一个batch内，针对每一个特征做归一化；LN是指对于每个样本做归一化；IN是指对于通道内的每个特征做归一化；GN是指对通道内的一组特征做归一化 对于一个y = [batch_size, channel_num, width, height] = [N, C, W, H]的张量： BN对于批次中的每一个通道作归一化，即：μc=1NHW∑n=1N∑h=1H∑w=1Wynchwσc2=1NHW∑n=1N∑h=1H∑w=1W(ynchw−μc)2ynchw′=γ(ynchw−μcσc)+β\\begin{align*} \\mu_{c} &amp;= \\frac{1}{NHW}\\sum\\limits_{n=1}^{N}\\sum\\limits_{h=1}^{H}\\sum\\limits_{w=1}^{W}y_{nchw} \\\\ \\sigma_{c}^{2} &amp;= \\frac{1}{NHW}\\sum\\limits_{n=1}^{N}\\sum\\limits_{h=1}^{H}\\sum\\limits_{w=1}^{W}(y_{nchw} - \\mu_{c})^{2} \\\\ y&#x27;_{nchw} &amp;= \\gamma(\\frac{y_{nchw} - \\mu_{c}}{\\sigma_{c}}) + \\beta \\end{align*} μc​σc2​ynchw′​​=NHW1​n=1∑N​h=1∑H​w=1∑W​ynchw​=NHW1​n=1∑N​h=1∑H​w=1∑W​(ynchw​−μc​)2=γ(σc​ynchw​−μc​​)+β​ LN为对批次中每一个样本做归一化：μn=1CHW∑c=1C∑h=1H∑w=1Wynchwσn2=1CHW∑c=1C∑h=1H∑w=1W(ynchw−μn)2ynchw′=γ(ynchw−μnσn)+β\\begin{align*} \\mu_{n} &amp;= \\frac{1}{CHW}\\sum\\limits_{c=1}^{C}\\sum\\limits_{h=1}^{H}\\sum\\limits_{w=1}^{W}y_{nchw} \\\\ \\sigma_{n}^{2} &amp;= \\frac{1}{CHW}\\sum\\limits_{c=1}^{C}\\sum\\limits_{h=1}^{H}\\sum\\limits_{w=1}^{W}(y_{nchw} - \\mu_{n})^{2} \\\\ y&#x27;_{nchw} &amp;= \\gamma(\\frac{y_{nchw} - \\mu_{n}}{\\sigma_{n}}) + \\beta \\end{align*} μn​σn2​ynchw′​​=CHW1​c=1∑C​h=1∑H​w=1∑W​ynchw​=CHW1​c=1∑C​h=1∑H​w=1∑W​(ynchw​−μn​)2=γ(σn​ynchw​−μn​​)+β​ IN为对样本的特征做归一化：μnc=1HW∑h=1H∑w=1Wynchwσnc2=1HW∑h=1H∑w=1W(ynchw−μnc)2ynchw′=γ(ynchw−μncσnc)+β\\begin{align*} \\mu_{nc} &amp;= \\frac{1}{HW}\\sum\\limits_{h=1}^{H}\\sum\\limits_{w=1}^{W}y_{nchw} \\\\ \\sigma_{nc}^{2} &amp;= \\frac{1}{HW}\\sum\\limits_{h=1}^{H}\\sum\\limits_{w=1}^{W}(y_{nchw} - \\mu_{nc})^{2} \\\\ y&#x27;_{nchw} &amp;= \\gamma(\\frac{y_{nchw} - \\mu_{nc}}{\\sigma_{nc}}) + \\beta \\end{align*} μnc​σnc2​ynchw′​​=HW1​h=1∑H​w=1∑W​ynchw​=HW1​h=1∑H​w=1∑W​(ynchw​−μnc​)2=γ(σnc​ynchw​−μnc​​)+β​ GN是对样本的一组特征做归一化： 首先将[N, C, H, W]划分为[N, G, S, H, W]，之后：μng=1SHW∑s=1S∑h=1H∑w=1Wyngshwσng2=1SHW∑s=1S∑h=1H∑w=1W(yngshw−μng)2yngshw′=γ(yngshw−μngσng)+β\\begin{align*} \\mu_{ng} &amp;= \\frac{1}{SHW}\\sum\\limits_{s=1}^{S}\\sum\\limits_{h=1}^{H}\\sum\\limits_{w=1}^{W}y_{ngshw} \\\\ \\sigma_{ng}^{2} &amp;= \\frac{1}{SHW}\\sum\\limits_{s=1}^{S}\\sum\\limits_{h=1}^{H}\\sum\\limits_{w=1}^{W}(y_{ngshw} - \\mu_{ng})^{2} \\\\ y&#x27;_{ngshw} &amp;= \\gamma(\\frac{y_{ngshw} - \\mu_{ng}}{\\sigma_{ng}}) + \\beta \\end{align*} μng​σng2​yngshw′​​=SHW1​s=1∑S​h=1∑H​w=1∑W​yngshw​=SHW1​s=1∑S​h=1∑H​w=1∑W​(yngshw​−μng​)2=γ(σng​yngshw​−μng​​)+β​ 当G=1G = 1G=1的时候，GN退化为LN；当G=CG = CG=C的时候，GN退化为IN 一般来说，LN更适用于数据量小、批大小更小的时候","tags":["Diffusion","Transformer","Attention","Speed up"],"categories":["科研"]},{"title":"自顶向下语法分析","path":"/2024/10/12/自顶向下语法分析/","content":"编译原理 笔记 1 自顶向下语法分析 自顶向下的核心思想是从文法的开始符号出发，每一步推导得到一个句型，最终产生一个句子即为期待的终结符串 带回溯的自顶向下分析 由于每一步推导的终结符串和使用的文法都是不确定的，因此复杂度很高，只能进行不断回溯，因此我们进行改进：每步推导总是用最左边的非终结符，产生最左推导，如果想进一步确认使用的文法，则需改进为： 确定的自顶向下分析 在从左向右扫描的过程中，向前查看常数个的单词，以确定每一步使用的文法 例如对于文法GGG： S→ABA→aA∣ϵB→b∣bB\\begin{align*} S &amp;\\to AB \\\\ A &amp;\\to aA | \\epsilon \\\\ B &amp;\\to b | bB \\end{align*} SAB​→AB→aA∣ϵ→b∣bB​ 则在自顶向下分析anbm(n≥0,m&gt;0)a^{n}b^{m}(n\\geq 0, m &gt; 0)anbm(n≥0,m&gt;0)时，只需要向前查看2个单词，即可预测每步所应该使用的文法 如果想要实现这种分析，需要保证文法不含左递归与左公因子，否则： 考虑文法GGG： S→Sa∣b\\begin{align*} S &amp;\\to Sa | b \\end{align*} S​→Sa∣b​ 则在分析banba^{n}ban时需要向前看的单词数为n+2n + 2n+2个 考虑文法GGG： S→aAb∣aAcA→a∣aA\\begin{align*} S &amp;\\to aAb | aAc \\\\ A &amp;\\to a | aA \\end{align*} SA​→aAb∣aAc→a∣aA​ 则在分析an(b+c)a^{n}(b + c)an(b+c)时需要向前看的单词数为n+2n + 2n+2个 都不为常数，无法确定地分析 LL(1) 分析 最常用的预测分析方法，要求文法是LL(1)文法 从左向右扫描单词 每步产生最左推导 向前看一个单词 重要的集合 First集合 First集合定义为： 设G=(VT,VN,P,S)G = (V_{T}, V_{N}, P, S)G=(VT​,VN​,P,S)是上下文无关文法，则对α∈(VT∪VN)∗\\alpha \\in (V_{T}\\cup V_{N})^{*}α∈(VT​∪VN​)∗：First(α)={a ∣ α⇒∗aβ, a∈VT,β∈(VT∪VN)∗ or a=β=ϵ}\\mathrm{First}(\\alpha) = \\{a\\,|\\, \\alpha \\Rightarrow^{*} a\\beta,\\, a\\in V_{T}, \\beta\\in(V_{T}\\cup V_{N})^{*}\\text{ or } a = \\beta = \\epsilon\\}First(α)={a∣α⇒∗aβ,a∈VT​,β∈(VT​∪VN​)∗ or a=β=ϵ} 即任意句型或句子的First是指这个句型或句子能推导出的串中首个单词的集合 First(α)\\mathrm{First}(\\alpha)First(α)计算过程为： 先置所有First(α)=∅\\mathrm{First}(\\alpha) = \\varnothingFirst(α)=∅ 若α∈VT∪{ϵ}\\alpha \\in V_{T}\\cup \\{\\epsilon\\}α∈VT​∪{ϵ}，则First(α)={α}\\mathrm{First}(\\alpha) = \\{\\alpha\\}First(α)={α} 若α=X1X2…Xk∈(VT∪VN)∗\\alpha = X_{1}X_{2}\\dots X_{k} \\in (V_{T} \\cup V_{N})^{*}α=X1​X2​…Xk​∈(VT​∪VN​)∗，则先置First(α)=First(X1)\\mathrm{First}(\\alpha) = \\mathrm{First}(X_{1})First(α)=First(X1​) 遍历XiX_{i}Xi​，若X1…Xi⇒∗ϵX_{1}\\dots X_{i} \\Rightarrow^{*} \\epsilonX1​…Xi​⇒∗ϵ 则First(α)∪=First(Xi+1)\\mathrm{First}(\\alpha) \\cup= \\mathrm{First}(X_{i + 1})First(α)∪=First(Xi+1​)，其中Xk+1=ϵX_{k + 1} = \\epsilonXk+1​=ϵ 若α∈VN\\alpha \\in V_{N}α∈VN​，且α→X1X2…Xk\\alpha \\to X_{1}X_{2}\\dots X_{k}α→X1​X2​…Xk​， 则First(α)∪=First(X1X2…Xk)\\mathrm{First}(\\alpha) \\cup= \\mathrm{First}(X_{1}X_{2}\\dots X_{k})First(α)∪=First(X1​X2​…Xk​) Follow集合 Follow集合定义为： 设G=(VT,VN,P,S)G = (V_{T}, V_{N}, P, S)G=(VT​,VN​,P,S)是上下文无关文法，则对A∈VNA\\in V_{N}A∈VN​：Follow(A)={a ∣ S#⇒∗αAβ#, a∈First(β#),α,β∈(VT∪VN)∗}\\mathrm{Follow}(A) = \\{a\\,|\\, S\\# \\Rightarrow^{*} \\alpha A\\beta\\#,\\, a\\in \\mathrm{First}(\\beta\\#), \\alpha, \\beta\\in(V_{T}\\cup V_{N})^{*}\\}Follow(A)={a∣S#⇒∗αAβ#,a∈First(β#),α,β∈(VT​∪VN​)∗} 也即Follow集合被定义为可能在某些句型中紧跟在AAA右边的终结符集合 Follow(A)\\mathrm{Follow}(A)Follow(A)的计算方法为： 置Follow(S)={#}\\mathrm{Follow}(S) = \\{\\#\\}Follow(S)={#}，其他均为∅\\varnothing∅ 循环直到所有集合不变： 对于A→αBβA\\to \\alpha B \\betaA→αBβ，Follow(B)∪=First(β)−{ϵ}\\mathrm{Follow}(B) \\cup= \\mathrm{First}(\\beta) - \\{\\epsilon\\}Follow(B)∪=First(β)−{ϵ} 若ϵ∈First(β)\\epsilon \\in \\mathrm{First}(\\beta)ϵ∈First(β)，则Follow(B)∪=Follow(A)\\mathrm{Follow}(B) \\cup= \\mathrm{Follow}(A)Follow(B)∪=Follow(A) 预测集合 预测集合的定义为： 设G=(VT,VN,P,S)G = (V_{T}, V_{N}, P, S)G=(VT​,VN​,P,S)是上下文无关文法，则对A→α∈PA\\to \\alpha \\in PA→α∈P：PS(A→α)={First(α)ϵ∉First(α)(First(α)−{ϵ})∪Follow(A)ϵ∈First(α)\\mathrm{PS}(A\\to \\alpha) = \\begin{cases} \\mathrm{First}(\\alpha) &amp; \\epsilon otin \\mathrm{First}(\\alpha) \\\\ (\\mathrm{First}(\\alpha) - \\{\\epsilon\\}) \\cup \\mathrm{Follow}(A) &amp; \\epsilon \\in \\mathrm{First}(\\alpha)\\end{cases}PS(A→α)={First(α)(First(α)−{ϵ})∪Follow(A)​ϵ∈/First(α)ϵ∈First(α)​ 预测集合给出了读入了什么字符的时候需要采用产生式A→αA\\to \\alphaA→α LL(1)文法 文法GGG是LL(1)文法当且仅当对于GGG的每个非终结符AAA的任何两个不同产生式A→α∣βA\\to \\alpha | \\betaA→α∣β，满足：PS(A→α)∩PS(A→β)=∅\\mathrm{PS}(A\\to\\alpha) \\cap \\mathrm{PS}(A\\to\\beta) = \\varnothingPS(A→α)∩PS(A→β)=∅ 递归下降LL(1)分析程序 每个非终结符对应一个子程序，每个子程序的行为根据语法描述来明确： 根据当前非终结符的PS集合与下一个输入符号选择产生式 如果产生式右端遇到非终结符，则调用相应的子程序 如果产生式右端遇到终结符，判断当前读入的单词是否与该终结符相匹配，匹配则继续读取，反之报错 递归下降分析 实际应用中，可以将产生式的右端添加新运算，使之更加简洁，例如将S→XSS→ϵS\\to XS\\quad S \\to \\epsilonS→XSS→ϵ替换为S→{X}S\\to \\{X\\}S→{X}等，具体来说： {X}=X∗\\{X\\} = X^{*}{X}=X∗ [X]=X ∣ ϵ[X] = X \\,|\\, \\epsilon[X]=X∣ϵ (X)(X)(X)代表XXX优先 表驱动LL(1)分析程序 由PS集合形成一个预测分析表，即根据非终结符和下一个单词决定产生式的表，并利用该表和一个下推栈实现： 将#\\##和SSS依次入栈 若栈顶为终结符，则判断读入的单词和终结符是否匹配，匹配则出栈并继续读取，反之报错 若栈顶为非终结符，则查表找到产生式，若为None则报错，反之非终结符出栈，产生式右端从右至左依次入栈，无需继续读入 直到栈顶和下一位输入都是#\\## 可以证明，预测分析表的每一项都只包含一个产生式，当且仅当文法是LL(1)的 文法变换 主要包含消除左递归与提取左公因子两种，通常用于将一些文法转换成LL(1)文法 消除左递归 消除直接左递归 对P→Pα ∣ βP \\to P\\alpha\\,|\\,\\betaP→Pα∣β，α≠ϵ\\alpha eq\\epsilonα=ϵ且β\\betaβ首字符不是PPP，则消除方法为引入新终结符QQQ使得： P→βQQ→αQ ∣ ϵ\\begin{align*} P &amp;\\to \\beta Q \\\\ Q &amp;\\to \\alpha Q \\,|\\, \\epsilon \\end{align*} PQ​→βQ→αQ∣ϵ​ 对于一般形式P→Pα1 ∣ … ∣ Pαm ∣ β1 ∣ … ∣ βnP \\to P\\alpha_{1}\\,|\\,\\dots\\,|\\,P\\alpha_{m}\\,|\\,\\beta_{1}\\,|\\,\\dots\\,|\\,\\beta_{n}P→Pα1​∣…∣Pαm​∣β1​∣…∣βn​，则： P→β1Q ∣ … ∣ βmQQ→α1Q ∣ … ∣ αnQ ∣ ϵ\\begin{align*} P &amp;\\to \\beta_{1}Q\\,|\\,\\dots\\,|\\, \\beta_{m}Q \\\\ Q &amp;\\to \\alpha_{1}Q \\,|\\,\\dots\\,|\\,\\alpha_{n}Q\\,|\\, \\epsilon \\end{align*} PQ​→β1​Q∣…∣βm​Q→α1​Q∣…∣αn​Q∣ϵ​ 消除一般左递归 对于无环无ϵ\\epsilonϵ产生式的文法，消除一般左递归的方法为： 排列非终结符A1,A2,…,AnA_{1}, A_{2}, \\dots, A_{n}A1​,A2​,…,An​ for i in 1..n: for j in 1..(i-1): 对于形如Ai→AjrA_{i} \\to A_{j}rAi​→Aj​r的规则 其中AjA_{j}Aj​的全部产生式为Aj→α1 ∣ α2 ∣ … ∣ αkA_{j} \\to \\alpha_{1}\\,|\\,\\alpha_{2}\\,|\\,\\dots\\,|\\,\\alpha_{k}Aj​→α1​∣α2​∣…∣αk​ 将AiA_{i}Ai​产生式替换为Ai→α1r ∣ α2r ∣ … ∣ αkrA_{i} \\to \\alpha_{1}r\\,|\\,\\alpha_{2}r\\,|\\,\\dots\\,|\\,\\alpha_{k}rAi​→α1​r∣α2​r∣…∣αk​r 再消除AiA_{i}Ai​的直接左递归 化简文法 提取左公因子 对于形如P→αβ ∣ αγP\\to \\alpha\\beta \\,|\\, \\alpha\\gammaP→αβ∣αγ的产生式，增加新终结符使得： P→αQQ→β ∣ γ\\begin{align*} P &amp;\\to \\alpha Q \\\\ Q &amp;\\to \\beta \\,|\\, \\gamma \\end{align*} PQ​→αQ→β∣γ​ 一般化为P→αβ1 ∣ … ∣ αβm ∣ γ1 ∣ … ∣ γnP\\to \\alpha\\beta_{1}\\,|\\,\\dots\\,|\\,\\alpha\\beta_{m}\\,|\\,\\gamma_{1}\\,|\\,\\dots\\,|\\,\\gamma_{n}P→αβ1​∣…∣αβm​∣γ1​∣…∣γn​： P→αQ ∣ γ1 ∣ … ∣ γnQ→β1 ∣ … ∣ βm\\begin{align*} P &amp;\\to \\alpha Q\\,|\\,\\gamma_{1}\\,|\\,\\dots\\,|\\,\\gamma_{n} \\\\ Q &amp;\\to \\beta_{1} \\,|\\,\\dots\\,|\\, \\beta_{m} \\end{align*} PQ​→αQ∣γ1​∣…∣γn​→β1​∣…∣βm​​ 预测分析中的出错处理 处理原则： 尽可能准确地给出错误位置与属性 尽可能校正 表驱动LL(1)分析中的错误处理 对于栈顶终结符与输入不匹配，直接弹出终结符 对于栈顶非终结符与输入符号在表中找不到产生式，我们采用恐慌模式，即跳过一些符号以找到同步符号 同步符号集合的构建为： Follow(A)\\mathrm{Follow}(A)Follow(A)中的所有符号都是AAA的同步符号 将First(B)\\mathrm{First}(B)First(B)中的符号加入AAA同步符号，代表AAA遇到错误的时候可以从BBB开始继续分析 递归下降分析的错误处理 当递归进入某个语法单位的时候，检查当前符号是否属于该单位的开始符号，离开该语法单位的时候检查符号是否属于该单位的结束符号 若不属于则不断滤去直到到达补救集合（即开始符号与结束符号的并集）中的符号并重新判断 递归下降分析错误处理 LL(k)的结论 LL(k)文法的定义是LL(1)的推广，有关的结论有： 给定k&gt;0k&gt;0k&gt;0，一个CFG是否为LL(k)是可判定的 给定CFG，是否存在kkk使得该文法是LL(k)是不可判定的 给定CFG，是否存在与之等价的LL(k)是不可判定的 两个LL(k)是否相等是可判定的 LL(k)无二义 LL(k)中不存在左递归 给定k&gt;0k&gt;0k&gt;0，不含ϵ\\epsilonϵ产生式的LL(k)的集合真包含于不含ϵ\\epsilonϵ产生式的LL(k+1)的集合","tags":["笔记","编原","语法分析","自顶向下"],"categories":["编译原理"]},{"title":"计算机组成原理2","path":"/2024/10/10/计算机组成原理2/","content":"计算机组成原理 笔记 2 #TODO","tags":["笔记","计组"],"categories":["计算机组成原理"]},{"title":"信号处理原理 3","path":"/2024/10/08/信号处理原理3/","content":"信号处理原理 笔记 3 信号的分解 信号的分解方法 直流与交流分解 fDC(t)=lim⁡T→∞∫−T/2T/2f(t)dtfAC(t)=f(t)−fDC(t)\\begin{align*} f_{DC}(t) &amp;= \\lim\\limits_{T\\to\\infty}\\int_{-T/2}^{T/2}f(t)dt \\\\ f_{AC}(t) &amp;= f(t) - f_{DC}(t) \\end{align*} fDC​(t)fAC​(t)​=T→∞lim​∫−T/2T/2​f(t)dt=f(t)−fDC​(t)​ 奇偶分解 fe(t)=f(t)+f(−t)2fo(t)=f(t)−f(−t)2\\begin{align*} f_{e}(t) &amp;= \\frac{f(t) + f(-t)}{2} \\\\ f_{o}(t) &amp;= \\frac{f(t) - f(-t)}{2} \\end{align*} fe​(t)fo​(t)​=2f(t)+f(−t)​=2f(t)−f(−t)​​ 复分解 Re(f(t))=f(t)+f(t)‾2Im(f(t))=f(t)−f(t)‾2j\\begin{align*} \\mathrm{Re}(f(t)) &amp;= \\frac{f(t) + \\overline{f(t)}}{2} \\\\ \\mathrm{Im}(f(t)) &amp;= \\frac{f(t) - \\overline{f(t)}}{2j} \\end{align*} Re(f(t))Im(f(t))​=2f(t)+f(t)​​=2jf(t)−f(t)​​​ 脉冲分解 TODO 信号的正交分解 当f(t)f(t)f(t)在[t1,t2][t_{1}, t_{2}][t1​,t2​]区间内具有连续一阶导数和逐段连续的二阶导数时，f(t)f(t)f(t)可以用完备的正交函数集{φi(t)}\\{\\varphi_{i}(t)\\}{φi​(t)}来表示，即： f(t)=∑i=1∞ciφi(t)f(t) = \\sum\\limits_{i=1}^{\\infty}c_{i}\\varphi_{i}(t) f(t)=i=1∑∞​ci​φi​(t) 定义ki=⟨φi(t),φi(t)⟩k_{i} = \\langle\\varphi_{i}(t), \\varphi_{i}(t)\\rangleki​=⟨φi​(t),φi​(t)⟩ 则常数cic_{i}ci​的定义为： ci=1ki⟨f(t),φi(t)⟩ c_{i} = \\frac{1}{k_{i}}\\langle f(t), \\varphi_{i}(t)\\rangle ci​=ki​1​⟨f(t),φi​(t)⟩ 我们有帕斯瓦尔定理： ∫t1t2∣∣f(t)∣∣2dt=∑i=1∞∣∣ci∣∣2ki\\int_{t_{1}}^{t_{2}}||f(t)||^{2}dt = \\sum\\limits_{i=1}^{\\infty}||c_{i}||^{2}k_{i} ∫t1​t2​​∣∣f(t)∣∣2dt=i=1∑∞​∣∣ci​∣∣2ki​ 周期信号的正交分解 满足Dirchlet条件的周期函数都可以在一组完备正交基函数上展开为无穷级数 Dirchlet条件为： 间断点个数有限 极值点个数有限 绝对积分数值有限 当完备正交基函数为三角函数集或指数函数集的时候，展成的级数称为Fourier级数 Fourier级数 三角Fourier 设f(t)f(t)f(t)周期为T1T_{1}T1​，令ω1=2π/T1\\omega_{1} = 2\\pi/T_{1}ω1​=2π/T1​，则Fourier级数为： f(t)=a0+∑n=1∞(ancos⁡nω1t+bnsin⁡nω1t)f(t) = a_{0} + \\sum\\limits_{n=1}^{\\infty}(a_{n}\\cos n\\omega_{1}t + b_{n}\\sin n\\omega_{1}t) f(t)=a0​+n=1∑∞​(an​cosnω1​t+bn​sinnω1​t) 积分变换为： a0=1T1∫t0t0+T1f(t)dtan=2T1∫t0t0+T1f(t)cos⁡(nω1t)dtbn=2T1∫t0t0+T1f(t)sin⁡(nω1t)dt\\begin{align*} a_{0} &amp;= \\frac{1}{T_{1}}\\int_{t_{0}}^{t_{0} + T_{1}}f(t)dt \\\\ a_{n} &amp;= \\frac{2}{T_{1}}\\int_{t_{0}}^{t_{0} + T_{1}}f(t)\\cos(n\\omega_{1}t)dt \\\\ b_{n} &amp;= \\frac{2}{T_{1}}\\int_{t_{0}}^{t_{0} + T_{1}}f(t)\\sin(n\\omega_{1}t)dt \\end{align*} a0​an​bn​​=T1​1​∫t0​t0​+T1​​f(t)dt=T1​2​∫t0​t0​+T1​​f(t)cos(nω1​t)dt=T1​2​∫t0​t0​+T1​​f(t)sin(nω1​t)dt​ 复指数Fourier 对三角Fouier利用欧拉函数进行转换，可以得到复指数形式的Fourier级数： f(t)=a0+∑n=1∞[an−jbn2ejnω1t+an+jbn2e−jnω1t]f(t) = a_{0} + \\sum\\limits_{n=1}^{\\infty}\\bigl[ \\frac{a_{n}-jb_{n}}{2}e^{jn\\omega_{1}t} + \\frac{a_{n}+jb_{n}}{2}e^{-jn\\omega_{1}t} \\bigr] f(t)=a0​+n=1∑∞​[2an​−jbn​​ejnω1​t+2an​+jbn​​e−jnω1​t] 定义： Fn={a0n=0F(nω1)=an−jbn2n∈Z/{0}F_{n} = \\begin{cases} a_{0} &amp; n = 0\\\\ F(n\\omega_{1}) = \\dfrac{a_{n} - jb_{n}}{2} &amp; n \\in \\mathbb{Z}/\\{0\\} \\end{cases} Fn​=⎩⎨⎧​a0​F(nω1​)=2an​−jbn​​​n=0n∈Z/{0}​ 则有： f(t)=∑n=−∞∞Fnejnω1tf(t) = \\sum\\limits_{n = -\\infty}^{\\infty}F_{n}e^{jn\\omega_{1}t} f(t)=n=−∞∑∞​Fn​ejnω1​t 其中： Fn=1T1∫T1f(t)e−jnω1tdtF_{n} = \\frac{1}{T_{1}}\\int_{T_{1}}f(t)e^{-jn\\omega_{1}t}dt Fn​=T1​1​∫T1​​f(t)e−jnω1​tdt Fouier频谱 考虑Fouier复系数{Fn}\\{F_{n}\\}{Fn​}，则为了表示这个复系数序列可以得到两张频谱： 幅度谱 ∣Fn∣|F_{n}|∣Fn​∣ 相位谱 Arg(Fn)\\mathrm{Arg}(F_{n})Arg(Fn​) 周期信号的Fouier频谱特点为： 仅在离散点n=kω1n = k\\omega_{1}n=kω1​处有值，为谐波 FnF_{n}Fn​是双边谱，也即正负频率的频率幅度相加才是实际幅度 信号的功率为∑n=−∞∞∣Fn∣2\\sum\\limits_{n=-\\infty}^{\\infty}|F_{n}|^{2}n=−∞∑∞​∣Fn​∣2 周期矩形脉冲信号 脉宽为τ\\tauτ，幅度为EEE，周期为T1T_{1}T1​ 周期矩形脉冲信号的FS 包络线为EτT1Sa(ωτ2)\\dfrac{E\\tau}{T_{1}}Sa(\\dfrac{\\omega\\tau}{2})T1​Eτ​Sa(2ωτ​) 可以看出，周期信号的能量主要集中在第一个零点以内，即∣ω∣≤2πτ|\\omega| \\leq \\dfrac{2\\pi}{\\tau}∣ω∣≤τ2π​内，因此这段频率范围被称为矩形信号的频带宽度，在允许失真的情况下可以只用这一段进行通信 信号的正交分解 信号的级数展开 用一组函数φi(t)\\varphi_{i}(t)φi​(t)将信号x(t)∈L2(R)x(t)\\in L^{2}(R)x(t)∈L2(R)展开成级数： x(t)=∑i=−∞∞ciφi(t)x(t) = \\sum\\limits_{i=-\\infty}^{\\infty}c_{i}\\varphi_{i}(t) x(t)=i=−∞∑∞​ci​φi​(t) 求出cic_{i}ci​的过程称为信号变换 正交变换 若基函数φi(t)\\varphi_{i}(t)φi​(t)为标准完备正交基，则积分变换为： ci=∫t1t2x(t)φi(t)‾dtc_{i} = \\int_{t_{1}}^{t_{2}}x(t)\\overline{\\varphi_{i}(t)}dt ci​=∫t1​t2​​x(t)φi​(t)​dt 称为x(t)x(t)x(t)的正交变换，亦称为Karhunen-Loeve变换 非周期信号的Fouier变换 非周期信号可以看成T→∞T\\to\\inftyT→∞的周期信号，于是其频谱会变化为连续频谱，也即ω1→0Fn→0\\omega_{1}\\to 0\\quad F_{n}\\to 0ω1​→0Fn​→0 我们将非周期信号的FT定义为： F(ω)=∫Rf(t)e−jωtdtF(\\omega) = \\int_{\\mathbb{R}}f(t)e^{-j\\omega t}dt F(ω)=∫R​f(t)e−jωtdt 逆Fourier变换定义为IFT: f(t)=12π∫RF(ω)ejωtdωf(t) = \\frac{1}{2\\pi}\\int_{\\mathbb{R}}F(\\omega)e^{j\\omega t}d\\omega f(t)=2π1​∫R​F(ω)ejωtdω 上式可写成，F(ω)=∣F(ω)∣ejφ(ω)F(\\omega) = |F(\\omega)|e^{j\\varphi(\\omega)}F(ω)=∣F(ω)∣ejφ(ω)，其中∣F(ω)∣|F(\\omega)|∣F(ω)∣为幅度频谱密度函数，φ(ω)\\varphi(\\omega)φ(ω)为相位频谱密度函数 FT性质 唯一性：FT与IFT可以分别确定唯一的函数 可逆性： F[f(t)]=F(ω)⇔F−1[F(ω)]=f(t)\\mathscr{F}[f(t)] = F(\\omega) \\Leftrightarrow \\mathscr{F}^{-1}[F(\\omega)] = f(t)F[f(t)]=F(ω)⇔F−1[F(ω)]=f(t) FT与FS的关系 将非周期信号f(t)f(t)f(t)做周期延拓，即时移并叠加，可得到一个周期信号f~(t)\\tilde{f}(t)f~​(t)，令其周期为T1T_{1}T1​，则我们有： Fn=1T1∫−T1/2T1/2f~(t)e−jnω1tdt=1T1∫Rf(t)e−jnω1tdtF(ω)=∫Rf(t)e−jωtdt\\begin{align*} F_{n} &amp;= \\frac{1}{T_{1}}\\int_{-T_{1}/2}^{T_{1}/2}\\tilde{f}(t)e^{-jn\\omega_{1}t}dt \\\\ &amp;= \\frac{1}{T_{1}}\\int_{\\mathbb{R}}f(t)e^{-jn\\omega_{1}t}dt \\\\ F(\\omega) &amp;= \\int_{\\mathbb{R}}f(t)e^{-j\\omega t}dt \\end{align*} Fn​F(ω)​=T1​1​∫−T1​/2T1​/2​f~​(t)e−jnω1​tdt=T1​1​∫R​f(t)e−jnω1​tdt=∫R​f(t)e−jωtdt​ 于是可以得到： Fn=1T1F(nω1)F_{n} = \\frac{1}{T_{1}}F(n\\omega_{1})Fn​=T1​1​F(nω1​) 这代表着我们可以从波形图上较为简单的在周期信号的FS与非周期信号的FT之间进行计算 周期信号至非周期信号：连接包络线，之后整体扩展T1T_{1}T1​倍 非周期信号至周期信号：离散化，只取nω1n\\omega_{1}nω1​处的点，并缩小1T1\\frac{1}{T_{1}}T1​1​ 典型信号的FT 矩形脉冲信号 信号为： f(t)=EGτ(t)f(t) = EG_{\\tau}(t) f(t)=EGτ​(t) 其FT为： F(ω)=Eτ⋅Sa(τ2ω)F(\\omega) = E\\tau\\cdot Sa(\\frac{\\tau}{2}\\omega) F(ω)=Eτ⋅Sa(2τ​ω) 冲激信号 F[Eδ(t)]=∫REδ(t)e−jωtdt=E\\mathscr{F}[E\\delta(t)] = \\int_{\\mathbb{R}}E\\delta(t)e^{-j\\omega t}dt = E F[Eδ(t)]=∫R​Eδ(t)e−jωtdt=E 也即频谱为常数，被称为白色谱 三角信号 F[cos⁡ω0t]=F[ejω0t+e−jω0t2]=πδ(ω−ω0)+πδ(ω+ω0)\\begin{align*} \\mathscr{F}[\\cos \\omega_{0}t] &amp;= \\mathscr{F}[\\frac{e^{j\\omega_{0}t} + e^{-j\\omega_{0}t}}{2}] \\\\ &amp;= \\pi\\delta(\\omega - \\omega_{0}) + \\pi\\delta(\\omega + \\omega_{0}) \\end{align*} F[cosω0​t]​=F[2ejω0​t+e−jω0​t​]=πδ(ω−ω0​)+πδ(ω+ω0​)​ 一些性质 常数的频谱 F[ejω0t]=2πδ(ω−ω0)F[12π]=δ(ω)\\begin{align*} \\mathscr{F}[e^{j\\omega_{0}t}] &amp;= 2\\pi\\delta(\\omega - \\omega_{0}) \\\\ \\mathscr{F}[\\frac{1}{2\\pi}] &amp;= \\delta(\\omega) \\end{align*} F[ejω0​t]F[2π1​]​=2πδ(ω−ω0​)=δ(ω)​ 证明的关键点为： F−1(δ(ω))=12π∫Rδ(ω)ejωtdω=12π\\mathscr{F}^{-1}(\\delta(\\omega)) = \\frac{1}{2\\pi}\\int_{\\mathbb{R}}\\delta(\\omega)e^{j\\omega t}d\\omega = \\frac{1}{2\\pi} F−1(δ(ω))=2π1​∫R​δ(ω)ejωtdω=2π1​ 线性 F\\mathscr{F}F是线性运算 反褶与共轭 F(f(−t))=F(−ω)F(f∗(t))=F∗(−ω)F(f∗(−t))=F∗(ω)\\begin{align*} \\mathscr{F}(f(-t)) &amp;= F(-\\omega) \\\\ \\mathscr{F}(f^{*}(t)) &amp;= F^{*}(-\\omega) \\\\ \\mathscr{F}(f^{*}(-t)) &amp;= F^{*}(\\omega) \\end{align*} F(f(−t))F(f∗(t))F(f∗(−t))​=F(−ω)=F∗(−ω)=F∗(ω)​ 对偶性 F−1[F(ω)]=12πFω∗[F∗(ω)]\\mathscr{F}^{-1}[F(\\omega)] = \\frac{1}{2\\pi}\\mathscr{F}_{\\omega}^{*}[F^{*}(\\omega)] F−1[F(ω)]=2π1​Fω∗​[F∗(ω)] 而FT和IFT的对偶性可以表示为： F(t)⇔2πf(−ω)F(t) \\Leftrightarrow 2\\pi f(-\\omega) F(t)⇔2πf(−ω) 尺度变换特性 F[f(at)]=1∣a∣F(ωa)\\mathscr{F}[f(at)] = \\frac{1}{|a|}F(\\frac{\\omega}{a}) F[f(at)]=∣a∣1​F(aω​) 等效性 对任意信号f(t)⇔F(ω)f(t)\\Leftrightarrow F(\\omega)f(t)⇔F(ω)，设f(0)f(0)f(0)与F(0)F(0)F(0)分别为最大值，则可定义： 等效脉宽τ=F(0)/f(0)\\tau = F(0) / f(0)τ=F(0)/f(0) 等效带宽Bf=f(0)/F(0)B_{f} = f(0) / F(0)Bf​=f(0)/F(0) 波形运算特性 F[f(t−t0)]=F(ω)e−jωt0F[f(at−t0)]=1∣a∣F(ωa)e−jωt0aF[f(t)ejω0t]=F(ω−ω0)F[1∣a∣f(ta)ejω0at]=F(aω−ω0)\\begin{align*} \\mathscr{F}[f(t-t_{0})] &amp;= F(\\omega)e^{-j\\omega t_{0}} \\\\ \\mathscr{F}[f(at-t_{0})] &amp;= \\frac{1}{|a|}F(\\frac{\\omega}{a})e^{-j\\omega \\frac{t_{0}}{a}} \\\\ \\mathscr{F}[f(t)e^{j\\omega_{0}t}] &amp;= F(\\omega - \\omega_{0}) \\\\ \\mathscr{F}[\\frac{1}{|a|}f(\\frac{t}{a})e^{j\\frac{\\omega_{0}}{a}t}] &amp;= F(a\\omega - \\omega_{0}) \\end{align*} F[f(t−t0​)]F[f(at−t0​)]F[f(t)ejω0​t]F[∣a∣1​f(at​)ejaω0​​t]​=F(ω)e−jωt0​=∣a∣1​F(aω​)e−jωat0​​=F(ω−ω0​)=F(aω−ω0​)​ 微积分特性 df(t)dt⇔jωF(ω)dF(ω)sω⇔−jtf(t)∫−∞tf(τ)dτ⇔(jω)−1F(ω)+πF(0)δ(ω)∫−∞ωF(λ)dλ⇔πf(0)δ(t)−(jt)−1f(t)\\begin{align*} \\frac{df(t)}{dt} &amp;\\Leftrightarrow j\\omega F(\\omega) \\\\ \\frac{dF(\\omega)}{s\\omega} &amp;\\Leftrightarrow -jtf(t) \\\\ \\int_{-\\infty}^{t}f(\\tau)d\\tau &amp;\\Leftrightarrow (j\\omega)^{-1}F(\\omega) + \\pi F(0)\\delta(\\omega) \\\\ \\int_{-\\infty}^{\\omega}F(\\lambda)d\\lambda &amp;\\Leftrightarrow \\pi f(0)\\delta(t) - (jt)^{-1}f(t) \\end{align*} dtdf(t)​sωdF(ω)​∫−∞t​f(τ)dτ∫−∞ω​F(λ)dλ​⇔jωF(ω)⇔−jtf(t)⇔(jω)−1F(ω)+πF(0)δ(ω)⇔πf(0)δ(t)−(jt)−1f(t)​ 卷积特性 F[f1(t)∗f2(t)]=F[f1(t)]⋅F[f2(t)]F[f1(t)⋅f2(t)]=12πF[f1(t)]∗F[f2(t)]\\begin{align*} \\mathscr{F}[f_{1}(t)*f_{2}(t)] &amp;= \\mathscr{F}[f_{1}(t)] \\cdot \\mathscr{F}[f_{2}(t)] \\\\ \\mathscr{F}[f_{1}(t)\\cdot f_{2}(t)] &amp;= \\frac{1}{2\\pi} \\mathscr{F}[f_{1}(t)] * \\mathscr{F}[f_{2}(t)] \\\\ \\end{align*} F[f1​(t)∗f2​(t)]F[f1​(t)⋅f2​(t)]​=F[f1​(t)]⋅F[f2​(t)]=2π1​F[f1​(t)]∗F[f2​(t)]​","tags":["信原","笔记","数学基础"],"categories":["信号处理原理"]},{"title":"计算机组成原理1","path":"/2024/10/07/计算机组成原理1/","content":"计算机组成原理 笔记 1 计算机组成原理 指令与数据 计算机指令系统 指令是计算机运行的最小的功能单元，计算机的指令系统是该计算机提供的全部指令 指令的功能与分类 算数与逻辑运算指令 加、减、乘、除等 与、或、非、异或等 移位操作指令 算数右移（补符号位）、逻辑右移、逻辑左移、循环左移 数据传送指令 寄存器之间 寄存器与内存间 不同内存之间 输入输出 计算器与外设之间 跳转指令 无条件与条件 调用与返回指令 堆栈操作指令 其它 指令表示 指令 = 操作码 + 操作数或操作数地址（寄存器、内存或外设） 即对哪些数据做什么操作 操作码可以是定长或变长，定长操作码的译码速度更快，变长操作码可以表示的指令更多 指令是定长的，和机器有关 操作码的扩展 显然，操作码的个数会限制指令系统的长度，因此可以对操作码进行扩展，从而支持更多样化的指令 扩展的方式为：充分利用空闲的位置，例如32位机器上，如果有2个8位地址段作为操作数，则有至多16位可以用于表示操作码，而如果只有1个8为地址段作为操作数，则有至多24位可以用于表示操作码 寻址方式 由于操作数可能需要在某一个地址中进行读取，因此需要指定指令系统的寻址方式： 立即数寻址：操作数直接给出，无需寻址 直接寻址：给出内存中的地址 寄存器寻址：给出操作数所存放在的寄存器编号，则addr = (base) 变址寻址：给出寄存器编号和立即数，则addr = (base) + offset 相对寻址：给出地址相对程序计数器PC的偏移 间接寻址：通过上述的某种方式，给出指向操作数的指针的地址 基址寻址：在计算机中设置一个寄存器用于存放固定的基址，指令中给出偏移量 堆栈寻址：利用sp进行寻址（变址寻址的一种） Riscv 指令 Riscv为定长操作码，如下图，从上到下依次为：寄存器型、立即数型、存储型、分支指令、跳转指令、大立即数 RISCV指令格式 由于指令长度为32位，因此U型指令是操作一些长立即数，例如向x1中写入0x12345678等 寄存器 RISCV中的寄存器 算数、位运算、移位指令 用后缀指明操作数的类型，无u代表有符号数，有u代表无符号数，i代表第二个操作数是立即数没有`subi` op dst, src1, src2: R型 opi dst, src, imm: I型 opu dst, src1, src2: R型 操作有： add sub mul div rem neg and or xor not sll srl sra lui reg, imm: U型，加载立即数到指定寄存器的高20位 其中，mul的结果是64位，但是dst指向的是32位，因此乘法指令有如下变体： mul rdl, rs1, rs2 &lt;==&gt; rdl = (rs1 * rs2)[31:0] mulh rdh, rs1, rs2 &lt;==&gt; rdh = (rs1 * rs2)[63:32] mulhu rdh, rs1, rs2 &lt;==&gt; rdh = (unsigned(rs1) * (unsigned)rs2)[63:32] mulhsu rdh, rs1, rs2 &lt;==&gt; rdh = (rs1 * (unsigned)rs2)[63:32] 访存指令 Riscv中有专属的Load/Store指令用于操作内存，其他指令只能操作寄存器，采用变址寻址的方式 l/s reg, offset(base): Load为I型，Store为S型 允许以字节为基本单位进行读写： 一字节：lb, sb 双字节：lh, sh 四字节：lw, sw 注： Riscv是小端 lb lh会做符号扩展，而lbu lhu会做0扩展 分支与跳转 比较指令有： slt rd, rs1, rs2: rd = 1 if rs1 &lt; rs2 else 0: R型 sgt rd, rs1, rs2: rd = 1 if rs1 &gt; rs2 else 0: R型 同理还有snez, seqz与0进行比较 分支跳转指令有： beq rs1, rs2, label: goto label if rs1 == rs2: B型 bne rs1, rs2, label: goto label if rs1 != rs2: B型 同理也有blt bgt等 无条件跳转指令有 jal rd, label: goto label and rd = pc + 4: J型 jalr rd, base, offset: goto [(base) + offset] and rd = pc + 4: J型 伪指令 一些更加直观的指令，会被翻译成上述指令 mv dst, src = addi dst, src, 0 li dst, imm la dst, label ret = jalr x0, x1, 0 函数调用 参数：x10 - x17(a0 - a7)为前8个参数，后面的参数倒序入栈，x1(ra)为返回值 注意需要维护好栈帧指针，并且调用者和被调用者需要维护好对应寄存器 数据表示与纠错 逻辑数据 True: 1 False: 0 字符数据 ASCII编码 占用1字节，表示128个西文字符 ASCII字符集 UNICODE字符集 为每种语言的每个字符设定了统一且唯一的二进制编码，兼容ASCII UTF-8编码 UTF-8编码 变长字符编码，长度由首字节确定 字符除首字节外均以10开头 字符显示 点阵字体：将字符展示在GUI界面中的方式，点阵字体是其中最简单的一种，即利用黑白位图来表示 矢量字体：用多条曲线来表示字符，每条曲线存储一部分关键点，显示的时候平滑连接关键点并填充 数值数据 整数 第一位为符号位，后续为数值位 正数的原=补=反 0有两个原码与反码(±0\\pm 0±0)，仅有1个补码 负数：反码为数值位取反，补码为反码+1 浮点数 浮点数组成为[s, exp, frac]，分别为符号位、阶码（表示方式为移码）与尾码（表示方式为原码） bias = 2^(len(exp) - 1) - 1 exp != 0, exp != 11..11时为规格化数，此时： E = exp - bias M = 1.frac num = (s ? -1 : 1) * M * 2^E exp == 0时为非规格化数，此时： E = 1 - bias M = 0.frac num = (s ? -1 : 1) * M * 2^E exp == 11..11, frac == 0时为inf 其他情况为NaN 浮点数加减： 操作阶码，阶码较小的右移，阶码大的为结果的阶码 尾数加减 规格化处理 舍入操作 检查阶码是否溢出 浮点数乘除： 阶码直接加减 尾数乘除法 规格化处理 舍入操作 检查阶码溢出 检错纠错码 码距指任意两个合法编码之间不同的二进制位数目的最小值，当码距为1的时候无检错能力 常见的检错纠错码有：奇偶校验码、海明校验码与循环冗余校验码 奇偶校验码 在k位数据码之外增加1位校验位，使得其中取值为1的位数总保持为奇数或偶数，码距为2 如偶校验：1101 -&gt; 11101，奇校验1101 -&gt; 01101 电路上来看是取异或即可 海明校验码 并行数据，为k位数据设定r位校验码，使其能够： 能够发现并改正k+r中任意一位出错 能够发现k+r中任意两位同时出错 码距为4 则k与r之间应该满足的关系是： 2r≥k+r+12^{r} \\geq k + r + 12r≥k+r+1：此时即为用2r2^{r}2r个编码分别表示出错的位数或都不出错 2r−1≥k+r2^{r - 1} \\geq k + r2r−1≥k+r：用r−1r - 1r−1为校验码为出错位编码，单独设置一位用于区分是1位还是2位出错（总校验位） 编码方案： 将校验位依次安排在2的幂次位，将数据位依次排布在剩下的位置 将数据位的编号拆分成2的幂的和，则所出现的幂对应位置上校验位负责对该数据位进行校验 校验位的值即为其所校验的数据的异或 总校验位的值为所有数据的异或 译码方案：对收到的数据的数据位再次编码并比较","tags":["笔记","计组","指令系统","数据表示","ALU"],"categories":["计算机组成原理"]},{"title":"从平板到辅助显示器","path":"/2024/10/07/从平板到辅助显示器/","content":"爆改平板ing 某日，某小伙痛定思痛，希望自己在撰写《计算机组成原理》的课程笔记时markdown预览页面不再只占电脑屏幕的25%，于是打开某东某宝某夕夕，搜索“便携式显示屏”并浏览，眼花缭乱，仔细抉择性价比后决定，不买了！ 高质量的价钱和大显示器差不多，但是暂时还不想入大显示器 原本决定利用平板文件传输助手进行文档分屏阅读，但是这有些许堂食，于是乎开始思考能否爆改平板，最终找到了一款免费的平板-&gt;显示器软件 —— Spacedesk Spacedesk 是一款投屏软件，可以将 Windows 系统投屏到 iOS 手机、安卓手机、iPad、iMac 上。（文案来自中文官网） 使用方法： 在你需要显示的设备上下载Spacedesk 在电脑上下载Spacedesk，官网需要科学上网，也可以在Microsoft应用商店下载 将两个设备置于同一局域网下 在PC上运行spacedeskConsole.exe，这里会显示连接的状况与连接方式，左上角显示的是连接接口，如下图 在显示器设备上运行spacedesk，可以看到其是作为Viewer，点击Connect to Primary Machine(Server)右边的+，输入PC上显示的IP地址即可 当然笔者只尝试过这一种连接方式，看上去它还提供了USB等多种方式；并且有的wifi可能会禁止这种内部设备相互通信的行为，此时可以试一下连接接口处显示的各个IP"},{"title":"密码学","path":"/2024/09/25/密码学/","content":"计算机网络安全技术 笔记 1 密码学基础 基本概念 传统加密 = 对称加密 = 单钥加密 安全性的来源是算法本身的保密性 现代加密 = 非对称加密 = 公钥加密 分离了算法与密钥 密码编码学的特征： 加密运算的运算类型： 置换：打乱输入数据的顺序 代换：将输入数据进行映射 所用的密钥数，即发送方与接收方使用的密钥是否相同 处理明文的方法： 块密码 / 分组密码：按组处理数据 流密码 / 序列密码：按比特处理数据 古典密码 代换密码 Caeser密码 对每个字母使用其后方的第3个字母代换 单表代换密码 单表代换代码：只有一张代换表，如Caeser与密钥词代码：设置一个密钥词放在前面，其余按照字母顺序 密钥词代码 Playfair密码 多表代换密码，同样有一个密钥词，按照行优先的方式填充在一个5×55\\times 55×5的矩阵内，剩余部分按顺序填充，i与j当成一个字母 加密方法： 每次加密两个字母，如果两个字母相同则更换后者为填充字，如果只剩一个字母同样填充，如： balloon -&gt; ba lx lo on 字母对落在同一行时，分别循环右移一位 字母对落在同一列时，分别循环下移一位 反之，对换两个字母的列 Hill密码 将字母指定为特定的数字，之后对原文序列做线性变换，因此密钥即为变换矩阵KKK 优势为完全隐藏了单字母的频率特性，并且矩阵越大，隐藏的信息就越多，例如3×33\\times 33×3矩阵隐藏了双字母的频率特性 Vigenere密码 多表代换密码的一种 Vigenere密码表 对于密钥中的每一个字母，在上表中取出其所对应的加密表，之后循环使用密钥中的加密表来为明文进行加密 Vernam密码和一次一密 利用与明文相同长度的密钥进行加密，基于二进制数据而非字节： ci=pi⊕kic_{i} = p_{i} \\oplus k_{i} ci​=pi​⊕ki​ 当kkk完全随机产生的时候，即为一次一密OTP，在理论上是牢不可破的，但是其在实际生活中几乎不可能实现 置换密码 常规的置换方法是按照密钥长度生成一个矩阵，并且按照行优先写入、列优先读出的规则，密钥决定了读出列的顺序 置换密码举例 ENIGMA Enigma结构示意图 三个滚轮对应三次单表代换，反射器负责使得编码和译码的过程完全对称，其并未增加复杂度 每次按下一个明文字母的时候，首先滚轮会转动（可能是左右移位），然后开始按照上面的路径依次读取，最后将结果显示在输出设备上 Enigma滚轮与反射器 破译 基本方法有： 穷举法：暴力，但是不能用于OTP 频率分析法：利用字符的统计特性，例如在英语中最常出现的字母是e，q后方总是跟着u 对称密码 加密与解密使用同样的密钥，因此密钥需要使用私密信道进行分配 对称密钥算法 常见的对称密钥算法简介： DES: Data Encryption Standard IDEA: International Data Encryption Algorithm RC 2/4/5 CAST-128 Blowfish 简化DES 加密算法：输入为一个8位明文组和10位密钥，输出8位密文组 解密算法：输出为一个8位密文组和10位密钥，输出8位明文组 S-DES算法的整体结构 密钥的生成 S-DES算法的整体结构 P10置换定义为[1..10] -&gt; [3, 5, 2, 7, 4, 10, 1, 9, 8, 6] LS-k指前5位与后5位分别循环左移k位 P8定义为[1..10] -&gt; [6, 3, 7, 4, 8, 5, 10, 9] 加密过程 S-DES算法加密过程 初始置换IP(1…8) = (2, 6, 3, 1, 4, 8, 5, 7) 扩展置换E/P(1…4) = (4, 1, 2, 3, 2, 3, 4, 1) ⊕\\oplus⊕代表异或操作 Lk/Rk分别代表左k位与右k为 S盒操作4输入2输出，S盒为4×44\\times 44×4矩阵，输出为123row = 2 * input[0] + input[3]col = 2 * input[1] + input[2]output = &#x27;&#123;0:b&#125;&#x27;.format(S[row][col]) S盒输出置换P4(1…4) = (2, 4, 3, 1) SW为交换左右4位 末尾置换IP−1^{-1}−1(1…8) = (4, 1, 3, 5, 7, 2, 8, 6) Feistel密码 建议使用乘积密码，即依次使用两个或以上的基本密码 交替使用代换和置换 Shannon引入了混淆和扩散来刻画密码系统 扩散是指将明文的统计信息消散在密文中 混淆是指尽量使密文与密钥之间的关系更复杂 Feistel密码结构为： 明文组等分成两部分，经过nnn轮迭代合成密文组 第iii轮输入为前一轮的输出 子密钥由密钥经过相应算法推导出 Feistel密码结构 DES密码 将明文分成64bits大小的块mmm，执行如下操作 DES(m)=IP−1⋅T16⋯T1⋅IP(m)\\mathrm{DES}(m) = \\mathrm{IP}^{-1}\\cdot T_{16} \\cdots T_{1}\\cdot \\mathrm{IP}(m) DES(m)=IP−1⋅T16​⋯T1​⋅IP(m) 密钥的生成步骤为： 拆分为两部分 左移一定位数 进行压缩置换 56bits→48bits\\quad56\\text{bits}\\to 48 \\text{bits}56bits→48bits 每一轮的迭代步骤（即F函数）为： E盒扩展置换32bits→48bits\\quad32\\text{bits}\\to 48\\text{bits}32bits→48bits 与对应轮次密钥异或 S盒代换选择，使用8个6进4出的S盒组成48bits→32bits\\quad48\\text{bits}\\to 32\\text{bits}48bits→32bits P盒置换 与另一半输入异或 三重DES加密 密钥长度为112比特，即两个常规DES算法的密钥拼接得到 加密算法为： C=Enc(k1,Dec(k2,Enc(k1,p)))C = \\mathrm{Enc}(k_{1}, \\mathrm{Dec}(k_{2}, \\mathrm{Enc}(k_{1}, p))) C=Enc(k1​,Dec(k2​,Enc(k1​,p))) Blowfish算法 分组长度64位，密钥长度在32~448位之间 Blowfish加密过程 F函数包含了4个S盒运算，子密钥与S盒都是由算法本身生成的，并且对数据左右同时执行运算，复杂性更强 RC5 分组长度为32/64/128位，密钥长度0~2040位，参数有： www：分组长度 rrr：迭代次数 bbb：密钥的字节数 RC5加密过程 非对称密码 公钥密码体制： 明文 加密算法 公钥 / 私钥 密文 解密算法 利用Alice的公钥加密的密文只能被Alice的私钥解密，因此只要Alice保证了私钥的私有性，即可保证密码的安全，公钥是公开的 同样的，Alice可以用自己的私钥对数据进行签名，这样其他人可以利用Alice的公钥解签名，验证其专有性 这两种方法也可以同时使用，如下图 同时做签名与加密 数学原理 公钥密码基于陷门单向函数，其是指满足下列条件的函数fff： y=f(x)y = f(x)y=f(x)是可计算的 x=f−1(y)x = f^{-1}(y)x=f−1(y)是不可计算的 ∃δ\\exists\\delta∃δ，当δ\\deltaδ已知的时候，x=f−1(y)x = f^{-1}(y)x=f−1(y)是可计算的 数论基础 欧拉函数φ(n)=∑i=1n1gcd(m,n)=1\\varphi(n) = \\sum\\limits_{i=1}^{n}\\mathbf{1}_{\\mathrm{gcd}(m, n) = 1}φ(n)=i=1∑n​1gcd(m,n)=1​ 欧拉定理： gcd(m,n)=1⇔mφ(n)≡1 mod n\\mathrm{gcd}(m, n) = 1 \\Leftrightarrow m^{\\varphi(n)} \\equiv 1 \\text{ mod }n gcd(m,n)=1⇔mφ(n)≡1 mod n 推论：给定素数p≠qp eq qp=q，整数0&lt;m&lt;n=pq0 &lt; m &lt; n = pq0&lt;m&lt;n=pq，则∀k∈Z\\forall k \\in \\mathbb{Z}∀k∈Z mkφ(n)+1≡m mod nm^{k\\varphi(n) + 1} \\equiv m \\text{ mod }n mkφ(n)+1≡m mod n RSA算法 密钥的产生： 取大素数p,qp, qp,q，计算n=pqn = pqn=pq，公开nnn 计算φ(n)=(p−1)(q−1)\\varphi(n) = (p-1)(q-1)φ(n)=(p−1)(q−1) 取eee满足：gcd(e,φ(n))=1\\mathrm{gcd}(e, \\varphi(n)) = 1gcd(e,φ(n))=1且1&lt;e&lt;φ(n)1 &lt; e &lt; \\varphi(n)1&lt;e&lt;φ(n) 计算d&lt;φ(n)d &lt; \\varphi(n)d&lt;φ(n)使得de≡1 mod φ(n)de \\equiv 1 \\text{ mod }\\varphi(n)de≡1 mod φ(n) 公钥为(e,n)(e, n)(e,n)，私钥为(d,n)(d, n)(d,n) 加密过程：将待解密的内容分为k≤log⁡2nk\\leq \\log_{2}nk≤log2​n组，则密文为：C=Me mod nC = M^{e}\\text{ mod }nC=Me mod n 相对应的解密过程为：M=Cd mod nM = C^{d}\\text{ mod } nM=Cd mod n 大素数质因数分解的困难性保证了这个算法的安全性，因此密钥越大，安全性越高，但是性能会越低 DH密钥交换算法 我们定义本原根： aaa是素数ppp的本原根当且仅当{a,a2,…,ap−1} mod p={1,…,p−1}\\{a, a^{2},\\dots,a^{p-1}\\}\\text{ mod }p = \\{1, \\dots, p-1\\}{a,a2,…,ap−1} mod p={1,…,p−1} 对于素数ppp，设其一个本原根为aaa，取整数b&lt;pb&lt;pb&lt;p，则我们可以找到唯一的指数iii，使得b≡ai mod pb\\equiv a^{i}\\text{ mod }pb≡ai mod p，则iii称为bbb以aaa为底模ppp的离散对数，记为i=inda,p(b)i = \\mathrm{ind}_{a, p}(b)i=inda,p​(b) 离散对数满足：计算bbb是简单的，但是计算iii非常困难 DH算法可以且仅可以用于密钥交换 DH密钥交换算法 这样之后Alice与Bob同时知道了一个密钥KKK，可以用于作为对称密码的密钥 密钥分配 传统的对称密码分配 最朴素的方法有人工传送密钥，但是这样只适用于链路加密，并且被破译的概率可能更大，如果对于端对端加密，则需要KDC 密钥分配中心KDC 假定每个用户与KDC共享唯一的一个主密钥，则Alice和Bob获得会话密钥KsK_{s}Ks​的过程是： Alice向KDC请求会话密钥以保护与Bob的逻辑连接，提供Alice与Bob的标识和临时交互号N1N_{1}N1​ KDC用KaK_{a}Ka​加密响应并告知Alice，其中包括Ks,N1,EncKb(Ks,IdA)K_{s}, N_{1}, \\mathrm{Enc}_{K_{b}}(K_{s}, Id_{A})Ks​,N1​,EncKb​​(Ks​,IdA​) Alice解密，利用N1N_{1}N1​分割信息，前一段为KsK_{s}Ks​，后一段转发给Bob Bob使用KbK_{b}Kb​解密即可 当网络规模过大的时候，使用层次式的KDC，类比ISP 公钥的分配 公开发布 即通信方直接公布自己的公钥，非常简便，但是容易被伪造 公开可访问目录 由管理员维护一个dict[name, public_key]，定期发布或者更新该目录 通信方通过管理员来注册公钥，可以随时更新自己的公-私钥对，并且可以通过与管理员的安全认证通道来访问公钥目录 这种方法的弱点在于目录管理员本身 公钥授权 由管理员来控制 A发送带有时间戳的信息请求B的公钥 管理员发送用自己私钥加密的消息，包括B公钥、原始请求与原始时间戳 A保存B公钥，将A的标识和临时交互号发给B（用于确认身份） B同样从管理员处获得A的公钥 A B通过临时交互号确认身份，开始通信 这种方法的瓶颈在与每次都要向管理员申请公钥 公钥证书 证书包含公钥和一些其他信息，由证书管理员产生并发给对应通信方，这样该通信方可以通过传递证书将密钥信息传递给另一方 证书需要满足的条件是： 任何通信方都可以读取证书并确定拥有者的姓名和公钥 任何通信方都可以验证证书的真伪性 任何通信方都可以验证证书的时效性 只有管理员可以产生、更新证书 利用公钥分配传统密码的密钥 直接分配 最简单的一种方法，但是容易受到主动攻击 A向B发送自己的公钥和标识 B计算KsK_{s}Ks​，用A的公钥加密后发给A A解密得到KsK_{s}Ks​ 安全分配 A和B交换公钥 A用B的公钥对含有A标识和临时交互号N1N_{1}N1​的消息加密，发给B B用A的公钥对N1N_{1}N1​和临时交互号N2N_{2}N2​加密，发给A A用B的公钥对N2N_{2}N2​加密，发给B（这一步之后可以让双方确认身份） A计算密钥KsK_{s}Ks​，依次用A私钥、B公钥加密后发给B B解密得到KsK_{s}Ks​","tags":["笔记","网安","密码学"],"categories":["计算机网络安全技术"]},{"title":"信号处理原理 2","path":"/2024/09/24/信号处理原理2/","content":"信号处理原理 笔记 2 信号的数学基础 信号运算 共有四种基本运算： 四则运算：线性、乘除 波形变换：时移、压扩、反褶 数学运算：微分、积分 相互运算：卷积、相关 四则运算 略 波形变换 时移运算：将原信号的波形沿横轴平移bbb个单位，即f(t)→f(t−b)f(t) \\to f(t - b)f(t)→f(t−b) 反褶运算: 将原信号沿着纵轴翻转 压扩运算：将原信号压缩/扩张为原来的∣a∣|a|∣a∣个单位，aaa的符号决定是否需要反褶 注意：画图细节，例如原点、横纵坐标轴注意原函数振幅为0的部分 数学运算 微分运算：图像边缘提取 积分运算：重叠 举例： 能量信号：E(f(t))=∫−∞∞∣∣f(t)∣∣2dtE\\bigl(f(t)\\bigr) = \\int_{-\\infty}^{\\infty}||f(t)||^{2}dtE(f(t))=∫−∞∞​∣∣f(t)∣∣2dt 功率信号：P(f(t))=lim⁡T→∞1T∫−T/2T/2∣∣f(t)∣∣2dtP\\bigl(f(t)\\bigr) = \\lim\\limits_{T\\to \\infty}\\frac{1}{T}\\int_{-T/2}^{T/2}||f(t)||^{2}dtP(f(t))=T→∞lim​T1​∫−T/2T/2​∣∣f(t)∣∣2dt 离散信号类似，将 ∫\\int∫ 换为 ∑\\sum∑ 即可 相互运算 卷积运算 设f,gf, gf,g为两个连续时间信号，其卷积定义为： (f∗g)(t)=f(t)∗g(t)=∫−∞∞f(t−τ)g(τ)dτ(f*g)(t) = f(t)*g(t) = \\int_{-\\infty}^{\\infty}f(t - \\tau)g(\\tau) d\\tau (f∗g)(t)=f(t)∗g(t)=∫−∞∞​f(t−τ)g(τ)dτ 运算性质： 交换律：f1∗f2=f2∗f1f_{1}*f_{2} = f_{2}*f_{1}f1​∗f2​=f2​∗f1​ 分配率: f1∗(f2+f3)=f1∗f2+f1∗f3f_{1}*(f_{2} + f_{3}) = f_{1}*f_{2} + f_{1} * f_{3}f1​∗(f2​+f3​)=f1​∗f2​+f1​∗f3​ 结合律：f1∗(f2∗f3)=(f1∗f2)∗f3f_{1}*(f_{2} * f_{3}) = (f_{1} * f_{2}) * f_{3}f1​∗(f2​∗f3​)=(f1​∗f2​)∗f3​ 微分积分性质：(f1∗f2)(n)=f1(m)∗f2(n−m)(f_{1}*f_{2})^{(n)} = f_{1}^{(m)} * f_{2}^{(n-m)}(f1​∗f2​)(n)=f1(m)​∗f2(n−m)​ 上式中的n,m,n−mn, m, n-mn,m,n−m代表微分/积分的阶数，正数代表微分，负数代表积分 相关运算 定义为： Rf1f2(t)=∫−∞∞f1(τ)f2(τ−t)‾dτ=∫−∞∞f1(τ+t)f2(τ)‾dτ\\begin{align*} R_{f_{1}f_{2}}(t) &amp;= \\int_{-\\infty}^{\\infty}f_{1}(\\tau)\\overline{f_{2}(\\tau - t)}d\\tau \\\\ &amp;= \\int_{-\\infty}^{\\infty}f_{1}(\\tau + t)\\overline{f_{2}(\\tau)}d\\tau \\end{align*} Rf1​f2​​(t)​=∫−∞∞​f1​(τ)f2​(τ−t)​dτ=∫−∞∞​f1​(τ+t)f2​(τ)​dτ​ 性质： Rf1f2(t)=Rf2f1(−t)‾R_{f_{1}f_{2}}(t) = \\overline{R_{f_{2}f_{1}}(-t)}Rf1​f2​​(t)=Rf2​f1​​(−t)​ Rf2f1(t)=f1(−t)‾∗f2(t)R_{f_{2}f_{1}}(t) = \\overline{f_{1}(-t)}*f_{2}(t)Rf2​f1​​(t)=f1​(−t)​∗f2​(t) 奇异信号 Sa函数 略 单位斜变信号 定义为： R(t)={0t&lt;0tt≥0R(t) = \\begin{cases} 0 &amp; t &lt; 0 \\\\ t &amp; t \\geq 0 \\end{cases} R(t)={0t​t&lt;0t≥0​ 截顶的单位斜变信号定义为： R(t,τ)={0t&lt;0t0≤t&lt;ττt≥τR(t, \\tau) = \\begin{cases} 0 &amp; t &lt; 0 \\\\ t &amp; 0\\leq t &lt; \\tau \\\\ \\tau &amp; t \\geq \\tau \\end{cases} R(t,τ)=⎩⎨⎧​0tτ​t&lt;00≤t&lt;τt≥τ​ 单位阶变信号 定义为： u(t)={0t&lt;01t≥0u(t) = \\begin{cases} 0 &amp; t &lt; 0 \\\\ 1 &amp; t \\geq 0 \\end{cases} u(t)={01​t&lt;0t≥0​ 单位矩形脉冲信号 定义为： Gτ(t)={1∣t∣≤τ/20∣t∣&gt;τ/2G_{\\tau}(t) = \\begin{cases} 1 &amp; |t| \\leq \\tau / 2\\\\ 0 &amp; |t| &gt; \\tau / 2 \\end{cases} Gτ​(t)={10​∣t∣≤τ/2∣t∣&gt;τ/2​ 脉冲的定义 符号函数 sgn(t)={1t≥0−1t&lt;0\\text{sgn}(t) = \\begin{cases} 1 &amp; t \\geq 0 \\\\ -1 &amp; t &lt; 0 \\end{cases} sgn(t)={1−1​t≥0t&lt;0​ 单位冲激信号 狄拉克定义δ(t)\\delta(t)δ(t)为满足以下两式的信号： δ(t)=0(t≠0)∫−∞∞δ(t)=1\\begin{align*} \\delta(t) &amp;= 0\\quad (t eq 0) \\\\ \\int_{-\\infty}^{\\infty}\\delta(t) &amp;= 1 \\end{align*} δ(t)∫−∞∞​δ(t)​=0(t=0)=1​ 可一般化为：δE,t0(t)=Eδ(t−t0)\\delta_{E, t_{0}}(t) = E\\delta(t - t_{0})δE,t0​​(t)=Eδ(t−t0​) 也可以定义为： δ(t)=lim⁡τ→0Gτ(t)τ\\delta(t) = \\lim\\limits_{\\tau\\to 0}\\frac{G_{\\tau}(t)}{\\tau} δ(t)=τ→0lim​τGτ​(t)​ 性质： f(t)∗δ(t)=f(t)f(t)∗δ(t−t0)=f(t−t0)δ(at)=1∣a∣δ(t)(a≠0)∫−∞tδ(τ)dτ=u(t)∫−∞∞f(t)δ(t−t0)dt=f(t0)\\begin{align*} f(t) * \\delta(t) &amp;= f(t) \\\\ f(t) * \\delta(t - t_{0}) &amp;= f(t - t_{0}) \\\\ \\delta(at) &amp;= \\frac{1}{|a|}\\delta(t)\\qquad(a eq 0) \\\\ \\int_{-\\infty}^{t}\\delta(\\tau)d\\tau &amp;= u(t) \\\\ \\int_{-\\infty}^{\\infty}f(t)\\delta(t - t_{0})dt &amp;= f(t_{0}) \\end{align*} f(t)∗δ(t)f(t)∗δ(t−t0​)δ(at)∫−∞t​δ(τ)dτ∫−∞∞​f(t)δ(t−t0​)dt​=f(t)=f(t−t0​)=∣a∣1​δ(t)(a=0)=u(t)=f(t0​)​ 当我们把很多个冲激点不同的冲激信号线性叠加时，可以得到冲激串信号，通常取冲激点为周期变化的序列，可以用于信号的抽样： ΔTs(t)=∑n=−∞∞δ(t−nTs)\\Delta_{T_{s}}(t) = \\sum\\limits_{n = -\\infty}^{\\infty}\\delta(t - nT_{s}) ΔTs​​(t)=n=−∞∑∞​δ(t−nTs​) 则我们可以对于信号f(t)f(t)f(t)抽样出其中的一个子信号序列： fs(t)=f(t)⋅ΔTs(t)=∑n=−∞∞f(nTs)δ(t−nTs)f_{s}(t) = f(t)\\cdot\\Delta_{T_{s}}(t) = \\sum\\limits_{n = -\\infty}^{\\infty}f(nT_{s})\\delta(t - nT_{s}) fs​(t)=f(t)⋅ΔTs​​(t)=n=−∞∑∞​f(nTs​)δ(t−nTs​)","tags":["信原","笔记","数学基础"],"categories":["信号处理原理"]},{"title":"信号处理原理 1","path":"/2024/09/10/信号处理原理1/","content":"信号处理原理 笔记 1 信号的基本概念 信号的描述 数学描述： 使用具体的表达式描述为函数Sa(t)=sin⁡(t)tSa(t) = \\frac{\\sin(t)}{t} Sa(t)=tsin(t)​ 波形描述： 函数图像，横纵坐标要求标出，原点要求标出，零点要求标出 分类： 确定信号与随机信号 周期信号(f(t)=f(t+T)∀t∈R)(f(t) = f(t + T) \\forall t \\in \\mathbb{R})(f(t)=f(t+T)∀t∈R)与非周期信号 奇异信号举例： 正余弦信号：f(t)=Ksin⁡(ωt+θ)f(t)=Kcos⁡(ωt+θ)\\begin{align*} f(t) &amp;= K\\sin(\\omega t + \\theta) \\\\ f(t) &amp;= K\\cos(\\omega t + \\theta) \\\\ \\end{align*} f(t)f(t)​=Ksin(ωt+θ)=Kcos(ωt+θ)​ Sa函数：Sa(t)=sin⁡(t)tSa(t) = \\frac{\\sin(t)}{t} Sa(t)=tsin(t)​ 有结论：∫−∞∞Sa(t)=π\\int_{-\\infty}^{\\infty}Sa(t) = \\pi ∫−∞∞​Sa(t)=π 指数信号：f(t)=Keαtf(t) = Ke^{\\alpha t} f(t)=Keαt 欧拉公式 eix=cos⁡(x)+isin⁡(x)sin⁡(x)=eix−e−ix2icos⁡(x)=eix+e−ix2\\begin{align*} e^{ix} &amp;= \\cos(x) + i\\sin(x) \\\\ \\sin(x) &amp;= \\frac{e^{ix} - e^{-ix}}{2i} \\\\ \\cos(x) &amp;= \\frac{e^{ix} + e^{-ix}}{2} \\end{align*} eixsin(x)cos(x)​=cos(x)+isin(x)=2ieix−e−ix​=2eix+e−ix​​ 用于描述复指数信号： f(t)=Kest=Ke(σ+jω)t=Keσt(cos⁡(ωt)+jsin⁡(ωt))\\begin{align*} f(t) &amp;= Ke^{st} \\\\ &amp;= Ke^{(\\sigma + j\\omega)t} \\\\ &amp;= Ke^{\\sigma t}(\\cos(\\omega t) + j\\sin(\\omega t)) \\end{align*} f(t)​=Kest=Ke(σ+jω)t=Keσt(cos(ωt)+jsin(ωt))​ 函数分解 若非零函数φ1(t)\\varphi_{1}(t)φ1​(t)与φ2(t)\\varphi_{2}(t)φ2​(t)满足： ∫t1t2φ1(t)φ2∗(t)dt=0\\int_{t_{1}}^{t_{2}}\\varphi_{1}(t)\\varphi_{2}^{*}(t)dt = 0 ∫t1​t2​​φ1​(t)φ2∗​(t)dt=0 则称其在[t1,t2][t_{1}, t_{2}][t1​,t2​]上正交 若非零函数序列φ1(t),φ2(t),⋯ ,φn(t)\\varphi_{1}(t), \\varphi_{2}(t), \\cdots, \\varphi_{n}(t)φ1​(t),φ2​(t),⋯,φn​(t)满足： ∫t1t2φi(t)φj∗(t)dt={0i≠jki≠0i=j\\int_{t_{1}}^{t_{2}}\\varphi_{i}(t)\\varphi_{j}^{*}(t)dt = \\begin{cases} 0 &amp; i eq j \\\\ k_{i} eq 0 &amp;i = j \\end{cases} ∫t1​t2​​φi​(t)φj∗​(t)dt={0ki​=0​i=ji=j​ 则称这组函数为正交函数集 举例： {cos⁡(kω1t+φk) ∣ k=0,1,…,n,φ0=0}\\{\\cos(k\\omega_{1}t + \\varphi_{k})\\ | \\,k = 0, 1, \\dots, n, \\varphi_{0} = 0\\}{cos(kω1​t+φk​) ∣k=0,1,…,n,φ0​=0}，区间[0,2πω1][0, \\frac{2\\pi}{\\omega_{1}}][0,ω1​2π​] {ejnω0t ∣ n=0,±1,±2,…,ω∈R}\\{e^{jn\\omega_{0}t}\\,|\\,n = 0, \\plusmn 1, \\plusmn 2, \\dots, \\omega \\in \\mathbf{R}\\}{ejnω0​t∣n=0,±1,±2,…,ω∈R}，区间[−πω0,πω0][-\\frac{\\pi}{\\omega_{0}}, \\frac{\\pi}{\\omega_{0}}][−ω0​π​,ω0​π​] 若在[t1,t2][t_{1}, t_{2}][t1​,t2​]上，除正交函数集{φi(t)}\\{\\varphi_{i}(t)\\}{φi​(t)}外，不存在函数x(t)满足： 0&lt;∫t1t2x(t)x∗(t)dt&lt;∞∫t1t2x(t)φi∗(t)dt=0∀i\\begin{align*} 0 &lt; &amp;\\int_{t_{1}}^{t_{2}}x(t)x^{*}(t)dt &lt; \\infty \\\\ &amp;\\int_{t_{1}}^{t_{2}}x(t)\\varphi_{i}^{*}(t)dt = 0 \\quad \\forall i \\end{align*} 0&lt;​∫t1​t2​​x(t)x∗(t)dt&lt;∞∫t1​t2​​x(t)φi∗​(t)dt=0∀i​ 则称{φi(t)}\\{\\varphi_{i}(t)\\}{φi​(t)}是完备的","tags":["信原","笔记","数学基础"],"categories":["信号处理原理"]},{"title":"Rust入门","path":"/2024/07/26/Rust入门/","content":"Rust学习随记（暂时停更） Rust 入门随记 本文用来记录在学习Rust的过程中遇到的各种问题 所有权 函数参数写法是x: &amp;u32而不是&amp;x: u32（蠢了 裸指针不涉及所有权 切片 数组切片的下表索引一定是usize 字符串切片是以字节为单位，一些UTF-8字符（例如中文）会占用多个字节，因此一般不采用切片 项目结构 main.rs为二进制项目的包根，lib.rs为库项目的包根，包根也即crates::访问的地方 一个功能文件夹如果要作为一个模块导出，需要在文件夹下添加mod.rs，其中指出需要导出的模块 Cargo换源 使用清华源避免在拉去第三方库的时候由于超时导致失败，方法如下： 在$HOME/.cargo/config.toml中添加 12[source.tuna]registry = &quot;https://mirrors.tuna.tsinghua.edu.cn/git/crates.io-index.git&quot; 并将replace-with的值改为tuna即可","tags":["Rust"]},{"title":"IAI-神经网络与机器学习","path":"/2024/06/17/IAI-神经网络与机器学习/","content":"人智导 神经网络与机器学习 神经网络 多层神经网络示意图 神经元 接收输入x⃗\\vec{x}x，计算net=w⃗⋅x⃗+bnet = \\vec{w} \\cdot \\vec{x} + bnet=w⋅x+b，之后使用激活函数ggg对其进行激活（限制其值域范围） 常见的激活函数有： 符号函数sgn\\mathrm{sgn}sgn Sigmoid函数σ(z)=11+e−z\\sigma(z) = \\frac{1}{1 + e^{-z}}σ(z)=1+e−z1​ 双曲正切函数tanh⁡(z)=ez−e−zez+e−z\\tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}tanh(z)=ez+e−zez−e−z​ 线性整流函数ReLU(z)=max⁡{0,z}\\mathrm{ReLU}(z) = \\max\\{0, z\\}ReLU(z)=max{0,z} 输出归一化 采用Softmax函数将输出层netinet_{i}neti​归一化： oi=eneti∑k=1menetko_{i} = \\frac{e^{net_{i}}}{\\sum\\limits_{k=1}^{m}e^{net_{k}}} oi​=k=1∑m​enetk​eneti​​ 全连接网络 隐含层之间是全连接的神经网络 训练方式为： 构建数据集，划分为训练集与验证集（实际应用的数据被称为为测试集，我们在训练阶段理应不能得到这批数据） 选择损失函数，通常选用误差平方和或交叉熵，误差平方和为：E(w⃗)=12∑d=1n∑k=1m(tkd−okd)2E(\\vec{w}) = \\frac{1}{2}\\sum\\limits_{d=1}^{n}\\sum\\limits_{k=1}^{m}(t_{kd} - o_{kd})^{2} E(w)=21​d=1∑n​k=1∑m​(tkd​−okd​)2 训练：求损失函数最小值，一种算法为梯度下降：wi⇐wi−η∂E∂wiw_{i} \\Leftarrow w_{i} - \\eta \\frac{\\partial E}{\\partial w_{i}} wi​⇐wi​−η∂wi​∂E​ 也即：w⇐w−η(∇wE)w \\Leftarrow w - \\eta( abla_{w}E) w⇐w−η(∇w​E) 梯度下降分为批量、小批量、随机样本三种，差距在与每次处理的样本个数 梯度的计算 随机梯度下降中最麻烦的问题在于梯度的计算，主要思想是链式法则与反向传播，以激活函数为σ\\sigmaσ为例，具体来说，算法为： 随机初始化为权重为较小随机值给定样本，计算所有输出对于输出层第jjj个元素，有：∂E∂wji=∂E∂oj∂oj∂netj∂netj∂wji=−(tj−oj)oj(1−oj)xji=−δjxji\\begin{align*} \\frac{\\partial E}{\\partial w_{ji}} &amp;= \\frac{\\partial E}{\\partial o_{j}} \\frac{\\partial o_{j}}{\\partial net_{j}} \\frac{\\partial net_{j}}{\\partial w_{ji}} \\\\ &amp;= -(t_{j} - o_{j})o_{j}(1-o_{j})x_{ji} \\\\ &amp;= - \\delta_{j}x_{ji}\\end{align*}∂wji​∂E​​=∂oj​∂E​∂netj​∂oj​​∂wji​∂netj​​=−(tj​−oj​)oj​(1−oj​)xji​=−δj​xji​​更新权重对于隐含层第jjj个元素，有：∂E∂wji=∑k∈succ(j)(∂E∂netk∂netk∂oj∂oj∂netj)∂netj∂wji=−∑k∈succ(j)(δkwkjoj(1−oj))xji=−δjxji\\begin{align*} \\frac{\\partial E}{\\partial w_{ji}} &amp;= \\sum\\limits_{k \\in \\text{succ}(j)}\\biggl(\\frac{\\partial E}{\\partial net_{k}} \\frac{\\partial net_{k}}{\\partial o_{j}} \\frac{\\partial o_{j}}{\\partial net_{j}}\\biggr) \\frac{\\partial net_{j}}{\\partial w_{ji}} \\\\ &amp;= -\\sum\\limits_{k \\in \\text{succ}(j)}\\bigl(\\delta_{k}w_{kj}o_{j}(1-o_{j})\\bigr)x_{ji} \\\\ &amp;= -\\delta_{j}x_{ji}\\end{align*}∂wji​∂E​​=k∈succ(j)∑​(∂netk​∂E​∂oj​∂netk​​∂netj​∂oj​​)∂wji​∂netj​​=−k∈succ(j)∑​(δk​wkj​oj​(1−oj​))xji​=−δj​xji​​更新权重 交叉熵 交叉熵损失函数为： H(w)=−∑d=1N∑k=1Mtkdlog⁡(okd)H(w) = -\\sum\\limits_{d=1}^{N}\\sum\\limits_{k=1}^{M}t_{kd}\\log(o_{kd}) H(w)=−d=1∑N​k=1∑M​tkd​log(okd​) 其中okdo_{kd}okd​为实际值，要求是概率，因此其输入层需要经过一次softmax 平方和损失函数常用于输出是具体数值的问题，交叉熵损失函数用于分类问题 卷积神经网络 全连接的不足：参数过多，影响速度与效率 卷积示意图 因此卷积神经网络利用卷积核对于输入数据进行卷积，降低输出维数，卷积核通过训练得到，并且卷积核是共享的，也即对于同一组数据的不同部分其参数值不变 填充与步长 填充为在原输入的最外围填充若干圈000来增加维数，例如5×55\\times 55×5变为7×77 \\times 77×7 步长为卷积核每次滑动的距离，必须要保证卷积核被完整的包含在输入当中 多卷积核与多通道 多个卷积共同卷同一个数据，每个卷积产生一个通道，通道数等于卷积核数 当输入为多通道时，例如6×6×36\\times 6\\times 36×6×3，卷积核的深度一定要与之一致，即x×y×3x \\times y \\times 3x×y×3 池化 降维的手段，通常是将一定的区域压缩为一个值，通常包括最大池化、平均池化等，窗口的大小与步长都可以设置 最大池化示意图 实例 两个实例 LeNet神经网络 VGG-16神经网络 总结 卷积神经网络总结： 卷积核能够提取特征 参数较少 梯度消失问题 神经网络的主要问题之一 在BP中，我们有： δh=oh(1−oh)∑k∈succ(h)δkwkh≤14∑k∈succ(h)δkwkh\\delta_{h} = o_{h}(1 - o_{h})\\sum\\limits_{k\\in \\mathrm{succ}(h)}\\delta_{k}w_{kh} \\leq \\frac{1}{4}\\sum\\limits_{k\\in \\mathrm{succ}(h)}\\delta_{k}w_{kh} δh​=oh​(1−oh​)k∈succ(h)∑​δk​wkh​≤41​k∈succ(h)∑​δk​wkh​ 因此层数过多的时候，梯度将以指数级下降，一种解决思路是采用ReLU\\mathrm{ReLU}ReLU 两个实例 GoogLeNet中的Inception模块 利用1×11\\times 11×1等卷积核改变通道数之后拼接起来，相当于在参数尽可能少的情况下减弱梯度消失的问题 残差网络中的残差模块 在残差网络中，在一层的常规计算结束之后，将计算结果与输入取加和得到下一层的输入，这样可以一定程度上避免神经网络发生退化（层数过多导致再增加层数的时候效果提升不显著） 注意要求F(X)F(X)F(X)与XXX的维数、通道数必须相同，因此需要对二者进行相应的填充 过拟合问题 对于训练集数据过拟合，训练出的模型不具有普适性，解决方法有： 使用验证集，个人理解是利用验证集来模拟测试集，在训练集上训练，在验证集上防止过拟合 正则化项法：将损失函数加上正则化项∣∣w⃗∣∣2||\\vec{w}||^{2}∣∣w∣∣2其中w⃗\\vec{w}w为所有的参数组成的向量，从而降低模型参数个数，降低模型复杂性 Dropout：随机临时舍弃一些神经元，使之不参与计算，减少参数量，舍弃率可调 数据增强：增加数据量，将同一份数据进行多种变换，例如图像的缩放、旋转等等，也有非线性化等高级的做法 词向量 第一个问题：如何来表示词与文本 独热编码(One-hot) 用于词表等长的向量来表示词，第iii个词的第iii位为111，其余全000 优点： 简单方便 缺点： 编码太长 无法度量相似性 分布式表示 稠密向量表示，向量的每一位代表一个特征，具体的数值代表这个词该种特征的强弱 克服了独热的两种问题，但是编码很困难，具体的值不容易找出，需要在训练过程中调整 语言模型 nnn元语言模型是指，通过前n−1n - 1n−1个词来推断下一个词，在神经网络中实现方式如下： n元模型神经网络 其中第一步为词嵌入得到词向量，具体的向量需要通过训练得到 参数的估计采用最大似然估计的方式，即： max⁡θ∏w∈CP(w=k ∣ context(w),θ)\\max\\limits_{\\theta}\\prod\\limits_{w\\in C}P(w = k\\,|\\, \\text{context}(w), \\theta) θmax​w∈C∏​P(w=k∣context(w),θ) word2vec 训练词向量的模型，有连续词袋模型和跳词模型 连续词袋模型(CBOW) 我们有一个词表WWW，训练集为大量的句子，对于某个句子w1…wmw_{1}\\dots w_{m}w1​…wm​，我们采用如下的方式进行训练： 在句中任选一位置合适的词wtw_{t}wt​ 取其前后各ccc个词的词向量进行求和并激活：xw=g(∑i=1c(wt−i+wt+i))x_{w} = g(\\sum\\limits_{i=1}^{c}(w_{t-i} + w_{t + i}))xw​=g(i=1∑c​(wt−i​+wt+i​)) 将xwx_{w}xw​作为输入传给一个霍夫曼树，其中每一个内部节点是一个神经元，叶节点为所有的词 霍夫曼树的内部节点，输入为一个词，输出为选择左边或者右边的概率，最终我们要极大到达原来的词wtw_{t}wt​的概率，也即神经网络需要训练每个节点的参数使得root→wt\\mathrm{root}\\rightarrow w_{t}root→wt​这条路径的概率尽可能大 跳词模型 PPT没说，略 循环神经网络RNN 循环神经网络 如上图，我们利用输入来更新状态向量h(k)=[h1(k),…,hm(k)]h^{(k)} = [h_{1}^{(k)}, \\dots, h_{m}^{(k)}]h(k)=[h1(k)​,…,hm(k)​] 最终输出的处理方式根据相应的实际问题变化而变化，例如情感分类问题可以接一个全连接层与一个softmax 并且我们可以将每一次循环的结果都输出出来进行相应的处理，例如看图说话的过程可以将每一次循环的结果分别做一次全连接与softmax来作为一个字，最终组成一段话 双向循环神经网络 由于一些情况下序列不仅是有正向的关系，利于一句话的某个词需要根据上下文而不是上文才能确定，而采用传统的RNN会导致下文信息的丢失，因此采用一个双向的形式 双向循环神经网络 如上图，这样可以同时考虑上下文的信息 序列到序列 考虑在实际中，许多问题的输入也是一个序列而不是一个简单的向量或矩阵，例如问答、翻译等，因此采用序列到序列的RNN模式，即采用编码器-解码器模块，现将输入序列编码为矩阵或向量，再将其放入解码器中 序列到序列循环神经网络 长短期记忆网络LSTM 简单RNN的问题： 长期依赖：如果输入序列具有距离较远的依赖关系，那RNN很容易丢失这层关系，例如&quot;bei jing shi yi ge mei li de&quot;这句话，&quot;shi&quot;具体的字的确认就很困难，需要根据后续的输入来确定，而这层关系被短期的RNN丢弃 重点选择问题：序列中不同部分的重要性不同 梯度消失问题 因此改进为LSTM LSTM循环结构 在上图的循环结构中，维护两个状态sss与hhh，循环结构内部是由“门”组成的 门是指一层神经网络，例如σ\\sigmaσ门就指的是将输入接一个全连接层和一个σ\\sigmaσ激活函数作为输出，全连接层的作用是将输入维数与状态的维数进行匹配 结构中×\\times×等算数运算符代表的是按位操作，相当于是对原有数据进行重新加权与筛选 下面依次介绍上图中的门 遗忘门 左数第一个，为σ\\sigmaσ门，将原有状态h(t−1)h^{(t-1)}h(t−1)和输入共同作为输入，经过全连接与σ\\sigmaσ之后直接与状态向量s(t−1)s^{(t-1)}s(t−1)按位相乘 表示遗忘掉状态中的一些信息，防止过拟合 输入部分 输入门：左数第二个，也为σ\\sigmaσ门 输入处理单元：左数第三个，为tanh⁡\\tanhtanh门 将这两个门的处理结果按位乘，表示这一轮学到的东西，之后与遗忘后的状态向量s′(t−1)s^{&#x27;(t-1)}s′(t−1)按位加，完成学习的过程得到s(t)s^{(t)}s(t) 输出部分 输出门：左数第四个，为σ\\sigmaσ门 输出处理单元：不是门！是一个单独的tanh⁡\\tanhtanh函数 将这两个的处理结果按位乘得到新一轮的输出状态h(t)h^{(t)}h(t) 实例 利用LSTM解决序列到序列的问题 编码器-解码器模式的LSTM","tags":["笔记","IAI","神经网络","机器学习"],"categories":["人工智能导论"]},{"title":"概统复习笔记","path":"/2024/06/15/概统复习笔记/","content":"概统 复习随笔 概统复习笔记 两两独立但不相互独立 例1 四张卡牌，分别写有2,3,5,302, 3, 5, 302,3,5,30，随机抽取一张，定义事件AAA为取出的数字是222的倍数，事件BBB为取出的数字是333的倍数，事件CCC为取出的数字是555的倍数，则有 P(A)=P(B)=P(C)=12P(AB)=P(BC)=P(CA)=14=12×12P(ABC)=14≠P(A)P(B)P(C)\\begin{align*} P(A) = P(B) &amp;= P(C) = \\frac{1}{2} \\\\ P(AB) = P(BC) &amp;= P(CA) = \\frac{1}{4} = \\frac{1}{2}\\times \\frac{1}{2} \\\\ P(ABC) = \\frac{1}{4} &amp; eq P(A)P(B)P(C) \\end{align*} P(A)=P(B)P(AB)=P(BC)P(ABC)=41​​=P(C)=21​=P(CA)=41​=21​×21​=P(A)P(B)P(C)​ 例2 连续独立抛一枚质地均匀的硬币两次，AAA代表第一次正面向上，BBB代表第二次正面向上，CCC代表一正一反，则 P(A)=P(B)=P(C)=12P(AB)=P(BC)=P(CA)=14=12×12P(ABC)=0≠P(A)P(B)P(C)\\begin{align*} P(A) = P(B) &amp;= P(C) = \\frac{1}{2} \\\\ P(AB) = P(BC) &amp;= P(CA) = \\frac{1}{4} = \\frac{1}{2}\\times \\frac{1}{2} \\\\ P(ABC) = 0 &amp; eq P(A)P(B)P(C) \\end{align*} P(A)=P(B)P(AB)=P(BC)P(ABC)=0​=P(C)=21​=P(CA)=41​=21​×21​=P(A)P(B)P(C)​ 条件独立与独立无关 条件独立不蕴含独立 对于任意非空事件A,BA, BA,B有： P(AB ∣ B)=P(AB)P(B)=P(A ∣ B)≡P(A ∣ B)P(B ∣ B)P(AB\\,|\\,B) = \\frac{P(AB)}{P(B)} = P(A\\,|\\,B) \\equiv P(A\\,|\\,B)P(B\\,|\\,B) P(AB∣B)=P(B)P(AB)​=P(A∣B)≡P(A∣B)P(B∣B) 因此它们都在条件BBB下独立，显然不一定A,BA, BA,B独立 独立不蕴含条件独立 对于独立事件A,BA, BA,B，满足C=A∪B⊊ΩC = A\\cup B \\subsetneq \\OmegaC=A∪B⊊Ω，则有： P(AB ∣ C)=P(ABC)P(C)=P(AC)P(BC)P(C)≠P(AC)P(BC)P(C)2=P(A ∣ C)P(B ∣ C)P(AB\\,|\\,C) = \\frac{P(ABC)}{P(C)} = \\frac{P(AC)P(BC)}{P(C)} eq \\frac{P(AC)P(BC)}{P(C)^{2}} = P(A\\,|\\,C)P(B\\,|\\,C) P(AB∣C)=P(C)P(ABC)​=P(C)P(AC)P(BC)​=P(C)2P(AC)P(BC)​=P(A∣C)P(B∣C) 泊松分布与指数分布 泊松分布P(λ)P(\\lambda)P(λ)为离散型分布，其PMF为： P(X=k)=λkk!e−λP(X = k) = \\frac{\\lambda^{k}}{k!}e^{-\\lambda} P(X=k)=k!λk​e−λ 其数字特征为： E(X)=Var(X)=λE(X) = Var(X) = \\lambda E(X)=Var(X)=λ 而指数分布Exp(λ)Exp(\\lambda)Exp(λ)为连续型分布，其PDF为： f(x)=λe−λxf(x) = \\lambda e^{-\\lambda x} f(x)=λe−λx 其数字特征为： E(X)=1λVar(X)=1λ2E(X) = \\frac{1}{\\lambda}\\quad Var(X) = \\frac{1}{\\lambda^{2}} E(X)=λ1​Var(X)=λ21​ 尾概率为： P(X&gt;x)=e−λxP(X &gt; x) = e^{-\\lambda x} P(X&gt;x)=e−λx 指数分布与泊松分布为对同一事件的不同描述，指数分布为两次发生这一事件之间的时间间隔（连续），泊松分布为固定时间段内发生事件的次数（离散） 全期望公式 E(Y)=E(E(Y ∣ X))E(E(g(X)Y ∣ X))=E(g(X)E(Y∣X))\\begin{align*} E(Y) &amp;= E(E(Y\\,|\\, X)) \\\\ E(E(g(X)Y\\,|\\, X)) &amp;= E(g(X)E(Y|X)) \\end{align*} E(Y)E(E(g(X)Y∣X))​=E(E(Y∣X))=E(g(X)E(Y∣X))​ 条件期望是均方误差意义下的最优预测，即∀ g\\forall\\, g∀g： E((Y−g(X))2)≥E((Y−E(Y∣X))2)E((Y - g(X))^{2})\\geq E((Y - E(Y|X))^{2}) E((Y−g(X))2)≥E((Y−E(Y∣X))2) 矩母函数与矩 nnn阶原点矩为矩母函数的nnn阶导数 E(Xn)=MX(n)(0)E(X^{n}) = M_{X}^{(n)}(0) E(Xn)=MX(n)​(0) 相对应的标准矩为： E((X−μ)n)=∑k=0nCnkE(Xk)μn−k=∑k=0nCnkMX(n)(0)μn−k\\begin{align*} E((X - \\mu)^{n}) &amp;= \\sum\\limits_{k=0}^{n}C_{n}^{k}E(X^{k})\\mu^{n-k} \\\\ &amp;= \\sum\\limits_{k=0}^{n}C_{n}^{k}M^{(n)}_{X}(0)\\mu^{n-k} \\end{align*} E((X−μ)n)​=k=0∑n​Cnk​E(Xk)μn−k=k=0∑n​Cnk​MX(n)​(0)μn−k​ 概率不等式 Markov 若随机变量X≥0X\\geq 0X≥0，则∀ a&gt;0\\forall\\, a &gt; 0∀a&gt;0 P(X≥a)≤E(X)aP(X \\geq a) \\leq \\frac{E(X)}{a} P(X≥a)≤aE(X)​ Chebyshev 若随机变量XXX方差存在，则： P(∣X−E(X)∣≥a)≤Var(X)a2P(|X - E(X)| \\geq a) \\leq \\frac{Var(X)}{a^{2}} P(∣X−E(X)∣≥a)≤a2Var(X)​ Chernoff XXX任意，则∀a&gt;0,t&gt;0\\forall a&gt;0, t&gt;0∀a&gt;0,t&gt;0 P(X≥a)≥E(etX)etaP(X \\geq a) \\geq \\frac{E(e^{tX})}{e^{ta}} P(X≥a)≥etaE(etX)​ Hoeffding bound 随机变量列Xi∈[ai,bi]X_{i} \\in [a_{i}, b_{i}]Xi​∈[ai​,bi​]，记X=∑i=1nXiX = \\sum\\limits_{i=1}^{n} X_{i}X=i=1∑n​Xi​，并记μ=E(X)\\mu = E(X)μ=E(X)，则： P(X≤μ−t)≤exp⁡(−2t2∑i=1n(ai−bi)2)P(X≥μ+t)≤exp⁡(−2t2∑i=1n(ai−bi)2)\\begin{align*} P(X \\leq \\mu - t) &amp;\\leq \\exp\\biggl(-\\frac{2t^{2}}{\\sum\\limits_{i=1}^{n}(a_{i} - b_{i})^{2}}\\biggr) \\\\ P(X \\geq \\mu + t) &amp;\\leq \\exp\\biggl(-\\frac{2t^{2}}{\\sum\\limits_{i=1}^{n}(a_{i} - b_{i})^{2}}\\biggr) \\end{align*} P(X≤μ−t)P(X≥μ+t)​≤exp(−i=1∑n​(ai​−bi​)22t2​)≤exp(−i=1∑n​(ai​−bi​)22t2​)​ Multiplicative-form Chernoff Bound 随机变量列Xi∈[0,1]X_{i} \\in [0, 1]Xi​∈[0,1]，记X=∑i=1nXiX = \\sum\\limits_{i=1}^{n} X_{i}X=i=1∑n​Xi​，并记μ=E(X)\\mu = E(X)μ=E(X)，则： P(X≤(1−ε)μ)≤exp⁡(−ε22μ)P(X≥(1+ε)μ)≤exp⁡(−ε22+εμ)\\begin{align*} P(X \\leq (1 - \\varepsilon)\\mu) &amp;\\leq \\exp\\bigl(-\\frac{\\varepsilon^{2}}{2}\\mu\\bigr) \\\\ P(X \\geq (1 + \\varepsilon)\\mu) &amp;\\leq \\exp\\bigl(-\\frac{\\varepsilon^{2}}{2 + \\varepsilon}\\mu\\bigr) \\end{align*} P(X≤(1−ε)μ)P(X≥(1+ε)μ)​≤exp(−2ε2​μ)≤exp(−2+εε2​μ)​ 收敛性的差异 Ω∼U(0,1)\\Omega \\sim U(0, 1)Ω∼U(0,1)，则考虑如下随机变量列： Y0(ω)=ω+1[0,1](ω)Y1(ω)=ω+1[0,12](ω)Y2(ω)=ω+1[12,1](ω)Y3(ω)=ω+1[0,13](ω)Y4(ω)=ω+1[13,23](ω)Y5(ω)=ω+1[23,1](ω)…\\begin{align*} Y_{0}(\\omega) &amp;= \\omega + \\mathrm{1}_{[0, 1]}(\\omega) \\\\ Y_{1}(\\omega) &amp;= \\omega + \\mathrm{1}_{[0, \\frac{1}{2}]}(\\omega) \\\\ Y_{2}(\\omega) &amp;= \\omega + \\mathrm{1}_{[\\frac{1}{2}, 1]}(\\omega) \\\\ Y_{3}(\\omega) &amp;= \\omega + \\mathrm{1}_{[0, \\frac{1}{3}]}(\\omega) \\\\ Y_{4}(\\omega) &amp;= \\omega + \\mathrm{1}_{[\\frac{1}{3}, \\frac{2}{3}]}(\\omega) \\\\ Y_{5}(\\omega) &amp;= \\omega + \\mathrm{1}_{[\\frac{2}{3}, 1]}(\\omega) \\\\ \\dots \\end{align*} Y0​(ω)Y1​(ω)Y2​(ω)Y3​(ω)Y4​(ω)Y5​(ω)…​=ω+1[0,1]​(ω)=ω+1[0,21​]​(ω)=ω+1[21​,1]​(ω)=ω+1[0,31​]​(ω)=ω+1[31​,32​]​(ω)=ω+1[32​,1]​(ω)​ 记Y(ω)=ωY(\\omega) = \\omegaY(ω)=ω，则Yn(ω)Y_{n}(\\omega)Yn​(ω)依概率收敛至Y(ω)Y(\\omega)Y(ω)，但是不以概率111收敛 中心极限定理连续性修正 由于常规的中心极限定理是： X‾−μσ/n→N(0,1)\\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}}\\rightarrow N(0, 1) σ/n​X−μ​→N(0,1) 因此一些离散分布使用该定理之后反而会失去其单点的概率（连续分布单点恒为0），因此进行连续性修正，以二项分布X∼B(n,p)X \\sim B(n, p)X∼B(n,p)为例： P(t1≤X≤t2)≈Φ(y2)−Φ(y1)P\\bigl(t_{1}\\leq X \\leq t_{2}\\bigr) \\approx \\Phi(y_{2}) - \\Phi(y_{1}) P(t1​≤X≤t2​)≈Φ(y2​)−Φ(y1​) 其中： Φ(yi)=ti−np+(12)inp(1−p)\\Phi(y_{i}) = \\frac{t_{i} - np + (\\frac{1}{2})^{i}}{\\sqrt{np(1-p)}} Φ(yi​)=np(1−p)​ti​−np+(21​)i​ 极大似然估计可能有偏 均匀分布U(0,θ)U(0, \\theta)U(0,θ)，样本值为{Xi}i=1n\\{X_{i}\\}_{i=1}^{n}{Xi​}i=1n​，则其MLE为θ∗=max⁡{Xi}\\theta^{*} = \\max\\{X_{i}\\}θ∗=max{Xi​}，下面我们证明这个不是无偏估计： Y=max⁡{Xi}Y = \\max\\{X_{i}\\}Y=max{Xi​}的CDF为： FY(y)=P(max⁡{Xi}≤y)=(FX(y))n=(yθ)n\\begin{align*} F_{Y}(y) &amp;= P(\\max\\{X_{i}\\} \\leq y) \\\\ &amp;= (F_{X}(y))^{n} \\\\ &amp;= \\bigl(\\frac{y}{\\theta}\\bigr)^{n} \\end{align*} FY​(y)​=P(max{Xi​}≤y)=(FX​(y))n=(θy​)n​ 因此其PDF为f(y)=FY′(y)=nθ(yθ)n−1f(y) = F&#x27;_{Y}(y) = \\frac{n}{\\theta}(\\frac{y}{\\theta})^{n-1}f(y)=FY′​(y)=θn​(θy​)n−1 因此我们有： E(θ∗)=∫0θyf(y)dy=nθn∫0θyndy=nn+1θE(\\theta^{*}) = \\int_{0}^{\\theta}yf(y)dy = \\frac{n}{\\theta^{n}}\\int_{0}^{\\theta}y^{n}dy = \\frac{n}{n+1}\\theta E(θ∗)=∫0θ​yf(y)dy=θnn​∫0θ​yndy=n+1n​θ 也即θ∗\\theta^{*}θ∗并不是θ\\thetaθ的无偏估计 无偏MSE不一定优于有偏 X∼N(μ,σ2)X \\sim N(\\mu, \\sigma^{2})X∼N(μ,σ2)，分别用二阶矩m2m_{2}m2​和样本方差S2S^{2}S2来估计σ2\\sigma^{2}σ2，有： E(m2)=n−1nσ2E(S2)=σ2\\begin{align*} E(m_{2}) &amp;= \\frac{n-1}{n}\\sigma^{2} \\\\ E(S^{2}) &amp;= \\sigma^{2} \\\\ \\end{align*} E(m2​)E(S2)​=nn−1​σ2=σ2​ 但是： E((m2−σ2)2)&lt;E((S2−σ2)2)E((m_{2} - \\sigma^{2})^{2}) &lt; E((S^{2} - \\sigma^{2})^{2}) E((m2​−σ2)2)&lt;E((S2−σ2)2) 区间估计 标准正态 如X∼N(μ,σ2)X \\sim N(\\mu, \\sigma^{2})X∼N(μ,σ2)，其中μ\\muμ未知而σ2\\sigma^{2}σ2已知，则： X‾−μσ/n∼N(0,1)\\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0, 1) σ/n​X−μ​∼N(0,1) 因此(1−α)(1 - \\alpha)(1−α)置信区间为： (X‾−zα/2σn,X‾+zα/2σn)(\\overline{X} - z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}, \\overline{X} + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}) (X−zα/2​n​σ​,X+zα/2​n​σ​) 其中zα2z_{\\frac{\\alpha}{2}}z2α​​为标准正态分布上α2\\frac{\\alpha}{2}2α​分位数 ttt分布 在上述例子中，如果σ2\\sigma^{2}σ2未知，则应利用ttt分布来进行区间估计，具体来说： X‾−μσ/n∼N(0,1)(n−1)S2σ2∼χ2(n−1)\\begin{align*} \\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{n}} &amp;\\sim N(0, 1) \\\\ \\frac{(n-1)S^{2}}{\\sigma^{2}} &amp;\\sim \\chi^{2}(n-1) \\end{align*} σ/n​X−μ​σ2(n−1)S2​​∼N(0,1)∼χ2(n−1)​ 因此有： X‾−μS/n∼t(n−1)\\frac{\\overline{X} - \\mu}{S / \\sqrt{n}} \\sim t(n-1) S/n​X−μ​∼t(n−1) (1−α)(1-\\alpha)(1−α)置信区间为： (X‾−tα/2(n−1)Sn,X‾+tα/2(1−α)Sn)(\\overline{X} - t_{\\alpha/2}(n-1)\\frac{S}{\\sqrt{n}}, \\overline{X} + t_{\\alpha/2}(1-\\alpha)\\frac{S}{\\sqrt{n}}) (X−tα/2​(n−1)n​S​,X+tα/2​(1−α)n​S​) 同样估计均值差也可以使用ttt分布：X∼N(μ1,σ12)X\\sim N(\\mu_{1}, \\sigma_{1}^{2})X∼N(μ1​,σ12​)，Y∼N(μ2,σ22)Y\\sim N(\\mu_{2}, \\sigma_{2}^{2})Y∼N(μ2​,σ22​)，则μ1−μ2\\mu_{1} - \\mu_{2}μ1​−μ2​的估计方法为： (X‾−Y‾)−(μ1−μ2)(1n+1m)(n−1)S12+(m−1)S22n+m−2∼t(n+m−2)\\frac{(\\overline{X} - \\overline{Y}) - (\\mu_{1} - \\mu_{2})}{\\sqrt{(\\frac{1}{n} + \\frac{1}{m})\\frac{(n-1)S_{1}^{2} + (m-1)S_{2}^{2}}{n+m-2}}} \\sim t(n + m - 2) (n1​+m1​)n+m−2(n−1)S12​+(m−1)S22​​​(X−Y)−(μ1​−μ2​)​∼t(n+m−2) F分布 常用在估计两正态总体方差之比上，所依赖的分布为： S12/σ12S22/σ22∼F(n−1,m−1)\\frac{S_{1}^{2}/\\sigma_{1}^{2}}{S_{2}^{2}/\\sigma_{2}^{2}} \\sim F(n - 1, m - 1) S22​/σ22​S12​/σ12​​∼F(n−1,m−1) 渐进估计 利用中心极限定理得到标准正态分布利用S2S^{2}S2或m2m_{2}m2​等方式来估计σ2\\sigma^{2}σ2 极大似然与Fisher θ∗−θ1nI(θ∗)→N(0,1)\\frac{\\theta^{*} - \\theta}{\\sqrt{\\frac{1}{nI(\\theta^{*})}}} \\rightarrow N(0, 1) nI(θ∗)1​​θ∗−θ​→N(0,1) 其中I(θ)I(\\theta)I(θ)为Fisher信息量，具体来说： I(θ)=E((∂ log⁡ f∂θ)2)I(\\theta) = E\\biggl(\\bigl(\\frac{\\partial\\,\\log\\,f}{\\partial \\theta}\\bigr)^{2}\\biggr) I(θ)=E((∂θ∂logf​)2)","tags":["笔记","概统","复习"],"categories":["概率论与数理统计"]},{"title":"IAI-搜索","path":"/2024/06/09/IAI-搜索/","content":"人智导 搜索 搜索问题 盲目搜索过于困难的时候，采用一些方法来帮助我们加快搜索进程 深度优先 优先扩展深度更深的节点，略 性质： 一般不能保证最优解 深度限制不合理时可能找不到解，并且可能退化为穷举 是一个通用的算法，并且相对节省内存 宽度优先 优先扩展深度更浅的节点，略 性质： 问题有解的时候一定能找到，如果问题是单位耗散值则一定能找到最优解 通用算法，但是效率较低，存储量较大 Dijkstra 略 优劣： 有解一定可以找到最佳解 只考虑了距离起点的具体 启发式图搜索 引入启发知识，用于评估节点到达目标的距离，尽可能减少搜索范围 A算法 评价函数为： f(n)=g(n)+h(n)f(n) = g(n) + h(n) f(n)=g(n)+h(n) 其中g(n)g(n)g(n)是点nnn到起点sss的耗散值估计值，h(n)h(n)h(n)是点nnn到目标ttt的耗散值估计值，真实值分别为g∗(n)g^{*}(n)g∗(n)与h∗(n)h^{*}(n)h∗(n) AAA算法伪代码如下，主要为维护CLOSE\\text{CLOSE}CLOSE表与OPEN\\text{OPEN}OPEN表： CLOSE=(), OPEN=(s)\\text{CLOSE} = (),\\, \\text{OPEN} = (s)CLOSE=(),OPEN=(s)123456789101112131415161718192021while OPEN is not empty, do: n = OPEN.first() if n == g return n OPEN.pop(n) CLOSE.push(n) expand(n) for child in n.childs() if child in OPEN: # 标记为m_&#123;k&#125; f(child) = min&#123;f(child), f(n) + d(n, child) + h(child)&#125; else if child in CLOSE: # 标记为m_&#123;l&#125; f(child) = min&#123;f(child), f(n) + d(n, child) + h(child)&#125; ### important! OPEN.push(child) if f(child) change else: # 标记为m_&#123;j&#125; f(child) = f(n) + d(n, child) + h(child) OPEN.push(child) sort(OPEN, f) 最终从目标开始顺次访问父节点即可 A*算法 若AAA算法中的启发函数满足条件h(n)≤h∗(n)h(n)\\leq h^{*}(n)h(n)≤h∗(n)，则得到A∗A^{*}A∗算法 放宽了约束条件得到估计值，A∗A^{*}A∗算法的优势在与： 一定能找到最优解 启发信息越少的算法，所拓展的节点越多（不少于信息更多的算法） 对启发函数的评价方式为平均分叉数b∗b^{*}b∗，探索ddd层后其与总搜索节点数NNN的关系为： N=∑i=0db∗d=1−b∗(d+1)1−b∗N = \\sum\\limits_{i=0}^{d}b^{*d} = \\frac{1 - b^{*(d+1)}}{1 - b^{*}} N=i=0∑d​b∗d=1−b∗1−b∗(d+1)​ 一般情况下，b∗b^{*}b∗是与问题相关，而与问题的规模关系不大 改进的A*算法 对于A∗A^{*}A∗算法，其最大的问题就是CLOSE表中的节点可能再次进入OPEN表中，也即没有在第一次探索到节点的时候就找到其最短路径，会造成重复探索，导致资源的浪费。因此我们需要对启发函数做出如下限制： 若启发函数hhh满足，对于节点vvv与其父节点uuu有：h(u)−h(v)≤d(u,v)h(u) - h(v) \\leq d(u, v) h(u)−h(v)≤d(u,v)并且有h(t)=0h(t) = 0h(t)=0，则称hhh是单调的若hhh是单调的，那么扩展了节点nnn之后就已经找到了到达nnn的最优路径，并且单调的hhh一定满足A∗A^{*}A∗条件 改进后有： 扩展的节点一定满足f(n)≤f∗(s)f(n) \\leq f^{*}(s)f(n)≤f∗(s) OPEN表中满足f(n)&lt;f∗(s)f(n) &lt; f^{*}(s)f(n)&lt;f∗(s)的一定会被扩展 再次改进，使用当前被扩展的最大节点来估计f∗(s)f^{*}(s)f∗(s)，即max⁡(f(n))∼f∗(s)\\max(f(n)) \\sim f^{*}(s)max(f(n))∼f∗(s)，具体来说： 维护一个NEST表，满足NEST={ni ∣ f(ni)&lt;fm,ni∈OPEN}\\mathrm{NEST} = \\{n_{i}\\,|\\,f(n_{i}) &lt; f_{m}, n_{i}\\in \\text{OPEN}\\}NEST={ni​∣f(ni​)&lt;fm​,ni​∈OPEN}，并且在选择的时候优先选择NEST表中ggg最小的节点，如果NEST空了再去OPEN表里面选择，并更新fmf_{m}fm​ 这种情况下仍可能会导致重复探索的出现！ 其他搜索算法 例如爬山法，随机搜索算法，动态规划等，h(n)=0h(n) = 0h(n)=0的时候A∗A^{*}A∗算法就变成了动态规划（？ Viterbi算法 Viterbi算法实例 转移方程为： Q(Wij)={min⁡k(Q(W(i−1)k)+D(W(i−1)k,Wij))i≠00i=0\\begin{align*} Q(W_{ij}) = \\begin{cases} \\min\\limits_{k}(Q(W_{(i-1)k}) + D(W_{(i-1)k, W_{ij}})) &amp; i eq 0 \\\\ 0 &amp; i = 0 \\end{cases} \\end{align*} Q(Wij​)={kmin​(Q(W(i−1)k​)+D(W(i−1)k,Wij​​))0​i=0i=0​​","tags":["笔记","IAI","对抗搜索"],"categories":["人工智能导论"]},{"title":"TCS-Lecture-E","path":"/2024/06/05/TCS-Lecture-E/","content":"TCS: Propositions as Types 本文含有大量复杂的LaTeX\\LaTeXLATE​X公式，因此md文档效果不好，仅供参考！ Propositions as Types Intuitionistic Logic and Natural Deduction Intuitionistic logic insists upon a constructionist notion of truth. In particular, a proof of A∨BA\\lor BA∨B must show which of AAA or BBB holds (different from classic logic). Natural Deduction Proof rules should come in pairs: Introduction rules which are like definitions of the logic operators. Elimination rules which are the consequences of theirdefinitions. Both of them should be in harmony. We will define the four kinds of rules, conjunction, implication, disjunction and falsehood in order. Gentzen’s contribution: Subformula principle: Proofs can be normalized so that no concepts enter the proof other than those contained in the final result (subformula). This means we can use only the known proposition and the subformulas of the conclusion. Guiding Question for Defining Logic Martin-Löf: The meaning of a proposition is determined by what counts as a verification (or proof) of it. Proposition: AAA Justification: A trueA \\text{ true}A true, A is true at time tA \\text{ is true at time } tA is true at time t, …\\dots… So that we need to determin a proposition by a verification(not only itself). In this lecture, we only consider justification A trueA \\text{ true}A true so we omit thet suffix true\\text{true}true Conjunction We use ‘→\\to→’ to represents the prooftree in PDF. (∧I)(A,B)→(A∧B)(∧E1)(A∧B)→A(∧E2)(A∧B)→B\\begin{align*} (\\land I)\\qquad &amp;(A, B) \\to (A\\land B) \\\\ (\\land E_{1})\\qquad &amp;(A\\land B) \\to A \\\\ (\\land E_{2})\\qquad &amp;(A\\land B) \\to B \\\\ \\end{align*} (∧I)(∧E1​)(∧E2​)​(A,B)→(A∧B)(A∧B)→A(A∧B)→B​ We define the local soundness and local completeness as follows: Local Soundness: The elimination cannot give us new information.((D→A), (E→B))→(A∧B)→A⇒R(D→A)\\begin{align*}&amp;\\quad((\\mathcal{D} \\to A),\\, (\\mathcal{E} \\to B)) \\to (A\\land B) \\to A \\\\&amp;\\Rightarrow_{R} (\\mathcal{D}\\to A)\\end{align*}​((D→A),(E→B))→(A∧B)→A⇒R​(D→A)​Local Completeness: The elimination can reconstitute the proof by introduction(D→A)⇒E(((D→(A∧B))→A), ((D→(A∧B))→B))→(A∧B)→A\\begin{align*} &amp;\\quad (\\mathcal{D}\\to A)\\\\ &amp;\\Rightarrow_{E}(((\\mathcal{D} \\to (A\\land B)) \\to A),\\, ((\\mathcal{D} \\to (A\\land B)) \\to B)) \\to (A\\land B) \\to A\\end{align*}​(D→A)⇒E​(((D→(A∧B))→A),((D→(A∧B))→B))→(A∧B)→A​ Implication We define the hypothetical judgment at first: (A∧(B∧C))⊢B(A\\land (B\\land C)) \\vdash B (A∧(B∧C))⊢B This is not an inference as it consists of two inferences! We have conjunctions inferences at now. Then we can define implication introduction and elimination rules: (⊃Ix)(A‾x→∗B)→(A⊃B)(⊃E)(A⊃B, A)→B\\begin{align*} (\\supset I^{x})\\qquad &amp;(\\overline{A}^{x} \\to^{*} B) \\to (A\\supset B) (\\supset E)\\qquad &amp; (A\\supset B,\\, A) \\to B \\end{align*} (⊃Ix)​(Ax→∗B)→(A⊃B)(⊃E)​(A⊃B,A)→B​ In which that the x^{x}x means the local scope. Disjunction Define the disjunction as follows: (∨I1)A→(A∨B)(∨I2)B→(A∨B)(∨Ex,y)(A∨B,A‾x→∗C,B‾y→∗C)→C\\begin{align*} (\\lor I_{1})\\qquad &amp;A \\to (A\\lor B) \\\\ (\\lor I_{2})\\qquad &amp;B \\to (A\\lor B) \\\\ (\\lor E^{x, y})\\qquad &amp;(A\\lor B, \\overline{A}^{x}\\to^{*}C, \\overline{B}^{y}\\to^{*}C) \\to C \\end{align*} (∨I1​)(∨I2​)(∨Ex,y)​A→(A∨B)B→(A∨B)(A∨B,Ax→∗C,By→∗C)→C​ Falsehood Falsehood is written as ⊥\\bot⊥. It has no introduction as we shouldn’t prove it. (⊥E)⊥→C(\\bot E) \\bot \\to C (⊥E)⊥→C Intuitionistic Natural Deduction So, we can use these four to define some other operates such as ¬ eg¬, ⊤\\top⊤ and ↔\\leftrightarrow↔ ¬A=defA⊃⊥⊤=def⊥⊃⊥A↔B=def(A⊃B)∧(B⊃A)\\begin{align*} eg A &amp;\\mathop{=}\\limits^{\\text{def}} A \\supset \\bot \\\\ \\top &amp;\\mathop{=}\\limits^{\\text{def}} \\bot \\supset \\bot \\\\ A \\leftrightarrow B &amp;\\mathop{=}\\limits^{\\text{def}} (A \\supset B) \\land (B \\supset A) \\end{align*} ¬A⊤A↔B​=defA⊃⊥=def⊥⊃⊥=def(A⊃B)∧(B⊃A)​ Now we can begin prove! The follows is some interesting conclusion: A⊃B⊃AA⊃¬¬A(A⊃B)⊃(¬B⊃¬A)¬(A∨B)↔(¬A∧¬B)\\begin{align} A \\supset &amp;B \\supset A \\\\ A \\supset &amp; eg eg A \\\\ (A \\supset B) \\supset &amp;( eg B \\supset eg A) \\\\ eg (A \\lor B) \\leftrightarrow &amp;( eg A \\land eg B) \\end{align} A⊃A⊃(A⊃B)⊃¬(A∨B)↔​B⊃A¬¬A(¬B⊃¬A)(¬A∧¬B)​​ But some weird things hapend as the following is not provable: ((A⊃B)⊃A)⊃A¬¬A⊃A(¬A⊃¬B)⊃(B⊃A)¬(A∧B)↔(¬A∨¬B)\\begin{align} ((A \\supset B) \\supset A) &amp;\\supset A \\\\ eg eg A &amp;\\supset A \\\\ ( eg A \\supset eg B) &amp;\\supset (B \\supset A) \\\\ eg (A \\land B) \\leftrightarrow &amp;( eg A \\lor eg B) \\end{align} ((A⊃B)⊃A)¬¬A(¬A⊃¬B)¬(A∧B)↔​⊃A⊃A⊃(B⊃A)(¬A∨¬B)​​ What the f***! The most interesting is that: (Gilvenko’s Theorem):, AAA is valid in classical logic if and only if ¬¬A eg eg A¬¬A is valid in intuitionistic logic! And intuitionistic logic is PSPACE-complete! Propositions as Types We write M:AM: AM:A to represent that MMM is a proof of AAA and alternatively MMM is a program of type AAA. So we can rewrite the four kinds of roles by λ\\lambdaλ-calculus! Implication (⊃Ix)((x:A‾x)→(M:B))→(λx.M):(A⊃B)(⊃E)((M:(A⊃B)),(N:A))→(MN:B)\\begin{align*} (\\supset I^{x})\\qquad &amp;((\\overline{x:A}^{x})\\to (M:B)) \\to (\\lambda x.M):(A\\supset B) \\\\ (\\supset E)\\qquad &amp;((M:(A\\supset B)), (N:A)) \\to (MN: B) \\end{align*} (⊃Ix)(⊃E)​((x:Ax)→(M:B))→(λx.M):(A⊃B)((M:(A⊃B)),(N:A))→(MN:B)​ From its local soundness we can get β\\betaβ reduction, and from local completeness we can get η\\etaη rule! Turing has proved that typed λ\\lambdaλ-calculus always terminates. Conjunction (∧I)((M:A),(N:B))→(⟨M,N⟩:A∧B)(∧E1)(M:(A∧B))→((fstM):A)(∧E2)(M:(A∧B))→((sndM):B)\\begin{align*} (\\land I)\\qquad((M:A), (N:B)) &amp;\\to (\\langle M, N\\rangle: A\\land B) \\\\ (\\land E_{1})\\qquad (M:(A\\land B)) &amp;\\to ((\\mathbf{fst}M):A) \\\\ (\\land E_{2})\\qquad (M:(A\\land B)) &amp;\\to ((\\mathbf{snd}M):B) \\end{align*} (∧I)((M:A),(N:B))(∧E1​)(M:(A∧B))(∧E2​)(M:(A∧B))​→(⟨M,N⟩:A∧B)→((fstM):A)→((sndM):B)​ The local reduction and expansion can give out the meaning of ⟨⋅,⋅⟩\\langle \\cdot, \\cdot\\rangle⟨⋅,⋅⟩, fst\\mathbf{fst}fst and snd\\mathbf{snd}snd Disjunction (∨I1)(M:A)→((inlM):A∨B)(∨I2)(M:B)→((inrM):A∨B)(∨Ex,y)(M:(A∨B),(x:A‾x→(N:C)),(y:B‾y→(P:C)))→case(M,x.N,y.P):C\\begin{align*} (\\lor I_{1})\\qquad (M:A) &amp;\\to ((\\mathbf{inl}M): A\\lor B) \\\\ (\\lor I_{2})\\qquad (M:B) &amp;\\to ((\\mathbf{inr}M): A\\lor B) \\\\ (\\lor E^{x,y}) \\qquad (M:(A\\lor B), &amp;(\\overline{x:A}^{x} \\to (N:C)), (\\overline{y:B}^{y} \\to (P:C))) \\\\ &amp;\\to \\mathbf{case}(M, x.N, y.P):C \\end{align*} (∨I1​)(M:A)(∨I2​)(M:B)(∨Ex,y)(M:(A∨B),​→((inlM):A∨B)→((inrM):A∨B)(x:Ax→(N:C)),(y:B​y→(P:C)))→case(M,x.N,y.P):C​ Falsehood No introduction rule. (⊥E)(M:⊥)→(abortM:C)(\\bot E)\\qquad(M:\\bot) \\to (\\mathbf{abort}M:C) (⊥E)(M:⊥)→(abortM:C)","tags":["笔记","TCS","命题","类型"],"categories":["理论计算机科学导引"]},{"title":"网原笔记7","path":"/2024/06/05/网原笔记7/","content":"计算机网络原理 笔记 7 无线网络和移动网络 概述 无线网络概述 在无线网络中，体系结构如下： 无线主机：端系统 无线链路：主机通过无线通信链路连接到基站或主机，不同无线链路具有不同的传输速率与覆盖距离 基站：负责协调与之相关联的多个主机之间的数据传输 网络基础设施：无线设备希望与之通信的网络 与基站相关联的主机称为以基础设施模式运行，所有网络服务有基站向主机提供，而自组织网络，主机向自身提供各种服务 由于无线主机可以移动，因此会出现切换现象，即改变与之相关联的基站 无线网络的分类一般是按照无线跳的数目和是否有基础设施（如基站）来共同决定的 基于基础设施 无基础设施 单跳 具有一个与较大有线网络连接的基站如802.11网络、4G LTE等 常用于协调其他节点的传输如蓝牙、自组织 多跳 无线节点为了与更大网络通信需要经过多个无线节点例如无线网状网络 没有基站，每个节点为了通信需要多个节点中继例如MANET或VANET 无线网络特征 相比于有线网络，无线网络有很多不同，例如： 信号强度递减：使用电磁波传输会导致信号的减弱，成为路径损耗 不同源之间会有干扰：在同一个频段中发送信号的源、环境噪声等都会相互干扰 多径传播：电磁波的不同部分在传播途中经过了不同的路径，导致信号模糊（例如经过了多次反射） 相干时间 在多径传播中，相干时间之信道中两次接收到预想信号的时间差，会影响到最大传输速率 相干时间示意图 取决于发送频率与接受者的速度 如果接受者不动则在一定时间后影响会被消除 噪声 由于无线链路非常容易出现差错，因此采用了CRC与ARQ结合的方式 对于主机，其接受到的信号事实上是退化后的初始信号与环境噪声的结合，我们使用信噪比来测量相对污染程度，信噪比越大，更容易提取出有效的信息，同时我们使用比特差错率来衡量接收方收到错误比特概率 不同的调制编码方式对于信号的传输也有影响，如下图 SNR、BER与调制编码方式 主要趋势为： 调制方案给定，BER与SNR成负相关（发送方增加传输速率） SNR给定：BER与调制方案的比特传输率成正相关 物理层调制技术可以动态选择，用于适配信道条件 其它问题 隐藏终端与衰减同样是无线传输中的两个重要问题，隐藏终端是是指两个终端相互之间不可见（被物理阻隔），但是其发送的信号在另一个终端有干扰；衰减很好理解 隐藏终端与衰减 CDMA 在无线领域使用非常广泛的协议，用于避免信号的相互干扰，举例来说如下 码分多址实例 CDMA将每个要发送的bit与编码bit想成来进行编码，编码bit以一个相当高的速率（码片速率）在变化，相当于将一个bit的信息编码为MMMbits的信息序列 理想状态下，编码为： Zi={Zim}∣1≤m≤M={di⋅cm}∣1≤m≤MZ_{i} = \\{Z_{im}\\}|_{1\\leq m \\leq M} = \\{d_{i}\\cdot c_{m}\\}|_{1\\leq m \\leq M} Zi​={Zim​}∣1≤m≤M​={di​⋅cm​}∣1≤m≤M​ 解码为： di=1M∑i=1MZim⋅cmd_{i} = \\frac{1}{M}\\sum\\limits_{i=1}^{M}Z_{im}\\cdot c_{m} di​=M1​i=1∑M​Zim​⋅cm​ 然而当有N&gt;1N &gt; 1N&gt;1个发送方时，接收方作加性处理，即： Zim∗=∑j=1NZimjZ^{*}_{im} = \\sum\\limits_{j=1}^{N}Z^{j}_{im} Zim∗​=j=1∑N​Zimj​ 而解码过程无需变化，在合适的CDMA编码的情况下，仍能辨别出所需要提取的信息 WiFi: 802.11无线LAN 多路访问使用CSMA/CA，有基站版和自组织版 体系结构 体系结构与自组织网络版 基本单位为基本服务集，一个BSS中包含若干个无线站点和一个接入点（中央基站），该种模式的WLAN称之为基础设施WLAN，其中基础设施指的是AP与其连接的有线网 每一个802.11无线站点和AP有一个6字节MAC地址，由IEEE\\text{IEEE}IEEE管理 同样可能存在自组织网络，相当于不需要与外部通信的情况下交换数据 信道与关联 802.11运行在2.4∼2.4835GHz2.4\\sim 2.4835\\text{GHz}2.4∼2.4835GHz的频段中，并将这个频段划分为了11个部分重叠的信道，当且仅当两个新岛之间距离超过4的时候才无重叠 每个AP会被分配一个单字或双字的服务集标识与一个信道号 WiFi丛林指的是一个物理位置，在此处无线站点可以收到多个AP的信号，因此我们需要和某一个AP进行关联，即在其间建立一条虚拟线路 为了了解到丛林中的AP，每个AP会周期性的发送信标帧，包括其SSID与MAC地址，站点通过扫描信道得知当前的AP，称之为被动扫描 指定关联AP没有相关准则，由软件方处理 同样的，站点可以主动向AP发送探测请求帧并期待AP回复探测响应帧，称之为主动扫描 主动扫描与被动扫描 确定了想要关联的AP后，站点发送关联请求帧，AP回复关联响应帧，之后将其加入AP子网中 802.11 MAC协议 采用CDMA/CA，由于无线设备的特殊性，信道的碰撞难以被检测（甚至有一部分无法被检测），因此采用避免碰撞的方式，一旦站点开始发送帧，就完整的发送 接收到信号的强度远小于发送的信号，制造检测碰撞设备代价高 不一定检测到所有碰撞，如隐藏终端和衰减 CSMA/CA协议如下： 站点监听到信道空闲，等待DIFS时间并完整发送帧 否则，选取一个随机回退值，在侦听到空闲时递减，在侦听到忙时不变 回退值减到0时，完整发送帧 等待ACK，若收到，则发送下一帧时从第二步开始 反之重新进入第二步并增大回退值 其与CSMA/CD最大的不同点在于，在侦听到空闲的时候不立即发送帧，而是等待回退值降到0，因此需要期待不同站点之间的回退值有一定距离 链路层确认 处理隐藏终端 采用RTS与CTS，即一个站点发送数据之前首先发送一个RTS控制帧，指示其所需要的总时间，AP接收到后广播CTS控制帧，告诉发送方可以发送，抑制其他的站点发送 处理隐藏终端 优势为： 有效解决隐藏终端 RTS和CTS的碰撞很短，对性能影响不大 用作点对点链路 略 IEEE 802.11帧 802.11帧示例 重要字段为： 有效载荷与CRC：通常包括IP数据报或者ARP分组 地址字段：共有四个，包括 地址1：目的地站点的MAC地址 地址2：源站点的MAC地址 地址3：该BSS所在子网对应的路由器接口MAC地址 地址4：用于自组织网络中互联，略 序号：用于区分同一个帧的不同副本（区分新帧与重传的帧） 持续期：预约享有信道的时间（RTS与CTS） 帧控制：很复杂，具体来说 类型：区分RTS、CTS、ACK与数据帧 到和从：定义地址字段含义 WEP：加密指示 相同IP子网中的移动性 在同一个子网下的多个BSS，TCP会话如何在其间丝滑切换？ 由于BSS在同一IP子网下，因此其IP地址不会发生变化，并且交换机可以通过自学习来改变与站点相连接的AP的端口MAC 高级特色 速率适应：根据信道特点来选择物理层调制技术，如果连续多帧没有收到ACK则降速，反之（或降速达到一定时间后）增速 功率管理：节点可以向AP发送信号表明自己进入睡眠状态，AP缓存发送到对应站点的帧。 节点在信标帧到来之前醒来，通过检测信标帧（包括所有被缓存帧的目标站点列表）确认是否有信号发过来，如果有则发送缓存请求报文，反之继续睡 个人域网络：蓝牙 自组织为一个皮可网，分为主设备、从设备与寄放设备，主设备统筹全局通信，所有通信必须经由主设备，寄放设备是不可活动的 皮可网 其采用TDM，每个时隙625μs625\\mu s625μs，工作在2.4GHz2.4\\text{GHz}2.4GHz，在每个时隙内，发送方利用79个信道中的一个进行传输，并且以不同时隙使用的信道是伪随机的，称之为跳频扩展频谱 蜂窝因特网接入 蜂窝网络与有线网络的同： 设备之间距离很远，但是属于同一个Carrier 全球蜂窝网络是一种网络的网络 广泛使用各种协议 与有线网络互联 蜂窝网络与有线网络的异： 有不同的无线链路层 移动性是第一要求 用户是可区分的（SIM卡） 用户需要向提供商订阅，权威机构提供基础设施 4G：LTE 4G网络架构 其中包括： 移动设备：将订阅者的身份信息ISMI存储在SIM卡中 基站：在服务范围边缘，管理范围内的无线通信资源；管理设备授权，与AP相似 归属订阅者服务：储存有关“归属网络”的信息，用于授权管理 S/P网关：位于数据传输的路径中，P网关是处理蜂窝网络与因特网的交流，提供NAT服务 移动管理实体：与HSS一起管理设备授权；管理设备的交接、位置跟踪等；设置设备到P网关的路径 4G无线网 将每个设备连接到一个基站 可以用很多频带，每个频带内有大量信道，可以区分上行与下行数据 通过OFDM共享信道，速率可以非常高 正交频分复用 图中，每一个PRB是一个传输单元，每一个单元内可以按照时隙与频段划分给不同用户，不同颜色代表不同用户 数据平面与控制平面分离 控制平面：管理移动性、安全与授权 数据平面：管理数据传输 控制平面 LTE中的控制平面有着不同链路层协议，如下： LTE协议1 新增的部分为： 数据收敛：压缩头部信息并加密 无线链路控制：信息的打碎与充足，执行可靠数据传输 中路访问：使用OFDM的需求 LTE协议2 传输规则为： 移动设备将数据传给S网关 S网关传给P网关 优势在与：用户移动的时候只有信道的末端（基站）在变 数据平面 主要是与基站通信，方法为： 基站全频段广播基础同步信号 移动设备找都一个同步信号，之后定位这个频段的第二同步信号（可能有多个基站），并拿到信道的相关信息 之后移动设备挑选基站连接 并且为了节省功率，同样会有睡眠模式，不同的是有两种模式： 浅睡眠：100ms100ms100ms不工作导致，并会时不时醒来检查下行传输 深睡眠：555-10s10s10s不动作导致，可能切换蜂窝 全球蜂窝网络 全IP连接，连接归属网络与被访网络，每个设备的SIM卡中存储了归属网络中的全球性身份信息，可以直接 与归属网络通信，也可以和被访网络进行漫游 5G 适用场景：大信息交流、高可信低延迟交流、增强移动宽带 新无线的新点： 两个频带：毫米波频率 不兼容4G 大量有线天线 毫米波有更高数据传输速率，但是传输距离更短 5G架构 用户直接向与数据中心相连的基站进行通信，数据中心会有分层，中心-边缘-远边缘 5G数据中心图示 移动性 移动性准则 移动性光谱 主要挑战是，如何知道发送的包要到哪，主要处理方式有两种： 路由器处理：路由器决定哪些设备跟它通信，通知这些设备给它发包。这种方式对路由器的变化较简单，可以直接使用之前的转发表和最长前缀匹配，但是当移动设备大量增加以后负担过重 端系统处理：在边缘进行处理： 间接路由：通过归属网络与移动设备进行交流 直接路由：直接与移动设备交流 其中“归属网络”非常重要： 有一个确定的信息源 别人可以与你进行通信 两种网络 4G/5G网络中有两种主要的网络： 归属网络：由蜂窝提供商提供服务，HSS储存了相关信息 被访网络：归属网络之外的所有网络，提供和远端的通信 而在ISP/WiFi中，不再有归属网络的概念： ISP的授权存储在设备或者用户上 ISP的影响力非常巨大 不同的网络有不同的授权，有为4G设计的结构但是未使用 ISP/WiFi网络 注册 移动设备和被访网络中MME相连接 被访网络中的MME向HSS注册移动设备的位置 最终被访MME知道设备存在，HSS知道设备位置 通信过程 通信者和移动设备通信的过程为： 将信息发给归属网关 归属网关将其发送给被访网关 被访网关与移动设备通信 之后被访网关间接路由（经过归属网关转移）或直接路由（直接发回） 但是这种情况下，如果通信者希望与同一网络下的移动设备通信，则效率会有很大降低；但是其优势在与连接的稳定性，移动设备的移动只会带来新的注册，同新方还是只用给HSS发信息即可 另一种通信过程为： 将信息发给归属网关 归属网关回复被访网络有关信息 直接与被访网关通信 克服了上述三角路由的效率问题，但是通信者必须保证自己发送信息到了正确的位置，并且被访网络的变化处理更复杂 实际中的移动性 4G 移动设备与被访网络中的基站通信，向基站提供IMSI 被访MME使用IMSI联系其HSS，并建立控制平面状态（相互知道移动设备在被访网络中） 数据平面建立：归属P网关和被访MME建立联系，被访MME通过基站与移动设备通信 移动设备可能改变其在被访网络中的接入点 移动设备的数据平面建立是通过S网关和基站共同完成的，其信道路径为：设备↔\\leftrightarrow↔基站↔\\leftrightarrow↔被访S网关↔\\leftrightarrow↔归属P网关↔\\leftrightarrow↔通信者，其中信道上通信的数据使用了GTP封装在UDP中 切换基站 源基站选择目的基站，向其发送请求 目的基站预先分配频段与时隙，回复ACK并告知相关信息 源基站告知移动设备新基站的信息（在移动设备看来切换已经完成） 源基站停止向移动设备发送信息，而是发送到目的基站 目的基站告知MME，MME通知S网关，S网关修改目的地 源基站收到ACK，释放资源，完成 基站切换 移动IP 大约20年前有了标准化架构，但是并没有广泛使用，其架构主要是： 间接路由 归属代理：HSS与归属P网关的结合 外部代理：MME与S网关结合 通过ICMP扩展注册，协议用于发现代理","tags":["笔记","网原","WiFi"],"categories":["计算机网络原理"]},{"title":"TCS-Lecture-D","path":"/2024/05/29/TCS-Lecture-D/","content":"TCS: Interactive Proofs and Zero-Knowledge Interactive Proofs and Zero-Knowledge Interactive Proofs Interactive Proof Verification Interactive proof system allows prover PPP and verifier VVV to exchange messages before stopping. We restrict VVV to be PPT while the probabilitic is necessary otherwise this system is NP\\text{NP}NP as PPP is stronger than VVV. Problem AAA is in IP\\text{IP}IP if there is a pair of interactive algorithms (P,V)(P, V)(P,V), with VVV running in probabilistic polynomial time in the length of input xxx, such that(Completeness). If x∈Ax\\in Ax∈A, then P(⟨P,V⟩(x)=1)=1P(\\langle P, V\\rangle(x) = 1) = 1P(⟨P,V⟩(x)=1)=1.(Soundness). If x∉Ax otin Ax∈/A, then for any possibly dishonest P∗P^{*}P∗, we have P(⟨P,V⟩(x)=1)≤12P(\\langle P, V\\rangle(x) = 1) \\leq \\frac{1}{2}P(⟨P,V⟩(x)=1)≤21​.(P,V)(P, V)(P,V) satisfying above is called a proof system for AAA. We say A∈IP[ℓ]A\\in\\text{IP}[\\ell]A∈IP[ℓ] if it has a proof system using ℓ=ℓ(∣x∣)\\ell = \\ell(|x|)ℓ=ℓ(∣x∣) times of message exchanges (number of messages, not rounds!). We have that: BPP⊆IP[1]\\text{BPP} \\subseteq \\text{IP}[1]BPP⊆IP[1] Concretely, we consider two problem GRAPH-ISO\\text{GRAPH-ISO}GRAPH-ISO(图同构问题) and GRAPH-NONISO\\text{GRAPH-NONISO}GRAPH-NONISO. Easily, GRAPH-ISO∈NP\\text{GRAPH-ISO}\\in \\text{NP}GRAPH-ISO∈NP since we can choose the isomorphic permutation π\\piπ as witness. Besides, we have GRAPH-NONISO∈IP\\text{GRAPH-NONISO}\\in \\text{IP}GRAPH-NONISO∈IP. The GNI protocol is: VVV samples a random b∈{0,1}b\\in\\{0, 1\\}b∈{0,1} and a random permutation π\\piπ, send π(Gb)\\pi(G_{b})π(Gb​) to PPPPPP returns an bit b′b&#x27;b′ to VVV and VVV accepts iff b′=bb&#x27; = bb′=b As PPP is all-know, it must have the ability to distinguish bbb if G0≁G1G_{0} ot\\sim G_{1}G0​∼G1​. But it can just guess arbitarily if they are isomorphic. Merlin-Arthur (Public-Coin) Protocols (Skip) A Merlin-Arthur protocol is an interactive proof system where the verifier (Arthur) messages are public random coin flips. A really simple VVV! Let AM[ℓ]\\text{AM}[\\ell]AM[ℓ] to be the Merlin-Arthur protocol with ℓ(∣x∣)\\ell(|x|)ℓ(∣x∣) messages. Consider MA=AM[1]\\text{MA} = \\text{AM}[1]MA=AM[1] and AM=AM[2]\\text{AM} = \\text{AM}[2]AM=AM[2] Though it seems week, but we have: Goldwasser-Sipser theorem: ∀ℓ\\forall \\ell∀ℓ, IP[ℓ]⊆AM[ℓ+2]\\text{IP}[\\ell]\\subseteq\\text{AM}[\\ell + 2]IP[ℓ]⊆AM[ℓ+2] Define a set: S={(H,π) ∣ π∈Aut(H),H∼G0 or H∼G1}S = \\{(H, \\pi) \\,|\\, \\pi\\in\\text{Aut}(H), H\\sim G_{0} \\text{ or } H\\sim G_{1} \\} S={(H,π)∣π∈Aut(H),H∼G0​ or H∼G1​} Aut(H)\\text{Aut}(H)Aut(H) represents the automorphism permutation multiplicity. So we have: ∣S∣={n!G0∼G12n!otherwise|S| = \\begin{cases} n! &amp; G_{0} \\sim G_{1} \\\\ 2n! &amp; \\text{otherwise} \\end{cases} ∣S∣={n!2n!​G0​∼G1​otherwise​ So the GRAPH-NONISO\\text{GRAPH-NONISO}GRAPH-NONISO is transformed into confirming ∣S∣|S|∣S∣ Let H\\mathcal{H}H be a pairwise independent hash family with U={0,1}mU = \\{0, 1\\}^{m}U={0,1}m and R={0,1}kR = \\{0, 1\\}^{k}R={0,1}k where k&lt;mk &lt; mk&lt;m. Then the protocol is: TODO More facts IP=PSPACE\\text{IP} = \\text{PSPACE}IP=PSPACE IP[ℓ]=AM[ℓ]=AM\\text{IP}[\\ell] = \\text{AM}[\\ell] = \\text{AM}IP[ℓ]=AM[ℓ]=AM for all constant ℓ≥2\\ell \\geq 2ℓ≥2 AM=MA=IP\\text{AM} = \\text{MA} = \\text{IP}AM=MA=IP if we allow completeness error Coin Flipping and Commitment We want a protocol where Alice and Bob talk to each other and then decide some important thing on the outcome R(a,b)R(a, b)R(a,b) of the coin flip and it makes sure that the result is not biased even if one of them is cheating (malicious). This means: P(R=0)≤12+negl(n)P(R=1)≤12+negl(n)\\begin{align*} P(R = 0) &amp;\\leq \\frac{1}{2} + \\text{negl}(n) \\\\ P(R = 1) &amp;\\leq \\frac{1}{2} + \\text{negl}(n) \\end{align*} P(R=0)P(R=1)​≤21​+negl(n)≤21​+negl(n)​ So we need something to hide aaa which filped by Alice to Bob to avoid bias. Bit Commitment The commitment scheme is a protocol consisting of the commit phase and reveal phase. A PPT protocol Com\\text{Com}Com is a (computationally hiding and statistically binding) commitment scheme if:Hiding: ∀ x0≠x1\\forall\\, x_{0} eq x_{1}∀x0​=x1​, Com(x0)≈cCom(x1)\\text{Com}(x_{0})\\approx_{c}\\text{Com}(x_{1})Com(x0​)≈c​Com(x1​).Binding: The probability that Alice can open Com(x0)\\text{Com}(x_{0})Com(x0​) to x1x_{1}x1​ with x1≠x0x_{1} eq x_{0}x1​=x0​ is negligible. In this ≈c\\approx_{c}≈c​ means that one cannot distinguish both is polynomial time. Intuitively, this definition means Bob(recevier) can hardly verify x0x_{0}x0​ or x1x_{1}x1​ and Alice(sender) can almost always verify them. Coin Flipping from Bit Commitment The safe protocol is as follows: Alice send Com(a)\\text{Com}(a)Com(a) to Bob with a random aaaBob sends bbb to AliceAlice opens Com(a)\\text{Com}(a)Com(a)Set R=a⊕bR = a \\oplus bR=a⊕b Bit Commitment From PRG (Naor’s Construction) Assume GGG is a PRG with ℓ(n)=3n\\ell(n) = 3nℓ(n)=3n In the commit phase:The receiver sends x∈{0,1}3nx\\in\\{0, 1\\}^{3n}x∈{0,1}3n;The sender samples m∈{0,1}m\\in\\{0, 1\\}m∈{0,1}, z∈{0,1}nz\\in\\{0, 1\\}^{n}z∈{0,1}n and sends y=G(z)⊕xmy = G(z)\\oplus x^{m}y=G(z)⊕xm;In the reveal phase:The sender sends zzz and mmm. Zero-Knowledge Proofs Definition at first is as follows, in which view\\text{view}view contains the transcript of the interaction(all messages and their probabilities) and local information. An interactive protocol (P,V)(P, V)(P,V) is perfect (statistical or computational) ZK for AAA if, ∀\\forall∀ PPT V∗V^{*}V∗, there exists a PPT simulator SSS such that ∀ x∈A\\forall\\, x\\in A∀x∈A, the following two distributions are the same:viewV∗⟨P,V∗⟩(x)\\text{view}_{V^{*}}\\langle P, V^{*}\\rangle(x)viewV∗​⟨P,V∗⟩(x)S(x)S(x)S(x) We have GRAPH-ISO∈PZK\\text{GRAPH-ISO} \\in \\text{PZK}GRAPH-ISO∈PZK. The protocol is as follows: PPP samples a random permutation π\\piπ and sends G=π(G0)G = \\pi(G_{0})G=π(G0​) to VVV VVV samples a random b∈{0,1}b\\in\\{0, 1\\}b∈{0,1} and sends it to PPP PPP responds with a proof that G∼GbG\\sim G_{b}G∼Gb​ with the permutation π∘σb\\pi\\circ\\sigma^{b}π∘σb simulator and rewind To prove this protocol is what we want, we need to prove its completeness, soundness and ZK. The first two are easy to argue, the ZK need a simulator and we generates it as follows: Choose aaa uniformly at random.Sample a random permutation π\\piπ and compute G=π(Ga)G = \\pi(G_{a})G=π(Ga​).Randomly sample rrr and simulate V∗V^{*}V∗ with random tape content rrr.If V∗V^{*}V∗ sends b=ab = ab=a, outputs (G,π)(G, \\pi)(G,π) as the message and the random tape rrr as the internal randomness of V∗V^{*}V∗.If V∗V^{*}V∗ sends b≠ab eq ab=a, rewind and start from the beginning. ZK Proofs for NP We have: (Goldreich-Micali-Wigderson). If statistically binding commitments exist, then there exists a zero-knowledge proof system for 3-COLORING\\text{3-COLORING}3-COLORING The protocol is: PPP samples random permutation π:{0,1,2}→{0,1,2}\\pi: \\{0, 1, 2\\}\\to \\{0, 1, 2\\}π:{0,1,2}→{0,1,2}. PPP sends {Com(π(ϕ(v))) ∣ v∈V}\\{\\text{Com}(\\pi(\\phi(v))) \\,|\\, v\\in V\\}{Com(π(ϕ(v)))∣v∈V} VVV samples a random edge (u,v)←E(u, v)\\gets E(u,v)←E and sends it to PPP PPP opens the commitment cuc_{u}cu​ and cvc_{v}cv​ VVV checks if π(ϕ(u)),π(ϕ(v))∈{0,1,2}\\pi(\\phi(u)), \\pi(\\phi(v))\\in\\{0, 1, 2\\}π(ϕ(u)),π(ϕ(v))∈{0,1,2} and π(ϕ(u))≠π(ϕ(v))\\pi(\\phi(u)) eq \\pi(\\phi(v))π(ϕ(u))=π(ϕ(v)) In this, ϕ\\phiϕ is a coloring scheme","tags":["笔记","交互式证明","零知识","TCS"],"categories":["理论计算机科学导引"]},{"title":"IAI-统计机器学习","path":"/2024/05/27/IAI-统计机器学习/","content":"人智导 统计机器学习 统计机器学习 对于数据集D={(xi,yi)}D = \\{(x_{i}, y_{i})\\}D={(xi​,yi​)}，输入输出之间存在关系fff，算法AAA根据训练集从假设空间H\\mathcal{H}H中选取一个合适的函数g≈fg\\approx fg≈f 主要决定因素：模型、策略、算法 分类方式： 监督式学习 半监督式学习 弱监督式学习 支持向量机(SVM) 按照模型的复杂程度，分为线性可分、线性与非线性 线性可分SVM 定义线性可分SVM相关概念如下： 线性可分训练集：T={(xi,yi) ∣ 1≤i≤N,xi∈Rn,yi∈{−1,1}}T = \\{ (x_{i}, y_{i}) \\,|\\, 1\\leq i\\leq N, x_{i}\\in \\mathbb{R}^{n}, y_{i}\\in\\{-1, 1\\} \\}T={(xi​,yi​)∣1≤i≤N,xi​∈Rn,yi​∈{−1,1}}给定超平面wx+b=0wx+b = 0wx+b=0，于是可以定义函数间隔为：γ^=min⁡1≤i≤N{(wxi+b)yi}\\hat{\\gamma} = \\mathop{\\min}\\limits_{1\\le i \\le N}\\{(wx_{i} + b)y_{i}\\}γ^​=1≤i≤Nmin​{(wxi​+b)yi​}相对应的，定义几何间隔为函数间隔的归一化，也即考虑超平面的缩放的影响γ=γ^∣∣w∣∣\\gamma = \\frac{\\hat{\\gamma}}{||w||}γ=∣∣w∣∣γ^​​通过间隔最大化得到分类超平面w∗x+b∗=0w^{*}x+b^{*} = 0w∗x+b∗=0，则得到决策函数：f(x)=sgn(w∗x+b∗)f(x) = \\mathrm{sgn}(w^{*}x+b^{*})f(x)=sgn(w∗x+b∗)此即线性可分SVM 于是关键问题即为间隔最大化： max⁡w,bγ=max⁡w,bγ^∣∣w∣∣\\max\\limits_{w, b}\\gamma = \\max\\limits_{w, b}{\\frac{\\hat{\\gamma}}{||w||}} w,bmax​γ=w,bmax​∣∣w∣∣γ^​​ 显然，函数间隔是可缩放的（函数缩放表示为$w, b$等比例缩放），因此不妨令γ^=1\\hat{\\gamma} = 1γ^​=1，则进一步转化为规划问题： max⁡w,b1∣∣w∣∣=min⁡w,b12∣∣w∣∣2\\max\\limits_{w, b}\\frac{1}{||w||} = \\min\\limits_{w, b} \\frac{1}{2}||w||^{2}w,bmax​∣∣w∣∣1​=w,bmin​21​∣∣w∣∣2使得：∀i,γi^=(wxi+b)yi≥1\\forall i,\\quad \\hat{\\gamma_{i}} = (wx_{i} + b)y_{i} \\geq 1∀i,γi​^​=(wxi​+b)yi​≥1 定义相对应的拉格朗日函数为： L(w,b,α)=12∣∣w∣∣2+∑i=1Nαi[1−(wxi+b)yi]L(w, b, \\alpha) = \\frac{1}{2}||w||^{2} + \\sum\\limits_{i=1}^{N}\\alpha_{i}[1 - (wx_{i} + b)y_{i}] L(w,b,α)=21​∣∣w∣∣2+i=1∑N​αi​[1−(wxi​+b)yi​] 则在满足优化条件的情况下，原问题转化为： min⁡w,bmax⁡αL(w,b,α)\\min\\limits_{w, b}\\max\\limits_{\\alpha}L(w, b, \\alpha) w,bmin​αmax​L(w,b,α) 当满足KKT条件时，该问题可转化为其对偶问题： max⁡αmin⁡w,bL(w,b,α)\\max\\limits_{\\alpha}\\min\\limits_{w, b}L(w, b, \\alpha) αmax​w,bmin​L(w,b,α) ∇w,bL(w,b,α)=0αi[1−(wxi+b)yi]=01−(wxi+b)yi≤0αi≥0\\begin{align*} abla_{w, b}L(w, b, \\alpha) &amp;= 0 \\\\\\alpha_{i}[1 - (wx_{i} + b)y_{i}] &amp;= 0 \\\\1 - (wx_{i} + b)y_{i} &amp;\\leq 0 \\\\\\alpha_{i} &amp;\\geq 0 \\end{align*}∇w,b​L(w,b,α)αi​[1−(wxi​+b)yi​]1−(wxi​+b)yi​αi​​=0=0≤0≥0​ 利用KKT条件转化为对偶问题之后，可以化简为： max⁡α(−12∑i=1N∑j=1Nαiαjyiyj(xi⋅xj)+∑i=1Nαi)=min⁡α(12∑i=1N∑j=1Nαiαjyiyj(xi⋅xj)−∑i=1Nαi)\\begin{align*}&amp;\\quad \\max\\limits_{\\alpha}\\bigl(-\\frac{1}{2}\\sum\\limits_{i = 1}^{N}\\sum\\limits_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(x_{i}\\cdot x_{j}) + \\sum\\limits_{i=1}^{N}\\alpha_{i} \\bigr) \\\\&amp;= \\min\\limits_{\\alpha}\\bigl(\\frac{1}{2}\\sum\\limits_{i = 1}^{N}\\sum\\limits_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(x_{i}\\cdot x_{j}) - \\sum\\limits_{i=1}^{N}\\alpha_{i} \\bigr) \\\\\\end{align*}​αmax​(−21​i=1∑N​j=1∑N​αi​αj​yi​yj​(xi​⋅xj​)+i=1∑N​αi​)=αmin​(21​i=1∑N​j=1∑N​αi​αj​yi​yj​(xi​⋅xj​)−i=1∑N​αi​)​使得：∑i=1Nαiyi=0αi≥0\\sum\\limits_{i=1}^{N}\\alpha_{i}y_{i} = 0\\quad \\alpha_{i} \\geq 0i=1∑N​αi​yi​=0αi​≥0 于是可以求出α∗\\alpha^{*}α∗，相对应的根据KKT条件求出w∗,b∗w^{*}, b^{*}w∗,b∗： w∗=∑i=1Nαi∗yixib∗=yj−∑i=1Nαi∗yi(xi⋅xj)αj≠0\\begin{align*}w^{*} &amp;= \\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}x_{i} \\\\b^{*} = y_{j} - &amp;\\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}(x_{i}\\cdot x_{j})\\quad \\alpha_{j} eq 0\\end{align*}w∗b∗=yj​−​=i=1∑N​αi∗​yi​xi​i=1∑N​αi∗​yi​(xi​⋅xj​)αj​=0​ 所得到的αi&gt;0\\alpha_{i} &gt; 0αi​&gt;0对应的实例xix_{i}xi​即为支持向量 线性SVM 在线性可分SVM中，约束条件要求每一个样本点的函数间隔都不小于111，这个条件事实上要求样本拥有很强的分类性，而对于一些分类性较弱的样本，很难全部满足这个条件，因此引入松弛变量ξi\\xi_{i}ξi​，将约束条件修改为 (wxi+b)yi≥1−ξi(wx_{i} + b)y_{i} \\geq 1 - \\xi_{i} (wxi​+b)yi​≥1−ξi​ 为了让分隔尽量好，因此要满足松弛变量尽量小，因此调整优化问题为： min⁡w,b,ξ(12∣∣w∣∣2+C∑i=1Nξi)\\min\\limits_{w, b, \\xi}\\bigl( \\frac{1}{2}||w||^{2} + C\\sum\\limits_{i=1}^{N}\\xi_{i} \\bigr) w,b,ξmin​(21​∣∣w∣∣2+Ci=1∑N​ξi​) 其中CCC为惩罚参数，用于调整间隔最大与误分类点数之间的矛盾 于是，可以转化为： min⁡α(12∑i=1N∑j=1Nαiαjyiyj(xi⋅xj)−∑i=1Nαi)\\min\\limits_{\\alpha}\\bigl(\\frac{1}{2}\\sum\\limits_{i = 1}^{N}\\sum\\limits_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(x_{i}\\cdot x_{j}) - \\sum\\limits_{i=1}^{N}\\alpha_{i} \\bigr) αmin​(21​i=1∑N​j=1∑N​αi​αj​yi​yj​(xi​⋅xj​)−i=1∑N​αi​)使得：∑i=1Nαiyi=00≤αi≤C\\sum\\limits_{i=1}^{N}\\alpha_{i}y_{i} = 0\\quad 0\\leq \\alpha_{i} \\leq Ci=1∑N​αi​yi​=00≤αi​≤C 可以看出与线性可分的唯一区别在与αi\\alpha_{i}αi​的范围，因此最终求出w∗,b∗w^{*}, b^{*}w∗,b∗时同样和线性可分只有这个区别，具体来说： w∗=∑i=1Nαi∗yixib∗=yj−∑i=1Nαi∗yi(xi⋅xj)0&lt;αj&lt;C\\begin{align*}w^{*} &amp;= \\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}x_{i} \\\\b^{*} = y_{j} - &amp;\\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}(x_{i}\\cdot x_{j})\\quad 0 &lt; \\alpha_{j} &lt; C\\end{align*}w∗b∗=yj​−​=i=1∑N​αi∗​yi​xi​i=1∑N​αi∗​yi​(xi​⋅xj​)0&lt;αj​&lt;C​ 同样，αi∗&gt;0\\alpha_{i}^{*} &gt; 0αi∗​&gt;0所对应的样本成为软间隔的支持向量，具体来说： αi∗&lt;C\\alpha_{i}^{*} &lt; Cαi∗​&lt;C时，ξi=0\\xi_{i} = 0ξi​=0，xix_{i}xi​位于间隔边界 αi∗=C\\alpha_{i}^{*} = Cαi∗​=C时，ξi&gt;0\\xi_{i} &gt; 0ξi​&gt;0： 0&lt;ξi&lt;10 &lt; \\xi_{i} &lt; 10&lt;ξi​&lt;1时，分类正确 ξi=1\\xi_{i} = 1ξi​=1时，位于超平面上 ξi&gt;1\\xi_{i} &gt; 1ξi​&gt;1时，分类错误 非线性SVM 关键思想：利用变换ϕ:X→H\\phi: \\mathcal{X}\\to \\mathcal{H}ϕ:X→H将原空间的数据映射到特征空间，使之变为线性的，相对应的问题为： min⁡α(12∑i=1N∑j=1Nαiαjyiyj(ϕ(xi)⋅ϕ(xj))−∑i=1Nαi)\\min\\limits_{\\alpha}\\bigl(\\frac{1}{2}\\sum\\limits_{i = 1}^{N}\\sum\\limits_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(\\phi(x_{i})\\cdot \\phi(x_{j})) - \\sum\\limits_{i=1}^{N}\\alpha_{i} \\bigr) αmin​(21​i=1∑N​j=1∑N​αi​αj​yi​yj​(ϕ(xi​)⋅ϕ(xj​))−i=1∑N​αi​)使得：∑i=1Nαiyi=00≤αi≤C\\sum\\limits_{i=1}^{N}\\alpha_{i}y_{i} = 0\\quad 0\\leq \\alpha_{i} \\leq Ci=1∑N​αi​yi​=00≤αi​≤C 可以看出其中只有内积有变化，因此若存在函数KKK满足K(x,z)=ϕ(x)⋅ϕ(z)K(x, z) = \\phi(x)\\cdot \\phi(z)K(x,z)=ϕ(x)⋅ϕ(z)对任二元素都成立，则称K(x,z)K(x, z)K(x,z)为核函数 同一个核函数对应的映射不一定相同 映射到新空间之后，可以解得： w∗=∑i=1Nαi∗yiϕ(xi)b∗=yj−∑i=1Nαi∗yiK(xi,xj)0&lt;αj&lt;C\\begin{align*}w^{*} &amp;= \\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}\\phi(x_{i}) \\\\b^{*} = y_{j} - &amp;\\sum\\limits_{i=1}^{N}\\alpha_{i}^{*}y_{i}K(x_{i}, x_{j})\\quad 0 &lt; \\alpha_{j} &lt; C\\end{align*}w∗b∗=yj​−​=i=1∑N​αi∗​yi​ϕ(xi​)i=1∑N​αi∗​yi​K(xi​,xj​)0&lt;αj​&lt;C​ 常用的核函数包括： K(x,z)=(x⋅z+1)pK(x,z)=exp⁡(−∣∣x−z∣∣22σ2)(Gaussian)\\begin{align*} K(x, z) &amp;= (x\\cdot z + 1)^{p} \\\\ K(x, z) &amp;= \\exp(-\\frac{||x - z||^{2}}{2\\sigma^{2}})\\quad (\\text{Gaussian}) \\end{align*} K(x,z)K(x,z)​=(x⋅z+1)p=exp(−2σ2∣∣x−z∣∣2​)(Gaussian)​ 采用高斯核函数的时候，关键为σ\\sigmaσ的选取，不当会导致欠拟合与过拟合 σ过大导致欠拟合 σ过小导致过拟合 由于求解凸二次规划的算法在样本数很多的时候非常低效，因此有许多快速算法，例如序列最小最优化算法SMO 当样本中有多类怎么办？ 将一类视为正，其余所有视为负 任意两类构造一个SVM，分类时采取投票法 二分类别，依次二分整体直至单独类别 SVM应用举例 文本分类：文本表达为一个向量(w1j,…,wnj)T(w_{1j}, \\dots, w_{nj})^{T}(w1j​,…,wnj​)T，wijw_{ij}wij​表示词iii在文档jjj中的权重，具体计算有很多版本，在此介绍两种： wij=tfijw_{ij} = \\mathrm{tf}_{ij}wij​=tfij​即tf权重，用词频代表权重 wij=tfij∗idfiw_{ij} = \\mathrm{tf}_{ij}*\\mathrm{idf}_{i}wij​=tfij​∗idfi​即tf-idf权重，其中idf为逆文档频率，记cnt(i)\\mathrm{cnt}(i)cnt(i)为词iii所出现的文档数，则idfi=log⁡(Ncnt(i))\\mathrm{idf}_{i} = \\log(\\frac{N}{\\mathrm{cnt}(i)})idfi​=log(cnt(i)N​) 决策树 对样本进行分类，由节点和有向边组成，每个内部节点表示一个特征或者一个属性，每个叶节点表示一个类 决策树通过在训练集中对于分类规则进行训练，得到一组矛盾较小的特征，即KKK分类问题，而最优决策树的选择是一个NPC问题，因此通常采用启发式方法 学习过程包括： 特征选择 决策树生成与剪枝 特征选择 按照信息增益来选择特征，信息增益g(D,A)g(D, A)g(D,A)代表了特征AAA对于数据集DDD分类的不确定性的减少程度，计算如下： 记X,YX, YX,Y是两个随机变量，P(X=xi)=piP(X = x_{i}) = p_{i}P(X=xi​)=pi​，则：随机变量的熵：H(X)=−∑i=1npilog⁡(pi)H(X) = -\\sum\\limits_{i=1}^{n}p_{i}\\log(p_{i})H(X)=−i=1∑n​pi​log(pi​)条件熵：H(Y ∣ X)=∑i=1NpiH(Y ∣ X=xi)H(Y\\,|\\, X) = \\sum\\limits_{i=1}^{N}p_{i}H(Y \\,|\\, X = x_{i})H(Y∣X)=i=1∑N​pi​H(Y∣X=xi​)信息增益：g(D,A)=H(D)−H(D ∣ A)g(D, A) = H(D) - H(D \\,|\\, A)g(D,A)=H(D)−H(D∣A)信息增益越大的特征分类能力越强 具体到特征AAA对于数据集DDD的信息增益，设一共有KKK个类别(C1,…,CK)(C_{1}, \\dots, C_{K})(C1​,…,CK​)，AAA有nnn种不同值(a1,…,an)(a_{1},\\dots, a_{n})(a1​,…,an​)，对应了一个划分(D1,…,Dn)(D_{1}, \\dots, D_{n})(D1​,…,Dn​)，记DijD_{ij}Dij​为DiD_{i}Di​中属于类CjC_{j}Cj​的集合，则： H(D)=∑j=1K∣Cj∣∣D∣log⁡(∣Cj∣∣D∣)H(D ∣ A)=∑i=1n∣Di∣∣D∣H(Di)=−∑i=1n(∣Di∣∣D∣∑j=1K(∣Dij∣∣Di∣log⁡(∣Dij∣∣Di∣)))g(D,A)=H(D)−H(D ∣ A)\\begin{align*}H(D) &amp;= \\sum\\limits_{j=1}^{K}\\frac{|C_{j}|}{|D|}\\log(\\frac{|C_{j}|}{|D|}) \\\\H(D\\,|\\, A) &amp;= \\sum\\limits_{i=1}^{n}\\frac{|D_{i}|}{|D|}H(D_{i}) \\\\&amp;= -\\sum\\limits_{i=1}^{n}\\biggl(\\frac{|D_{i}|}{|D|}\\sum\\limits_{j=1}^{K}\\bigl(\\frac{|D_{ij}|}{|D_{i}|}\\log(\\frac{|D_{ij}|}{|D_{i}|})\\bigr)\\biggr) \\\\g(D, A) &amp;= H(D) - H(D\\,|\\, A)\\end{align*}H(D)H(D∣A)g(D,A)​=j=1∑K​∣D∣∣Cj​∣​log(∣D∣∣Cj​∣​)=i=1∑n​∣D∣∣Di​∣​H(Di​)=−i=1∑n​(∣D∣∣Di​∣​j=1∑K​(∣Di​∣∣Dij​∣​log(∣Di​∣∣Dij​∣​)))=H(D)−H(D∣A)​ 决策树的生成 两个常用的算法为ID3与C4.5 ID3算法 输入：训练集DDD，特征AAA，阈值ε\\varepsilonε 输出：决策树TTT 算法如下： 若DDD中所有实例属于同一类CCC，则TTT单节点，类标记为CCC，直接返回若A=∅A = \\varnothingA=∅，则TTT也为单节点，类标记为DDD中最多的类CjC_{j}Cj​，直接返回计算AAA中所有特征对DDD的信息增益，选择其中信息增益最大的特征AkA_{k}Ak​若g(D,Ak)≤εg(D, A_{k}) \\leq \\varepsilong(D,Ak​)≤ε，则将TTT置为单节点树，类标记为DDD中最多的类CjC_{j}Cj​，直接返回反之，遍历Ak=(ak1,…,aknk)A_{k} = (a_{k1}, \\dots, a_{kn_{k}})Ak​=(ak1​,…,aknk​​)，将DDD划分为nkn_{k}nk​个子集分别作为子节点遍历子节点DiD_{i}Di​，若为空，则将DDD中最多的类标记这个子节点反之以(Di,A−Ak,ε)(D_{i}, A - A_{k}, \\varepsilon)(Di​,A−Ak​,ε)递归返回TTT 也就是按照特征集合不断划分，当出现所有属于同一类或某一个划分为空集的时候进行特判即可 问题：信息增益倾向于选择分支较多的特征，但是有的分支是毫无意义的 C4.5算法 考虑信息增益比： gR(D,A)=g(D,A)HA(D)=g(D,A)(−∑i=1n∣Di∣∣D∣log⁡(∣Di∣∣D∣))−1g_{R}(D, A) = \\frac{g(D, A)}{H_{A}(D)} = g(D, A)\\bigl(-\\sum\\limits_{i=1}^{n}\\frac{|D_{i}|}{|D|}\\log(\\frac{|D_{i}|}{|D|})\\bigr)^{-1} gR​(D,A)=HA​(D)g(D,A)​=g(D,A)(−i=1∑n​∣D∣∣Di​∣​log(∣D∣∣Di​∣​))−1 因此C4.5引入信息增益比来选择特征，同时允许特征的取值为连续的而非离散的，相对于ID3的改进如下： 将选择信息增益最大的特征改为： 选择信息增益前kkk大的特征，再从其中选择信息增益比最大的特征 原因是信息增益比倾向于选择分割不均匀的特征 对于连续的特征，采用二分，找到中间值a0a_{0}a0​，将≤a0\\leq a_{0}≤a0​的划分到左子树，&gt;a0&gt;a_{0}&gt;a0​的划分到右子树 决策树的剪枝 由于决策树非常容易出现过拟合，因此需要对其进行剪枝先生成树再剪枝，这种方法称之为后剪枝 剪枝方式为： 对于某个内部节点，删除这棵子树，用这棵子树的根节点作为新的叶节点，其类别标记为其中最多的类 当数据集比较大的时候，剪枝方式为： 在训练集上训练，逐步剪枝 在验证集上验证直至性能下降 在测试集上测试 当数据集比较小的时候，直接利用训练集进行剪枝，方法如下： 设决策树TTT的叶节点为leaf(T)=(T1,…,Tt)\\mathrm{leaf}(T) = (T_{1}, \\dots, T_{t})leaf(T)=(T1​,…,Tt​)，TiT_{i}Ti​有NiN_{i}Ni​个样本，其中第kkk类的样本点有NikN_{ik}Nik​个，Hi(T)H_{i}(T)Hi​(T)为经验熵，aaa为参数，记损失函数为： Ca(T)=∑i=1tNiHi(T)+at=−∑i=1t∑j=1KNijlog⁡NijNi+at\\begin{align*} C_{a}(T) &amp;= \\sum\\limits_{i=1}^{t}N_{i}H_{i}(T) + at \\\\ &amp;= -\\sum\\limits_{i=1}^{t}\\sum\\limits_{j=1}^{K}N_{ij}\\log\\frac{N_{ij}}{N_{i}} + at \\end{align*} Ca​(T)​=i=1∑t​Ni​Hi​(T)+at=−i=1∑t​j=1∑K​Nij​logNi​Nij​​+at​ 其中两项分别代表预测误差与模型复杂程度 最终，剪枝算法为： 输入：整个树TTT，参数aaa输出：修剪后的TaT_{a}Ta​计算每个节点的经验熵从叶节点向上回溯，如果在某个点剪枝之后可以降低损失函数，则剪枝，反之跳过直到不能继续剪枝，结束 随机森林 由于决策树非常容易过拟合，因此使用多棵决策树组成一片随机森林，利用投票机制进行决策 单棵决策树的生成是通过有放回的数据采样，关键点为集外数据的使用（也即别的决策树怎么使用某棵决策树没使用的数据）","tags":["笔记","IAI","统计机器学习"],"categories":["人工智能导论"]},{"title":"TCS-Lecture-C","path":"/2024/05/22/TCS-Lecture-C/","content":"TCS: Pseudorandomness and Private-Key Encryption Pseudorandomness and Private-Key Encryption Private-Key Encryption This encryption(加密) problem is starting form the transmission question: two people need to transmit information while avoiding others to know the content. The resolution is to maintain a ‘key’ kkk by two people and one can use kkk to encrypt information while the other can use it to decrypt Validity A pair of polynomial-time computable functions (Enc,Dec)(\\text{Enc}, \\text{Dec})(Enc,Dec) is a valid private key encryption scheme if for every n∈Nn\\in \\mathbb{N}n∈N, k∈{0,1}nk\\in \\{0, 1\\}^{n}k∈{0,1}n,and xxx, we haveDec(k,Enc(k,x))=x \\text{Dec}(k, \\text{Enc}(k, x)) = xDec(k,Enc(k,x))=x And we have the length of the ciphertext(密文) is no less than that of the plaintext, written as: lc(n)≥lp(n)l_{c}(n) \\geq l_{p}(n) lc​(n)≥lp​(n) Security We need to define the security with following assumption: A cryptosystem should be secure even if everything about the system, except the key, is public knowledge. Due to this assumption, the kkk must be generated randomly. So, let’s define the security: A valid encryption scheme (Enc,Dec)(\\text{Enc}, \\text{Dec})(Enc,Dec) with plaintext length l(⋅)l(\\cdot)l(⋅) is perfectly secret if for every n∈Nn\\in \\mathbb{N}n∈N and plaintexts x0,x1∈{0,1}l(n)x_{0}, x_{1} \\in \\{0, 1\\}^{l(n)}x0​,x1​∈{0,1}l(n), the following two distributions Y0Y_{0}Y0​and Y1Y_{1}Y1​ over {0,1}∗\\{0, 1\\}^{*}{0,1}∗ are identical:YiY_{i}Yi​ is obtained by sampling kkk and outputting Enc(k,xi)\\text{Enc}(k, x_{i})Enc(k,xi​) for i=0,1i = 0, 1i=0,1. Definition Analysis We have a secrecy experiment as follows: Sample k∈{0,1}nk \\in \\{0, 1\\}^{n}k∈{0,1}n Adversary A\\mathcal{A}A outputs x0,x1x_{0}, x_{1}x0​,x1​ given input 1n1^{n}1n Randomly choose bbb and send y=Enc(k,xb)y = \\text{Enc}(k, x_{b})y=Enc(k,xb​) to A\\mathcal{A}A A\\mathcal{A}A returns b′∈{0,1}b&#x27;\\in\\{0, 1\\}b′∈{0,1} If b=b′b = b&#x27;b=b′, A\\mathcal{A}A wins We can prove A\\mathcal{A}A has at most 12\\frac{1}{2}21​ probability to succeed under perfectly secret. P(Y=y ∣ b=i)=P(Yi=y)=p(y)\\begin{align*} P(Y = y\\,|\\, b = i) &amp;= P(Y_{i} = y) = p(y)\\end{align*}P(Y=y∣b=i)​=P(Yi​=y)=p(y)​And P(Y=y)=p(y)P(Y = y) = p(y)P(Y=y)=p(y) due to YYY is perfect, so:P(Y=y,b=i)=P(b=i)P(Y=y ∣ b=i)=P(b=i)p(y)=P(b=i)P(Y=y)\\begin{align*} P(Y = y, b = i) &amp;= P(b = i)P(Y = y \\,|\\, b = i) \\\\ &amp;= P(b = i)p(y) \\\\ &amp;= P(b = i)P(Y = y)\\end{align*}P(Y=y,b=i)​=P(b=i)P(Y=y∣b=i)=P(b=i)p(y)=P(b=i)P(Y=y)​This means YYY is independent to bbb, so A\\mathcal{A}A cannot improve its probability to win by getting yyy Construction Give the One-time pad construction: lp(n)=lc(n)=nEnc(k,x)=x⊕kDec(k,c)=k⊕c\\begin{align*} l_{p}(n) = l_{c}&amp;(n) = n \\\\ \\text{Enc}(k, x) &amp;= x \\oplus k \\\\ \\text{Dec}(k, c) &amp;= k \\oplus c\\end{align*}lp​(n)=lc​Enc(k,x)Dec(k,c)​(n)=n=x⊕k=k⊕c​ In this construction, we have one glaring dis advantage, that is the kkk has the same length of plaintext! This is necessary for perfect secrecy: For every perfectly secret encryption scheme, the length function lp(n)l_{p}(n)lp​(n) satisfies lp(n)≤nl_{p}(n)\\leq nlp​(n)≤n Computational Secrecy and PRG The long kkk is unadorable in reality. So we use computational secrecy instead. An encryption scheme is computationally secret if no probabilistic polynomial-time(PPT) algorithms can break it. Let Enc,Dec\\text{Enc}, \\text{Dec}Enc,Dec be a valid encryption scheme. The scheme is computationally secret if, for every PPT adversary algorithm A\\mathcal{A}A in the secrecy experiment, there is negligible function negl\\text{negl}negl such thatP(A succ)≤12+negl(n) P(\\mathcal{A} \\text{ succ}) \\leq \\frac{1}{2} + \\text{negl}(n)P(A succ)≤21​+negl(n)where the probability is taken over the randomness of A\\mathcal{A}A and the experiment. Pseudorandom Generators Definition: A cryptographic pseudorandom generator (PRG) with stretch l(⋅)l(\\cdot)l(⋅) is a PPT computable function G:{0,1}∗→{0,1}∗G: \\{0, 1\\}^{*} \\to \\{0, 1\\}^{*}G:{0,1}∗→{0,1}∗ such that:∀ n∈N\\forall \\, n\\in \\mathbb{N}∀n∈N and s∈{0,1}ns\\in \\{0, 1\\}^{n}s∈{0,1}n, ∣G(s)∣=l(n)|G(s)| = l(n)∣G(s)∣=l(n)For any poly-algorithm A\\mathcal{A}A, s∈{0,1}ns\\in \\{0, 1\\}^{n}s∈{0,1}n and r∈{0,1}l(n)r\\in \\{0, 1\\}^{l(n)}r∈{0,1}l(n):∣P(A((G(s)))=1)−P(A((r))=1)∣=negl(n) |{P (\\mathcal{A}((G(s))) = 1) - P (\\mathcal{A}((r)) =1)}| = \\text{negl}(n)∣P(A((G(s)))=1)−P(A((r))=1)∣=negl(n) Intuitively, this means we can get the difference between output of PRG G(⋅)G(\\cdot)G(⋅) and a actual random output rrr in a negligible probability. Its existance is obtained by the cryptographic PRG conjecture: PRG with l(n)=na∀a∈Nl(n) = n^{a}\\quad \\forall a\\in\\mathbb{N}l(n)=na∀a∈N exists. If the cryptographic PRG conjecture is true, then computationally secret encryption exists for l(n)≥na∀a∈Nl(n) \\geq n^{a}\\quad \\forall a\\in\\mathbb{N}l(n)≥na∀a∈N Enc(k,x)=x⊕G(k)Dec(c,k)=c⊕G(k)\\begin{align*} \\text{Enc}(k, x) &amp;= x \\oplus G(k) \\\\ \\text{Dec}(c, k) &amp;= c \\oplus G(k)\\end{align*}Enc(k,x)Dec(c,k)​=x⊕G(k)=c⊕G(k)​ This can be proved to be computation secret by contradiction proof, which is to construct a adversary for PRG by the assuming contradiction. CPA Security and PRF Choose Plaintext Attack (CPA) The CPA experiments is similar to secrecy experiments, while A\\mathcal{A}A can interact freely with Enc(k,⋅)\\text{Enc}(k, \\cdot)Enc(k,⋅) as a black-box. An encryption scheme (Enc,Dec)(\\text{Enc}, \\text{Dec})(Enc,Dec) is CPA-secure if, for all PPT adversary A\\mathcal{A}A, there exists a negligible function negl\\text{negl}negl such thatP(A succ)≤12+negl(n) P(\\mathcal{A} \\text{ succ}) \\leq \\frac{1}{2} + \\text{negl}(n)P(A succ)≤21​+negl(n) All CPA-secure encryption scheme must be probabilistic otherwise A\\mathcal{A}A can query all Enc(k,x)\\text{Enc}(k, x)Enc(k,x) to get ciphertexts and compare. Pseudorandom Functions (PRF) Consider a keyed family of functions: Fk:{0,1}∗→{0,1}∗F_{k}: \\{0, 1\\}^{*} \\to \\{0, 1\\}^{*}Fk​:{0,1}∗→{0,1}∗, then we can define PRF as follows: Let FkF_{k}Fk​ be a keyed family of functions that is efficient and length-preserving. We say FkF_{k}Fk​ is a pseudorandom function if, for all PPT distinguishers D\\mathcal{D}D, there exists a negligible function negl\\text{negl}negl such that:∣P(DFk(⋅)(1n)=1)−P(Dfn(⋅)(1n)=1)∣≤negl(n) |{P \\bigl( D^{F_k(\\cdot)}(1^n) = 1 \\bigr) - P \\bigl( D^{f_n(\\cdot)}(1^n) = 1 \\bigr)}| \\le \\text{negl}(n)∣P(DFk​(⋅)(1n)=1)−P(Dfn​(⋅)(1n)=1)∣≤negl(n)where k←{0,1}nk\\gets\\{0, 1\\}^{n}k←{0,1}n is chosen uniformly at random and fnf_{n}fn​ is chosen uniformly from the set of functions mapping nnn-bit strings to nnn-bit strings. Intuitively, this means we can get the difference between PRF Fk(⋅)F_{k}(\\cdot)Fk​(⋅) and a actual random funtions fff in a negligible probability. PRF =&gt; CPA-secure Encryption Let FFF be a PRF. Define a CPA-secuee private-key encryption scheme for messages of length nnn as follows: Enc(k,x)=⟨r,Fk(r)⊕x⟩\\text{Enc}(k, x) = \\langle r, F_{k}(r)\\oplus x \\rangleEnc(k,x)=⟨r,Fk​(r)⊕x⟩Dec(k,⟨r,s⟩)=Fk(r)⊕s\\text{Dec}(k, \\langle r, s\\rangle) = F_{k}(r) \\oplus sDec(k,⟨r,s⟩)=Fk​(r)⊕sIn this r←{0,1}nr\\gets\\{0, 1\\}^{n}r←{0,1}n is randomly chosen. Proof is as follows, we use contradiction-proof and construct a contradiction to PRF with assumption. Consider above scheme as Π=(Enc,Dec)\\Pi = (\\text{Enc}, \\text{Dec})Π=(Enc,Dec) and the similar scheme Π~=(Enc~,Dec~)\\widetilde{\\Pi} = (\\widetilde{\\text{Enc}}, \\widetilde{\\text{Dec}})Π=(Enc,Dec) in which we replace FkF_{k}Fk​ with an actual random function.Assume that Π\\PiΠ is not CPA-secure, which means there exists an A\\mathcal{A}A:P(AΠ succ)≥12+1poly(n)P(\\mathcal{A}_{\\Pi}\\text{ succ}) \\geq \\frac{1}{2} + \\frac{1}{\\text{poly}(n)}P(AΠ​ succ)≥21​+poly(n)1​Let rcr_{c}rc​ represents the randomness used in encrypting xxx, while r1,…,rqr_{1}, \\dots, r_{q}r1​,…,rq​ represents the q(n)=poly(n)q(n) = \\text{poly}(n)q(n)=poly(n) randomness used when A\\mathcal{A}A queries to the oracle Enc\\text{Enc}Enc.Then we can argue that:P(AΠ~ succ)≤12+negl(n)P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}) \\leq \\frac{1}{2} + \\text{negl}(n) P(AΠ​ succ)≤21​+negl(n)We can argue this according to whether rc∈{r1,…,rq}r_{c} \\in \\{r_{1},\\dots ,r_{q}\\}rc​∈{r1​,…,rq​}If rc∈{r1,…,rq}r_{c} \\in \\{r_{1},\\dots ,r_{q}\\}rc​∈{r1​,…,rq​}, then A\\mathcal{A}A can actually get rcr_{c}rc​ as we contain it in the ciphertext. So A\\mathcal{A}A can always succeed in this case.But this case has a negligible probability q(n)2n\\frac{q(n)}{2^{n}}2nq(n)​ to appear.If rc∉{r1,…,rq}r_{c} otin \\{r_{1},\\dots ,r_{q}\\}rc​∈/{r1​,…,rq​}, then the encryption is like a perfect OTP as we cannot get any information about the random function fff. So A\\mathcal{A}A has a probability of 12\\frac{1}{2}21​ to win.So, we have that:P(AΠ~ succ)=P(AΠ~ succ ∣∈)P(∈)+P(AΠ~ succ ∣∉)P(∉)≤q(n)2n+12=12+negl(n)\\begin{align*}P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}) &amp;= P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}\\,|\\in)P(\\in) + P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}\\,| otin)P( otin) \\\\&amp;\\leq \\frac{q(n)}{2^{n}} + \\frac{1}{2} = \\frac{1}{2} + \\text{negl}(n)\\end{align*}P(AΠ​ succ)​=P(AΠ​ succ∣∈)P(∈)+P(AΠ​ succ∣∈/)P(∈/)≤2nq(n)​+21​=21​+negl(n)​Define the distinguisher D\\mathcal{D}D, who has an orecal O\\mathcal{O}O, as follows:Run A(1n)\\mathcal{A}(1^{n})A(1n), for each oracle query of A\\mathcal{A}A with xxx, do:Choose r←{0,1}nr\\gets \\{0, 1\\}^{n}r←{0,1}nreturn ⟨r,O(r)⊕x⟩\\langle r, \\mathcal{O}(r)\\oplus x\\rangle⟨r,O(r)⊕x⟩ to A\\mathcal{A}AWhen A\\mathcal{A}A gives D\\mathcal{D}D two string x0,x1x_{0}, x_{1}x0​,x1​, randomly choose a bit bbb and:Choose r←{0,1}nr\\gets \\{0, 1\\}^{n}r←{0,1}nreturn ⟨r,O(r)⊕xb⟩\\langle r, \\mathcal{O}(r)\\oplus x_{b}\\rangle⟨r,O(r)⊕xb​⟩ to A\\mathcal{A}AAnswer A\\mathcal{A}A as Step 1 until A\\mathcal{A}A gives an output b′b&#x27;b′. Then we output 111 if b′=bb&#x27; = bb′=b otherwise 000.Actually, this distinguisher is simulating the CPA-experiment. So:P(DFk(⋅)(1n)=1)=P(AΠ succ)P(Df(⋅)(1n)=1)=P(AΠ~ succ)\\begin{align*}P(\\mathcal{D}^{F_{k}(\\cdot)}(1^{n}) = 1) &amp;= P(A_{\\Pi}\\text{ succ}) \\\\P(\\mathcal{D}^{f(\\cdot)}(1^{n}) = 1) &amp;= P(A_{\\widetilde{\\Pi}}\\text{ succ})\\end{align*}P(DFk​(⋅)(1n)=1)P(Df(⋅)(1n)=1)​=P(AΠ​ succ)=P(AΠ​ succ)​This means that:∣P(DFk(⋅)(1n)=1)−P(Df(⋅)(1n)=1)∣=∣P(AΠ succ)−P(AΠ~ succ)∣≥∣1poly(n)−negl(n)∣≥1poly(n)\\begin{align*}&amp;\\quad |P(\\mathcal{D}^{F_{k}(\\cdot)}(1^{n}) = 1) -P(\\mathcal{D}^{f(\\cdot)}(1^{n}) = 1)| \\\\&amp;= |P(\\mathcal{A}_{\\Pi}\\text{ succ}) - P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ})| \\\\&amp;\\geq |\\frac{1}{\\text{poly}(n)} - \\text{negl}(n)| \\geq \\frac{1}{\\text{poly}(n)}\\end{align*}​∣P(DFk​(⋅)(1n)=1)−P(Df(⋅)(1n)=1)∣=∣P(AΠ​ succ)−P(AΠ​ succ)∣≥∣poly(n)1​−negl(n)∣≥poly(n)1​​This is contradict to that FkF_{k}Fk​ is PRF!","tags":["笔记","TCS","伪随机","私钥加密"],"categories":["理论计算机科学导引"]},{"title":"网原笔记6","path":"/2024/05/22/网原笔记6/","content":"计算机网络原理 笔记 6 链路层与局域网 链路层 运行链路层协议的任何设备称为节点，相邻节点的通信信道称为链路，在链路上传递的数据报被封装为链路层帧 可能提供的服务 成帧：将网络层数据添加一些首部字段封装为链路层帧 链路接入：由MAC规定了帧在链路上的传输规则 可靠交付：保证无差错地传递网络层数据报，但是对于部分低比特差错链路，可靠性是不必要的 差错检测和纠正：由于硬件设备原因可能会导致部分比特被错误传输，因此可以在帧中包含相应差错检测/纠正比特来检测 实现 通常通过网络适配器（又称为网络接口卡）来实现 网络适配器 差错检测与纠正 接收方需要判断接收到的数据是否是原始数据，通常通过EDC来实现，但是需要注意的是EDC本身也有可能被损坏，并且即使使用了EDC也可能出现漏检的情况 差错检测与纠正 常见的EDC方法包括奇偶校验、检验和与循环冗余检测 奇偶校验 增加一位校验位，用于指示原始数据中’1’的个数的奇偶性，但是这只能判断出数据中出现了奇数个比特差错 为了提升其鲁棒性，采用二维奇偶校验的方式，即将原始数据划分为一个矩阵，分别检测每一行与每一列的奇偶校验和，这样可以检测并纠正单个比特差错，并且可以检测双比特差错 二维奇偶校验 检验和 与运输层协议中内容相似，将数据按字节求和取反码 循环冗余检测 现代广泛使用CRC编码，主要思想为将数据流看做系数为0, 1的多项式 CRC编码 如上图，编码操作为： 发送方与接收方协商r+1r+1r+1位比特模式作为生成多项式，记为GGG，要求GGG的最高位必须是1 对于数据段DDD，发送方将其附加rrr个比特RRR，得到d+rd+rd+r位比特模式，使其可以被GGG整除 接收方检测是否可以整除即可 因此关键问题在于如何选取RRR使得： (D&lt;&lt;r)⊕R=nG (D &lt;&lt; r) \\oplus R = nG (D&lt;&lt;r)⊕R=nG 该式可化简为： D&lt;&lt;r=nG⊕R D &lt;&lt; r = nG \\oplus R D&lt;&lt;r=nG⊕R 在CRC中，所有的加法和减法都等价于异或操作，因此乘法和除法需要对应的变化（竖式中的加减法也变成了异或） 因此，可以计算RRR为： R=(D&lt;&lt;r)(modG) R = (D &lt;&lt; r) \\pmod{G} R=(D&lt;&lt;r)(modG) 国际标准的生产多项式为： GCRC-32=10000001001100000010001110110110111 G_{\\text{CRC-32}} = 10000001001100000010001110110110111 GCRC-32​=10000001001100000010001110110110111 CRC可以检测出所有的奇数位、双比特、不大于∣G∣|G|∣G∣长度的错误 多路访问链路和协议 由于所有的节点都可以传输帧，因此同时被接收的信号会在接收方处发生碰撞，导致所有信号丢失，因此需要多路访问协议用于协调多个发送和接收节点共享一个信道的访问。 其应当具有的特性为： 仅有一个节点发送数据时，需要使用完整信道 有多个节点发送数据时，每个节点吞吐量可以趋近于平均 协议是分散的：不会因一个节点崩溃而崩溃 造价便宜！ 可以划分为信道划分协议、随机接入协议与轮流协议 信道划分协议 采用时分复用或频分复用的方式，平均划分时间或频率 时分复用与频分复用 TDM/FDM的特点： 消除了碰撞，并且非常公平 在及诶单书很少的时候效果很差 另一种信道划分协议为码分多址，为每个节点分配一种不同的编码，如果编码选择合适，即可同时传输同时接收并且互不干扰 随机接入协议 每个节点都以信道最大速率发送分组，当发生碰撞时，等待一个随机时延并重发该分组，直到发送成功。 随机试验种类繁多，具体介绍ALOHA协议与载波侦听多路访问(CSMA)协议 时隙ALOHA 假设： 所有帧大小相同，记为LLL 时间被划分为等长的时隙，每个时隙可以发送一帧 只在时隙起点传输帧 节点之间同步时隙信息 如果在一个时隙中发生了碰撞，则时隙结束时所有节点可以检测到碰撞 则时隙ALOHA的操作如下： 当有数据需要发送时，等待下一个时隙起点传输 如果没有碰撞则万事大吉 反之，则在后续的每个时隙起点独立地以 ppp 的概率重传，直到成功发送 定义成功时隙为恰好只有一个节点传输的时隙，成功时隙占所有时隙的比例为效率，则N(N≫1)N(N\\gg 1)N(N≫1)个节点的效率为： f(p)=CN1p(1−p)N−1=Np(1−p)N−1 f(p) = C_{N}^{1}p(1-p)^{N-1} = Np(1-p)^{N-1} f(p)=CN1​p(1−p)N−1=Np(1−p)N−1 极值点为： p=1N p = \\frac{1}{N} p=N1​ 因此： f(p)≤(1−1N)N−1lim⁡N→∞f(p)≤1e\\begin{align*} f(p) &amp;\\leq (1 - \\frac{1}{N})^{N - 1} \\\\ \\lim\\limits_{N\\to\\infty}&amp;f(p) \\leq \\frac{1}{e} \\end{align*} f(p)N→∞lim​​≤(1−N1​)N−1f(p)≤e1​​ 所以当节点数充分大时，效率最高约为37% ALOHA 纯ALOHA将不考虑时隙问题，在分组到达时则立刻进行传输，碰撞时立即以概率 ppp 重传分组，以概率 1−p1-p1−p 等待一个分组传输时间，重复循环直到成功发送 若一个节点想要成功发送，则必须要保证其发送时间的前后各一个分组传输时间之内不能有其他节点发送，因此可以计算得其最大效率为： lim⁡N→∞f(p)≤12e\\lim\\limits_{N\\to\\infty}f(p) \\leq \\frac{1}{2e} N→∞lim​f(p)≤2e1​ CSMA 模仿人类聚会时的发言，CSMA新增了如下协议： 说话之前先听：在传输之前先“听”信道，如果有其他节点正在发送则等待，直到一段时间内没有传输 而CSMA/CD则进一步增加了如下协议 和别人同时开始说话时停止说话：节点在传输过程中保持“听”信道，当有其他节点也开始传输的时候立刻停止传输，等待一段随机时间后，进入上一种状态 采用时空图说明： 时空图，其中B与D碰撞 可以看出，决定其碰撞发生的概率即决定性能的关键因素为信道传播时延，即在节点之间通信的效率 CSMA/CD的一些讨论 讨论两个问题： 每次检测到碰撞后应该等待多久 CSMA/CD效率如何 对于等待时间的问题，采用二进制指数后退算法，具体为： 在nnn次碰撞之后，令K∼U({0,1,…,2n−1})K \\sim \\text{U}(\\{0, 1, \\dots, 2^{n} - 1\\})K∼U({0,1,…,2n−1})，并且等待发送512K512K512K比特所需要的时间 对于效率问题，定义CSMA/CD的效率为： 节点数和分组数充分多的时候，分组能够无碰撞传输所占有的时间比例 定义dpropd_{\\text{prop}}dprop​为两个适配器之间传递信号的最大时间，dtransd_{\\text{trans}}dtrans​为传输一个最大以太网帧的时间，则CSMA/CD的效率为： f=11+5dprop/dtrans f = \\frac{1}{1 + 5d_{\\text{prop}}/ d_{\\text{trans}}} f=1+5dprop​/dtrans​1​ 轮流协议 是一大类能够满足大量节点平均享有吞吐量的协议，主要讨论轮询协议与令牌传递协议 轮询协议 指定主节点，主节点可以轮询每个节点，告知其可以传输的最大帧数 这种方法引入了轮询时延，并且是集中式的（主节点坏了就似了） 令牌传递协议 讲一个称之为令牌的特殊帧在节点之间以一个固定的次序进行交换，每个节点持有令牌当且仅当自己需要发送帧，反之立刻传递给下一节点 同样的，该协议单个节点的故障可能导致整体的崩溃 DOCSIS 一个实际应用的综合性协议 上行与下行信道 DOCSIS定义了电缆数据网络体系结构及其协议，对于上行信道与下行信道都采用FDM，每个信道均为广播信道，并且下行信道不会存在多路访问问题，主要考虑上行信道 上行信道被划分时间间隔，每个时间间隔包含微时隙序列（类似TDM） CMTS发送MAP报文指定特定的调制解调器在特定时间间隔发送分组 调制解调器们在一组特殊的微时隙间隔内向CMTS发送请求帧，向其请求分配微时隙用于发送数据 请求帧以随机接入的方式发送，当其发生碰撞时（调制解调器只能通过下行信道的数据推测是否碰撞），采用二进制指数回退算法决定等待时间并重新发送 交换局域网 链路层寻址 MAC地址 链路层地址的所有者并非主机或路由器，而是其中的适配器（网络接口），链路层地址有多种称呼，包括LAN地址，物理地址，MAC地址，常用的为MAC地址，长度为6字节即48bits MAC地址示意图 每个适配器拥有唯一MAC地址，其唯一性由IEEE保证（付费！） 与IP不同，MAC具有扁平化特征，即不再具有类似IP的层次化特征，其地址值是随着设备而固定下来的 MAC寻址方法为，向帧中插入目的MAC地址后发送到局域网上，当接收时，检测目的MAC地址是否与己方一致，一致则解析数据，反之则丢给局域网，如果需要广播则使用广播地址（全1） ARP 地址解析协议用于实现网络层地址与链路层地址之间的转换，是一个介于链路层和网络层之间的协议 ARP只解析同一个子网下的IP地址，不能解析任意的IP地址 工作方式为询表，ARP表中存有IP地址到MAC地址的映射，以及该表项的过期时间，当表项缺失时，会广播ARP查询分组，向子网上所有的主机询问此IP地址对应的MAC地址，相应的适配器接收到报文后会发送ARP响应报文 注意：查询报文是广播而发送报文不是 向子网外发送 通过路由器的转发表实现不同子网之间的转换，每个子网中的主机只需要把数据传到路由器就可以了，不然就会到达数据报天国！ 以太网 简易、便宜、首发、告诉，在物理结构上采用交换机（之前是总线与集线器），有效避免了碰撞 帧结构 以太网帧架构 字段意义如下： 数据字段（46-1500字节）：过长的数据需要被分片 目的地址（6字节）：目的地MAC 源地址（6字节）：发送方MAC 类型字段（2字节）：用于指示需要使用的网络层协议 CRC（4字节）：检测差错 前同步码（8字节）：AA-AA-AA-AA-AA-AA-AA-AB，用于同步时钟，最后两个1用于指示数据到来 以太网是无连接的，没有类似TCP的握手需求，也没有重传机制 以太网技术 100MHz以太网标准 一种标准是IEEE 803.2z： 使用上述帧格式 允许点对点以及广播 使用CSMA/CD来共享广播信道 点对点信道允许40Gbps全双工 链路层交换机 主要任务是接收入链路层帧并将其转发到出链路，对于主机来说是透明的，可能会存在过量数据，因此设有缓存 转发与过滤 过滤是决定一帧应该被转发到某个接口还是被丢弃，转发决定帧应该被导向哪个接口，这两项操作由交换机表完成，每个表项包含： MAC地址 通往该地址的交换机接口 表项存在时间 当接口xxx到达一帧链路层帧后，交换机表的索引过程如下： 如果不存在目的地MAC地址对应的表项，则广播 如果存在，但是表中的接口是xxx，也即想发给自己所在子网，直接丢弃（过滤） 如果存在，并且接口为y≠xy eq xy=x，则转发到yyy的输出缓存 自学习 交换机表的建立是自动、自治、动态建立的，即自学习，方法如下： 初始表为空 对于每个接口存储到的每个入帧，存储：源MAC地址、到达的接口、当前时间 一段时间后，如果没有接收到该MAC为源的帧，则删除之 交换机是即插即用的、双工的 链路层交换机的性质 清除碰撞：有缓存，网段上至多同时传输一帧 异质的：链路之间彼此隔离，不同链路能够以不同速率在不同媒体上运行 管理：更加安全，易于管理，例如可以自行解决异常适配器 交换机与路由器 交换机是链路层的分组交换机，路由器是网络层的分组交换机 路由器与交换机 虚拟局域网 交换局域网的缺点： 缺乏流量隔离：广播可以被整个机构的网络接收到，无法局部广播 交换机的无效使用：如果组小而交换机大，每个交换机将会有大量端口被浪费 用户管理：用户换组或多组将会导致复杂的物理布线变化 因此引入虚拟局域网，由网管将一个交换机的不同端口划分为不同组，每个VLAN中的端口形成一个广播域 VLAN实例 但是这样会导致VLAN之间完全隔离，常用的解决办法是引入一个路由器进行VLAN间的通信，与交换机中某个空闲的端口连接，该端口可以视作同时属于多个VLAN 如果需要多个交换机，并且交换机之间的VLAN需要互联（也许就是同种VLAN），采用的方法为VLAN干线互联而并非将各个VLAN分别互联，每个干线端口同时属于所有VLAN 为了确保帧可以正确跨越干线，对以太网帧进行扩展 扩展以太网帧 增加字段有： 标签协议控制符（2字节）：固定81-00 标签控制信息（2字节）：包含12比特的VLAN标识符字段和3比特的优先权字段 新增字段被干线端口添加与删除 EVPN 链路层交换机在逻辑上联结在一起，并且使用更顶层的协议进行通信，如将链路层帧包裹在IP数据报中 链路虚拟化 引入多协议标签交换，用于改善IP路由器交换速度，目标是通过选择性的标识数据报，并允许路由器通过固定长度标签转发数据报 MPLS首部 MPLS会扩展链路层帧，增加的首部字段位于链路层和网络层首部之间，新增字段包括： 标签 实验字段（3比特）：预留 S字段：用于指示MPLS首部栈的结束 TTL：寿命字段 MPLS使能的路由器称为标签交换路由器，其在转发表中查找MPLS标签并将数据报传递给相应的输出接口进行转发，但是这要求通信的两个路由器都是MPLS使能的 利用MPLS进行通信，其中R1234都是MPLS使能的 从上图可以看出，MPLS可以提供多条路径（同样的也可以人为限制路径），例如图中R4-A具有两条MPLS路径，这被称为流量工程 相比于传统网络，MPLS的优势有： 交换速度增加 流量工程 转发路径的快速恢复 VPN 数据中心网络 数据中心：包含大量主机，称为刀片，刀片堆叠在机架上，每个机架顶部有一台交换机，交换机之间互联，数据中心网络需要支持两种类型的流量——外部通信与内部交换，由边界路由器负责与公共因特网相连 数据中心网络示意 负载均衡 外部请求首先被重定向到负载均衡器，向主机发送请求并在主机之间尽量保持负载均衡，基于目的端口号和IP地址做决定 同时其提供了客户与数据中心网络之间的屏障，形成了类似NAT的效果（公网内网转换） 等级体系结构 大型数据中心需要使用路由器和交换机等级结构，以保证交换机工作的稳定性（如上图），其中每台接入路由器下的主机构成了子网，并且可以被进一步划分为多个VLAN子网 但是这种等级体系结构可能导致主机之间容量首先，即交换机速率不足以支撑并发时主机之间能够以最大速率通信 发展趋势 全连接拓扑示意 克服等级结构缺陷可以采用FCT，即第一层和第二层之间全连接，提升了主机之间不相交的路径数，并且未直接连接到同一个交换机的机架之间的通信逻辑上是等价的 另一种修改方式称为模块化数据中心，略过 目前数据中心常用的协议有： 链路层：RoCE 运输层：DCTCP/DCQCN 路由选择：SDN","tags":["笔记","网原","链路层","局域网"],"categories":["计算机网络原理"]},{"title":"IAI-对抗搜索","path":"/2024/05/20/IAI-对抗搜索/","content":"人智导 对抗搜索 对抗搜索 对于一些分支极多的对抗式问题，穷举法所需要消耗的时间、空间资源无法承受，无法实现，因此考虑充分的剪枝 极小-极大模型 进行有限步内的穷举，从根节点出发，叶节点标记得分，并且期望每位选手都选择对于自己最有利的走法，最后选择期望得分最高的一步 极大-极小模型示例图 图中，两种图形代表两位选手，分别记为A,BA, BA,B，叶节点上所标记的为AAA在四步之后的期望得分，每位选手每步都是期望自身得分尽量高（对方得分尽量低） 但是极小极大仍然没有剪枝，时空资源仍然无法承受 α-β剪枝算法 α\\alphaα-β\\betaβ 剪枝算法如下 α\\alphaα为极大节点（我方选手尽量多得分）的下界 β\\betaβ为极小节点（我方选手尽量少得分）的上界 后辈 β≤\\beta \\leqβ≤ 祖先 α\\alphaα 时，α\\alphaα 剪枝 后辈 α≥\\alpha \\geqα≥ 祖先 β\\betaβ 时，β\\betaβ 剪枝 实例如下：注意比较时需要和祖先节点而不是父节点比较 alpha-beta剪枝实例 每次α\\alphaα-β\\betaβ 剪枝只能得到下一步的走法 局限性：非常依赖局面估计（也就是叶节点的得分）的准确性，需要大量的专家知识与人工整理 蒙特卡洛(MCTS) 基本思想： 可能出现的状态用状态树表示 逐步扩展树节点 父节点利用子节点的结果 随时得到行为评价 基本过程为： 选择 →\\to→ 扩展 →\\to→ 模拟 →\\to→ 回传 选择策略 考虑两方面因素： 充分探索尚未探索的节点 利用效果尽量好的节点 因此采用多臂老虎机模型 拥有kkk个拉杆的老虎机，拉动每个拉杆的收益相互独立并且遵循一定分布，求如何使得受益最大化 采用信心上限算法：每次选择信心上限最大的节点，节点jjj的信心上限计算方式为： Ij=X‾j+c2ln⁡(n)Tj(n)I_{j} = \\overline{X}_{j} + c\\sqrt{\\frac{2\\ln(n)}{T_{j}(n)}} Ij​=Xj​+cTj​(n)2ln(n)​​ 其中参数含义为： ccc：调节参数 nnn：访问次数 Tj(n)T_{j}(n)Tj​(n)：此时节点 jjj 被访问的次数 X‾j\\overline{X}_{j}Xj​：此时节点 jjj 的平均收益 以围棋为例，每一次模拟可以看成是随机落点，平均收益可以看成是胜率，如下图，其中为简便令c=0c = 0c=0，最终选择根节点的子节点中胜率最大的节点作为下一步： 采用UBC选择的MCTS 注意： 每个节点的胜率是站在己方的角度考虑的！ AlphaGo 为了解决MCTS的盲目性问题（随机落子），将神经网络与蒙特卡洛结合起来，使用了策略网络与估值网络两种神经网络 策略网络 一个神经网络，用于提供行棋概率 输入：48个通道，每个通道大小19*19，记录了棋局的相关信息输出：棋盘上每个节点的行棋概率 策略网络 策略网络可以看成是一个361类别分类问题，通过人类棋手的棋谱进行训练，损失函数为 L(w)=−talog⁡(pa)L(w) = -t_{a}\\log(p_{a}) L(w)=−ta​log(pa​) 其中tat_{a}ta​为实际落子概率，pap_{a}pa​为网络落子概率 估值网络 一个神经网络，用于提供棋局收益 输入：49个通道，每个通道大小19*19，记录了棋局的相关信息（比策略网络多一个）输出：当前棋局收益 ∈[−1,1]\\in [-1, 1]∈[−1,1] 估值网络 估值网络可以看成回归问题，也是通过人类棋手棋谱进行训练，损失函数： L(w)=(R−V(s))2L(w) = (R - V(s))^{2} L(w)=(R−V(s))2 其中RRR为实际收益，111 胜 −1-1−1 负，V(s)V(s)V(s)为网络输出 与MCTS融合 给定参数 λ\\lambdaλ 每次模拟收益为： vi(s)=λvalue(s)+(1−λ)sim(s)v_{i}(s) = \\lambda \\text{value}(s) + (1 - \\lambda)\\text{sim}(s) vi​(s)=λvalue(s)+(1−λ)sim(s) 其中 value(s)\\text{value}(s)value(s) 为估值网络输出，sim(s)\\text{sim}(s)sim(s) 为模拟结果 因此定义平均收益： Q(sa)=∑i=1nvi(sa)nQ(s_{a}) = \\frac{\\sum\\limits_{i=1}^{n}v_{i}(s_{a})}{n} Q(sa​)=ni=1∑n​vi​(sa​)​ 定义探索项： u(sa)=c⋅p(sa)N(s)N(sa)+1u(s_{a}) = c \\cdot p(s_{a})\\frac{\\sqrt{N(s)}}{N(s_{a}) + 1} u(sa​)=c⋅p(sa​)N(sa​)+1N(s)​​ 其中： sas_{a}sa​代表棋局sss在aaa处落子后的棋局 N(s)N(s)N(s)代表对于棋局sss的模拟次数 p(s)p(s)p(s)代表策略网络对于sss的输出 ccc为系数 信心上限切换为： Ij=Q(sa)+u(sa)I_{j} = Q(s_{a}) + u(s_{a})Ij​=Q(sa​)+u(sa​) MCTS过程如下： 信息：每个节点记录收益、到达该节点概率与被选择次数 选择：从根节点开始，每次选择子节点中信心上限最大的节点，直到叶节点即停止并选中 生成：生成选中节点的所有叶节点（也即所有可能的落子），并规定了最大的节点深度 模拟：采用推演策略网络（更快），计算其viv_{i}vi​ 回传：注意正负号（即注意行棋是双方依次进行） 最终将根节点的子节点中，被选择次数最多的节点作为选择 深度强化学习方法 强化学习：学习“做什么可以使得收益最大化”深度强化学习：利用深度学习实现的强化学习 以围棋为例，通过自己博弈训练策略网络，三种实现方法： 策略梯度：学习每个点获胜的概率 价值评估：学习每个点获得最大收益的概率 演员评价方法：学习到每个落子点获得最大收益增量的概率 策略梯度 数据由自我博弈产生，损失函数为： L(w)=−talog⁡(pa)L(w) = - t_{a}\\log(p_{a}) L(w)=−ta​log(pa​) 其中，pap_{a}pa​为当前棋局在aaa处下棋的概率，ta∈{−1,1}t_{a}\\in\\{-1, 1\\}ta​∈{−1,1}为胜负值 基于策略梯度的强化学习流程 注意点： 强化学习过程中，每个样本只使用一次 该方法学习到的是每个可落子点行棋的获胜概率 价值评估 输入为当前棋局和行棋点，输出为该行棋点的价值，在[−1,1][-1, 1][−1,1]之间，数据也是自我博弈产生，损失函数为： L(w)=(R−V(s,a))2L(w) = (R - V(s, a))^{2} L(w)=(R−V(s,a))2 其中，RRR为胜负值，V(s,a)V(s, a)V(s,a)为棋局sss在aaa处落子后网络的输出 演员-评价方法 利用收益增量评价一步棋的好坏： A=Q(s,a)−V(s)A = Q(s, a) - V(s) A=Q(s,a)−V(s) 其中，V(s)∈[−1,1]V(s)\\in[-1, 1]V(s)∈[−1,1]为棋局sss的预期收益，Q(s,a)∈[−1,1]Q(s, a)\\in[-1, 1]Q(s,a)∈[−1,1]为sss在aaa处行棋之后的收益，在实际中常去Q(s,a)=RQ(s, a) = RQ(s,a)=R为胜负值，最终AAA越大收益越好 演员-策略网络，评价-估值网络 损失函数为： L(w)=L1(w)+λL2(w)=A2−λAlog⁡(pa)\\begin{align*} L(w) &amp;= L_{1}(w) + \\lambda L_{2}(w) \\\\ &amp;= A^{2} - \\lambda A\\log(p_{a}) \\end{align*} L(w)​=L1​(w)+λL2​(w)=A2−λAlog(pa​)​ AlphaGo Zreo 将估值网络和策略网络合并为“双输出”网络 输入：17个通道，记录8个棋局，每个棋局2通道，1个通道记录行棋方输出：策略网络输出362维，增加的一维为放弃；估值网络输出棋局的估值 Alpha-Zero原理 与MCTS融合 与AlphaGo基本相同，差别如下： 模拟被估值网络完全取代，模拟收益vi(s)v_{i}(s)vi​(s)即为估值网络的输出 规定了总模拟次数 结合MCTS与深度强化学习 Alpha-Zero中的深度强化学习 损失函数为： Lvalue=(R−v)2Lstrategy=−∑i=1362πilog⁡(pi)L=Lvalue+Lstrategy+∣∣θ∣∣2\\begin{align*} L_{value} &amp;= (R - v)^{2} \\\\ L_{strategy} &amp;= -\\sum\\limits_{i=1}^{362}\\pi_{i}\\log(p_{i}) \\\\ L &amp;= L_{value} + L_{strategy} + ||\\theta||^{2} \\end{align*} Lvalue​Lstrategy​L​=(R−v)2=−i=1∑362​πi​log(pi​)=Lvalue​+Lstrategy​+∣∣θ∣∣2​ 其中RRR为胜负值，vvv为估值网络输出，πi\\pi_{i}πi​为MCTS给出的该走法概率，pip_{i}pi​为策略网络给出的该走法概率 引入多样性 人为引入噪声，增加策略网络输出的随机性，通常增加一个狄利克雷分布，生成一些大多值为0，小部分值较大的随机变量，并修正策略网络输出为： p⇐λp+(1−λ)pdp \\Leftarrow \\lambda p + (1 - \\lambda) p_{d} p⇐λp+(1−λ)pd​","tags":["笔记","IAI","对抗搜索"],"categories":["人工智能导论"]},{"title":"TCS-Lecture-B","path":"/2024/05/15/TCS-Lecture-B/","content":"TCS: Randomized Computation Randomized Computation Randomized Algorithm A randomized algorithm outputs the correct value with good probability on every possible input. Matrix multiplication Input matrix A,B,CA, B, CA,B,C, decide if C=ABC = ABC=AB Obviously there is a deterministic and polynomial algorithm for this. A random algorithm: Freivalds’ algorithm Repeat the following for kkk times.Randomly choose v∈{0,1}nv\\in \\{0, 1\\}^{n}v∈{0,1}nCompute (d=A(Bv)−Cv)(d = A(Bv) - Cv)(d=A(Bv)−Cv)Reject if d≠0d eq 0d=0Accept We have that this algorithm can solve this problem in O(kn2)O(kn^{2})O(kn2) time with a probability of failure ≤2−k\\leq 2^{-k}≤2−k Proof: If AB≠CAB eq CAB=C, we prove P(d=0)≤12P(d = 0) \\leq \\frac{1}{2}P(d=0)≤21​ for each time.So D=AB−C≠0D = AB - C eq 0D=AB−C=0. Let Dij≠0D_{ij} eq 0Dij​=0The iii-th entry of ddd holds that:di=∑Dikvk=Dijvj+∑k≠jDikvkd_{i} = \\sum D_{ik}v_{k} = D_{ij}v_{j} + \\sum\\limits_{k eq j}D_{ik}v_{k}di​=∑Dik​vk​=Dij​vj​+k=j∑​Dik​vk​Let s=∑k≠jDikvks = \\sum\\limits_{k eq j}D_{ik}v_{k}s=k=j∑​Dik​vk​, so:P(di=0)=P(di=0 ∣ s=0)P(s=0)+P(di=0 ∣ s≠0)P(s≠0)≤P(vi=0)P(s=0)+P(vi=1)P(s≠0)≤12(P(s=0)+P(s≠0))≤12\\begin{align*}P(d_{i} = 0) &amp;= P(d_{i} = 0 \\,|\\, s = 0)P(s = 0) \\\\&amp;\\quad +P(d_{i} = 0 \\,|\\, s eq 0)P(s eq 0) \\\\&amp;\\leq P(v_{i} = 0)P(s = 0) + P(v_{i} = 1)P(s eq 0)\\\\&amp;\\leq \\frac{1}{2}(P(s = 0) + P(s eq 0)) \\leq \\frac{1}{2}\\end{align*}P(di​=0)​=P(di​=0∣s=0)P(s=0)+P(di​=0∣s=0)P(s=0)≤P(vi​=0)P(s=0)+P(vi​=1)P(s=0)≤21​(P(s=0)+P(s=0))≤21​​So P(d=0n)≤P(di=0)≤12P(d = 0^{n}) \\leq P(d_{i} = 0) \\leq \\frac{1}{2}P(d=0n)≤P(di​=0)≤21​ Maxcut Approximation The MAX-CUT problem is NP-Complete. So our task is to find a cut CCC whose size is not far from the optimal one C∗C^{*}C∗. If sizeC≥α sizeC∗\\text{size}_C \\ge \\alpha\\,\\text{size}_{C^*}sizeC​≥αsizeC∗​, we call CCC is an α\\alphaα-approximation, then we have an easily way to find 12\\frac{1}{2}21​-approximation, which is universal randomly distribute each vertex into set 000 or 111. E(sizeC)=E∑{u,v}∈E1xu≠xv=12∣E∣≥12sizeC∗.\\begin{equation*} \\mathbb{E}(\\text{size}_C) = \\mathbb{E} \\sum_{\\{u, v\\} \\in E} 1_{x_u e x_v} = \\frac{1}{2} |E| \\ge \\frac{1}{2} \\text{size}_{C^*}. \\end{equation*} E(sizeC​)=E{u,v}∈E∑​1xu​=xv​​=21​∣E∣≥21​sizeC∗​.​ This is just sufficient expection, but we can give an always-large-enough cut by conditional expection if we can compute this equation efficiently. E(sizeC(x1,…,xi,Xi+1,…Xn)),\\begin{equation*} \\mathbb{E}(\\text{size}_C(x_1, \\ldots, x_i, X_{i+1}, \\ldots X_{n})), \\end{equation*} E(sizeC​(x1​,…,xi​,Xi+1​,…Xn​)),​ We maximize this in each choice. Derandomize Above algorithm uses nnn random choices, covering 2n2^{n}2n possibilities. We can try to reduce the randomness to a polynomial number of possibilities, we can derandomize the algorithm. Considering Universal hash function: Consider a family of hash functions H={h:U→R}\\mathcal{H} = \\{ h : U \\to R \\}H={h:U→R}. Universal hash functions are a family of functions with the random-like property while the size of the family is small. We can use a small seed to choose hash functions from the family. Pairwise independent hash functions. A family H={h:U→R}\\mathcal{H} = \\{h : U \\to R\\}H={h:U→R} is called Pairwise independent if for any distinct x1,x2∈Ux_{1}, x_{2}\\in Ux1​,x2​∈Uand any y1,y2∈Ry_{1}, y_{2}\\in Ry1​,y2​∈R, we have:Ph∈H(h(x1)=y1 and h(x2)=y2)=1∣R∣2.\\begin{equation*}P_{h \\in \\mathcal{H}} \\bigl( h(x_1) = y_1 \\text{ and } h(x_2) = y_2 \\bigr) = \\frac{1}{|R|^2}.\\end{equation*}Ph∈H​(h(x1​)=y1​ and h(x2​)=y2​)=∣R∣21​.​ A pairwise independent hash functions mapping {0,1}k\\{0, 1\\}^{k}{0,1}k to {0,1}\\{0, 1\\}{0,1}. H={h(x)=(ax+b)(mod 2) ∣ a∈{0,1}kb∈{0,1}}\\mathcal{H} = \\{ h(x) = (ax + b)(\\text{mod }2) \\,|\\, a \\in \\{0, 1\\}^{k}\\quad b\\in\\{0, 1\\} \\}H={h(x)=(ax+b)(mod 2)∣a∈{0,1}kb∈{0,1}} This family size is ∣H∣=2k+1|\\mathcal{H}| = 2^{k+1}∣H∣=2k+1. Assign k=⌈log⁡n⌉k = \\lceil \\log n\\rceilk=⌈logn⌉, then UUU can encoding each vertex in GGG. So ∣H∣≤2n|\\mathcal{H}| \\leq 2n∣H∣≤2n, which means we can go through all the hash function in H\\mathcal{H}H and output the maximized cut. BPP Define Prob TM as follows: A probabilistic Turing machine is a type of NTM in which each nondeterministic step is called a coin-flip step and has two legal next moves. We assign a probability 2−k2^{-k}2−k to each branch of the machine’s computation where kkk is the number of coin flips occur in the branch.The probability of the machine accepting the input is defined asP(M accepts w)=∑b:b is acceptingP(b).\\begin{equation*}P(M \\text{ accepts } w) = \\sum_{b:b \\text{ is accepting}} P(b).\\end{equation*}P(M accepts w)=b:b is accepting∑​P(b).​ This is equvilant to that each son of a vertex in NTM can be reach in the same probability. Define the error probability ε\\varepsilonε: If w∈Aw \\in Aw∈A, then P(M(w)=1)≥1−εP(M(w) = 1) \\geq 1 - \\varepsilonP(M(w)=1)≥1−εIf w∉Aw otin Aw∈/A, then P(M(w)=1)≤εP(M(w) = 1) \\leq \\varepsilonP(M(w)=1)≤ε Then we can define BPP\\text{BPP}BPP with error probability: BPP\\text{BPP}BPP is the class of languages decided by probabilistic polynomial-time Turing machines with an error probability of 13\\frac{1}{3}31​Actually, the 13\\frac{1}{3}31​ can be replaced by any constant exactly greatly than 12\\frac{1}{2}21​ BPP\\text{BPP}BPP can be also defined with verifier: A decision problem AAA is in BPP\\text{BPP}BPP if and only if there is a polynomial-time verifier VVV such that for all xxx, x∈Ax\\in Ax∈A if and only ifPr(V(x,r)=1)≥23.\\begin{equation*}P_{r} \\bigl(V(x, r) = 1 \\bigr) \\ge \\frac{2}{3}.\\end{equation*}Pr​(V(x,r)=1)≥32​.​ Error Reduction Any decision problem A∈BPPA\\in\\text{BPP}A∈BPP has a polynomial-time randomized algorithm whose error probability is 2−p(n)2^{-p(n)}2−p(n) where ppp is a polynomial and nnn is the input size. This can be proved by Chernoff bound or Sampling Theroem Circuits v.s. BPP Define SIZEn(s)\\text{SIZE}_{n}(s)SIZEn​(s): For a finite function g:{0,1}n→{0,1}g: \\{0, 1\\}^{n}\\rightarrow\\{0, 1\\}g:{0,1}n→{0,1}, g∈SIZEn(s)g \\in \\text{SIZE}_{n}(s)g∈SIZEn​(s) if there is a circuit of at most sss NAND gates computing ggg. And we define the restricted function: F↾n(x)=F(x) for x∈{0,1}n.\\begin{equation*} F_{\\restriction n} (x) = F(x) \\text{ for } x\\in \\{0,1\\}^n. \\end{equation*} F↾n​(x)=F(x) for x∈{0,1}n.​ Then FFF is non-uniformly computable in T(n)T(n)T(n) size, as F∈SIZE(T)F\\in\\text{SIZE}(T)F∈SIZE(T) if there is a sequence C0,C1,…C_{0}, C_{1}, \\dotsC0​,C1​,… of NAND circuits such that: CnC_{n}Cn​ computes F↾nF_{\\restriction n}F↾n​CnC_{n}Cn​ has at most T(n)T(n)T(n) gates when nnn is sufficiently large So the non-uniform analog P\\text{P}P: P/poly=⋃c∈NSIZE(nc)\\text{P}/\\text{poly} = \\bigcup\\limits_{c\\in\\mathbb{N}}\\text{SIZE}(n^{c})P/poly=c∈N⋃​SIZE(nc) Obviously, P⊊P/poly\\text{P}\\subsetneq\\text{P}/\\text{poly}P⊊P/poly and it can be proved BPP⊂P/poly\\text{BPP}\\subset\\text{P}/\\text{poly}BPP⊂P/poly as follows: Due to error reduction, A∈BPPA\\in \\text{BPP}A∈BPP has a polynomial-time randomized algorithm whose error probability is less than 2−n2^{-n}2−n, which means there is a verifier VVV, such that∀x Py(V(x,y)≠A(x))&lt;12n\\forall x \\,\\, P_{y}(V(x, y) eq A(x)) &lt; \\frac{1}{2^{n}}∀xPy​(V(x,y)=A(x))&lt;2n1​So due to the union bound:Py(∃x V(x,y)≠A(x))≤∑xPy(V(x,y)≠A(x))&lt;1P_{y}(\\exist x\\,V(x, y) eq A(x)) \\leq \\sum\\limits_{x}P_{y}(V(x, y) eq A(x)) &lt; 1Py​(∃xV(x,y)=A(x))≤x∑​Py​(V(x,y)=A(x))&lt;1As this probability is not 111, there must exist some y∗y^{*}y∗ for which ∀x V(x,y∗)=A(x)\\forall x\\, V(x, y^{*}) = A(x)∀xV(x,y∗)=A(x).Thus there exists a circuit with poly(n)\\text{poly}(n)poly(n) gates to caculate problem AAA beacuse y∗y^{*}y∗ is polynomial P = BPP &lt;= P = NP Sipser–Gács Theorem: BPP∈Σ2P∩Π2P\\text{BPP} \\in \\Sigma^{P}_{2} \\cap \\Pi_{2}^{P}BPP∈Σ2P​∩Π2P​, while the ΣP\\Sigma^{P}ΣP and ΠP\\Pi^{P}ΠP are defined as:ΣiP=∃∀∃…PΠiP=∀∃∀…P \\begin{align*} \\Sigma_{i}^{P} &amp;= \\exists\\forall\\exists\\dots \\text{P} \\\\ \\Pi_{i}^{P} &amp;= \\forall\\exists\\forall\\dots \\text{P} \\end{align*}ΣiP​ΠiP​​=∃∀∃…P=∀∃∀…P​ And we have the following theroem P=NP\\text{P} = \\text{NP}P=NP implies P=BPP\\text{P} = \\text{BPP}P=BPP The proof is diffcult with the technique ‘probabilistic method’ And there is also a theroem that reveals the relation between B\\text{B}B and BPP\\text{BPP}BPP Relations with P NP EXP We know P⊊EXP\\text{P} \\subsetneq \\text{EXP}P⊊EXP and BPP⊆EXP\\text{BPP} \\subseteq \\text{EXP}BPP⊆EXP Expected: P=BPP⊊NP⊆EXP\\text{P} = \\text{BPP} \\subsetneq \\text{NP} \\subseteq \\text{EXP}P=BPP⊊NP⊆EXP Extreme: P⊊NP⊆BPP=EXP\\text{P} \\subsetneq \\text{NP} \\subseteq \\text{BPP} = \\text{EXP}P⊊NP⊆BPP=EXP Extreme also: P=BPP=NP⊊EXP\\text{P} = \\text{BPP} = \\text{NP} \\subsetneq \\text{EXP}P=BPP=NP⊊EXP","tags":["笔记","TCS","随机计算"],"categories":["理论计算机科学导引"]},{"title":"网原单词表","path":"/2024/05/15/网原单词表/","content":"计算机网络原理 中-英对照表 packet：分组 circuit switching：电路交换 packet switching：分组交换 packet switch：分组交换机 rooter：路由器 linker layer：链路层交换机 store-and-forword transmission：存储转发传输 output buffer/queue：输出缓存/队列 queuing delay：排队时延 packet loss：丢包 forwarding table：转发表 routing protocol：路由转发协议 Frequency-Division Multiplexing Address(FDMA)：频分复用地址 Time-Division Multiplexing Address(TDMA)：时分复用地址 bandwidth：带宽 slient period：静默期 Internet service provider(ISP)：因特网提供商 Point of Presence(PoP)：存在点 multi-home：多宿 peer(P2P)：对等 Internet Exchange Point(IXP)：因特网交换点 content provider network：内容提供商网络 nodal processing delay：节点处理时延 queuing delay：排队时延 transmission delay：传输时延 propagation delay：传播时延 total nodal delay：节点总时延 traffic intensity：流量强度 instantaneous throughout：瞬时吞吐量 average throughout：平均吞吐量 bottleneck link：瓶颈链路 layer：分层 protocol stack：协议栈 top-down approach：自顶向下方法 application-layer：应用层 message：报文 transport-layer：运输层 segment：报文段 network-layer：网络层 datagram：数据报 link-layer：链路层 frame：帧 encapsulation：封装 payload field：有效载荷字段 malware：恶意软件 botnet：僵尸网络 self-replicating：自我复制 worm：蠕虫 Denial-of-Service(DoS) attack：拒绝服务攻击 Distributed Dos(DDoS)：分布式拒绝网络攻击 packet sniffer：分组嗅探器 IP spoofing：IP哄骗 application architexture：应用程序体系结构 data ceenter：数据中心 process：进程 socket：套接字 Appllication Programming Interface(API)：应用程序编程接口 port numbe：端口号 reliable data transfer：可靠数据传输 bindwidth-sensitive application：带宽敏感应用 elastic application：弹性应用 Secure Socket Layer：安全套接字层 HyperText Transfer Protocol(HTTP)：超文本传输协议 stateless protocol：无状态协议 persistent connection：持续连接 non-persistent connection：非持续连接 Round-Trip Time(RTT)：往返时间 request line：请求行 header line：首部行 entity body：实体体 Web cache：Web缓存器 proxy server：代理服务器 Simple Mail Transfer Protocol(SMTP)：简单邮件传输协议 Post Office Protocol-Version3(POP3)：第三版的邮局协议 Internet Mail Access Protocol：因特网邮件访问协议 authorization：特许 transaction：事务处理 update：更新 Domain Name System(DNS)：域名系统 host aliasing：主机别名 canonical hostname：规范主机名 mail server aliasing：邮件服务器别名 load distribution：负载分配 distant centralized database：远距离集中式数据库 torrent：洪流 chunk：块 unchoked：疏通 tit-for-tat：一报还一报 Dynamic Adaptive Streaming over HTTP(DASH)：经HTTP的动态适应性流 manifest file：告示文件 content distribution network(CDN)：内容分发网络 reliable data transfer：可靠数据传输 Automatic Repeat reQuest(ARQ)：自动重传请求 Positive acknowledgment(ACK)：肯定确认 negative acknowledgment(NCK)：否定确认 duplicate packet：冗余分组 alter-nating-bit protocol：比特交替协议 Go-Back-N(GBN)：回退N步 sliding-window protocol：滑动窗口协议 cumulative acknowledgmemt：累计确认 Transmission Control Protocol：传输控制协议 connection oriented：面向连接的 full-duplex service：全双工服务 three-way handshake：三次握手 Maximum Segment Size(MSS)：最大报文长度 Maximum Transmission Unit(MTU)：最大设置单元 piggybacked：捎带 Exponential Weighted Moving Average(EWMA)：指数加权移动平均 congestion control：拥塞控制 per-connection throughput：每连接的吞吐量 Available Bite Rate(ABR)：可用比特率 congestion window：拥塞窗口 self-clocking：自计时 Additive-Increase, Multiplicative-Decrease(AIMD)：加性增，乘性减 Explicit Congestion Notification：明确拥塞通告 Explicit Congestion Notification Echo：明确拥塞通告回显 forwarding：转发 routing：路由选择 forwarding table：转发表 Software Defined Network(SDN)：软件定义网络 best-effort service：尽力而为服务 Tenary Content Address Memory(TCAM)：三态内容可寻址寄存器 Active Queue Management(AQM)：主动队列管理 Random Early Detection(RED)：随机早期检测 packet scheduler：分组调度 non-preemptive priority ququeing：非抢占式优先权排队 round robin queuing discipline：循环排队规则 work-conserving queuing：保持工作排队 weighted fair queuing：加权公平排队 Maximum Transmission Unit(MTU)：最大传送单元 dotted-decimal notation：点分十进制记法 Classless Interdomain Routing(CIDR)：无类别域间路由选择 address aggreration：地址聚合 Dynamic Host Configuration Protocol(DHCP)：动态主机配置协议 Plug-and-play Protocol：即插即用协议 Nonzero Protocol：需配置协议 Network Address Translation(NAT)：网络地址转换 tunneling：建隧道 Link State(LS) Algorithm：链路状态算法 Distance Vector(DV) Algorithm：距离向量算法 link state broadcast：链路状态广播 Autonomous System(AS)：自治系统 Open Shortest Path First(OSPF)：开放最短路优先 Broder Gateway Protocol(BGP)：边界网关协议 Routing Information Protocol(RIP)：路由信息协议 anycast：任播 switch farbic：交换结构 northbound/southbound API：北向/南向API Internet Control Messsage Protocol(ICMP)：因特网控制报文协议 Simple Network Management Protocol(SNMP)：简单网络管理协议 Management Information Base(MIB)：管理信息库 Structure of Management Information(SMI)：管理信息结构 Prorocol Data Unit(PDU)：协议数据单元 framing：成帧 Medium Access Control(MAC)：媒体访问控制 network adapter：网络适配器 Network Interface Card(NIC)：网络接口卡 Error Detection and Correction(EDC)：差错检测和纠正 undetected bit error：未检出比特差错 parity bit：奇偶校验位 two-dimensional parity：二维奇偶校验 Cyclic Redundancy Check(CRC)：循环冗余检测 polynomial code：多项式编码 generator：生成多项式 point-to-point link：点对点链路 point-to-point protocol(PPP)：点对点协议 high-level data link control(HIDC)：高级数据链路控制 broadcast link：广播链路 myltiple access problem：多路访问问题 Myltiple Access Control(MAC)：多路访问控制 collide：碰撞 channel partitioning protocol：信道划分协议 random access protocol：随机接入协议 taking-turns protocol：轮流协议 time-frame：时间帧 slot：时隙 Code Division Multiple Access(CDMA)：码分多址 Carrier Sense Multiple Access(CSMA)：载波侦听多路访问 CSMA with Collision Detection(CSMA/CD)：具有碰撞检测的CSMA channel propagation delay：信道传播时延 binary exponential backoff：二进制指数后退 polling protocol：轮询协议 token-passing protocol：令牌传递协议 Cable Modem Termination System(CMTS)：电缆调制解调器端接系统 Data-Over-Cable Service Interface CMTS(DOCSIS)：数据经电缆服务接口 Address Resolution Protocol(ARP)：地址解析协议 repeater:：转发器 filtering：过滤 forwording：转发 self-learning：自学习 aging-time：老化期 plug-and-play device：即插即用设备 jabbering：快而含糊的 switch poisoning：交换机毒化 Virtual Local Network(VLAN)：虚拟局域网 VLAN trunking：VLAN干线互联 Tag Protocol Identifier(TPID)：标签协议标识符 Multiprotocol Label Switchig(MPLS)：多协议标签交换 Ether VPN(EVPN or VXLAN)：链路层虚拟专用网络 Virtual Circuit(VC)：虚拟电路 label-switched router：标签交换路由器 Virtual Private Network(VPN)：虚拟专用网 traffic engineering：流量工程 data center network：数据中心网络 Top of Rack(TOR)：机架顶部交换机 blade：刀片 board router：边界路由器 load balancer：负载均衡器 hierachy of router and swtich：路由器和交换机等级结构 fully connected topology(FCT)：全连接拓扑 Modular Data Center(MDC)：模块化数据中心 Remote DMA(RDMA) over Converged Ethernet(RoCE)：??? base station：基站 cell tower：蜂窝塔 Access Point(AP)：接入点 infrastructure mode：基础设施模式 ad hoc network：自组织网络 handoff：切换 single/Multiple hop：单/多跳 mesh network：网状网络 mobile ad hoc network(MANET)：移动自组织网络 vehihcular ad hoc network(VANET)：车载自组织网络 path loss：路径损耗 multipath propagation：多径传播 coherence time：相干时间 Signal-to-Noise Ratio(SNR)：信噪比 Bit Error Ratio(BER)：比特差错率 hidden terminal problem：隐藏终端问题 fading：衰减 chipping rate：码片速率 Basic Service Set(BSS)：基本服务集 Service Set Identifier(SSID)：服务集标识 WiFi jungle：WiFi丛林 associate：关联 beacon frame：信标帧 active/passive scanning：主动/被动扫描 CSMA with Collision Avoidance(CSMA/CA)：具有碰撞避免的CSMA link-layer acknowledgement：链路层确认 Short Inter-Frame Spacing(SIFS)：短帧间间隔 Distributed Inter-Frame Spacing(DIFS)：分布式帧间间隔 Request to Send(RTS)：请求发送 Clear to Send(CTS)：允许发送 Wireless Personal Area Network(WPAN)：无线个人域网络 Frequency-Hopping Spread Spectrum(FHSS)：跳频扩展频谱 piconet：皮克网 Long-Term Evolution(LTE)：长期演进 Mobile divice(UE)：移动设备 Base station(eNode-B)：基站 Mobility Management Entity(MME)：移动管理实体 Home Subscriber Service(HSS)：家庭订阅者服务 Serving/PDN Gateway(S/P-GW)：服务/PDN网关 Mobile Subscriber Identity(IMSI)：移动订阅者身份 Subscriber Identity Module(SIM)：订阅者身份模型 Radio Access Network(RAN)：无线接入网络 Orthogonal Frequency Division Multiplexing(OFDM)：正交频分复用 All-IP Enhanced Packet Core(EPC)：全IP加强分组核 Packet Data Convergence(PDC)：数据收敛 Radio Link Control(PLC)：无线链路控制 GPRS Tunneling Protocol(GTP)：GPRS信道协议 Massive Machine Type Communications(mMTC)：大信息传输 Ultra-reliable and low latency communications(URLLC)：高可信低延迟交流 Multiple Directional Antennae(MIMO)：什么什么天线","tags":["笔记","网原"],"categories":["计算机网络原理"]},{"title":"网原笔记5","path":"/2024/05/15/网原笔记5/","content":"计算机网络原理 笔记 5 控制平面 路由选择算法 在路由器中寻找到最短路径，对于一个路由器，主要寻找到将其数据转发到其他路由器所需要的最短路径 算法分类方式 根据信息量 集中式路由选择：全局，了解该路由网络的全部信息并据此进行计算 分散式路由选择：局部，每个节点只知道与自己到相邻接点的花销 根据可变性 静态：路由基本不随时间变化 动态：随着网络流量或拓扑变化而动态改变路径，更加方便但是受一些特殊问题的影响 对负载敏感性： 敏感：趋近于绕开拥塞链路 迟钝：拥塞无影响，现代多采用这种，原因是链路开销不明确反映拥塞水平 LS 信息的全局性通过链路状态广播算法来完成 之后使用——伟大的Dijkstra!!! 路由振荡问题： 如图的链路为了避免选择高拥塞的道路，每次LS之后都会改变道路，导致了路由实际上处在振荡之中，并且从结果上来看，其选择的也并不是全局最优解 解决方案： 要求链路开销不依赖负载（不合理） 确保并非所有路由器同时运行LS，但是由于自同步的存在很困难，避免自同步可以采用链路通告随机化的方式 DV 迭代：循环计算直到没有更多信息需要交换 异步：不要求所有计算同步执行 分发式：每个节点计算接收邻居的信息，执行计算之后再发回去 基本原理是动态规划Bellman-Ford方程： dx→y=min⁡v∈Γ(x)(cx→v+dv→y)d_{x\\to y} = \\min_{v\\in\\Gamma(x)}(c_{x\\to v} + d_{v\\to y}) dx→y​=v∈Γ(x)min​(cx→v​+dv→y​) 算法如下： 给定图G=(V,E)G = (V, E)G=(V,E) ∀x∈V\\forall x \\in V∀x∈V，维护如下信息： 其与每个直接邻居的开销cx→vc_{x\\to v}cx→v​ 距离向量Dx→=[Dx→y: ∀y∈V]\\overrightarrow{D_{x}} = [D_{x\\to y}:\\text{ } \\forall y \\in V]Dx​​=[Dx→y​: ∀y∈V] 其所有邻居的距离向量 每个节点不时向邻居发送自己的距离向量 某个节点接收到邻居的信息或发现与自己连接的链路开销有变的时候，根据BF方程更新自己的距离向量 如果距离向量发生了变化，则发送给邻居 可以证明，lim⁡Dx→y→dx→y\\lim D_{x\\to y} \\to d_{x\\to y}limDx→y​→dx→y​ 注：图中cx→yc_{x\\to y}cx→y​应该是222而非212121 链路开销改变与链路故障 当链路开销增加时，很容易导致链路故障，如下图 右边的图会出现选择选择环路，即： Init: Dz→x=5(z→y→∗x),Dy→x=4(y→z→∗x)D_{z\\to x} = 5(z \\to y \\to^{*}x), D_{y\\to x} = 4(y \\to z \\to^{*}x)Dz→x​=5(z→y→∗x),Dy→x​=4(y→z→∗x) 1st forward: Dy→x=6(y→z→∗x),Dz→x=7(z→y→∗x)D_{y\\to x} = 6(y \\to z \\to^{*}x), D_{z\\to x} = 7(z \\to y \\to^{*}x)Dy→x​=6(y→z→∗x),Dz→x​=7(z→y→∗x) 2nd forward: Dz→x=8(z→y→∗x),Dy→x=9(y→z→∗x)D_{z\\to x} = 8(z \\to y \\to^{*}x), D_{y\\to x} = 9(y \\to z \\to^{*}x)Dz→x​=8(z→y→∗x),Dy→x​=9(y→z→∗x) … Until: Dz→x=50(z→x),Dy→x=51(y→z→x)D_{z\\to x} = 50(z\\to x), D_{y\\to x} = 51(y\\to z \\to x)Dz→x​=50(z→x),Dy→x​=51(y→z→x) 在最终情况之前，y,zy, zy,z所保存的到xxx的路径都是错误的，当变化后的开销（此处是4→604\\to 604→60）过大的时候，迭代轮次会过大导致传播速率迅速降低 毒性逆转 解决上述特定问题的方式（对于节点度数超过333的环路将无法解决） 如果zzz需要通过yyy到达xxx，则在zzz发送过去的信息中，记Dz→x=∞D_{z\\to x} = \\inftyDz→x​=∞ 善意的小谎言~ 两种算法的比较 记n=∣V∣,m=∣E∣n = |V|, m = |E|n=∣V∣,m=∣E∣： 报文复杂性：由于LS是全局的，因此其需要O(mn)O(mn)O(mn)个报文进行初始化，并且在一条链路发生改变时需要传递给所有节点，更复杂 收敛速度：LS复杂度O((m+n)log⁡n)O((m + n)\\log n)O((m+n)logn)，DV收敛很慢 鲁棒性：LS鲁棒性更强，因为全局算法相对来说路由器是解耦的，但是DV中一个不正确的节点会扩散到全局 OSPF 自治系统：由一组通常处在相同管理控制下的路由器组成，通常一个ISP中的路由器和其链路构成同一个AS，一个自治系统内的路由选择算法为自治系统内部路由选择协议 OSPF是一种LS，也即一个自治系统内采用全局广播的形式，并且即使未发生变化，也要周期性的广播链路状态，同时各条链路的开销，同时要检查链路运行状态，并允许路由器向相邻路由器广播 优点： 安全：能够鉴别OSPF路由器之间的交换，防止数据入侵 并发：允许使用多条相同开销的路径 可综合：容易扩展为MOSPF，从而支持多播 可层次化：支持一个AS中的层次化，即一个自治系统可以被划分为多个区域，每个区域之间可以相互交流，并且只包含一个主干 BGP 用于AS之间的通信，是一种分布式、异步的协议。 作用 在BGP中，一个路由器的转发表具有(xi,I)(x_{i}, I)(xi​,I)的形式，分别代表前缀与接口号 从邻接AS处获得前缀的可达性信息 并且每个子网可以向其他部分广播自己的存在性 确定到该前缀的最优路由 可达性通告 如上图，每对路由器中间使用179端口的半永久TCP连接，每个AS内部的会话为iBGP，跨AS的称为eBGP，于是通告路径如下： xxx子网向自己所在的AS的网关路由器发报文通知自己存在 网关路由器3a3a3a告知邻接的AS网关路由器：AS3中存在子网xxx 2c2c2c接收到这个消息，并通知AS2内的所有路由器 2a2a2a将信息发送给相邻的AS1，告知其xxx存在AS3内，并且可由AS2到达 同样的，不同AS之间可以增加对等链路，这样会导致子网和路由器之间存在多条路径 最优路由选择 在通告的子网前缀中增加一些属性，称为BGP属性，前缀及其属性称为路由，比较重要的属性包括： AS-PATH：这个AS是一条路由器路径中的一个，包含了已经通过的路由器列表，可以用于防止环路 NEXT-HOP：AS-PATH的起始路由器接口地址，每个AS的不同路由器接收到的NEXT-HOP属性可能不一样，用于指示从该路由器出发怎么找到子网 热土豆 查找AS内部路由转发信息，找到通往不同NEXT-HOP的最低开销路径，进而选择开销最低的那条 也即，热土豆追求的是贪心的尽快将报文传递出这个AS 路由器选择 当一个路由器希望到达一个前缀时，会将到该前缀的路由集合进行优先级排序，优先级如下： 每个路由增加一个本地偏好属性，属性值取决于管理员，本地偏好越高越优先 本地偏好相同时，选择AS-PATH最短的路由，由此规则确定路由之后通过DV决定路径 都相同时，采用热土豆 热土豆仍然无法选择时，采用BGP标识符 IP 任播 用于DNS中的服务，通常用语降低时延，例如CDN会向其下的多台服务器分配相同的IP，这样当一台路由器向这个IP发送信息的时候，路由器会向最近的一个服务器转发请求 路由选择策略 客户网络在多宿的情况下，可能会有类似提供商网络的行为，因此，其需要向相邻的所有提供商网络通告自己不能连通任何其他目的地，这样可以确保客户与提供商身份的相对稳定性 任何穿越ISP主干网的流量必须是其源或目的中至少一个唯一ISP的客户网络中（商业原因） SDN SDN体系结构具有4个关键特征： 基于流的转发：分组转发规则被规定在流表中，SDN控制平面用于计算、管理和安装流表项 数据平面和控制平面分离 位于数据平面交换机外部的网络控制：控制平面独立于数据平面之外 可编程的网络：网络控制应用程序是可编程的 控制器与控制程序 控制器的功能需要有： 通信层：负责控制器与数据平面之间的交流，称为南向API 网络范围管理层：控制决定层，配置流表以完成端到端转发、负载均衡、防火墙等功能 与应用程序接口：负责控制器与控制程序之间的交流，称为北向API OpenFlow协议 运行在实现了OpenFlow API的设备上，例如SDN控制器和数据平面之间，基于TCP，默认端口6653 控制器发送的重要报文包括： 配置：查询并设置交换机的配置参数 修改状态：增加、删除或修改交换机的流表项，设置交换机端口特性 发送分组：在交换机的特定端口发送特定报文 交换机发送的重要报文报告： 流删除：通知控制器删除一个流表项 端口状态：通知控制器端口状态的变化 分组入：将分组发送给控制器，如果该分组不能被流表匹配则控制器会做额外处理，如果可以匹配则会将该分组作为一个动作 实例 ICMP 主机和路由器之间用来沟通网络层信息的协议，最典型的用途是差错报告 通常被认为是IP的一部分，体系上位于IP之上，其内容作为IP报文的有效载荷 报文中包含一个类型字段和一个编码字段，包含引发该ICMP的IP的首部和前8个字节 这些报文可被用于探测，例如Traceroute程序利用ICMP来探测路由器的名字与IP地址 网络管理和SNMP 定义是一个冗长的单句： 网络管理框架 网络管理关键组件 如上图，关键组件包括： 管理服务器：控制网络管理信息的收集、处理、分析与显示，由人类控制 被管设备：被管理的真实设备，有若干个被管对象组成，被管对象包括实际硬件与配置参数 MIB：位于一个被管设备中收集被管对象的关联信息的数据库，其每个对象由SMI语言定义 网络管理代理：运行在被管设备中的进程，用于与管理服务器通信 网络管理协议：运行在管理服务器和被管设备之间的协议，为管理者提供了相应操作的能力 SNMP 一种网络管理协议，最常用的是请求响应模式，即管理服务器向代理发送请求，通常用于检索或修改MIB对象。其次可被用于代理向管理服务器发送陷阱报文，通知服务器有异常情况导致了MIB对象的改变 SNMP的PDU通过UDP传输，超时重传由管理服务器决定","tags":["笔记","网络层","网原"],"categories":["计算机网络原理"]},{"title":"网原笔记4","path":"/2024/05/08/网原笔记4/","content":"计算机网络原理 笔记 4 网络层 概述 网络层分为数据平面和控制平面 数据平面是将数据在输入链路和输出链路之间进行转发，控制平面是协调转发操作 转发和路由选择 转发：将数据报从输入链路转移到输出链路（数据平面） 路由选择：决定每个分组的路由（控制平面） 转发表：由路由选择确定，决定了转发的路由 确定转发表 传统方法：人工 路由器决定自身的转发表，但是需要路由器间的通信 SDN：由远程控制器决定每个路由器的转发表 网络服务模型 可能的服务： 确保交付 时延上界 有序分组 最小带宽 安全性 尽力而为服务：不提供任何服务 工作原理 四个组件： 输入端口：查询转发表决定输出路由，并且将数据转移至交换结构 交换结构：连接输入端口与输出端口 输出端口：从建环结构获取数据并此昂输出链路传输 路由选择处理器：执行控制平面功能，计算转发表（通常是一种传统的CPU） 转发策略： 基于目的地转发 通用转发 输入端口处理和基于目的地转发 最简单的情况下，每一个目的地址有一个对应的链路接口对应，采用前缀匹配的方法与最长前缀匹配规则（同时匹配多个前缀的时候选择最长的那个），为了效率通常使用SRAM，DRAM，TCAM 排队是指不同输入端口的数据在进入交换结构时排队 交换 交换方式很多 内存：直接经由CPU控制，这导致了速率较慢（受到内存带宽的限制），并且不能同时转发多个分组 总线：每一段数据会加上一个标签用于标记输出端口，所有输出端口都能接收数据但是只有被标记的可以保存数据，速率受到总线速率的影响，并且不允许并发 互联网：如纵横式交换机，共2N2N2N条总线，当想从输入端口发送到特定输出端口时只需要闭合对应交点即可，不同输出端口的分组可以并行 输出端口 何处排队 输入排队 当交换结构的速率不够快的时候会发生，并且会有线路前部阻塞，即同一个输出端口队列中前部的分组被堵塞会导致后面的也被堵塞 如果分组到达速率达到容量的58%58\\%58%，则输入队列会无限增长 输出排队 发送过快时会发生，采用丢弃新包或已有包来解决，同时有主动队列管理策略，如随机早期检测 传输顺序由分组调度决定 缓存的数量BBB与链路容量CCC的关系为： B=RTT∗CB = \\text{RTT} * C B=RTT∗C 分组调度 排队的分组怎么经过输出链路传输问题 FCFS：先来先服务 优先权排队：被分类放入优先权类中，同一类中的分组采用FCFS，非抢占式优先权排队中，分组开始传输就不能被打断 循环和加权公平排队：分组会被分类，但是不同类之间是平等的，也即会依次循环发送每一个类中的队列头，当某个类为空（链路空闲）时立即寻找其下一个类，例如加权公平排队，每个类会分配一个权重，并且加权分类吞吐量 网际协议 IPv4 版本号：确定剩余解释方式 首部长度：确定载荷与选项的分隔 服务类型：区别不同类型IP数据报 数据报长度：首部 + 数据 标识、标志、片偏移：与分片有关 寿命（TTL）：确保数据报不会循环 协议：指定运输层协议 检验和：检测比特错误，求和取反码 IPv4分片 一个链路层帧能承载的最大数据量称为最大传送单元，限制着IP数据包长度，并且一段路径上的链路之间可能有不同协议不同的MTU，因此采用分片技术，每一个大数据报被分为若干片 标识、标志、片偏移三个字段用于分片，标志比特用于标记最后一个片，片偏移用于决定正确的顺序 IPv4编址 点分十进制记法：每个字节用十进制书写，不同字节用句点隔开，如127.0.0.1127.0.0.1127.0.0.1 具有相同前缀的一些主机或路由器可以连接形成子网 其中223.1.1.0/24223.1.1.0/24223.1.1.0/24代表前242424为相同，/24/24/24为子网掩码 地址分配策略为无类别域间路由选择 地址聚合 得到地址 获取组织地址 由上游管理机构分配 获取主机地址 采用动态主机配置协议（又称即插即用或零配置），主机可以通过其来自动获取IP地址 DHCP发现：主机发现能够交互的DHCP服务器，通过DHCP发现报文，由链路层进行广播 DHCP提供：DHCP服务器回应一份DHCP提供报文，包含一些必要信息 DHCP请求：客户选择一个服务器，向其发送DHCP请求报文 DHCP ACK：服务器回应DHCP ACK报文 网络地址转换 在小型区域内合理使用一个IP地址的方法 NAT路由器是一个具有单一IP地址的打你设备，其中包含一张NAT转换表，用于将公网IP和端口转换为子网IP与端口 也即NAT用公网的端口进行寻址 中间盒 网络核心中的非交换机组成，包括NAT，流量负载均衡，流量防火墙等 IPv6 改动： 地址容量扩大：32→12832\\rightarrow 12832→128，引入任播地址，将数据报交给一组主机中的任意一个 简化首部 流标签：发送方要求进行特殊处理的流 字段： 版本号，指明是IPv4还是IPv6 流量类型：同IPv4的TOS 下一个首部：运输层协议 跳限制：最多能经过的路由器数目 去除了分片，取而代之的是差错报文，即数据太大时会被直接丢弃，并且向发送方返回一个ICMP差错报文 IPv4迁移到IPv6 好笑版：宣布标志日 实用版：建隧道 隧道指两台IPv6路由器之间的IPv4路由器的集合，方法是将IPv6的整个数据报作为数据包裹在IPv4载荷中进行传输，并且在下一个IPv6节点进行解包 通用转发和SDN 匹配加动作转发表称为流表，每个表项包括： 首部字段值的集合 计数器集合 动作集合 匹配 对来自不同层次的协议首部的一部分字段进行匹配，允许通配，例如192.118.∗192.118.*192.118.∗将匹配所有192.118192.118192.118开头的IP地址 动作 转发：转发到特定端口、端口集合或其余所有端口 丢弃 修改字段：在被转发之前重写首部字段（IP协议不可重写） 封装并转发给远程控制器","tags":["笔记","网络层","网原"],"categories":["计算机网络原理"]},{"title":"网原笔记3","path":"/2024/05/08/网原笔记3/","content":"计算机网络原理 笔记 3 网络原理 运输层 无连接运输：UDP 优势： 关于发送什么数据以及何时发送的应用层控制更加精细 无需建立连接（无需握手） 无连接状态 报文段首部短 报文段 检验和 发送方将所有161616比特字段求和并取反码，得到检验和，接收方将所有161616比特字段（包括检验和）进行求和，如果结果不是全111则有错，只能检验不能恢复 可靠数据传输 下层协议可能不可靠 (ARQ) 功能： 差错检测 接收方反馈 重传 在上一组数据传完并得到ACK相应之前不会有下一组数据，也即上层协议的send不会被调用，称为停等协议 考虑处理ACK/NAK受损的问题： 在2.22.22.2中，可以看出在接收到ACK的时候会判断其数字是否与当前状态相同，如果不相同则视作NAK 为了处理丢包，在发送发建立一个定时器，使得其能够在一定时间未接收到ACK之后默认为丢包，重发分组并且重置定时器 流水线 减少停等带来的传输利用率低下（传播时延远远大于传输时延） 增加序号 双方缓存多个分组 差错恢复：回退N步与选择重传 回退N步 当base得到确认之后窗口开始滑动，具体的FSM如下： 超时的时候，重传所有已发送但是未被确认的分组，同时接收方会丢弃所有失序的分组 选择重传 窗口长度必须不大于分组序号空间大小的一半，反之无法正常工作，接收方会出现无法分辨重传与新分组的现象 接收方收到自身的滑动窗口之前的分组时仍要发送ACK，否则发送方无法知道已被接收，窗口不能滑动 可靠数据传输总结 TCP 连接 全双工服务：双向传输 点对点：一对一传输 传输路径：进程 -&gt; 套接字 -&gt; 发送缓存 -&gt; 网络层 -&gt; 接收缓存 -&gt; 套接字 -&gt; 进程 典型的MSS的值为146014601460字节 报文 接收窗口字段：用于流量控制，指示接收方愿意接受的字节数量 选项字段：协商MSS，或在高速网络下作为窗口调解因子 标志字段： ACK：确认接收 RST, SYN, FIN：用于建立和拆除连接 PSH：指示接收方立即上传数据 URG：指示紧急数据 序号和确认号 一个报文段的序号是指该报文段首字节的字节流编号，TCP将数据看成有序字节流，对每一个字节分别标号 确认号指的是期待收到的最小字节标号，例如发送方已经收到0∼1000\\sim1000∼100和200∼300200\\sim300200∼300，则确认号为101101101 往返时间与超时 时限必须要大于RTT SampleRTT：报文段从发出到接被确认接收所需要的时间，在任意时刻仅测量一个报文段的SampleRTT而不是计算所有待确认的报文段，得到结果后加权更新，同时计算RTT偏差：EstimatedRTT=(1−α)EstimatedRTT+αSampleRTT\\text{EstimatedRTT} = (1-\\alpha)\\text{EstimatedRTT} + \\alpha\\text{SampleRTT} EstimatedRTT=(1−α)EstimatedRTT+αSampleRTT DevRTT=(1−β)DevRTT+β∣SampleRTT−EstimatedRTT∣\\text{DevRTT} = (1-\\beta)\\text{DevRTT} + \\beta|\\text{SampleRTT} - \\text{EstimatedRTT}| DevRTT=(1−β)DevRTT+β∣SampleRTT−EstimatedRTT∣ 时限应当确定为：Timeout=EstimatedRTT+4DevRTT\\text{Timeout} = \\text{EstimatedRTT} + 4\\text{DevRTT} Timeout=EstimatedRTT+4DevRTT 在真实处理中，有一种技术是在每次超时之后将时限翻倍 可靠数据传输 冗余ACK：用于指示报文丢失，当重复收到一个报文段的333次冗余ACK，之后，立即重传其下一个报文 流量控制 使得发送速率与接收方的读取速率相匹配，通过发送发来维护接收窗口实现，指示接收方剩余的缓存空间 发送方保证发送到连接中但是未被确认的数据量小于rwnd即可 特例：当缓存已经满了的时候发送仅含一字节数据的报文段，此时接收方开始清空缓存，并在确认报文里发送新rwnd 三次握手 客户向服务器发送一个SYN为111的报文段，随机选择一个初始序号，请求连接 服务器接收，分配缓存与变量，选择初始序号，返回SYNACK报文段表示允许连接 客户端接收，分配缓存与变量，连接建立 关闭过程： 客户端发送FIN置111的报文段表示关闭请求，并接收ACK，清理变量和缓存 服务端发送FIN置111的报文段表示关闭请求，并接收ACK，清理变量和缓存 拥塞控制 原因 理想路由器，分组的到达速率接近链路容量时，排队时间趋近于无穷大 有缓存的路由器，发送方因为大时延进行不必要重传占据链路带宽 上游路由器发送的分组最终被丢弃，这样发送它所占用的资源就被浪费了 控制方法 端到端：网络层不反馈，全部依靠运输层 网络辅助：网络层会反馈一些信息 TCP拥塞控制 发送方维护一个拥塞窗口cwnd，满足 LastByteSent−LastByteAck≤min⁡(cwnd,rwnd)\\text{LastByteSent} - \\text{LastByteAck} \\leq \\min(\\text{cwnd}, \\text{rwnd}) LastByteSent−LastByteAck≤min(cwnd,rwnd) 发送速率为 cwndRTT字节/秒\\frac{\\text{cwnd}}{\\text{RTT}}字节/秒 RTTcwnd​字节/秒 发送方判定丢包为超时或三个冗余ACK TCP为自计时的 TCP拥塞控制算法 慢启动： cwnd初始值被确定为一个MSS，传输的报文段被首次确认的时候增加一个MSS，因此整体呈现几何级数增长的形式，同时在发送方维护ssthresh（慢启动阈值），结束增长有如下情况： 超时丢包：重新初始化并慢启动，令ssthresh=cwnd/2\\text{ssthresh} = \\text{cwnd}/2ssthresh=cwnd/2 cwnd=ssthresh\\text{cwnd} = \\text{ssthresh}cwnd=ssthresh：进入拥塞避免 333个冗余ACK：快速重传，进入快速恢复 拥塞避免 每个RTT只增加一个MSS而不是翻倍，例如每个ACK增加MSS2/cwnd\\text{MSS}^{2}/\\text{cwnd}MSS2/cwnd，结束控制如下： 超时丢包：同慢启动 333个冗余：快速重传，令ssthresh=cwnd/2,cwnd=ssthresh+3MSS\\text{ssthresh} = \\text{cwnd}/2, \\text{cwnd} = \\text{ssthresh} + 3\\text{MSS}ssthresh=cwnd/2,cwnd=ssthresh+3MSS 快速恢复 每个冗余ACK增加一个MSS，结束控制： 超时丢包：同慢启动 回顾 整体拥塞控制方法成为加性增，乘性减 另一种拥塞控制方法为基于延迟，即实时检测吞吐量，并于最大吞吐量cwnd/RTT\\text{cwnd}/\\text{RTT}cwnd/RTT进行比较，并且线性增减去趋近最大吞吐量 宏观吞吐量 以WWW代表窗口长度，则 Mean=0.75∗WRTTMean = \\frac{0.75*W}{\\text{RTT}} Mean=RTT0.75∗W​ 高带宽TCP 设LLL为丢包率，则 Mean=1.22∗MSSRTT∗LMean = \\frac{1.22*\\text{MSS}}{\\text{RTT}*\\sqrt{L}} Mean=RTT∗L​1.22∗MSS​ 这代表高吞吐率需要非常低的丢包率来支持 TCP公平性 公平性代表瓶颈链路分配给每条链路的资源应该是相近的 TCP趋近于多条链路之间平等分享，但是在实际应用中，RTT较小的通常吞吐量更大 公平与UDP UDP无拥塞控制，并且可能会抑制TCP 公平与并行TCP 一个应用使用多条TCP并行会导致占用过多资源，但是资源的公平应该是在应用层面上的 明确拥塞公告 网络层辅助的拥塞控制机制 IP协议的首部中有两个比特被用于标记ECN，当接收方收到ECN时则在回复的ACK中设置ECE，发送发收到之后进行窗口减半处理（和超时丢包相同），并在下一个报文段首部标记CWR字段（拥塞窗口缩减）","tags":["笔记","网原","运输层"],"categories":["计算机网络原理"]},{"title":"网原笔记2","path":"/2024/05/08/网原笔记2/","content":"计算机网络原理 笔记 2 网络原理 应用层 应用层协议原理 APP是运行在端系统上，而不是诸如路由器等的网络核心设备上，因为网络核心设备基本只在网络层及以下的地方起作用 网络应用程序体系结构 两种主流体系结构： 客户-服务器体系 对等体系 客户-服务器 服务器：一个总是打开的主机，处理来自其他客户主机的请求，例如Web浏览器等 客户之间不会直接通信，而是需要经过服务器中转，并且服务器具有固定的地址（称之为IP地址） 数据中心：为了防止单一的服务器主机无法处理大量请求，部分服务商会部署数据中心，其中配备有大量主机，用于模拟服务器 对等 端系统主机之间直接通信，无需经过服务器中转，一些流量密集型应用采用的是P2P结构 P2P结构具有自扩展性，每个对等方通过请求文件产生工作负载，但是其也可以通过向其他对等方分发文件提升系统服务能力 进程通信 这里讨论的是不同端系统之间进程的通信，其通过交换报文相互通信 客户与服务器进程 对于任意一对进行通信的进程，在会话开始时等待联系的一方为服务器，发起通信的一方为客户，无论其采用的体系结构是可恶-服务器或P2P 进程与计算机网络的接口 进程间通过套接字（也被称为API）接口进行报文的发送和接收，套接字是应用层与运输层的接口，开发者可以选择运输层协议，并借助该协议进行开发 进程寻址 接收进程的地址包括： 主机地址 在目标主机中指定接收进程的标识符 主机由其IP地址确定，是一个32bit32bit32bit的量并且可以唯一标识一个主机，指定接收进程由目的地端口号保证，一个端口号只能接收一个进程的信息 可供应用程序使用的运输服务 一个运输层协议所能提供的服务分为四类： 可靠数据传输 吞吐量 定时 安全性 可靠数据传输 由于丢包、数据损坏等情况，数据可能发生丢失，因此，我们需要一种使得发送的数据一定可以正确、完全的交付给另一方的协议，称之为可靠数据运输 部分应用（例如音视频、原神等）允许一定量的数据丢失，这被称为容忍丢失的应用 吞吐量 可用吞吐量：两个进程之间发送比特的速率，由于其他会话会共享带宽，因此可用吞吐量会随着时间波动 因此，一部分协议保证了应用可用吞吐量的下界，这对于一些带宽敏感应用（具有特定的吞吐量要求）是很有必要的，与之相对，弹性应用不需要限制吞吐量 定时 定时协议可以保证时延的上界，例如可以确保发送的比特一定会在100ms100ms100ms内到达接收方，广泛应用于实时交互的应用中 安全性 协议能够提供数据的加密、解密，以保证只有进程可以直接观察到发送的的数据，同时还有数据完整性鉴别、端点鉴别等 因特网提供的运输服务 包括TCP与UDP两种 TCP 包括面向连接服务与可靠传输服务 面向连接服务：应用岑报文开始流动之前，TCP让客户服务器进行握手（交换运输层控制信息），握手结束后即建立了一条TCP连接，双方进程可以在该连接上进行报文的收发，结束发送至后必须拆除连接 可靠传输服务：同上 同时，TCP拥有拥塞控制机制，可以在适当时机抑制发送进程，并且限制每个连接使之公平共享带宽 由于其没有加密机制，因此有基于TCP的SSL，可以提供关键的安全性服务,SSL不是一种新的因特网运输协议 UDP 轻量级，仅提供最小服务，没有握手机制、拥塞控制机制、可靠传输等 因特网运输协议所不提供的服务 没有包括定时和吞吐量等，这些操作被巧妙的设计所尽量保障，但是在一些极端情况下仍然会被限制 应用层协议 应用层协议定义了进程之间传递报文的格式，如： 交换报文的类型 各种报文类型的语法 报文中字段的语义 确定进程何时、如何发送报文 对报文进行响应的规则 应用层协议是网络应用的重要组成部分 Web &amp; HTTP HTTP概况 Web页面有对象组成，可以通过URL（由主机名+路径名构成）寻址访问Web服务器实现了HTTP服务器端，用于存储Web对象，基本通信方式如下： HTTP是一个无状态协议，也即其不会存储有关客户的任何信息（例如短时间内连续请求信息，则服务器每次会重新发送） 持续连接与非持续连接 客户与服务器之间需要进行一系列请求，并且两个请求之间的间隔可能是随机的或是周期性的，所以不同请求可以使用不同的TCP连接或者同一个TCP连接，被分为非持续连接和持续连接两种，HTTP1.1及更高版本默认情况下使用的是持续连接，HTTP1.0采用的是非持续连接，而HTTP2.0版本更新了队列机制，不强制要求FCFS，而是可以让用户自己定义优先级 非持续连接 每一个对象需要一次TCP连接 定义往返时间：一个短分组从客户到服务器再返回客户的时间，如下： 上图中设计三次握手过程，其中前两个过程消耗了一个RTT，最后一次握手以及发送HTML文件这个响应操作消耗了一个RTT，因此总响应时间为2∗RTT+2*\\text{RTT} +2∗RTT+传输文件时间 持续连接 非持续连接需要为每个请求的对象建立并维护一个连接，需要大量TCP缓冲区与变量，并且会导致相对更高的时延 持续连接即建立连接后，即使完成请求也不关闭，因此不同请求可以使用这一条连接进行，避免了反复建立连接，当连接在一定时间内没有被使用时才会被关闭 HTTP 报文格式 分为请求报文与响应报文两种 HTTP请求报文 第一行称作请求行，其后续都称为首部行 请求行分为方法、URL、HTTP版本三个字段 主机的信息提供给Web代理高速缓存 第三行用于关闭持续连接 第四行用于指明用户代理，即浏览器类型 第五行用于指明需要得到的语言版本 通用格式如下： 实体体在GET方法中为空，在POST等方法中包含信息，例如用户在搜索框内的输入信息等，而需要给服务器提供信息的操作不一定是POST操作，例如可以将信息附在URL中然后使用GET操作 HTTP响应报文 比请求报文多了一个实体体的部分，同时第一行称作状态行 状态行包括协议版本，状态码与状态信息三部分 第二行与请求报文相同 第三行表示了发送响应报文的时间 第四行表示服务器 第五行表示发送的对象被最后修改的时间，对于缓存来说非常重要 第六行表示发送对象的字节数 第七行表示对象类型 通用格式如下： 用户与服务器的交互：cookie 允许站点对用户进行跟踪，技术有如下四个组件： 响应报文中的cookie首部行 请求报文中的cookie首部行 端系统中的cookie文件 后端数据库 用户首次访问一个站点的时候，服务器会为其建立一个 cookie用来唯一标识这个客户，并将其发送给浏览器，后续会话中浏览器与服务器之间可以通过cookie来确定用户信息 Web缓存 又称代理服务器，可以理解为是客户和初始服务器之间的一个代理，可以提升用户的访问速度，用户可以往缓存中发请求，如果缓存中拥有的话则可以直接返回响应，反之则需要在初始服务器中进行寻找，因此可以有效的降低时延并且减少供应商成本 条件GET方法 用于确定缓存中的数据是最新的方法，具体来说，缓存数据会存储数据的最近修改时间，因此，如果用户在请求报文中增加了行 1If-modified-since: xxx 则缓存与代理之间会经过一次通信确定文件在xxx时间之后是否有被修改过，这种报文称之为条件GET请求 电子邮件 &amp; SMTP SMTP 步骤如下： 发送方代理将报文发送给自身邮件服务器，并存储在报文队列中 发送方服务器SMTP与接收方服务器SMTP直接建立TCP连接 握手结束后，通过该连接发送报文 接收方服务器接收报文，并将其放入接收方的邮箱中 SMTP可以通过可靠数据传输将邮件完整的发送到接收方，并且其采用的是直接连接的方式 SMTP有一条特殊规则是：只包含nnn个句点符号的单行，表示的是n−1n-1n−1个句点，因为单个句点是指示报文结束，对话形式如下图： 由用户端发送的、全大写的字符串代表特殊命令，其含义可以直接翻译理解 与HTTP比较 同： 都用于在两台主机之间传送文件 都是持续连接 异： HTTP是拉协议，即此时连接由接收方向发送方发起；TCP是推协议，即此时连接由发送方向接收方发起 SMTP要求发送数据必须编码为ASCII字符，但是HTTP没有限制 对于多对象（例如包含图片、视频、音频等）文档，HTTP将每个对象分别封装，但是SMTP将其全部封装在一起 报文格式 使用的是RFC 5322定义，其中的From, To两行是必选的 访问协议 由于SMTP是一个推协议，因此用户是无法通过自己设备上的代理向服务器请求邮件的，因此我们没有办法实时读取到存储在服务器中的邮件，为了解决这个问题引入了邮件访问协议，如POP3, IMAP, HTTP POP3 由RFC 1939定义，极其简单，首先用户向服务器提出建立TCP连接，建立之后依次分为三个阶段：特许，事务处理与更新 鉴权（特许）阶段：客户端使用命令user 与pass 鉴别身份信息（明文发送） 事务处理：客户端允许使用list, retr , dele 三条命令，分别代表：列出所有邮件长度，接收id号邮件，删除id邮件 更新：当用户使用了quit命令之后进入更新阶段，服务器删除被标记的斑纹，POP3会话结束 每次客户端发来一个命令之后，服务端的回复是+OK 或-ERR IMAP 允许用户可以在远程服务器上操作邮件，包括创建文件夹、移动邮件、在远程文件夹上查询邮件等，更加方便，并且允许用户获取报文的部分，以避免大量信息造成网络负担过重 邮件中的HTTP 在代理和服务器直接发送信息的时候采用HTTP协议，在服务器之间传输的时候采用SMTP，也即将浏览器当成用户代理 DNS：因特网的目录 用于转换主机在主机名与IP地址之间的一种系统，主机名方便人类记忆，而IP更容易被计算机处理 DNS的服务 DNS是指： 由分层的DNS服务器实现的分布式数据库 使主机能够查询分布式数据库的应用层协议 DNS服务器运行BIND软件，协议运行在UDP之上，使用53号端口 DNS通常是一种被其他应用层协议使用的应用程协议，用于将它们请求报文中的主机名转换为IP地址，而并不常与用户直接通信 除了转换外还有其他服务： 主机别名，部分主机拥有多个主机名，而其中有一个成为规范主机名，而别名的存在是为了更方便的记忆，因此DNS可以识别别名 邮件服务器别名：电子邮件的后缀可以是别名，由邮件app调用DNS进行处理 负载分配：部分站点有多个服务器，也即一个规范主机名会对应多个IP地址，因此DNS用于调配这些地址之间的负载，用户向这个主机名发送请求等效于向当前队列中最前方的IP发送请求 工作机理概述 从用户来看，DNS是一个提供转换服务的黑盒，但是其内部是由大量DNS服务器及应用层协议组成的 简单设计：全球仅有一台DNS服务器，会有诸多问题 单点故障导致全球故障 通信容量巨大 远距离的集中式数据库导致高时延 维护复杂 因此采用了分布式的设计方案 分布式层次数据库 从上到下依次为：根服务器，顶级域服务器与权威服务器，访问一个主机名的时候从上至下访问服务器，从右至左依次匹配 根服务器：全球有400400400多个 顶级域：例如.com, .edu等 权威：每个公共可访问主机的组织需要提供公共可访问的DNS记录，这些记录被记录在权威服务器中 本地DNS服务器：属于ISP，起到的是代理、加速作用 每次向服务器发送请求是，得到的是下一级的服务器IP地址列表，权威服务器将会返回查询地址的IP，同时，权威服务器有可能需要用过中间服务器再次分层，也即权威-&gt;中间-&gt;权威 查询方式分为递归查询与迭代查询，上图中，请求主机与本地服务器之间为递归查询，其与全部为迭代查询，即迭代查询是接受请求后直接返回，而递归查询是接受请求后向其他服务器查询之后再返回给请求方 DNS缓存 为了改善时延并且减少报文数量，DNS服务器可以将请求/回答信息环城存在本地存储器中，以便更快返回，由于IP对应关系不永久，因此缓存信息会被定时清除 DNS记录与报文 DNS服务器存储了资源记录，其提供了主机名到IP地址的映射，形式为： (Name, Value, Type, TTL)\\text{(Name, Value, Type, TTL)} (Name, Value, Type, TTL) 其中TTL代表的是应当删除的时间，其余三个的对应如下： Type = A，则Name是主机名，Value是对应的IP地址 Type = NS，则Name是一个域，Value是域中可获取主机IP的权威服务器主机名 Type = CNAME，则Name是一个别名，Value是对应的规范主机名 Type = MX，则Name是一个别名，Value是对应邮件服务器的规范主机名 报文 前121212字节称为首部区域，标识符用于匹配，标志用于提供一些额外信息 问题区域包含查询信息，包括主机名、问题类型（查规范主机名还是邮件服务器等） 回答区域包含了资源记录，可以包含多条 在DNS数据库中插入 略 P2P文件分发 对等方直接通信，减少对服务器的依赖 P2P体系的可扩展性 FFF：文件长度 NNN：对等方数量 usu_sus​：服务器接入链路的上传速率 uiu_iui​：第iii个对等方接入链路的上传速率 did_idi​：第iii个对等方接入链路的下载速率 考虑在客户-服务端与P2P两种模式下所需要的分发时间 客户-服务器体系Dcs≥max(NFus,Fdmin)D_{cs} \\geq max(\\frac{NF}{u_s}, \\frac{F}{d_{min}}) Dcs​≥max(us​NF​,dmin​F​) P2PDP2P≥max(Fus,Fdmin,NFus+∑ui)D_{P2P} \\geq max(\\frac{F}{u_s}, \\frac{F}{d_{min}}, \\frac{NF}{u_s + \\sum u_i}) DP2P​≥max(us​F​,dmin​F​,us​+∑ui​NF​) 当对等方数量非常多时，采用P2P将会具有很好的效果（增长缓慢） BitTorrent 一种P2P协议，其中，参与特定文件分发的所有对等方集合被称为一个洪流，每个洪流有一个基础设施节点称为追踪器，其中记录并追踪了每个对等方及其是否离开了洪流 新对等方向追踪器请求对等方列表，并尝试向所有对等方建立TCP连接，成功建立连接之后称为邻近对等方，并向所有的邻近对等方请求未含有的块 请求块的方法是最稀缺优先，请求其邻居中所含副本最少的块，以便尽快达到块数量的均衡 给其他对等方上传数据时，每隔一段时间选择向其发送数据最快的444个对等方，其集合成为疏通，并向它们上传块，同时会每隔一段时间随机寻找新对等方进行对换，也即最多会向555个对等方上传块，这种激励机制成为一报还一报 视频流和CDN 因特网视频 比特率决定视频质量以及对传输所需要的流量 HTTP流和DASH 常规的HTTP流为对视频进行编码后使用常规方法进行发送，在用户端有两种方式，一种为缓存字节数超过一定数目就开始播放，另一种为流式视频，即按帧缓存，从接受视频开始即播放 DASH被称为经HTTP的动态适应性流，其将视频编码为不同版本，随着带宽的变化选择不同版本，服务器中存在告示文件，提供不同版本的URL与分辨率 CDN 分布在多个地理位置上的服务器，用于帮助世界各地的用户尽快获取内容 服务器安置原则为： 深入：遍历接入ISP来深入其中，靠近端用户 邀请做客：在关键位置部署少量大集群，邀请ISP做客 CDN采用拉策略，并非将视频存储在每一个集群中，当集群缺少这个视频时则会向其他集群检索并缓存 CDN操作","tags":["笔记","网原","应用层"],"categories":["计算机网络原理"]},{"title":"网原笔记1","path":"/2024/05/08/网原笔记1/","content":"计算机网络原理 笔记 1 网络原理 概要 考核 随堂测 15% 作业 25% 期末考试 60% Key problems Multiple access control: MAC rooting naming: how to give each user a unique id Congestion control（阻塞控制） RDT: Reliable Data Transfrom Protocol 协议：协议定义了网络实体之间发送和接收消息的格式、顺序，以及对消息传输、接收所采取的操作 网络核心 分组交换 端系统（主机）之间交换报文，报文包含了通讯者需要的信息，并通过通信链路从源发送至目的地 源会将长报文划分为较小的数据块，称为分组，通信链路上拥有分组交换机，以使得以链路允许的最大传输速率传输报文，分为路由器和链路层交换机两种 存储转发传输：在链路发送信息时必须要整组发送，即需要等待源将一组信息完全发送至交换机才能发送至目的地 端到端时延：通过NNN条传输速率为RRR的链路组成的路径，从源向目的地发送一个LLL比特的分组，端到端时延（传输时延）为d=NLRd = N\\frac{L}{R} d=NRL​ 发送PPP个分组的时延为d=(N+P−1)LRd = (N+P-1)\\frac{L}{R} d=(N+P−1)RL​ 排队时延与丢包：分组交换机拥有一个输出队列（缓存），当交换机的输出速率小于输入速率时，后进入的包会进入缓存中等待，这一种延迟称之为排队时延，主要取决于网络阻塞程度，当缓存被填满时，再次有包进入时会导致有的包（可能是新来的或队列中的）被丢弃，即为丢包 转发表：路由器决定应该将信息往哪一条链路发送的方式，可以将目的地IP地址（或其一部分）映射到对应的输出链路，转发表通常会根据路由转移协议来自动设置 电路交换 与分组交换的最大区别在与：电路交换会提前预留端到端通信所需要的资源，包括缓存、链路传输数据等，每一条链接称为一条电路，因此其时延主要来自于建立电路与在电路上传播 复用：分为频分复用与时分复用 频分复用指一组连接共用一段频谱，每个连接有一个独享的频段。例如调频无线电台使用FDM共享88MHz-108MHz的频谱，每一个电台会被分配一个特定的频段（通常带宽为4MHz），使用完毕之后会被回收投入下一次使用 时分复用指，将时间分割为固定的帧，每一帧被分割为固定量的时隙，每个时隙只传播一个连接的数据（类似并行的概念） 电路交换会有静默期，也即建立了电路之后不传播信息，可能会引发资源浪费，但是电路交换的端到端时延与链路数量无关（在路由器处无需等待） 通常情况下，分组交换的效率会优于电路交换 网络的网络 此节讨论我们怎么能够使用网络资源，也即因特网的结构（发展动力主要是商业竞争） 网络结构111：一个单一的全球ISP互联所有接入ISP，所有的客户直接向该全球ISP付费 网络结构222：多个全球ISP，全球ISP之间是互联的，用户可以向性价比最高的全球ISP付费 网络结构333：有区域ISP，ISP按照层级高低分为接入、区域、第一层（全球传输），低层需要向直接连接的高层付费 网络结构444：在结构333的基础上增加了PoP、多宿，对等与IXP PoP：提供商网络中位于相同位置的一组路由器，客户ISP可以通过其与提供商ISP相连接 多宿：任何非顶层ISP可以与多台上游ISP相连接 对等：同层的相邻ISP之间直接连接，无需通过上游ISP进行中转，通常对等无需付费 IXP：可以使得多个ISP一起对等，类似于一个中转站 网络结构555：在网络结构444的基础上增加了内容提供商网络，更多的用于直接与较低层的ISP互联，避免由于中间ISP的收费 时延、丢包与吞吐量 时延 delay=dproc+dqueue+dtrans+dpropdelay = d_{proc} + d_{queue} + d_{trans} + d_{prop} delay=dproc​+dqueue​+dtrans​+dprop​ 处理时延：检查数据是否有错，决定输出链路等，数量级为μs\\mu sμs 排队时延：在输出队列中等待的时间，取决于网络拥塞程度，数量级为ms−μsms-\\mu sms−μs 传输时延：将数据从路由器传输到链路的时间，数量级在ms−μsms-\\mu sms−μs 传播时延：数据在链路上传播的时间，通常很小（传播速率在108m/s10^8m/s108m/s量级），但是在长距离传播中需要考虑 排队时延和丢包 流量强度定义为 ti=LaRti=\\frac{La}{R} ti=RLa​ 其中，aaa代表数据到达队列的平均速率，LLL代表分组的平均比特数，ti→0ti\\rightarrow 0ti→0时排队时延很小，ti→1−ti\\rightarrow 1^-ti→1−时排队时延很大，ti&gt;1ti&gt;1ti&gt;1的时候排队时延无界 当ti≤1ti\\leq 1ti≤1的时候，分组到达的方式（周期性或突发性等）将会影响排队时延 当路由器的输出队列已满时，新进入的分组会被丢弃，称为丢包 端到端时延 dend−end=N(dproc+dtrans+dprop)d_{end-end} = N(d_{proc} + d_{trans} + d_{prop}) dend−end​=N(dproc​+dtrans​+dprop​) 其中 dtrans=LRd_{trans} = \\frac{L}{R} dtrans​=RL​ 这个式子假设了网络是畅通的 吞吐量 定义：主机接受文件的速率，分为瞬间吞吐量与平均吞吐量 瓶颈链路：指平均传输速率最小的一条链路，限制了整个网络的吞吐量 上述的平均指的是，分配给每条链路的传输速率，例如一条速率为100Mbps的高速链路，需要同时承担100010001000个客户-服务器的通信，那平均速率将会降至100kbps，有可能成为瓶颈链路 协议层次及其服务模型 分层的体系结构 协议分层 为了更好的结构化与模块化，网络以分层的方式组织协议与硬软件，每一层通过在该层中执行动作或使用直接下层的服务来提供服务。 各层的所有协议被称为协议栈，因特网的协议栈自顶向下为应用层，运输层，网络层，链路层，物理层 应用层：网络应用程序以及其应用层协议存留的地方，其中的信息分组称为报文。应用层提供了许多协议，如： HTTP：Web文档协议 SMTP：电子邮件报文协议 FTP：端系统协议 DNS：域名系统协议 运输层：用于在应用程序端点之间传送应用层报文，有两种运输协议：TCP, UDP，其中TCP提供了截断机制与拥塞控制机制。运输层的分组称为报文段 网络层：分组称为数据报，网络层负责将数据报从一台主机移动到另一台主机，网际协议包括IP，其定义了数据报中的各个字段以及端、路由器如何作用在这些字段上 链路层：在节点之间传递数据，每个节点的网络层将数据下放给链路层，传递至下一个节点之后再上传至网络层。如以太网、WiFi、电缆接入网的DOCSIS协议，其中的分组称为帧 物理层：在物理层面上将帧中的比特移到下一个节点，每一种链路层中包括很多物理层协议，与实际的物理媒介有关 OSI模型 777层分层，包括应用层、表示层、会话层、运输层、数据链路层、物理层。 表示层用于将交换的数据可以被应用程序解释，会话层提供了数据交换的定界和同步功能，包括检查与恢复等 封装 每一层会将来自上一层的数据进行封装，也即附加一些首部信息，包括一些权限信息以及检测信息等，引测，每一层的分组都有两种字段，首部字段和有效载荷字段 坏家伙 危害终端设备 坏家伙将恶意软件植入设备中，并利用僵尸网络（被控制的主机）展开攻击，从而实现自我复制。恶意软件分为病毒与蠕虫两类： 病毒：需要用户交互来感染用户设备的恶意软件 蠕虫：无需用户交互即可进入设备 危害服务器和网络设施 拒绝服务攻击，也即DoS, 包括以下三种： 弱点攻击：攻击不完备的应用或操作系统 带宽洪泛：往目标发送大量分组，例如DDoS通过大量源向目标发送分组造成目标瘫痪 连接洪泛：在目标中创建大量的半开或全开TCP连接 嗅探分组：在传输分组时，精心布置的被动接收机可以得到传输信息的副本，并且由于其不会注入信息，所以很难被检测出来，这种接收机被称为分组嗅探器 身份伪装：通过IP哄骗，向目标发送具有恶意的信息","tags":["笔记","网原","概要"],"categories":["计算机网络原理"]},{"title":"Hexo + Stellar","path":"/2024/05/07/Hexo初探/","content":"终于弄好了www 经过一天的不懈奋斗，在经过了jekyll配置环境的痛苦折磨之后，最后选择了用hexo+github pages配置，hexo是一款静态博客工具，使用起来比较简单，指比让从来没有配过ruby的我去弄明白jekyll简单多了！ 配置方法 新建github仓库，名为&lt;username&gt;.github.io，这个是后来访问用的 回到本地命令行（笔者用的是wsl）123456npm install -g hexo-clisudo npm install -g hexo-cli (Mac) # 据说Mac得这么干cd AN-EMPTY-FLRODER # 进入你想放置的本地文件夹 一定要是空的！hexo init # 初始化hexo内容npm install # 下载配置npm install hexo-deployer-git --save # 下载部署工具 此时环境基本配置完毕了，开始修改配置，打开_config.yml，将其Deployment部分改为1234deploy: type: git repository: git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git branch: main 部署准备完成1hexo g -d # 生成页面并部署 此时可以访问https://&lt;username&gt;.github.io访问自己的博客！ 操作方法 12345678hexo new &quot;name&quot; # 新建文章hexo new page &quot;name&quot; # 新建页面hexo g # 生成页面hexo d # 部署hexo g -d # 生成页面并部署hexo s # 本地预览hexo clean # 清除缓存和已生成的静态文件hexo help # 帮助 更换主题 进入网站https://hexo.io/themes/可以选择主题，挑选好后进行配置，配置方法为在博客根目录.下执行如下命令： 1git clone THEME-REPO themes/&lt;theme-name&gt; 例如本博客使用的是stellar主题，执行命令为： 1git clone git@github.com:xaoxuu/hexo-theme-stellar.git themes/stellar 下载好后，在./_config.yml下修改theme的内容为你想要的即可 致谢 https://zhuanlan.zhihu.com/p/60578464 Debug TypeError: Cannot read properties of null (reading 'utcOffset') 时区设置错误，允许的中国时区只有Asia/Harbin,Asia/Shanghai,Asia/Chongqing,Asia/Urumqi,Asia/Kashgar 无法生成.html文件 检查themes下的文件名和配置文件中的是否相同，如果相同尝试先clean再重新创建，如果还是不行则直接重新clone一下主题库（原因未知） 行内公式无法渲染 更换md渲染器，并添加Katex支持，方法为：123npm un hexo-renderer-marked --savenpm i hexo-renderer-markdown-it --savenpm i @traptitech/markdown-it-katex --save 并在_config.yml中加入（注意缩进）：123456789101112131415161718markdown: preset: &#x27;default&#x27; render: html: true xhtmlOut: true breaks: true langPrefix: &#x27;language-&#x27; linkify: true typographer: true quotes: &#x27;“”‘’&#x27; plugins: - plugin: name: &#x27;@traptitech/markdown-it-katex&#x27; options: # see https://katex.org/docs/options.html blockClass: &quot;math-block&quot; strict: false throwOnError: false errorColor: &quot;#cc0000&quot; 单纯做了上面的操作之后会出现行内数字/字母重复渲染的现象，也即一遍纯文本一遍公式文本，例如’ISP’会被渲染成’ISPISPISPISP’ 在文章头部加上katex: true即可 静态图片问题 使用相对于source文件夹的绝对路径，例如/assets/...代表存在/blog/sources/assets/...下，这样在本地md可能显示会有问题，但是stellar可以正常生成"},{"title":"杂记","path":"/freenotes/index.html","content":"本文会记录一些平常开发过程中遇到的小小问题 CLion相关问题 Too many errors emitted, stopping now 在配置HUADB项目的时候，发现CLion无法在项目里进行自动补全，仔细看代码发现在所有cpp文件的第一个token之前会有一个红色波浪线，报错为Too many errors emitted, stopping now. 遂懵逼 查阅了很久资料之后没有找到可用的东西，但是发现网上的帖子都是集中于在make过程中发现有很多很多明显的报错，而我并没有在CLion中主动进行make操作，于是寻找CLion的自动cmake，发现其尝试使用windows下的cmake编译wsl下面的项目（我把HUADB直接放在了wsl下面），怀疑是这个原因，于是修改： 在Setting -&gt; Build, Execution, Deployment -&gt; Toolchain中，点击+添加WSL CMake，等待其自动检测成功 在Setting -&gt; Build, Execution, Deployment -&gt; CMake中，将Toolchain修改为WSL，等待再次编译即可 WSL配置Chrome环境 在wsl环境下进行一些Web相关的开发时需要使用chrome来进行，因此我们需要在其中安装chrome浏览器，总结出可行的步骤如下： 换源，否则在apt install的时候会出现404的错误，以更换清华源为例，具体方法为： 进入/etc/apt文件夹，保存一份source.list的副本（副本名字任取）： $ cd /etc/apt &amp;&amp; cp ./source.list ./source.copy.list lsb_release -a查看wsl版本相关信息 前往清华镜像源网址 找到自己对应的版本格式对应的镜像信息，例如本人是Ubuntu 22.04 LTS(jammy) 利用vim等工具将source.list中的内容修改为清华镜像的内容 更新apt： $ sudo apt-get upgrade 进入想要安装的目录，依次执行： 123$ wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb$ sudo apt install --fix-broken -y$ sudo dpkg -i google-chrome-stable_current_amd64.deb 使用google-chrome --version确认已安装成功 参考资料：https://blog.csdn.net/m0_63834988/article/details/135044587https://blog.csdn.net/m0_63834988/article/details/135044587 https://blog.csdn.net/Jason_Todd/article/details/125479130https://blog.csdn.net/Jason_Todd/article/details/125479130 尚未解决的问题 无法显示中文 谷歌搜索不能进行（代理？ 会报一些关于dbus的错误，例如Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are &quot;tcp&quot; and on UNIX &quot;unix&quot;)等等比较多的 用windows吧 Latex使用问题记录 minipage 如果想让多个minipage在水平方向上排列，则需要所有组件水平方向上的宽度之和小于\\linewidth vscode 编译Beamer的时候vscode有的情况下会出现一些奇怪的问题，例如和lstlisting不兼容，但是关机重启之后就能编译过了（不能理解 verb 在写Beamer的时候，在一个frame里面如果想使用\\verb命令的话需要在\\begin&#123;frame&#125;后加上选项[fragile] 蓝屏问题 在 2025 年 4 月 1 日，本人第一台自己买的电脑机械革命蛟龙 16 pro 到达，配置为： 32 GB + 1TB (+ 1TB) AMD R7 7435H RTX4060 详细配置为（超长警告）： CPU1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Address sizes: 48 bits physical, 48 bits virtual Byte Order: Little EndianCPU(s): 16 On-line CPU(s) list: 0-15Vendor ID: AuthenticAMD Model name: AMD Ryzen 7 7435H CPU family: 25 Model: 68 Thread(s) per core: 2 Core(s) per socket: 8 Socket(s): 1 Stepping: 1 BogoMIPS: 6188.21 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscal l nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl tsc_reliable nonstop_tsc cpuid extd_apici d pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_ legacy svm cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext perfctr_core ssbd ibrs ibpb stibp vm mcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xget bv1 xsaves clzero xsaveerptr arat npt nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload umip vaes vpclmulqdq rdpid fsrmVirtualization features: Virtualization: AMD-V Hypervisor vendor: Microsoft Virtualization type: fullCaches (sum of all): L1d: 256 KiB (8 instances) L1i: 256 KiB (8 instances) L2: 4 MiB (8 instances) L3: 16 MiB (1 instance)Vulnerabilities: Gather data sampling: Not affected Itlb multihit: Not affected L1tf: Not affected Mds: Not affected Meltdown: Not affected Mmio stale data: Not affected Reg file data sampling: Not affected Retbleed: Not affected Spec rstack overflow: Mitigation; safe RET Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp Spectre v1: Mitigation; usercopy/swapgs barriers and __user pointer sanitization Spectre v2: Mitigation; Retpolines; IBPB conditional; IBRS_FW; STIBP always-on; RSB filling; PBRSB-eIBRS Not affected; BHI Not affected Srbds: Not affected Tsx async abort: Not affected内存12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758BankLabel=P0 CHANNEL ACapacity=17179869184DataWidth=64Description=Physical MemoryDeviceLocator=DIMM 0FormFactor=12HotSwappable=InstallDate=InterleaveDataDepth=InterleavePosition=Manufacturer=CrucialMemoryType=0Model=Name=Physical MemoryOtherIdentifyingInfo=PartNumber=CT16G48C40S5.C8A1PositionInRow=PoweredOn=Removable=Replaceable=SerialNumber=E930E2B6SKU=Speed=4800Status=Tag=Physical Memory 0TotalWidth=64TypeDetail=16512Version=BankLabel=P0 CHANNEL BCapacity=17179869184DataWidth=64Description=Physical MemoryDeviceLocator=DIMM 0FormFactor=12HotSwappable=InstallDate=InterleaveDataDepth=InterleavePosition=Manufacturer=Micron TechnologyMemoryType=0Model=Name=Physical MemoryOtherIdentifyingInfo=PartNumber=CT16G48C40S5.M8A1PositionInRow=PoweredOn=Removable=Replaceable=SerialNumber=E978ADEBSKU=Speed=4800Status=Tag=Physical Memory 1TotalWidth=64TypeDetail=16512Version=磁盘12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394Availability=BytesPerSector=512Capabilities=&#123;3,4&#125;CapabilityDescriptions=&#123;&quot;Random Access&quot;,&quot;Supports Writing&quot;&#125;CompressionMethod=ConfigManagerErrorCode=0ConfigManagerUserConfig=FALSEDefaultBlockSize=Description=Disk driveDeviceID=\\\\.\\PHYSICALDRIVE0ErrorCleared=ErrorDescription=ErrorMethodology=Index=0InstallDate=InterfaceType=SCSILastErrorCode=Manufacturer=(Standard disk drives)MaxBlockSize=MaxMediaSize=MediaLoaded=TRUEMediaType=Fixed hard disk mediaMinBlockSize=Model=ZHITAI Ti600 1TBName=\\\\.\\PHYSICALDRIVE0NeedsCleaning=NumberOfMediaSupported=Partitions=1PNPDeviceID=SCSI\\DISK&amp;amp;VEN_NVME&amp;amp;PROD_ZHITAI_TI600_1TB\\5&amp;amp;142FA3BA&amp;amp;0&amp;amp;000000PowerManagementCapabilities=PowerManagementSupported=SCSIBus=0SCSILogicalUnit=0SCSIPort=0SCSITargetId=0SectorsPerTrack=63Signature=Size=1000202273280Status=OKStatusInfo=SystemName=YWANG22TotalCylinders=121601TotalHeads=255TotalSectors=1953520065TotalTracks=31008255TracksPerCylinder=255Availability=BytesPerSector=512Capabilities=&#123;3,4&#125;CapabilityDescriptions=&#123;&quot;Random Access&quot;,&quot;Supports Writing&quot;&#125;CompressionMethod=ConfigManagerErrorCode=0ConfigManagerUserConfig=FALSEDefaultBlockSize=Description=Disk driveDeviceID=\\\\.\\PHYSICALDRIVE1ErrorCleared=ErrorDescription=ErrorMethodology=Index=1InstallDate=InterfaceType=SCSILastErrorCode=Manufacturer=(Standard disk drives)MaxBlockSize=MaxMediaSize=MediaLoaded=TRUEMediaType=Fixed hard disk mediaMinBlockSize=Model=CT1000E100SSD8Name=\\\\.\\PHYSICALDRIVE1NeedsCleaning=NumberOfMediaSupported=Partitions=3PNPDeviceID=SCSI\\DISK&amp;amp;VEN_NVME&amp;amp;PROD_CT1000E100SSD8\\5&amp;amp;1B5F0352&amp;amp;0&amp;amp;000000PowerManagementCapabilities=PowerManagementSupported=SCSIBus=0SCSILogicalUnit=0SCSIPort=1SCSITargetId=0SectorsPerTrack=63Signature=Size=1000202273280Status=OKStatusInfo=SystemName=YWANG22TotalCylinders=121601TotalHeads=255TotalSectors=1953520065TotalTracks=31008255TracksPerCylinder=255 在两个月的时间内，这台电脑表现良好，威风凛凛，就是开狂暴模式打大表哥2太吵了，然而从 6 月份以来，这台电脑频繁出现蓝屏问题，我所记得的错误码包括： KERNEL_SECURITY_CHECK_FAILED KERNEL_MODE_HEAP_CORRUPTION MEMORY_MANAGEMENT SYSTEM_SERVICE_EXCEPTION PAGE_FAULT_IN_NONPAGED_AREA DRIVER_OVERRAN_STACK_BUFFER IRQL_NOT_LESS_OR_EQUAL UNEXPECTED_KERNEL_MODE_TRAP HYPERVISOR_ERROR 出现蓝屏非常随机，在打游戏、工作、发呆等等时候都出现过（不过打游戏的时候出现的最多），现记录一下我用过的所有方法以及查到的东西： 修复磁盘 12sfc /scannow # 修复系统文件chkdsk c: /f # 检查 C 盘上的错误 等了很久，结果开机半小时就蓝了 重装驱动 由于有一次通过 windbg 查出来发现是 nvidia 的驱动导致的蓝屏，于是重装了显卡驱动 但是我怀疑不是它的问题，我在买回电脑之后装的驱动就没有更新过，而且重装之后仍然会有这个问题） 降性能 主要是限制电源性能，再加之降频，目前看来一切安好 首先需要修改注册表，打开处理器最大频率设置开关 在注册表中定位到 1计算机\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Power\\PowerSettings\\54533251-82be-4824-96c1-47b60b740d00\\75b0ae3f-bce0-45a7-8c89-c9611c25e100 之后修改其中 Attributes = 2，默认值应该是 1 打开电源设置（徽标键搜索编辑电源选项）之后，更改高级电源设置，之后将 最大处理器状态 修改为 99%，处理器最大频率 修改为 4000，如下图： 注意： 不修改注册表是没有 处理器最大频率 这一项的 处理器最大频率如果是 0 则代表无限制，我也不知道得改成多少就把接通电源改成和使用电池一样了 物理修复 还找到了一篇博客说的是紧了主板螺丝就好了，还没尝试，但是如果真是这个原因我就生气生气生气 最终解决 保修换了个主板嘿嘿嘿"},{"title":"关于","path":"/about/index.html","content":"欢迎来到我的个人博客！本人为清华大学计算机系二字班学生，第一次尝试写博客还请大家多多担待噢~ 这里主要想写一写平时学习中遇到的笔记和内容，也方便统一管理一些，当然以后也会有可能有一些随笔和杂谈之类的"}]