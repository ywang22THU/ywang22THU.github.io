[{"title":"TCS-Lecture-C","path":"/2024/05/22/TCS-Lecture-C/","content":"TCS: Pseudorandomness and Private-Key Encryption Pseudorandomness and Private-Key Encryption Private-Key Encryption This encryption(加密) problem is starting form the transmission question: two people need to transmit information while avoiding others to know the content. The resolution is to maintain a ‘key’ kkk by two people and one can use kkk to encrypt information while the other can use it to decrypt Validity A pair of polynomial-time computable functions (Enc,Dec)(\\text{Enc}, \\text{Dec})(Enc,Dec) is a valid private key encryption scheme if for every n∈Nn\\in \\mathbb{N}n∈N, k∈{0,1}nk\\in \\{0, 1\\}^{n}k∈{0,1}n,and xxx, we haveDec(k,Enc(k,x))=x \\text{Dec}(k, \\text{Enc}(k, x)) = xDec(k,Enc(k,x))=x And we have the length of the ciphertext(密文) is no less than that of the plaintext, written as: lc(n)≥lp(n)l_{c}(n) \\geq l_{p}(n) lc​(n)≥lp​(n) Security We need to define the security with following assumption: A cryptosystem should be secure even if everything about the system, except the key, is public knowledge. Due to this assumption, the kkk must be generated randomly. So, let’s define the security: A valid encryption scheme (Enc,Dec)(\\text{Enc}, \\text{Dec})(Enc,Dec) with plaintext length l(⋅)l(\\cdot)l(⋅) is perfectly secret if for every n∈Nn\\in \\mathbb{N}n∈N and plaintexts x0,x1∈{0,1}l(n)x_{0}, x_{1} \\in \\{0, 1\\}^{l(n)}x0​,x1​∈{0,1}l(n), the following two distributions Y0Y_{0}Y0​and Y1Y_{1}Y1​ over {0,1}∗\\{0, 1\\}^{*}{0,1}∗ are identical:YiY_{i}Yi​ is obtained by sampling kkk and outputting Enc(k,xi)\\text{Enc}(k, x_{i})Enc(k,xi​) for i=0,1i = 0, 1i=0,1. Definition Analysis We have a secrecy experiment as follows: Sample k∈{0,1}nk \\in \\{0, 1\\}^{n}k∈{0,1}n Adversary A\\mathcal{A}A outputs x0,x1x_{0}, x_{1}x0​,x1​ given input 1n1^{n}1n Randomly choose bbb and send y=Enc(k,xb)y = \\text{Enc}(k, x_{b})y=Enc(k,xb​) to A\\mathcal{A}A A\\mathcal{A}A returns b′∈{0,1}b&#x27;\\in\\{0, 1\\}b′∈{0,1} If b=b′b = b&#x27;b=b′, A\\mathcal{A}A wins We can prove A\\mathcal{A}A has at most 12\\frac{1}{2}21​ probability to succeed under perfectly secret. P(Y=y ∣ b=i)=P(Yi=y)=p(y)\\begin{align*} P(Y = y\\,|\\, b = i) &amp;= P(Y_{i} = y) = p(y)\\end{align*}P(Y=y∣b=i)​=P(Yi​=y)=p(y)​And P(Y=y)=p(y)P(Y = y) = p(y)P(Y=y)=p(y) due to YYY is perfect, so:P(Y=y,b=i)=P(b=i)P(Y=y ∣ b=i)=P(b=i)p(y)=P(b=i)P(Y=y)\\begin{align*} P(Y = y, b = i) &amp;= P(b = i)P(Y = y \\,|\\, b = i) \\\\ &amp;= P(b = i)p(y) \\\\ &amp;= P(b = i)P(Y = y)\\end{align*}P(Y=y,b=i)​=P(b=i)P(Y=y∣b=i)=P(b=i)p(y)=P(b=i)P(Y=y)​This means YYY is independent to bbb, so A\\mathcal{A}A cannot improve its probability to win by getting yyy Construction Give the One-time pad construction: lp(n)=lc(n)=nEnc(k,x)=x⊕kDec(k,c)=k⊕c\\begin{align*} l_{p}(n) = l_{c}&amp;(n) = n \\\\ \\text{Enc}(k, x) &amp;= x \\oplus k \\\\ \\text{Dec}(k, c) &amp;= k \\oplus c\\end{align*}lp​(n)=lc​Enc(k,x)Dec(k,c)​(n)=n=x⊕k=k⊕c​ In this construction, we have one glaring dis advantage, that is the kkk has the same length of plaintext! This is necessary for perfect secrecy: For every perfectly secret encryption scheme, the length function lp(n)l_{p}(n)lp​(n) satisfies lp(n)≤nl_{p}(n)\\leq nlp​(n)≤n Computational Secrecy and PRG The long kkk is unadorable in reality. So we use computational secrecy instead. An encryption scheme is computationally secret if no probabilistic polynomial-time(PPT) algorithms can break it. Let Enc,Dec\\text{Enc}, \\text{Dec}Enc,Dec be a valid encryption scheme. The scheme is computationally secret if, for every PPT adversary algorithm A\\mathcal{A}A in the secrecy experiment, there is negligible function negl\\text{negl}negl such thatP(A succ)≤12+negl(n) P(\\mathcal{A} \\text{ succ}) \\leq \\frac{1}{2} + \\text{negl}(n)P(A succ)≤21​+negl(n)where the probability is taken over the randomness of A\\mathcal{A}A and the experiment. Pseudorandom Generators Definition: A cryptographic pseudorandom generator (PRG) with stretch l(⋅)l(\\cdot)l(⋅) is a PPT computable function G:{0,1}∗→{0,1}∗G: \\{0, 1\\}^{*} \\to \\{0, 1\\}^{*}G:{0,1}∗→{0,1}∗ such that:∀ n∈N\\forall \\, n\\in \\mathbb{N}∀n∈N and s∈{0,1}ns\\in \\{0, 1\\}^{n}s∈{0,1}n, ∣G(s)∣=l(n)|G(s)| = l(n)∣G(s)∣=l(n)For any poly-algorithm A\\mathcal{A}A, s∈{0,1}ns\\in \\{0, 1\\}^{n}s∈{0,1}n and r∈{0,1}l(n)r\\in \\{0, 1\\}^{l(n)}r∈{0,1}l(n):∣P(A((G(s)))=1)−P(A((r))=1)∣=negl(n) |{P (\\mathcal{A}((G(s))) = 1) - P (\\mathcal{A}((r)) =1)}| = \\text{negl}(n)∣P(A((G(s)))=1)−P(A((r))=1)∣=negl(n) Intuitively, this means we can get the difference between output of PRG G(⋅)G(\\cdot)G(⋅) and a actual random output rrr in a negligible probability. Its existance is obtained by the cryptographic PRG conjecture: PRG with l(n)=na∀a∈Nl(n) = n^{a}\\quad \\forall a\\in\\mathbb{N}l(n)=na∀a∈N exists. If the cryptographic PRG conjecture is true, then computationally secret encryption exists for l(n)≥na∀a∈Nl(n) \\geq n^{a}\\quad \\forall a\\in\\mathbb{N}l(n)≥na∀a∈N Enc(k,x)=x⊕G(k)Dec(c,k)=c⊕G(k)\\begin{align*} \\text{Enc}(k, x) &amp;= x \\oplus G(k) \\\\ \\text{Dec}(c, k) &amp;= c \\oplus G(k)\\end{align*}Enc(k,x)Dec(c,k)​=x⊕G(k)=c⊕G(k)​ This can be proved to be computation secret by contradiction proof, which is to construct a adversary for PRG by the assuming contradiction. CPA Security and PRF Choose Plaintext Attack (CPA) The CPA experiments is similar to secrecy experiments, while A\\mathcal{A}A can interact freely with Enc(k,⋅)\\text{Enc}(k, \\cdot)Enc(k,⋅) as a black-box. An encryption scheme (Enc,Dec)(\\text{Enc}, \\text{Dec})(Enc,Dec) is CPA-secure if, for all PPT adversary A\\mathcal{A}A, there exists a negligible function negl\\text{negl}negl such thatP(A succ)≤12+negl(n) P(\\mathcal{A} \\text{ succ}) \\leq \\frac{1}{2} + \\text{negl}(n)P(A succ)≤21​+negl(n) All CPA-secure encryption scheme must be probabilistic otherwise A\\mathcal{A}A can query all Enc(k,x)\\text{Enc}(k, x)Enc(k,x) to get ciphertexts and compare. Pseudorandom Functions (PRF) Consider a keyed family of functions: Fk:{0,1}∗→{0,1}∗F_{k}: \\{0, 1\\}^{*} \\to \\{0, 1\\}^{*}Fk​:{0,1}∗→{0,1}∗, then we can define PRF as follows: Let FkF_{k}Fk​ be a keyed family of functions that is efficient and length-preserving. We say FkF_{k}Fk​ is a pseudorandom function if, for all PPT distinguishers D\\mathcal{D}D, there exists a negligible function negl\\text{negl}negl such that:∣P(DFk(⋅)(1n)=1)−P(Dfn(⋅)(1n)=1)∣≤negl(n) |{P \\bigl( D^{F_k(\\cdot)}(1^n) = 1 \\bigr) - P \\bigl( D^{f_n(\\cdot)}(1^n) = 1 \\bigr)}| \\le \\text{negl}(n)∣P(DFk​(⋅)(1n)=1)−P(Dfn​(⋅)(1n)=1)∣≤negl(n)where k←{0,1}nk\\gets\\{0, 1\\}^{n}k←{0,1}n is chosen uniformly at random and fnf_{n}fn​ is chosen uniformly from the set of functions mapping nnn-bit strings to nnn-bit strings. Intuitively, this means we can get the difference between PRF Fk(⋅)F_{k}(\\cdot)Fk​(⋅) and a actual random funtions fff in a negligible probability. PRF =&gt; CPA-secure Encryption Let FFF be a PRF. Define a CPA-secuee private-key encryption scheme for messages of length nnn as follows: Enc(k,x)=⟨r,Fk(r)⊕x⟩\\text{Enc}(k, x) = \\langle r, F_{k}(r)\\oplus x \\rangleEnc(k,x)=⟨r,Fk​(r)⊕x⟩Dec(k,⟨r,s⟩)=Fk(r)⊕s\\text{Dec}(k, \\langle r, s\\rangle) = F_{k}(r) \\oplus sDec(k,⟨r,s⟩)=Fk​(r)⊕sIn this r←{0,1}nr\\gets\\{0, 1\\}^{n}r←{0,1}n is randomly chosen. Proof is as follows, we use contradiction-proof and construct a contradiction to PRF with assumption. Consider above scheme as Π=(Enc,Dec)\\Pi = (\\text{Enc}, \\text{Dec})Π=(Enc,Dec) and the similar scheme Π~=(Enc~,Dec~)\\widetilde{\\Pi} = (\\widetilde{\\text{Enc}}, \\widetilde{\\text{Dec}})Π=(Enc,Dec) in which we replace FkF_{k}Fk​ with an actual random function.Assume that Π\\PiΠ is not CPA-secure, which means there exists an A\\mathcal{A}A:P(AΠ succ)≥12+1poly(n)P(\\mathcal{A}_{\\Pi}\\text{ succ}) \\geq \\frac{1}{2} + \\frac{1}{\\text{poly}(n)}P(AΠ​ succ)≥21​+poly(n)1​Let rcr_{c}rc​ represents the randomness used in encrypting xxx, while r1,…,rqr_{1}, \\dots, r_{q}r1​,…,rq​ represents the q(n)=poly(n)q(n) = \\text{poly}(n)q(n)=poly(n) randomness used when A\\mathcal{A}A queries to the oracle Enc\\text{Enc}Enc.Then we can argue that:P(AΠ~ succ)≤12+negl(n)P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}) \\leq \\frac{1}{2} + \\text{negl}(n) P(AΠ​ succ)≤21​+negl(n)We can argue this according to whether rc∈{r1,…,rq}r_{c} \\in \\{r_{1},\\dots ,r_{q}\\}rc​∈{r1​,…,rq​}If rc∈{r1,…,rq}r_{c} \\in \\{r_{1},\\dots ,r_{q}\\}rc​∈{r1​,…,rq​}, then A\\mathcal{A}A can actually get rcr_{c}rc​ as we contain it in the ciphertext. So A\\mathcal{A}A can always succeed in this case.But this case has a negligible probability q(n)2n\\frac{q(n)}{2^{n}}2nq(n)​ to appear.If rc∉{r1,…,rq}r_{c} otin \\{r_{1},\\dots ,r_{q}\\}rc​∈/{r1​,…,rq​}, then the encryption is like a perfect OTP as we cannot get any information about the random function fff. So A\\mathcal{A}A has a probability of 12\\frac{1}{2}21​ to win.So, we have that:P(AΠ~ succ)=P(AΠ~ succ ∣∈)P(∈)+P(AΠ~ succ ∣∉)P(∉)≤q(n)2n+12=12+negl(n)\\begin{align*}P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}) &amp;= P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}\\,|\\in)P(\\in) + P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ}\\,| otin)P( otin) \\\\&amp;\\leq \\frac{q(n)}{2^{n}} + \\frac{1}{2} = \\frac{1}{2} + \\text{negl}(n)\\end{align*}P(AΠ​ succ)​=P(AΠ​ succ∣∈)P(∈)+P(AΠ​ succ∣∈/)P(∈/)≤2nq(n)​+21​=21​+negl(n)​Define the distinguisher D\\mathcal{D}D, who has an orecal O\\mathcal{O}O, as follows:Run A(1n)\\mathcal{A}(1^{n})A(1n), for each oracle query of A\\mathcal{A}A with xxx, do:Choose r←{0,1}nr\\gets \\{0, 1\\}^{n}r←{0,1}nreturn ⟨r,O(r)⊕x⟩\\langle r, \\mathcal{O}(r)\\oplus x\\rangle⟨r,O(r)⊕x⟩ to A\\mathcal{A}AWhen A\\mathcal{A}A gives D\\mathcal{D}D two string x0,x1x_{0}, x_{1}x0​,x1​, randomly choose a bit bbb and:Choose r←{0,1}nr\\gets \\{0, 1\\}^{n}r←{0,1}nreturn ⟨r,O(r)⊕xb⟩\\langle r, \\mathcal{O}(r)\\oplus x_{b}\\rangle⟨r,O(r)⊕xb​⟩ to A\\mathcal{A}AAnswer A\\mathcal{A}A as Step 1 until A\\mathcal{A}A gives an output b′b&#x27;b′. Then we output 111 if b′=bb&#x27; = bb′=b otherwise 000.Actually, this distinguisher is simulating the CPA-experiment. So:P(DFk(⋅)(1n)=1)=P(AΠ succ)P(Df(⋅)(1n)=1)=P(AΠ~ succ)\\begin{align*}P(\\mathcal{D}^{F_{k}(\\cdot)}(1^{n}) = 1) &amp;= P(A_{\\Pi}\\text{ succ}) \\\\P(\\mathcal{D}^{f(\\cdot)}(1^{n}) = 1) &amp;= P(A_{\\widetilde{\\Pi}}\\text{ succ})\\end{align*}P(DFk​(⋅)(1n)=1)P(Df(⋅)(1n)=1)​=P(AΠ​ succ)=P(AΠ​ succ)​This means that:∣P(DFk(⋅)(1n)=1)−P(Df(⋅)(1n)=1)∣=∣P(AΠ succ)−P(AΠ~ succ)∣≥∣1poly(n)−negl(n)∣≥1poly(n)\\begin{align*}&amp;\\quad |P(\\mathcal{D}^{F_{k}(\\cdot)}(1^{n}) = 1) -P(\\mathcal{D}^{f(\\cdot)}(1^{n}) = 1)| \\\\&amp;= |P(\\mathcal{A}_{\\Pi}\\text{ succ}) - P(\\mathcal{A}_{\\widetilde{\\Pi}}\\text{ succ})| \\\\&amp;\\geq |\\frac{1}{\\text{poly}(n)} - \\text{negl}(n)| \\geq \\frac{1}{\\text{poly}(n)}\\end{align*}​∣P(DFk​(⋅)(1n)=1)−P(Df(⋅)(1n)=1)∣=∣P(AΠ​ succ)−P(AΠ​ succ)∣≥∣poly(n)1​−negl(n)∣≥poly(n)1​​This is contradict to that FkF_{k}Fk​ is PRF!","tags":["Pseudorandomness","Private-Key Encryption","TCS"],"categories":["理论计算机科学导引"]},{"title":"网原笔记6","path":"/2024/05/22/网原笔记6/","content":"计算机网络原理 笔记 6 链路层与局域网 链路层 运行链路层协议的任何设备称为节点，相邻节点的通信信道称为链路，在链路上传递的数据报被封装为链路层帧 可能提供的服务 成帧：将网络层数据添加一些首部字段封装为链路层帧 链路接入：由MAC规定了帧在链路上的传输规则 可靠交付：保证无差错地传递网络层数据报，但是对于部分低比特差错链路，可靠性是不必要的 差错检测和纠正：由于硬件设备原因可能会导致部分比特被错误传输，因此可以在帧中包含相应差错检测/纠正比特来检测 实现 通常通过网络适配器（又称为网络接口卡）来实现 网络适配器 差错检测与纠正 接收方需要判断接收到的数据是否是原始数据，通常通过EDC来实现，但是需要注意的是EDC本身也有可能被损坏，并且即使使用了EDC也可能出现漏检的情况 差错检测与纠正 常见的EDC方法包括奇偶校验、检验和与循环冗余检测 奇偶校验 增加一位校验位，用于指示原始数据中’1’的个数的奇偶性，但是这只能判断出数据中出现了奇数个比特差错 为了提升其鲁棒性，采用二维奇偶校验的方式，即将原始数据划分为一个矩阵，分别检测每一行与每一列的奇偶校验和，这样可以检测并纠正单个比特差错，并且可以检测双比特差错 二维奇偶校验 检验和 与运输层协议中内容相似，将数据按字节求和取反码 循环冗余检测 现代广泛使用CRC编码，主要思想为将数据流看做系数为0, 1的多项式 CRC编码 如上图，编码操作为： 发送方与接收方协商r+1r+1r+1位比特模式作为生成多项式，记为GGG，要求GGG的最高位必须是1 对于数据段DDD，发送方将其附加rrr个比特RRR，得到d+rd+rd+r位比特模式，使其可以被GGG整除 接收方检测是否可以整除即可 因此关键问题在于如何选取RRR使得： (D&lt;&lt;r)⊕R=nG (D &lt;&lt; r) \\oplus R = nG (D&lt;&lt;r)⊕R=nG 该式可化简为： D&lt;&lt;r=nG⊕R D &lt;&lt; r = nG \\oplus R D&lt;&lt;r=nG⊕R 在CRC中，所有的加法和减法都等价于异或操作，因此乘法和出发需要对应的变化（竖式中的加减法也变成了异或） 因此，可以计算RRR为： R=(D&lt;&lt;r)(modG) R = (D &lt;&lt; r) \\pmod{G} R=(D&lt;&lt;r)(modG) 国际标准的生产多项式为： GCRC-32=10000001001100000010001110110110111 G_{\\text{CRC-32}} = 10000001001100000010001110110110111 GCRC-32​=10000001001100000010001110110110111 多路访问链路和协议 由于所有的节点都可以传输帧，因此同时被接收的信号会在接收方处发生碰撞，导致所有信号丢失，因此需要多路访问协议用于协调多个发送和接收节点共享一个信道的访问。 其应当具有的特性为： 仅有一个节点发送数据时，需要使用完整信道 有多个节点发送数据时，每个节点吞吐量可以趋近于平均 协议是分散的：不会因一个节点崩溃而崩溃 造价便宜！ 可以划分为信道划分协议、随机接入协议与轮流协议 信道划分协议 采用时分复用或频分复用的方式，平均划分时间或频率 时分复用与频分复用 TDM/FDM的特点： 消除了碰撞，并且非常公平 在及诶单书很少的时候效果很差 另一种信道划分协议为码分多址，为每个节点分配一种不同的编码，如果编码选择合适，即可同时传输同时接收并且互不干扰 随机接入协议 每个节点都以信道最大速率发送分组，当发生碰撞时，等待一个随机时延并重发该分组，直到发送成功。 随机试验种类繁多，具体介绍ALOHA协议与载波侦听多路访问(CSMA)协议 时隙ALOHA 假设： 所有帧大小相同，记为LLL 时间被划分为等长的时隙，每个时隙可以发送一帧 只在时隙起点传输帧 节点之间同步时隙信息 如果在一个时隙中发生了碰撞，则时隙结束时所有节点可以检测到碰撞 则时隙ALOHA的操作如下： 当有数据需要发送时，等待下一个时隙起点传输 如果没有碰撞则万事大吉 反之，则在后续的每个时隙起点独立地以 ppp 的概率重传，直到成功发送 定义成功时隙为恰好只有一个节点传输的时隙，成功时隙占所有时隙的比例为效率，则N(N≫1)N(N\\gg 1)N(N≫1)个节点的效率为： f(p)=CN1p(1−p)N−1=Np(1−p)N−1 f(p) = C_{N}^{1}p(1-p)^{N-1} = Np(1-p)^{N-1} f(p)=CN1​p(1−p)N−1=Np(1−p)N−1 极值点为： p=1N p = \\frac{1}{N} p=N1​ 因此： f(p)≤(1−1N)N−1lim⁡N→∞f(p)≤1e\\begin{align*} f(p) &amp;\\leq (1 - \\frac{1}{N})^{N - 1} \\\\ \\lim\\limits_{N\\to\\infty}&amp;f(p) \\leq \\frac{1}{e} \\end{align*} f(p)N→∞lim​​≤(1−N1​)N−1f(p)≤e1​​ 所以当节点数充分大时，效率最高约为37% ALOHA 纯ALOHA将不考虑时隙问题，在分组到达时则立刻进行传输，碰撞时立即以概率 ppp 重传分组，以概率 1−p1-p1−p 等待一个分组传输时间，重复循环直到成功发送 若一个节点想要成功发送，则必须要保证其发送时间的前后各一个分组传输时间之内不能有其他节点发送，因此可以计算得其最大效率为： lim⁡N→∞f(p)≤12e\\lim\\limits_{N\\to\\infty}f(p) \\leq \\frac{1}{2e} N→∞lim​f(p)≤2e1​ CSMA 模仿人类聚会时的发言，CSMA新增了如下协议： 说话之前先听：在传输之前先“听”信道，如果有其他节点正在发送则等待，直到一段时间内没有传输 而CSMA/CD则进一步增加了如下协议 和别人同时开始说话时停止说话：节点在传输过程中保持“听”信道，当有其他节点也开始传输的时候立刻停止传输，等待一段随机时间后，进入上一种状态 采用时空图说明： 时空图，其中B与D碰撞 可以看出，决定其碰撞发生的概率即决定性能的关键因素为信道传播时延，即在节点之间通信的效率 CSMA/CD的一些讨论 讨论两个问题： 每次检测到碰撞后应该等待多久 CSMA/CD效率如何 对于等待时间的问题，采用二进制指数后退算法，具体为： 在nnn次碰撞之后，令K∼U({0,1,…,2n−1})K \\sim \\text{U}(\\{0, 1, \\dots, 2^{n} - 1\\})K∼U({0,1,…,2n−1})，并且等待发送512K512K512K比特所需要的时间 对于效率问题，定义CSMA/CD的效率为： 节点数和分组数充分多的时候，分组能够无碰撞传输所占有的时间比例 定义dpropd_{\\text{prop}}dprop​为两个适配器之间传递信号的最大时间，dtransd_{\\text{trans}}dtrans​为传输一个最大以太网帧的时间，则CSMA/CD的效率为： f=11+5dprop/dtrans f = \\frac{1}{1 + 5d_{\\text{prop}}/ d_{\\text{trans}}} f=1+5dprop​/dtrans​1​ 轮流协议 是一大类能够满足大量节点平均享有吞吐量的协议，主要讨论轮询协议与令牌传递协议 轮询协议 指定主节点，主节点可以轮询每个节点，告知其可以传输的最大帧数 这种方法引入了轮询时延，并且是集中式的（主节点坏了就似了） 令牌传递协议 讲一个称之为令牌的特殊帧在节点之间以一个固定的次序进行交换，每个节点持有令牌当且仅当自己需要发送帧，反之立刻传递给下一节点 同样的，该协议单个节点的故障可能导致整体的崩溃 DOCSIS 一个实际应用的综合性协议 上行与下行信道 DOCSIS定义了电缆数据网络体系结构及其协议，对于上行信道与下行信道都采用FDM，每个信道均为广播信道，并且下行信道不会存在多路访问问题，主要考虑上行信道 上行信道被划分时间间隔，每个时间间隔包含微时隙序列（类似TDM） CMTS发送MAP报文指定特定的调制解调器在特定时间间隔发送分组 调制解调器们在一组特殊的微时隙间隔内向CMTS发送请求帧，向其请求分配微时隙用于发送数据 请求帧以随机接入的方式发送，当其发生碰撞时（调制解调器只能通过下行信道的数据推测是否碰撞），采用二进制指数回退算法决定等待时间并重新发送","tags":["网原","笔记","链路层","局域网"],"categories":["计算机网络原理"]},{"title":"IAI-对抗搜索","path":"/2024/05/20/IAI-对抗搜索/","content":"人智导 对抗搜索 对抗搜索 对于一些分支极多的对抗式问题，穷举法所需要消耗的时间、空间资源无法承受，无法实现，因此考虑充分的剪枝 极小-极大模型 进行有限步内的穷举，从根节点出发，叶节点标记得分，并且期望每位选手都选择对于自己最有利的走法，最后选择期望得分最高的一步 极大-极小模型示例图 图中，两种图形代表两位选手，分别记为A,BA, BA,B，叶节点上所标记的为AAA在四步之后的期望得分，每位选手每步都是期望自身得分尽量高（对方得分尽量低） 但是绩效极大仍然没有剪枝，时空资源仍然无法承受 α-β剪枝算法 α\\alphaα-β\\betaβ 剪枝算法如下 α\\alphaα为极大节点（我方选手尽量多得分）的下界 β\\betaβ为极小节点（我方选手尽量少得分）的上界 后辈 β≤\\beta \\leqβ≤ 祖先 α\\alphaα 时，α\\alphaα 剪枝 后辈 α≥\\alpha \\geqα≥ 祖先 β\\betaβ 时，β\\betaβ 剪枝 实例如下：注意比较时需要和祖先节点而不是父节点比较 alpha-beta剪枝实例 每次α\\alphaα-β\\betaβ 剪枝只能得到下一步的走法 局限性：非常依赖局面估计（也就是叶节点的得分）的准确性，需要大量的专家知识与人工整理 蒙特卡洛(MCTS) 基本思想： 可能出现的状态用状态树表示 逐步扩展树节点 父节点利用子节点的结果 随时得到行为评价 基本过程为： 选择 →\\to→ 扩展 →\\to→ 模拟 →\\to→ 回传 选择策略 考虑两方面因素： 充分探索尚未探索的节点 利用效果尽量好的节点 因此采用多臂老虎机模型 拥有kkk个拉杆的老虎机，拉动每个拉杆的收益相互独立并且遵循一定分布，求如何使得受益最大化 采用信心上限算法：每次选择信心上限最大的节点，节点jjj的信心上限计算方式为： Ij=X‾j+c2ln⁡(n)Tj(n)I_{j} = \\overline{X}_{j} + c\\sqrt{\\frac{2\\ln(n)}{T_{j}(n)}} Ij​=Xj​+cTj​(n)2ln(n)​​ 其中参数含义为： ccc：调节参数 nnn：访问次数 Tj(n)T_{j}(n)Tj​(n)：此时节点 jjj 被访问的次数 X‾j\\overline{X}_{j}Xj​：此时节点 jjj 的平均收益 以围棋为例，每一次模拟可以看成是随机落点，平均收益可以看成是胜率，如下图，其中为简便令c=0c = 0c=0，最终选择根节点的子节点中胜率最大的节点作为下一步： 采用UBC选择的MCTS 注意： 每个节点的胜率是站在己方的角度考虑的！ AlphaGo 为了解决MCTS的盲目性问题（随机落子），将神经网络与蒙特卡洛结合起来，使用了策略网络与估值网络两种神经网络 策略网络 一个神经网络，用于提供行棋概率 输入：48个通道，每个通道大小19*19，记录了棋局的相关信息输出：棋盘上每个节点的行棋概率 策略网络 策略网络可以看成是一个361类别分类问题，通过人类棋手的棋谱进行训练，损失函数为 L(w)=−talog⁡(pa)L(w) = -t_{a}\\log(p_{a}) L(w)=−ta​log(pa​) 其中tat_{a}ta​为实际落子概率，pap_{a}pa​为网络落子概率 估值网络 一个神经网络，用于提供棋局收益 输入：49个通道，每个通道大小19*19，记录了棋局的相关信息（比策略网络多一个）输出：当前棋局收益 ∈[−1,1]\\in [-1, 1]∈[−1,1] 估值网络 估值网络可以看成回归问题，也是通过人类棋手棋谱进行训练，损失函数： L(w)=(R−V(s))2L(w) = (R - V(s))^{2} L(w)=(R−V(s))2 其中RRR为实际收益，111 胜 −1-1−1 负，V(s)V(s)V(s)为网络输出 与MCTS融合 给定参数 λ\\lambdaλ 每次模拟收益为： vi(s)=λvalue(s)+(1−λ)sim(s)v_{i}(s) = \\lambda \\text{value}(s) + (1 - \\lambda)\\text{sim}(s) vi​(s)=λvalue(s)+(1−λ)sim(s) 其中 value(s)\\text{value}(s)value(s) 为估值网络输出，sim(s)\\text{sim}(s)sim(s) 为模拟结果 因此定义平均收益： Q(sa)=∑i=1nvi(sa)nQ(s_{a}) = \\frac{\\sum\\limits_{i=1}^{n}v_{i}(s_{a})}{n} Q(sa​)=ni=1∑n​vi​(sa​)​ 定义探索项： u(sa)=c⋅p(sa)N(s)N(sa)+1u(s_{a}) = c \\cdot p(s_{a})\\frac{\\sqrt{N(s)}}{N(s_{a}) + 1} u(sa​)=c⋅p(sa​)N(sa​)+1N(s)​​ 其中： sas_{a}sa​代表棋局sss在aaa处落子后的棋局 N(s)N(s)N(s)代表对于棋局sss的模拟次数 p(s)p(s)p(s)代表策略网络对于sss的输出 ccc为系数 信心上限切换为： Ij=Q(sa)+u(sa)I_{j} = Q(s_{a}) + u_(s_{a})Ij​=Q(sa​)+u(​sa​) MCTS过程如下： 信息：每个节点记录收益、到达该节点概率与被选择次数 选择：从根节点开始，每次选择子节点中信心上限最大的节点，直到叶节点即停止并选中 生成：生成选中节点的所有叶节点（也即所有可能的落子），并规定了最大的节点深度 模拟：采用推演策略网络（更快），计算其viv_{i}vi​ 回传：注意正负号（即注意行棋是双方依次进行） 最终将根节点的子节点中，被选择次数最多的节点作为选择 深度强化学习方法 强化学习：学习“做什么可以使得收益最大化”深度强化学习：利用深度学习实现的强化学习 以围棋为例，通过自己博弈训练策略网络，三种实现方法： 策略梯度：学习每个点获胜的概率 价值评估：学习每个点获得最大收益的概率 演员评价方法：学习到每个罗字典获得最大收益增量的概率 策略梯度 数据由自我博弈产生，损失函数为： L(w)=−talog⁡(pa)L(w) = - t_{a}\\log(p_{a}) L(w)=−ta​log(pa​) 其中，pap_{a}pa​为当前棋局在aaa处下棋的概率，ta∈{−1,1}t_{a}\\in\\{-1, 1\\}ta​∈{−1,1}为胜负值 基于策略梯度的强化学习流程 注意点： 强化学习过程中，每个样本只使用一次 该方法学习到的是每个可落子点行棋的获胜概率 价值评估 输入为当前棋局和行棋点，输出为该行棋点的价值，在[−1,1][-1, 1][−1,1]之间，数据也是自我博弈产生，损失函数为： L(w)=(R−V(s,a))2L(w) = (R - V(s, a))^{2} L(w)=(R−V(s,a))2 其中，RRR为胜负值，V(s,a)V(s, a)V(s,a)为棋局sss在aaa处落子后网络的输出 演员-评价方法 利用收益增量评价一步棋的好坏： A=Q(s,a)−V(s)A = Q(s, a) - V(s) A=Q(s,a)−V(s) 其中，V(s)∈[−1,1]V(s)\\in[-1, 1]V(s)∈[−1,1]为棋局sss的预期收益，Q(s,a)∈[−1,1]Q(s, a)\\in[-1, 1]Q(s,a)∈[−1,1]为sss在aaa处行棋之后的收益，在实际中常去Q(s,a)=RQ(s, a) = RQ(s,a)=R为胜负值，最终AAA越大收益越好 演员-策略网络，评价-估值网络 损失函数为： L(w)=L1(w)+λL2(w)=A2−λAlog⁡(pa)\\begin{align*} L(w) &amp;= L_{1}(w) + \\lambda L_{2}(w) \\\\ &amp;= A^{2} - \\lambda A\\log(p_{a}) \\end{align*} L(w)​=L1​(w)+λL2​(w)=A2−λAlog(pa​)​ AlphaGo Zreo 将估值网络和策略网络合并为“双输出”网络 输入：17个通道，记录8个棋局，每个棋局2通道，1个通道记录行棋方输出：策略网络输出362维，增加的一维为放弃；估值网络输出棋局的估值 Alpha-Zero原理 与MCTS融合 与AlphaGo基本相同，差别如下： 模拟被估值网络完全取代，模拟收益vi(s)v_{i}(s)vi​(s)即为估值网络的输出 规定了总模拟次数 结合MCTS与深度强化学习 Alpha-Zero中的深度强化学习 损失函数为： Lvalue=(R−v)2Lstrategy=−∑i=1362πilog⁡(pi)L=Lvalue+Lstrategy+∣∣θ∣∣2\\begin{align*} L_{value} &amp;= (R - v)^{2} \\\\ L_{strategy} &amp;= -\\sum\\limits_{i=1}^{362}\\pi_{i}\\log(p_{i}) \\\\ L &amp;= L_{value} + L_{strategy} + ||\\theta||^{2} \\end{align*} Lvalue​Lstrategy​L​=(R−v)2=−i=1∑362​πi​log(pi​)=Lvalue​+Lstrategy​+∣∣θ∣∣2​ 其中RRR为胜负值，vvv为估值网络输出，πi\\pi_{i}πi​为MCTS给出的该走法概率，pip_{i}pi​为策略网络给出的该走法概率 引入多样性 人为引入噪声，增加策略网络输出的随机性，通常增加一个狄利克雷分布，生成一些大多值为0，小部分值较大的随机变量，并修正策略网络输出为： p⇐λp+(1−λ)pdp \\Leftarrow \\lambda p + (1 - \\lambda) p_{d} p⇐λp+(1−λ)pd​","tags":["笔记","IAI","对抗搜索"],"categories":["人工智能导论"]},{"title":"TCS-Lecture-B","path":"/2024/05/15/TCS-Lecture-B/","content":"TCS: Randomized Computation Randomized Computation Randomized Algorithm A randomized algorithm outputs the correct value with good probability on every possible input. Matrix multiplication Input matrix A,B,CA, B, CA,B,C, decide if C=ABC = ABC=AB Obviously there is a deterministic and polynomial algorithm for this. A random algorithm: Freivalds’ algorithm Repeat the following for kkk times.Randomly choose v∈{0,1}nv\\in \\{0, 1\\}^{n}v∈{0,1}nCompute (d=A(Bv)−Cv)(d = A(Bv) - Cv)(d=A(Bv)−Cv)Reject if d≠0d eq 0d=0Accept We have that this algorithm can solve this problem in O(kn2)O(kn^{2})O(kn2) time with a probability of failure ≤2−k\\leq 2^{-k}≤2−k Proof: If AB≠CAB eq CAB=C, we prove P(d=0)≤12P(d = 0) \\leq \\frac{1}{2}P(d=0)≤21​ for each time.So D=AB−C≠0D = AB - C eq 0D=AB−C=0. Let Dij≠0D_{ij} eq 0Dij​=0The iii-th entry of ddd holds that:di=∑Dikvk=Dijvj+∑k≠jDikvkd_{i} = \\sum D_{ik}v_{k} = D_{ij}v_{j} + \\sum\\limits_{k eq j}D_{ik}v_{k}di​=∑Dik​vk​=Dij​vj​+k=j∑​Dik​vk​Let s=∑k≠jDikvks = \\sum\\limits_{k eq j}D_{ik}v_{k}s=k=j∑​Dik​vk​, so:P(di=0)=P(di=0 ∣ s=0)P(s=0)+P(di=0 ∣ s≠0)P(s≠0)≤P(vi=0)P(s=0)+P(vi=1)P(s≠0)≤12(P(s=0)+P(s≠0))≤12\\begin{align*}P(d_{i} = 0) &amp;= P(d_{i} = 0 \\,|\\, s = 0)P(s = 0) \\\\&amp;\\quad +P(d_{i} = 0 \\,|\\, s eq 0)P(s eq 0) \\\\&amp;\\leq P(v_{i} = 0)P(s = 0) + P(v_{i} = 1)P(s eq 0)\\\\&amp;\\leq \\frac{1}{2}(P(s = 0) + P(s eq 0)) \\leq \\frac{1}{2}\\end{align*}P(di​=0)​=P(di​=0∣s=0)P(s=0)+P(di​=0∣s=0)P(s=0)≤P(vi​=0)P(s=0)+P(vi​=1)P(s=0)≤21​(P(s=0)+P(s=0))≤21​​So P(d=0n)≤P(di=0)≤12P(d = 0^{n}) \\leq P(d_{i} = 0) \\leq \\frac{1}{2}P(d=0n)≤P(di​=0)≤21​ Maxcut Approximation The MAX-CUT problem is NP-Complete. So our task is to find a cut CCC whose size is not far from the optimal one C∗C^{*}C∗. If sizeC≥α sizeC∗\\text{size}_C \\ge \\alpha\\,\\text{size}_{C^*}sizeC​≥αsizeC∗​, we call CCC is an α\\alphaα-approximation, then we have an easily way to find 12\\frac{1}{2}21​-approximation, which is universal randomly distribute each vertex into set 000 or 111. E(sizeC)=E∑{u,v}∈E1xu≠xv=12∣E∣≥12sizeC∗.\\begin{equation*} \\mathbb{E}(\\text{size}_C) = \\mathbb{E} \\sum_{\\{u, v\\} \\in E} 1_{x_u e x_v} = \\frac{1}{2} |E| \\ge \\frac{1}{2} \\text{size}_{C^*}. \\end{equation*} E(sizeC​)=E{u,v}∈E∑​1xu​=xv​​=21​∣E∣≥21​sizeC∗​.​ This is just sufficient expection, but we can give an always-large-enough cut by conditional expection if we can compute this equation efficiently. E(sizeC(x1,…,xi,Xi+1,…Xn)),\\begin{equation*} \\mathbb{E}(\\text{size}_C(x_1, \\ldots, x_i, X_{i+1}, \\ldots X_{n})), \\end{equation*} E(sizeC​(x1​,…,xi​,Xi+1​,…Xn​)),​ We maximize this in each choice. Derandomize Above algorithm uses nnn random choices, covering 2n2^{n}2n possibilities. We can try to reduce the randomness to a polynomial number of possibilities, we can derandomize the algorithm. Considering Universal hash function: Consider a family of hash functions H={h:U→R}\\mathcal{H} = \\{ h : U \\to R \\}H={h:U→R}. Universal hash functions are a family of functions with the random-like property while the size of the family is small. We can use a small seed to choose hash functions from the family. Pairwise independent hash functions. A family H={h:U→R}\\mathcal{H} = \\{h : U \\to R\\}H={h:U→R} is called Pairwise independent if for any distinct x1,x2∈Ux_{1}, x_{2}\\in Ux1​,x2​∈Uand any y1,y2∈Ry_{1}, y_{2}\\in Ry1​,y2​∈R, we have:Ph∈H(h(x1)=y1 and h(x2)=y2)=1∣R∣2.\\begin{equation*}P_{h \\in \\mathcal{H}} \\bigl( h(x_1) = y_1 \\text{ and } h(x_2) = y_2 \\bigr) = \\frac{1}{|R|^2}.\\end{equation*}Ph∈H​(h(x1​)=y1​ and h(x2​)=y2​)=∣R∣21​.​ A pairwise independent hash functions mapping {0,1}k\\{0, 1\\}^{k}{0,1}k to {0,1}\\{0, 1\\}{0,1}. H={h(x)=(ax+b)(mod 2) ∣ a∈{0,1}kb∈{0,1}}\\mathcal{H} = \\{ h(x) = (ax + b)(\\text{mod }2) \\,|\\, a \\in \\{0, 1\\}^{k}\\quad b\\in\\{0, 1\\} \\}H={h(x)=(ax+b)(mod 2)∣a∈{0,1}kb∈{0,1}} This family size is ∣H∣=2k+1|\\mathcal{H}| = 2^{k+1}∣H∣=2k+1. Assign k=⌈log⁡n⌉k = \\lceil \\log n\\rceilk=⌈logn⌉, then UUU can encoding each vertex in GGG. So ∣H∣≤2n|\\mathcal{H}| \\leq 2n∣H∣≤2n, which means we can go through all the hash function in H\\mathcal{H}H and output the maximized cut. BPP Define Prob TM as follows: A probabilistic Turing machine is a type of NTM in which each nondeterministic step is called a coin-flip step and has two legal next moves. We assign a probability 2−k2^{-k}2−k to each branch of the machine’s computation where kkk is the number of coin flips occur in the branch.The probability of the machine accepting the input is defined asP(M accepts w)=∑b:b is acceptingP(b).\\begin{equation*}P(M \\text{ accepts } w) = \\sum_{b:b \\text{ is accepting}} P(b).\\end{equation*}P(M accepts w)=b:b is accepting∑​P(b).​ This is equvilant to that each son of a vertex in NTM can be reach in the same probability. Define the error probability ε\\varepsilonε: If w∈Aw \\in Aw∈A, then P(M(w)=1)≥1−εP(M(w) = 1) \\geq 1 - \\varepsilonP(M(w)=1)≥1−εIf w∉Aw otin Aw∈/A, then P(M(w)=1)≤εP(M(w) = 1) \\leq \\varepsilonP(M(w)=1)≤ε Then we can define BPP\\text{BPP}BPP with error probability: BPP\\text{BPP}BPP is the class of languages decided by probabilistic polynomial-time Turing machines with an error probability of 13\\frac{1}{3}31​Actually, the 13\\frac{1}{3}31​ can be replaced by any constant exactly greatly than 12\\frac{1}{2}21​ BPP\\text{BPP}BPP can be also defined with verifier: A decision problem AAA is in BPP\\text{BPP}BPP if and only if there is a polynomial-time verifier VVV such that for all xxx, x∈Ax\\in Ax∈A if and only ifPr(V(x,r)=1)≥23.\\begin{equation*}P_{r} \\bigl(V(x, r) = 1 \\bigr) \\ge \\frac{2}{3}.\\end{equation*}Pr​(V(x,r)=1)≥32​.​ Error Reduction Any decision problem A∈BPPA\\in\\text{BPP}A∈BPP has a polynomial-time randomized algorithm whose error probability is 2−p(n)2^{-p(n)}2−p(n) where ppp is a polynomial and nnn is the input size. This can be proved by Chernoff bound or Sampling Theroem Circuits v.s. BPP Define SIZEn(s)\\text{SIZE}_{n}(s)SIZEn​(s): For a finite function g:{0,1}n→{0,1}g: \\{0, 1\\}^{n}\\rightarrow\\{0, 1\\}g:{0,1}n→{0,1}, g∈SIZEn(s)g \\in \\text{SIZE}_{n}(s)g∈SIZEn​(s) if there is a circuit of at most sss NAND gates computing ggg. And we define the restricted function: F↾n(x)=F(x) for x∈{0,1}n.\\begin{equation*} F_{\\restriction n} (x) = F(x) \\text{ for } x\\in \\{0,1\\}^n. \\end{equation*} F↾n​(x)=F(x) for x∈{0,1}n.​ Then FFF is non-uniformly computable in T(n)T(n)T(n) size, as F∈SIZE(T)F\\in\\text{SIZE}(T)F∈SIZE(T) if there is a sequence C0,C1,…C_{0}, C_{1}, \\dotsC0​,C1​,… of NAND circuits such that: CnC_{n}Cn​ computes F↾nF_{\\restriction n}F↾n​CnC_{n}Cn​ has at most T(n)T(n)T(n) gates when nnn is sufficiently large So the non-uniform analog P\\text{P}P: P/poly=⋃c∈NSIZE(nc)\\text{P}/\\text{poly} = \\bigcup\\limits_{c\\in\\mathbb{N}}\\text{SIZE}(n^{c})P/poly=c∈N⋃​SIZE(nc) Obviously, P⊊P/poly\\text{P}\\subsetneq\\text{P}/\\text{poly}P⊊P/poly and it can be proved BPP⊂P/poly\\text{BPP}\\subset\\text{P}/\\text{poly}BPP⊂P/poly as follows: Due to error reduction, A∈BPPA\\in \\text{BPP}A∈BPP has a polynomial-time randomized algorithm whose error probability is less than 2−n2^{-n}2−n, which means there is a verifier VVV, such that∀x Py(V(x,y)≠A(x))&lt;12n\\forall x \\,\\, P_{y}(V(x, y) eq A(x)) &lt; \\frac{1}{2^{n}}∀xPy​(V(x,y)=A(x))&lt;2n1​So due to the union bound:Py(∃x V(x,y)≠A(x))≤∑xPy(V(x,y)≠A(x))&lt;1P_{y}(\\exist x\\,V(x, y) eq A(x)) \\leq \\sum\\limits_{x}P_{y}(V(x, y) eq A(x)) &lt; 1Py​(∃xV(x,y)=A(x))≤x∑​Py​(V(x,y)=A(x))&lt;1As this probability is not 111, there must exist some y∗y^{*}y∗ for which ∀x V(x,y∗)=A(x)\\forall x\\, V(x, y^{*}) = A(x)∀xV(x,y∗)=A(x).Thus there exists a circuit with poly(n)\\text{poly}(n)poly(n) gates to caculate problem AAA beacuse y∗y^{*}y∗ is polynomial P = BPP &lt;= P = NP Sipser–Gács Theorem: BPP∈Σ2P∩Π2P\\text{BPP} \\in \\Sigma^{P}_{2} \\cap \\Pi_{2}^{P}BPP∈Σ2P​∩Π2P​, while the ΣP\\Sigma^{P}ΣP and ΠP\\Pi^{P}ΠP are defined as:ΣiP=∃∀∃…PΠiP=∀∃∀…P \\begin{align*} \\Sigma_{i}^{P} &amp;= \\exists\\forall\\exists\\dots \\text{P} \\\\ \\Pi_{i}^{P} &amp;= \\forall\\exists\\forall\\dots \\text{P} \\end{align*}ΣiP​ΠiP​​=∃∀∃…P=∀∃∀…P​ And we have the following theroem P=NP\\text{P} = \\text{NP}P=NP implies P=BPP\\text{P} = \\text{BPP}P=BPP The proof is diffcult with the technique ‘probabilistic method’ And there is also a theroem that reveals the relation between B\\text{B}B and BPP\\text{BPP}BPP Relations with P NP EXP We know P⊊EXP\\text{P} \\subsetneq \\text{EXP}P⊊EXP and BPP⊆EXP\\text{BPP} \\subseteq \\text{EXP}BPP⊆EXP Expected: P=BPP⊊NP⊆EXP\\text{P} = \\text{BPP} \\subsetneq \\text{NP} \\subseteq \\text{EXP}P=BPP⊊NP⊆EXP Extreme: P⊊NP⊆BPP=EXP\\text{P} \\subsetneq \\text{NP} \\subseteq \\text{BPP} = \\text{EXP}P⊊NP⊆BPP=EXP Extreme also: P=BPP=NP⊊EXP\\text{P} = \\text{BPP} = \\text{NP} \\subsetneq \\text{EXP}P=BPP=NP⊊EXP","tags":["TCS","Randomized Computation"],"categories":["理论计算机科学导引"]},{"title":"网原单词表","path":"/2024/05/15/网原单词表/","content":"计算机网络原理 中-英对照表 packet：分组 circuit switching：电路交换 packet switching：分组交换 packet switch：分组交换机 root：路由器 linker layer：链路层交换机 store-and-forword transmission：存储转发传输 output buffer/queue：输出缓存/队列 queuing delay：排队时延 packet loss：丢包 forwarding table：转发表 routing protocol：路由转发协议 Frequency-Division Multiplexing(FDM)：频分复用 Time-Division Multiplexing(TDM)：时分复用 bind width：带宽 slient period：静默期 Internet service provider(ISP)：因特网提供商 Point of Presence(PoP)：存在点 multi-home：多宿 peer(P2P)：对等 Interner Exchange Point(IXP)：因特网交换点 content provider network：内容提供商网络 nodal processing delay：节点处理时延 queuing delay：排队时延 transmission delay：传输时延 propagation delay：传播时延 total nodal delay：节点总时延 traffic intensity：流量强度 instantaneous throughout：瞬时吞吐量 average throughout：平均吞吐量 bottleneck link：瓶颈链路 layer：分层 protocol stack：协议栈 top-down approach：自顶向下方法 application-layer：应用层 message：报文 transport-layer：运输层 segment：报文段 network-layer：网络层 datagram：数据报 link-layer：链路层 frame：帧 encapsulation：封装 payload field：有效载荷字段 malware：恶意软件 botnet：僵尸网络 self-replicating：自我复制 worm：蠕虫 Denial-of-Service(DoS) attack：拒绝服务攻击 Distributed Dos(DDoS)：分布式拒绝网络攻击 packet sniffer：分组嗅探器 IP spoofing：IP哄骗 application architexture：应用程序体系结构 data ceenter：数据中心 process：进程 socket：套接字 Appllication Programming Interface(API)：应用程序编程接口 port numbe：端口号 reliable data transfer：可靠数据传输 bindwidth-sensitive application：带宽敏感应用 elastic application：弹性应用 Secure Socket Layer：安全套接字层 HyperText Transfer Protocol(HTTP)：超文本传输协议 stateless protocol：无状态协议 persistent connection：持续连接 non-persistent connection：非持续连接 Round-Trip Time(RTT)：往返时间 request line：请求行 header line：首部行 entity body：实体体 Web cache：Web缓存器 proxy server：代理服务器 Simple Mail Transfer Protocol(SMTP)：简单邮件传输协议 Post Office Protocol-Version3(POP3)：第三版的邮局协议 Internet Mail Access Protocol：因特网邮件访问协议 authorization：特许 transaction：事务处理 update：更新 Domain Name System(DNS)：域名系统 host aliasing：主机别名 canonical hostname：规范主机名 mail server aliasing：邮件服务器别名 load distribution：负载分配 distant centralized database：远距离集中式数据库 torrent：洪流 chunk：块 unchoked：疏通 tit-for-tat：一报还一报 Dynamic Adaptive Streaming over HTTP(DASH)：经HTTP的动态适应性流 manifest file：告示文件 content distribution network(CDN)：内容分发网络 reliable data transfer：可靠数据传输 Automatic Repeat reQuest(ARQ)：自动重传请求 Positive acknowledgment(ACK)：肯定确认 negative acknowledgment(NCK)：否定确认 duplicate packet：冗余分组 alter-nating-bit protocol：比特交替协议 Go-Back-N(GBN)：回退N步 sliding-window protocol：滑动窗口协议 cumulative acknowledgmemt：累计确认 Transmission Control Protocol：传输控制协议 connection oriented：面向连接的 full-duplex service：全双工服务 three-way handshake：三次握手 Maximum Segment Size(MSS)：最大报文长度 Maximum Transmission Unit(MTU)：最大设置单元 piggybacked：捎带 Exponential Weighted Moving Average(EWMA)：指数加权移动平均 congestion control：拥塞控制 per-connection throughput：每连接的吞吐量 Available Bite Rate(ABR)：可用比特率 congestion window：拥塞窗口 self-clocking：自计时 Additive-Increase, Multiplicative-Decrease(AIMD)：加性增，乘性减 Explicit Congestion Notification：明确拥塞通告 Explicit Congestion Notification Echo：明确拥塞通告回显 forwarding：转发 routing：路由选择 forwarding table：转发表 Software Defined Network(SDN)：软件定义网络 best-effort service：尽力而为服务 Tenary Content Address Memory(TCAM)：三态内容可寻址寄存器 Active Queue Management(AQM)：主动队列管理 Random Early Detection(RED)：随机早期检测 packet scheduler：分组调度 non-preemptive priority ququeing：非抢占式优先权排队 round robin queuing discipline：循环排队规则 work-conserving queuing：保持工作排队 weighted fair queuing：加权公平排队 Maximum Transmission Unit(MTU)：最大传送单元 dotted-decimal notation：点分十进制记法 Classless Interdomain Routing(CIDR)：无类别域间路由选择 address aggreration：地址聚合 Dynamic Host Configuration Protocol(DHCP)：动态主机配置协议 Plug-and-play Protocol：即插即用协议 Nonzero Protocol：零配置协议 Network Address Translation(NAT)：网络地址转换 tunneling：建隧道 Link State(LS) Algorithm：链路状态算法 Distance Vector(DV) Algorithm：距离向量算法 link state broadcast：链路状态广播 Autonomous System(AS)：自治系统 Open Shortest Path First(OSPF)：开放最短路优先 Broder Gateway Protocol(BGP)：边界网关协议 anycast：任播 switch farbic：交换结构 northbound/southbound API：北向/南向API Internet Control Messsage Protocol(ICMP)：因特网控制报文协议 Simple Network Management Protocol(SNMP)：简单网络管理协议 Management Information Base(MIB)：管理信息库 Structure of Management Information(SMI)：管理信息结构 Prorocol Data Unit(PDU)：协议数据单元 framing：成帧 Medium Access Control(MAC)：媒体访问控制 network adapter：网络适配器 Network Interface Card(NIC)：网络接口卡 Error Detection and Correction(EDC)：差错检测和纠正 undetected bit error：未检出比特差错 parity bit：奇偶校验位 two-dimensional parity：二维奇偶校验 Cyclic Redundancy Check(CRC)：循环冗余检测 polynomial code：多项式编码 generator：生成多项式 point-to-point link：点对点链路 point-to-point protocol(PPP)：点对点协议 high-level data link control(HIDC)：高级数据链路控制 broadcast link：广播链路 myltiple access problem：多路访问问题 collide：碰撞 channel partitioning protocol：信道划分协议 random access protocol：随机接入协议 taking-turns protocol：轮流协议 time-frame：时间帧 slot：时隙 Code Division Multiple Access(CDMA)：码分多址 Carrier Sense Multiple Access(CSMA)：载波侦听多路访问 CSMA with Collision Detection(CSMA/CD)：具有碰撞检测的CSMA channel propagation delay：信道传播时延 binary exponential backoff：二进制指数后退 polling protocol：轮询协议 token-passing protocol：令牌传递协议 Cable Modem Termination System(CMTS)：电缆调制解调器端接系统 Data-Over-Cable Service Interface CMTS(DOCSIS)：数据经电缆服务接口","tags":["网原","笔记"],"categories":["计算机网络原理"]},{"title":"网原笔记5","path":"/2024/05/15/网原笔记5/","content":"计算机网络原理 笔记 5 控制平面 路由选择算法 在路由器中寻找到最短路径，对于一个路由器，主要寻找到将其数据转发到其他路由器所需要的最短路径 算法分类方式 根据信息量 集中式路由选择：全局，了解该路由网络的全部信息并据此进行计算 分散式路由选择：局部，每个节点只知道与自己到相邻接点的花销 根据可变性 静态：路由基本不随时间变化 动态：随着网络流量或拓扑变化而动态改变路径，更加方便但是受一些特殊问题的影响 对负载敏感性： 敏感：趋近于绕开拥塞链路 迟钝：拥塞无影响，现代多采用这种，原因是链路开销不明确反映拥塞水平 LS 信息的全局性通过链路状态广播算法来完成 之后使用——伟大的Dijkstra!!! 路由振荡问题： 如图的链路为了避免选择高拥塞的道路，每次LS之后都会改变道路，导致了路由实际上处在振荡之中，并且从结果上来看，其选择的也并不是全局最优解 解决方案： 要求链路开销不依赖负载（不合理） 确保并非所有路由器同时运行LS，但是由于自同步的存在很困难，避免自同步可以采用链路通告随机化的方式 DV 迭代：循环计算直到没有更多信息需要交换 异步：不要求所有计算同步执行 分发式：每个节点计算接收邻居的信息，执行计算之后再发回去 基本原理是动态规划Bellman-Ford方程： dx→y=min⁡v∈Γ(x)(cx→v+dv→y)d_{x\\to y} = \\min_{v\\in\\Gamma(x)}(c_{x\\to v} + d_{v\\to y}) dx→y​=v∈Γ(x)min​(cx→v​+dv→y​) 算法如下： 给定图G=(V,E)G = (V, E)G=(V,E) ∀x∈V\\forall x \\in V∀x∈V，维护如下信息： 其与每个直接邻居的开销cx→vc_{x\\to v}cx→v​ 距离向量Dx→=[Dx→y: ∀y∈V]\\overrightarrow{D_{x}} = [D_{x\\to y}:\\text{ } \\forall y \\in V]Dx​​=[Dx→y​: ∀y∈V] 其所有邻居的距离向量 每个节点不时向邻居发送自己的距离向量 某个节点接收到邻居的信息或发现与自己连接的链路开销有变的时候，根据BF方程更新自己的距离向量 如果距离向量发生了变化，则发送给邻居 可以证明，lim⁡Dx→y→dx→y\\lim D_{x\\to y} \\to d_{x\\to y}limDx→y​→dx→y​ 注：图中cx→yc_{x\\to y}cx→y​应该是222而非212121 链路开销改变与链路故障 当链路开销增加时，很容易导致链路故障，如下图 右边的图会出现选择选择环路，即： Init: Dz→x=5(z→y→∗x),Dy→x=4(y→z→∗x)D_{z\\to x} = 5(z \\to y \\to^{*}x), D_{y\\to x} = 4(y \\to z \\to^{*}x)Dz→x​=5(z→y→∗x),Dy→x​=4(y→z→∗x) 1st forward: Dy→x=6(y→z→∗x),Dz→x=7(z→y→∗x)D_{y\\to x} = 6(y \\to z \\to^{*}x), D_{z\\to x} = 7(z \\to y \\to^{*}x)Dy→x​=6(y→z→∗x),Dz→x​=7(z→y→∗x) 2nd forward: Dz→x=8(z→y→∗x),Dy→x=9(y→z→∗x)D_{z\\to x} = 8(z \\to y \\to^{*}x), D_{y\\to x} = 9(y \\to z \\to^{*}x)Dz→x​=8(z→y→∗x),Dy→x​=9(y→z→∗x) … Until: Dz→x=50(z→x),Dy→x=51(y→z→x)D_{z\\to x} = 50(z\\to x), D_{y\\to x} = 51(y\\to z \\to x)Dz→x​=50(z→x),Dy→x​=51(y→z→x) 在最终情况之前，y,zy, zy,z所保存的到xxx的路径都是错误的，当变化后的开销（此处是4→604\\to 604→60）过大的时候，迭代轮次会过大导致传播速率迅速降低 毒性逆转 解决上述特定问题的方式（对于节点度数超过333的环路将无法解决） 如果zzz需要通过yyy到达xxx，则在zzz发送过去的信息中，记Dz→x=∞D_{z\\to x} = \\inftyDz→x​=∞ 善意的小谎言~ 两种算法的比较 记n=∣V∣,m=∣E∣n = |V|, m = |E|n=∣V∣,m=∣E∣： 报文复杂性：由于LS是全局的，因此其需要O(mn)O(mn)O(mn)个报文进行初始化，并且在一条链路发生改变时需要传递给所有节点，更复杂 收敛速度：LS复杂度O((m+n)log⁡n)O((m + n)\\log n)O((m+n)logn)，DV收敛很慢 鲁棒性：LS鲁棒性更强，因为全局算法相对来说路由器是解耦的，但是DV中一个不正确的节点会扩散到全局 OSPF 自治系统：由一组通常处在相同管理控制下的路由器组成，通常一个ISP中的路由器和其链路构成同一个AS，一个自治系统内的路由选择算法为自治系统内部路由选择协议 OSPF是一种LS，也即一个自治系统内采用全局广播的形式，并且即使未发生变化，也要周期性的广播链路状态，同时各条链路的开销，同时要检查链路运行状态，并允许路由器向相邻路由器广播 优点： 安全：能够鉴别OSPF路由器之间的交换，防止数据入侵 并发：允许使用多条相同开销的路径 可综合：容易扩展为MOSPF，从而支持多播 可层次化：支持一个AS中的层次化，即一个自治系统可以被划分为多个区域，每个区域之间可以相互交流，并且只包含一个主干 BGP 用于AS之间的通信，是一种分布式、异步的协议。 作用 在BGP中，一个路由器的转发表具有(xi,I)(x_{i}, I)(xi​,I)的形式，分别代表前缀与接口号 从邻接AS处获得前缀的可达性信息 并且每个子网可以向其他部分广播自己的存在性 确定到该前缀的最优路由 可达性通告 如上图，每对路由器中间使用179端口的半永久TCP连接，每个AS内部的会话为iBGP，跨AS的称为eBGP，于是通告路径如下： xxx子网向自己所在的AS的网关路由器发报文通知自己存在 网关路由器3a3a3a告知邻接的AS网关路由器：AS3中存在子网xxx 2c2c2c接收到这个消息，并通知AS2内的所有路由器 2a2a2a将信息发送给相邻的AS1，告知其xxx存在AS3内，并且可由AS2到达 同样的，不同AS之间可以增加对等链路，这样会导致子网和路由器之间存在多条路径 最优路由选择 在通告的子网前缀中增加一些属性，称为BGP属性，前缀及其属性称为路由，比较重要的属性包括： AS-PATH：这个AS是一条路由器路径中的一个，包含了已经通过的路由器列表，可以用于防止环路 NEXT-HOP：AS-PATH的起始路由器接口地址，每个AS的不同路由器接收到的NEXT-HOP属性可能不一样，用于指示从该路由器出发怎么找到子网 热土豆 查找AS内部路由转发信息，找到通往不同NEXT-HOP的最低开销路径，进而选择开销最低的那条 也即，热土豆追求的是贪心的尽快将报文传递出这个AS 路由器选择 当一个路由器希望到达一个前缀时，会将到该前缀的路由集合进行优先级排序，优先级如下： 每个路由增加一个本地偏好属性，属性值取决于管理员，本地偏好越高越优先 本地偏好相同时，选择AS-PATH最短的路由，由此规则确定路由之后通过DV决定路径 都相同时，采用热土豆 热土豆仍然无法选择时，采用BGP标识符 IP 任播 用于DNS中的服务，通常用语降低时延，例如CDN会向其下的多台服务器分配相同的IP，这样当一台路由器向这个IP发送信息的时候，路由器会向最近的一个服务器转发请求 路由选择策略 客户网络在多宿的情况下，可能会有类似提供商网络的行为，因此，其需要向相邻的所有提供商网络通告自己不能连通任何其他目的地，这样可以确保客户与提供商身份的相对稳定性 任何穿越ISP主干网的流量必须是其源或目的中至少一个唯一ISP的客户网络中（商业原因） SDN SDN体系结构具有4个关键特征： 基于流的转发：分组转发规则被规定在流表中，SDN控制平面用于计算、管理和安装流表项 数据平面和控制平面分离 位于数据平面交换机外部的网络控制：控制平面独立于数据平面之外 可编程的网络：网络控制应用程序是可编程的 控制器与控制程序 控制器的功能需要有： 通信层：负责控制器与数据平面之间的交流，称为南向API 网络范围管理层：控制决定层，配置流表以完成端到端转发、负载均衡、防火墙等功能 与应用程序接口：负责控制器与控制程序之间的交流，称为北向API OpenFlow协议 运行在实现了OpenFlow API的设备上，例如SDN控制器和数据平面之间，基于TCP，默认端口6653 控制器发送的重要报文包括： 配置：查询并设置交换机的配置参数 修改状态：增加、删除或修改交换机的流表项，设置交换机端口特性 发送分组：在交换机的特定端口发送特定报文 交换机发送的重要报文报告： 流删除：通知控制器删除一个流表项 端口状态：通知控制器端口状态的变化 分组入：将分组发送给控制器，如果该分组不能被流表匹配则控制器会做额外处理，如果可以匹配则会将该分组作为一个动作 实例 ICMP 主机和路由器之间用来沟通网络层信息的协议，最典型的用途是差错报告 通常被认为是IP的一部分，体系上位于IP之上，其内容作为IP报文的有效载荷 报文中包含一个类型字段和一个编码字段，包含引发该ICMP的IP的首部和前8个字节 这些报文可被用于探测，例如Traceroute程序利用ICMP来探测路由器的名字与IP地址 网络管理和SNMP 定义是一个冗长的单句： 网络管理框架 网络管理关键组件 如上图，关键组件包括： 管理服务器：控制网络管理信息的收集、处理、分析与显示，由人类控制 被管设备：被管理的真实设备，有若干个被管对象组成，被管对象包括实际硬件与配置参数 MIB：位于一个被管设备中收集被管对象的关联信息的数据库，其每个对象由SMI语言定义 网络管理代理：运行在被管设备中的进程，用于与管理服务器通信 网络管理协议：运行在管理服务器和被管设备之间的协议，为管理者提供了相应操作的能力 SNMP 一种网络管理协议，最常用的是请求响应模式，即管理服务器向代理发送请求，通常用于检索或修改MIB对象。其次可被用于代理向管理服务器发送陷阱报文，通知服务器有异常情况导致了MIB对象的改变 SNMP的PDU通过UDP传输，超时重传由管理服务器决定","tags":["网原","网络层","笔记"],"categories":["计算机网络原理"]},{"title":"网原笔记4","path":"/2024/05/08/网原笔记4/","content":"计算机网络原理 笔记 4 网络层 概述 网络层分为数据平面和控制平面 数据平面是将数据在输入链路和输出链路之间进行转发，控制平面是协调转发操作 转发和路由选择 转发：将数据报从输入链路转移到输出链路（数据平面） 路由选择：决定每个分组的路由（控制平面） 转发表：由路由选择确定，决定了转发的路由 确定转发表 传统方法：人工 路由器决定自身的转发表，但是需要路由器间的通信 SDN：由远程控制器决定每个路由器的转发表 网络服务模型 可能的服务： 确保交付 时延上界 有序分组 最小带宽 安全性 尽力而为服务：不提供任何服务 工作原理 四个组件： 输入端口：查询转发表决定输出路由，并且将数据转移至交换结构 交换结构：连接输入端口与输出端口 输出端口：从建环结构获取数据并此昂输出链路传输 路由选择处理器：执行控制平面功能，计算转发表（通常是一种传统的CPU） 转发策略： 基于目的地转发 通用转发 输入端口处理和基于目的地转发 最简单的情况下，每一个目的地址有一个对应的链路接口对应，采用前缀匹配的方法与最长前缀匹配规则（同时匹配多个前缀的时候选择最长的那个），为了效率通常使用SRAM，DRAM，TCAM 排队是指不同输入端口的数据在进入交换结构时排队 交换 交换方式很多 内存：直接经由CPU控制，这导致了速率较慢（受到内存带宽的限制），并且不能同时转发多个分组 总线：每一段数据会加上一个标签用于标记输出端口，所有输出端口都能接收数据但是只有被标记的可以保存数据，速率受到总线速率的影响，并且不允许并发 互联网：如纵横式交换机，共2N2N2N条总线，当想从输入端口发送到特定输出端口时只需要闭合对应交点即可，不同输出端口的分组可以并行 输出端口 何处排队 输入排队 当交换结构的速率不够快的时候会发生，并且会有线路前部阻塞，即同一个输出端口队列中前部的分组被堵塞会导致后面的也被堵塞 如果分组到达速率达到容量的58%58\\%58%，则输入队列会无限增长 输出排队 发送过快时会发生，采用丢弃新包或已有包来解决，同时有主动队列管理策略，如随机早期检测 传输顺序由分组调度决定 缓存的数量BBB与链路容量CCC的关系为： B=RTT∗CB = \\text{RTT} * C B=RTT∗C 分组调度 排队的分组怎么经过输出链路传输问题 FCFS：先来先服务 优先权排队：被分类放入优先权类中，同一类中的分组采用FCFS，非抢占式优先权排队中，分组开始传输就不能被打断 循环和加权公平排队：分组会被分类，但是不同类之间是平等的，也即会依次循环发送每一个类中的队列头，当某个类为空（链路空闲）时立即寻找其下一个类，例如加权公平排队，每个类会分配一个权重，并且加权分类吞吐量 网际协议 IPv4 版本号：确定剩余解释方式 首部长度：确定载荷与选项的分隔 服务类型：区别不同类型IP数据报 数据报长度：首部 + 数据 标识、标志、片偏移：与分片有关 寿命（TTL）：确保数据报不会循环 协议：指定运输层协议 检验和：检测比特错误，求和取反码 IPv4分片 一个链路层帧能承载的最大数据量称为最大传送单元，限制着IP数据包长度，并且一段路径上的链路之间可能有不同协议不同的MTU，因此采用分片技术，每一个大数据报被分为若干片 标识、标志、片偏移三个字段用于分片，标志比特用于标记最后一个片，片偏移用于决定正确的顺序 IPv4编址 点分十进制记法：每个字节用十进制书写，不同字节用句点隔开，如127.0.0.1127.0.0.1127.0.0.1 具有相同前缀的一些主机或路由器可以连接形成子网 其中223.1.1.0/24223.1.1.0/24223.1.1.0/24代表前242424为相同，/24/24/24为子网掩码 地址分配策略为无类别域间路由选择 地址聚合 得到地址 获取组织地址 由上游管理机构分配 获取主机地址 采用动态主机配置协议（又称即插即用或零配置），主机可以通过其来自动获取IP地址 DHCP发现：主机发现能够交互的DHCP服务器，通过DHCP发现报文，由链路层进行广播 DHCP提供：DHCP服务器回应一份DHCP提供报文，包含一些必要信息 DHCP请求：客户选择一个服务器，向其发送DHCP请求报文 DHCP ACK：服务器回应DHCP ACK报文 网络地址转换 在小型区域内合理使用一个IP地址的方法 NAT路由器是一个具有单一IP地址的打你设备，其中包含一张NAT转换表，用于将公网IP和端口转换为子网IP与端口 也即NAT用公网的端口进行寻址 中间盒 网络核心中的非交换机组成，包括NAT，流量负载均衡，流量防火墙等 IPv6 改动： 地址容量扩大：32→12832\\rightarrow 12832→128，引入任播地址，将数据报交给一组主机中的任意一个 简化首部 流标签：发送方要求进行特殊处理的流 字段： 版本号，指明是IPv4还是IPv6 流量类型：同IPv4的TOS 下一个首部：运输层协议 跳限制：最多能经过的路由器数目 去除了分片，取而代之的是差错报文，即数据太大时会被直接丢弃，并且向发送方返回一个ICMP差错报文 IPv4迁移到IPv6 好笑版：宣布标志日 实用版：建隧道 隧道指两台IPv6路由器之间的IPv4路由器的集合，方法是将IPv6的整个数据报作为数据包裹在IPv4载荷中进行传输，并且在下一个IPv6节点进行解包 通用转发和SDN 匹配加动作转发表称为流表，每个表项包括： 首部字段值的集合 计数器集合 动作集合 匹配 对来自不同层次的协议首部的一部分字段进行匹配，允许通配，例如192.118.∗192.118.*192.118.∗将匹配所有192.118192.118192.118开头的IP地址 动作 转发：转发到特定端口、端口集合或其余所有端口 丢弃 修改字段：在被转发之前重写首部字段（IP协议不可重写） 封装并转发给远程控制器","tags":["网原","网络层","笔记"],"categories":["计算机网络原理"]},{"title":"网原笔记3","path":"/2024/05/08/网原笔记3/","content":"计算机网络原理 笔记 3 网络原理 运输层 无连接运输：UDP 优势： 关于发送什么数据以及何时发送的应用层控制更加精细 无需建立连接（无需握手） 无连接状态 报文段首部短 报文段 检验和 发送方将所有161616比特字段求和并取反码，得到检验和，接收方将所有161616比特字段（包括检验和）进行求和，如果结果不是全111则有错，只能检验不能恢复 可靠数据传输 下层协议可能不可靠 (ARQ) 功能： 差错检测 接收方反馈 重传 在上一组数据传完并得到ACK相应之前不会有下一组数据，也即上层协议的send不会被调用，称为停等协议 考虑处理ACK/NAK受损的问题： 在2.22.22.2中，可以看出在接收到ACK的时候会判断其数字是否与当前状态相同，如果不相同则视作NAK 为了处理丢包，在发送发建立一个定时器，使得其能够在一定时间未接收到ACK之后默认为丢包，重发分组并且重置定时器 流水线 减少停等带来的传输利用率低下（传播时延远远大于传输时延） 增加序号 双方缓存多个分组 差错恢复：回退N步与选择重传 回退N步 当base得到确认之后窗口开始滑动，具体的FSM如下： 超时的时候，重传所有已发送但是未被确认的分组，同时接收方会丢弃所有失序的分组 选择重传 窗口长度必须不大于分组序号空间大小的一半，反之无法正常工作，接收方会出现无法分辨重传与新分组的现象 接收方收到自身的滑动窗口之前的分组时仍要发送ACK，否则发送方无法知道已被接收，窗口不能滑动 可靠数据传输总结 TCP 连接 全双工服务：双向传输 点对点：一对一传输 传输路径：进程 -&gt; 套接字 -&gt; 发送缓存 -&gt; 网络层 -&gt; 接收缓存 -&gt; 套接字 -&gt; 进程 典型的MSS的值为146014601460字节 报文 接收窗口字段：用于流量控制，指示接收方愿意接受的字节数量 选项字段：协商MSS，或在高速网络下作为窗口调解因子 标志字段： ACK：确认接收 RST, SYN, FIN：用于建立和拆除连接 PSH：指示接收方立即上传数据 URG：指示紧急数据 序号和确认号 一个报文段的序号是指该报文段首字节的字节流编号，TCP将数据看成有序字节流，对每一个字节分别标号 确认号指的是期待收到的最小字节标号，例如发送方已经收到0∼1000\\sim1000∼100和200∼300200\\sim300200∼300，则确认号为101101101 往返时间与超时 时限必须要大于RTT SampleRTT：报文段从发出到接被确认接收所需要的时间，在任意时刻仅测量一个报文段的SampleRTT而不是计算所有待确认的报文段，得到结果后加权更新，同时计算RTT偏差：EstimatedRTT=(1−α)EstimatedRTT+αSampleRTT\\text{EstimatedRTT} = (1-\\alpha)\\text{EstimatedRTT} + \\alpha\\text{SampleRTT} EstimatedRTT=(1−α)EstimatedRTT+αSampleRTT DevRTT=(1−β)DevRTT+β∣SampleRTT−EstimatedRTT∣\\text{DevRTT} = (1-\\beta)\\text{DevRTT} + \\beta|\\text{SampleRTT} - \\text{EstimatedRTT}| DevRTT=(1−β)DevRTT+β∣SampleRTT−EstimatedRTT∣ 时限应当确定为：Timeout=EstimatedRTT+4DevRTT\\text{Timeout} = \\text{EstimatedRTT} + 4\\text{DevRTT} Timeout=EstimatedRTT+4DevRTT 在真实处理中，有一种技术是在每次超时之后将时限翻倍 可靠数据传输 冗余ACK：用于指示报文丢失，当重复收到一个报文段的333次冗余ACK，之后，立即重传其下一个报文 流量控制 使得发送速率与接收方的读取速率相匹配，通过发送发来维护接收窗口实现，指示接收方剩余的缓存空间 发送方保证发送到连接中但是未被确认的数据量小于rwnd即可 特例：当缓存已经满了的时候发送仅含一字节数据的报文段，此时接收方开始清空缓存，并在确认报文里发送新rwnd 三次握手 客户向服务器发送一个SYN为111的报文段，随机选择一个初始序号，请求连接 服务器接收，分配缓存与变量，选择初始序号，返回SYNACK报文段表示允许连接 客户端接收，分配缓存与变量，连接建立 关闭过程： 客户端发送FIN置111的报文段表示关闭请求，并接收ACK，清理变量和缓存 服务端发送FIN置111的报文段表示关闭请求，并接收ACK，清理变量和缓存 拥塞控制 原因 理想路由器，分组的到达速率接近链路容量时，排队时间趋近于无穷大 有缓存的路由器，发送方因为大时延进行不必要重传占据链路带宽 上游路由器发送的分组最终被丢弃，这样发送它所占用的资源就被浪费了 控制方法 端到端：网络层不反馈，全部依靠运输层 网络辅助：网络层会反馈一些信息 TCP拥塞控制 发送方维护一个拥塞窗口cwnd，满足 LastByteSent−LastByteAck≤min⁡(cwnd,rwnd)\\text{LastByteSent} - \\text{LastByteAck} \\leq \\min(\\text{cwnd}, \\text{rwnd}) LastByteSent−LastByteAck≤min(cwnd,rwnd) 发送速率为 cwndRTT字节/秒\\frac{\\text{cwnd}}{\\text{RTT}}字节/秒 RTTcwnd​字节/秒 发送方判定丢包为超时或三个冗余ACK TCP为自计时的 TCP拥塞控制算法 慢启动： cwnd初始值被确定为一个MSS，传输的报文段被首次确认的时候增加一个MSS，因此整体呈现几何级数增长的形式，同时在发送方维护ssthresh（慢启动阈值），结束增长有如下情况： 超时丢包：重新初始化并慢启动，令ssthresh} = \\text{cwnd}/2$ cwnd} = \\text{ssthresh：进入拥塞避免 333个冗余ACK：快速重传，进入快速恢复 拥塞避免 每个RTT只增加一个MSS而不是翻倍，例如每个ACK增加MSS}^{2}/\\text{cwnd，结束控制如下： 超时丢包：同慢启动 333个冗余：快速重传，令ssthresh} = \\text{cwnd}/2, \\text{cwnd} = \\text{ssthresh} + 3\\text{MSS 快速恢复 每个冗余ACK增加一个MSS，结束控制： 超时丢包：同慢启动 回顾 整体拥塞控制方法成为加性增，乘性减 另一种拥塞控制方法为基于延迟，即实时检测吞吐量，并于最大吞吐量cwnd}/\\text{RTT进行比较，并且线性增减去趋近最大吞吐量 宏观吞吐量 以WWW代表窗口长度，则 Mean=0.75∗WRTTMean = \\frac{0.75*W}{\\text{RTT}} Mean=RTT0.75∗W​ 高带宽TCP 设LLL为丢包率，则 Mean=1.22∗MSSRTT∗LMean = \\frac{1.22*\\text{MSS}}{\\text{RTT}*\\sqrt{L}} Mean=RTT∗L​1.22∗MSS​ 这代表高吞吐率需要非常低的丢包率来支持 TCP公平性 公平性代表瓶颈链路分配给每条链路的资源应该是相近的 TCP趋近于多条链路之间平等分享，但是在实际应用中，RTT较小的通常吞吐量更大 公平与UDP UDP无拥塞控制，并且可能会抑制TCP 公平与并行TCP 一个应用使用多条TCP并行会导致占用过多资源，但是资源的公平应该是在应用层面上的 明确拥塞公告 网络层辅助的拥塞控制机制 IP协议的首部中有两个比特被用于标记ECN，当接收方收到ECN时则在回复的ACK中设置ECE，发送发收到之后进行窗口减半处理（和超时丢包相同），并在下一个报文段首部标记CWR字段（拥塞窗口缩减）","tags":["网原","笔记","运输层"],"categories":["计算机网络原理"]},{"title":"网原笔记2","path":"/2024/05/08/网原笔记2/","content":"计算机网络原理 笔记 2 网络原理 应用层 应用层协议原理 APP是运行在端系统上，而不是诸如路由器等的网络核心设备上，因为网络核心设备基本只在网络层及以下的地方起作用 网络应用程序体系结构 两种主流体系结构： 客户-服务器体系 对等体系 客户-服务器 服务器：一个总是打开的主机，处理来自其他客户主机的请求，例如Web浏览器等 客户之间不会直接通信，而是需要经过服务器中转，并且服务器具有固定的地址（称之为IP地址） 数据中心：为了防止单一的服务器主机无法处理大量请求，部分服务商会部署数据中心，其中配备有大量主机，用于模拟服务器 对等 端系统主机之间直接通信，无需经过服务器中转，一些流量密集型应用采用的是P2P结构 P2P结构具有自扩展性，每个对等方通过请求文件产生工作负载，但是其也可以通过向其他对等方分发文件提升系统服务能力 进程通信 这里讨论的是不同端系统之间进程的通信，其通过交换报文相互通信 客户与服务器进程 对于任意一对进行通信的进程，在会话开始时等待联系的一方为服务器，发起通信的一方为客户，无论其采用的体系结构是可恶-服务器或P2P 进程与计算机网络的接口 进程间通过套接字（也被称为API）接口进行报文的发送和接收，套接字是应用层与运输层的接口，开发者可以选择运输层协议，并借助该协议进行开发 进程寻址 接收进程的地址包括： 主机地址 在目标主机中指定接收进程的标识符 主机由其IP地址确定，是一个32bit32bit32bit的量并且可以唯一标识一个主机，指定接收进程由目的地端口号保证，一个端口号只能接收一个进程的信息 可供应用程序使用的运输服务 一个运输层协议所能提供的服务分为四类： 可靠数据传输 吞吐量 定时 安全性 可靠数据传输 由于丢包、数据损坏等情况，数据可能发生丢失，因此，我们需要一种使得发送的数据一定可以正确、完全的交付给另一方的协议，称之为可靠数据运输 部分应用（例如音视频、原神等）允许一定量的数据丢失，这被称为容忍丢失的应用 吞吐量 可用吞吐量：两个进程之间发送比特的速率，由于其他会话会共享带宽，因此可用吞吐量会随着时间波动 因此，一部分协议保证了应用可用吞吐量的下界，这对于一些带宽敏感应用（具有特定的吞吐量要求）是很有必要的，与之相对，弹性应用不需要限制吞吐量 定时 定时协议可以保证时延的上界，例如可以确保发送的比特一定会在100ms100ms100ms内到达接收方，广泛应用于实时交互的应用中 安全性 协议能够提供数据的加密、解密，以保证只有进程可以直接观察到发送的的数据，同时还有数据完整性鉴别、端点鉴别等 因特网提供的运输服务 包括TCP与UDP两种 TCP 包括面向连接服务与可靠传输服务 面向连接服务：应用岑报文开始流动之前，TCP让客户服务器进行握手（交换运输层控制信息），握手结束后即建立了一条TCP连接，双方进程可以在该连接上进行报文的收发，结束发送至后必须拆除连接 可靠传输服务：同上 同时，TCP拥有拥塞控制机制，可以在适当时机抑制发送进程，并且限制每个连接使之公平共享带宽 由于其没有加密机制，因此有基于TCP的SSL，可以提供关键的安全性服务,SSL不是一种新的因特网运输协议 UDP 轻量级，仅提供最小服务，没有握手机制、拥塞控制机制、可靠传输等 因特网运输协议所不提供的服务 没有包括定时和吞吐量等，这些操作被巧妙的设计所尽量保障，但是在一些极端情况下仍然会被限制 应用层协议 应用层协议定义了进程之间传递报文的格式，如： 交换报文的类型 各种报文类型的语法 报文中字段的语义 确定进程何时、如何发送报文 对报文进行响应的规则 应用层协议是网络应用的重要组成部分 Web &amp; HTTP HTTP概况 Web页面有对象组成，可以通过URL（由主机名+路径名构成）寻址访问Web服务器实现了HTTP服务器端，用于存储Web对象，基本通信方式如下： HTTP是一个无状态协议，也即其不会存储有关客户的任何信息（例如短时间内连续请求信息，则服务器每次会重新发送） 持续连接与非持续连接 客户与服务器之间需要进行一系列请求，并且两个请求之间的间隔可能是随机的或是周期性的，所以不同请求可以使用不同的TCP连接或者同一个TCP连接，被分为非持续连接和持续连接两种，HTTP1.1及更高版本默认情况下使用的是持续连接，HTTP1.0采用的是非持续连接，而HTTP2.0版本更新了队列机制，不强制要求FCFS，而是可以让用户自己定义优先级 非持续连接 每一个对象需要一次TCP连接 定义往返时间：一个短分组从客户到服务器再返回客户的时间，如下： 上图中设计三次握手过程，其中前两个过程消耗了一个RTT，最后一次握手以及发送HTML文件这个响应操作消耗了一个RTT，因此总响应时间为2∗RTT+2*\\text{RTT} +2∗RTT+传输文件时间 持续连接 非持续连接需要为每个请求的对象建立并维护一个连接，需要大量TCP缓冲区与变量，并且会导致相对更高的时延 持续连接即建立连接后，即使完成请求也不关闭，因此不同请求可以使用这一条连接进行，避免了反复建立连接，当连接在一定时间内没有被使用时才会被关闭 HTTP 报文格式 分为请求报文与响应报文两种 HTTP请求报文 第一行称作请求行，其后续都称为首部行 请求行分为方法、URL、HTTP版本三个字段 主机的信息提供给Web代理高速缓存 第三行用于关闭持续连接 第四行用于指明用户代理，即浏览器类型 第五行用于指明需要得到的语言版本 通用格式如下： 实体体在GET方法中为空，在POST等方法中包含信息，例如用户在搜索框内的输入信息等，而需要给服务器提供信息的操作不一定是POST操作，例如可以将信息附在URL中然后使用GET操作 HTTP响应报文 比请求报文多了一个实体体的部分，同时第一行称作状态行 状态行包括协议版本，状态码与状态信息三部分 第二行与请求报文相同 第三行表示了发送响应报文的时间 第四行表示服务器 第五行表示发送的对象被最后修改的时间，对于缓存来说非常重要 第六行表示发送对象的字节数 第七行表示对象类型 通用格式如下： 用户与服务器的交互：cookie 允许站点对用户进行跟踪，技术有如下四个组件： 响应报文中的cookie首部行 请求报文中的cookie首部行 端系统中的cookie文件 后端数据库 用户首次访问一个站点的时候，服务器会为其建立一个 cookie用来唯一标识这个客户，并将其发送给浏览器，后续会话中浏览器与服务器之间可以通过cookie来确定用户信息 Web缓存 又称代理服务器，可以理解为是客户和初始服务器之间的一个代理，可以提升用户的访问速度，用户可以往缓存中发请求，如果缓存中拥有的话则可以直接返回响应，反之则需要在初始服务器中进行寻找，因此可以有效的降低时延并且减少供应商成本 条件GET方法 用于确定缓存中的数据是最新的方法，具体来说，缓存数据会存储数据的最近修改时间，因此，如果用户在请求报文中增加了行 1If-modified-since: xxx 则缓存与代理之间会经过一次通信确定文件在xxx时间之后是否有被修改过，这种报文称之为条件GET请求 电子邮件 &amp; SMTP SMTP 步骤如下： 发送方代理将报文发送给自身邮件服务器，并存储在报文队列中 发送方服务器SMTP与接收方服务器SMTP直接建立TCP连接 握手结束后，通过该连接发送报文 接收方服务器接收报文，并将其放入接收方的邮箱中 SMTP可以通过可靠数据传输将邮件完整的发送到接收方，并且其采用的是直接连接的方式 SMTP有一条特殊规则是：只包含nnn个句点符号的单行，表示的是n−1n-1n−1个句点，因为单个句点是指示报文结束，对话形式如下图： 由用户端发送的、全大写的字符串代表特殊命令，其含义可以直接翻译理解 与HTTP比较 同： 都用于在两台主机之间传送文件 都是持续连接 异： HTTP是拉协议，即此时连接由接收方向发送方发起；TCP是推协议，即此时连接由发送方向接收方发起 SMTP要求发送数据必须编码为ASCII字符，但是HTTP没有限制 对于多对象（例如包含图片、视频、音频等）文档，HTTP将每个对象分别封装，但是SMTP将其全部封装在一起 报文格式 使用的是RFC 5322定义，其中的From, To两行是必选的 访问协议 由于SMTP是一个推协议，因此用户是无法通过自己设备上的代理向服务器请求邮件的，因此我们没有办法实时读取到存储在服务器中的邮件，为了解决这个问题引入了邮件访问协议，如POP3, IMAP, HTTP POP3 由RFC 1939定义，极其简单，首先用户向服务器提出建立TCP连接，建立之后依次分为三个阶段：特许，事务处理与更新 鉴权（特许）阶段：客户端使用命令user 与pass 鉴别身份信息（明文发送） 事务处理：客户端允许使用list, retr , dele 三条命令，分别代表：列出所有邮件长度，接收id号邮件，删除id邮件 更新：当用户使用了quit命令之后进入更新阶段，服务器删除被标记的斑纹，POP3会话结束 每次客户端发来一个命令之后，服务端的回复是+OK 或-ERR IMAP 允许用户可以在远程服务器上操作邮件，包括创建文件夹、移动邮件、在远程文件夹上查询邮件等，更加方便，并且允许用户获取报文的部分，以避免大量信息造成网络负担过重 邮件中的HTTP 在代理和服务器直接发送信息的时候采用HTTP协议，在服务器之间传输的时候采用SMTP，也即将浏览器当成用户代理 DNS：因特网的目录 用于转换主机在主机名与IP地址之间的一种系统，主机名方便人类记忆，而IP更容易被计算机处理 DNS的服务 DNS是指： 由分层的DNS服务器实现的分布式数据库 使主机能够查询分布式数据库的应用层协议 DNS服务器运行BIND软件，协议运行在UDP之上，使用53号端口 DNS通常是一种被其他应用层协议使用的应用程协议，用于将它们请求报文中的主机名转换为IP地址，而并不常与用户直接通信 除了转换外还有其他服务： 主机别名，部分主机拥有多个主机名，而其中有一个成为规范主机名，而别名的存在是为了更方便的记忆，因此DNS可以识别别名 邮件服务器别名：电子邮件的后缀可以是别名，由邮件app调用DNS进行处理 负载分配：部分站点有多个服务器，也即一个规范主机名会对应多个IP地址，因此DNS用于调配这些地址之间的负载，用户向这个主机名发送请求等效于向当前队列中最前方的IP发送请求 工作机理概述 从用户来看，DNS是一个提供转换服务的黑盒，但是其内部是由大量DNS服务器及应用层协议组成的 简单设计：全球仅有一台DNS服务器，会有诸多问题 单点故障导致全球故障 通信容量巨大 远距离的集中式数据库导致高时延 维护复杂 因此采用了分布式的设计方案 分布式层次数据库 从上到下依次为：根服务器，顶级域服务器与权威服务器，访问一个主机名的时候从上至下访问服务器，从右至左依次匹配 根服务器：全球有400400400多个 顶级域：例如.com, .edu等 权威：每个公共可访问主机的组织需要提供公共可访问的DNS记录，这些记录被记录在权威服务器中 本地DNS服务器：属于ISP，起到的是代理、加速作用 每次向服务器发送请求是，得到的是下一级的服务器IP地址列表，权威服务器将会返回查询地址的IP，同时，权威服务器有可能需要用过中间服务器再次分层，也即权威-&gt;中间-&gt;权威 查询方式分为递归查询与迭代查询，上图中，请求主机与本地服务器之间为递归查询，其与全部为迭代查询，即迭代查询是接受请求后直接返回，而递归查询是接受请求后向其他服务器查询之后再返回给请求方 DNS缓存 为了改善时延并且减少报文数量，DNS服务器可以将请求/回答信息环城存在本地存储器中，以便更快返回，由于IP对应关系不永久，因此缓存信息会被定时清除 DNS记录与报文 DNS服务器存储了资源记录，其提供了主机名到IP地址的映射，形式为： (Name, Value, Type, TTL)\\text{(Name, Value, Type, TTL)} (Name, Value, Type, TTL) 其中TTL代表的是应当删除的时间，其余三个的对应如下： Type = A，则Name是主机名，Value是对应的IP地址 Type = NS，则Name是一个域，Value是域中可获取主机IP的权威服务器主机名 Type = CNAME，则Name是一个别名，Value是对应的规范主机名 Type = MX，则Name是一个别名，Value是对应邮件服务器的规范主机名 报文 前121212字节称为首部区域，标识符用于匹配，标志用于提供一些额外信息 问题区域包含查询信息，包括主机名、问题类型（查规范主机名还是邮件服务器等） 回答区域包含了资源记录，可以包含多条 在DNS数据库中插入 略 P2P文件分发 对等方直接通信，减少对服务器的依赖 P2P体系的可扩展性 FFF：文件长度 NNN：对等方数量 usu_sus​：服务器接入链路的上传速率 uiu_iui​：第iii个对等方接入链路的上传速率 did_idi​：第iii个对等方接入链路的下载速率 考虑在客户-服务端与P2P两种模式下所需要的分发时间 客户-服务器体系Dcs≥max(NFus,Fdmin)D_{cs} \\geq max(\\frac{NF}{u_s}, \\frac{F}{d_{min}}) Dcs​≥max(us​NF​,dmin​F​) P2PDP2P≥max(Fus,Fdmin,NFus+∑ui)D_{P2P} \\geq max(\\frac{F}{u_s}, \\frac{F}{d_{min}}, \\frac{NF}{u_s + \\sum u_i}) DP2P​≥max(us​F​,dmin​F​,us​+∑ui​NF​) 当对等方数量非常多时，采用P2P将会具有很好的效果（增长缓慢） BitTorrent 一种P2P协议，其中，参与特定文件分发的所有对等方集合被称为一个洪流，每个洪流有一个基础设施节点称为追踪器，其中记录并追踪了每个对等方及其是否离开了洪流 新对等方向追踪器请求对等方列表，并尝试向所有对等方建立TCP连接，成功建立连接之后称为邻近对等方，并向所有的邻近对等方请求未含有的块 请求块的方法是最稀缺优先，请求其邻居中所含副本最少的块，以便尽快达到块数量的均衡 给其他对等方上传数据时，每隔一段时间选择向其发送数据最快的444个对等方，其集合成为疏通，并向它们上传块，同时会每隔一段时间随机寻找新对等方进行对换，也即最多会向555个对等方上传块，这种激励机制成为一报还一报 视频流和CDN 因特网视频 比特率决定视频质量以及对传输所需要的流量 HTTP流和DASH 常规的HTTP流为对视频进行编码后使用常规方法进行发送，在用户端有两种方式，一种为缓存字节数超过一定数目就开始播放，另一种为流式视频，即按帧缓存，从接受视频开始即播放 DASH被称为经HTTP的动态适应性流，其将视频编码为不同版本，随着带宽的变化选择不同版本，服务器中存在告示文件，提供不同版本的URL与分辨率 CDN 分布在多个地理位置上的服务器，用于帮助世界各地的用户尽快获取内容 服务器安置原则为： 深入：遍历接入ISP来深入其中，靠近端用户 邀请做客：在关键位置部署少量大集群，邀请ISP做客 CDN采用拉策略，并非将视频存储在每一个集群中，当集群缺少这个视频时则会向其他集群检索并缓存 CDN操作","tags":["网原","笔记","应用层"],"categories":["计算机网络原理"]},{"title":"网原笔记1","path":"/2024/05/08/网原笔记1/","content":"计算机网络原理 笔记 1 网络原理 概要 考核 随堂测 15% 作业 25% 期末考试 60% Key problems Multiple access control: MAC rooting naming: how to give each user a unique id Congestion control（阻塞控制） RDT: Reliable Data Transfrom Protocol 协议：协议定义了网络实体之间发送和接收消息的格式、顺序，以及对消息传输、接收所采取的操作 网络核心 分组交换 端系统（主机）之间交换报文，报文包含了通讯者需要的信息，并通过通信链路从源发送至目的地 源会将长报文划分为较小的数据块，称为分组，通信链路上拥有分组交换机，以使得以链路允许的最大传输速率传输报文，分为路由器和链路层交换机两种 存储转发传输：在链路发送信息时必须要整组发送，即需要等待源将一组信息完全发送至交换机才能发送至目的地 端到端时延：通过NNN条传输速率为RRR的链路组成的路径，从源向目的地发送一个LLL比特的分组，端到端时延（传输时延）为d=NLRd = N\\frac{L}{R} d=NRL​ 发送PPP个分组的时延为d=(N+P−1)LRd = (N+P-1)\\frac{L}{R} d=(N+P−1)RL​ 排队时延与丢包：分组交换机拥有一个输出队列（缓存），当交换机的输出速率小于输入速率时，后进入的包会进入缓存中等待，这一种延迟称之为排队时延，主要取决于网络阻塞程度，当缓存被填满时，再次有包进入时会导致有的包（可能是新来的或队列中的）被丢弃，即为丢包 转发表：路由器决定应该将信息往哪一条链路发送的方式，可以将目的地IP地址（或其一部分）映射到对应的输出链路，转发表通常会根据路由转移协议来自动设置 电路交换 与分组交换的最大区别在与：电路交换会提前预留端到端通信所需要的资源，包括缓存、链路传输数据等，每一条链接称为一条电路，因此其时延主要来自于建立电路与在电路上传播 复用：分为频分复用与时分复用 频分复用指一组连接共用一段频谱，每个连接有一个独享的频段。例如调频无线电台使用FDM共享88MHz-108MHz的频谱，每一个电台会被分配一个特定的频段（通常带宽为4MHz），使用完毕之后会被回收投入下一次使用 时分复用指，将时间分割为固定的帧，每一帧被分割为固定量的时隙，每个时隙只传播一个连接的数据（类似并行的概念） 电路交换会有静默期，也即建立了电路之后不传播信息，可能会引发资源浪费，但是电路交换的端到端时延与链路数量无关（在路由器处无需等待） 通常情况下，分组交换的效率会优于电路交换 网络的网络 此节讨论我们怎么能够使用网络资源，也即因特网的结构（发展动力主要是商业竞争） 网络结构111：一个单一的全球ISP互联所有接入ISP，所有的客户直接向该全球ISP付费 网络结构222：多个全球ISP，全球ISP之间是互联的，用户可以向性价比最高的全球ISP付费 网络结构333：有区域ISP，ISP按照层级高低分为接入、区域、第一层（全球传输），低层需要向直接连接的高层付费 网络结构444：在结构333的基础上增加了PoP、多宿，对等与IXP PoP：提供商网络中位于相同位置的一组路由器，客户ISP可以通过其与提供商ISP相连接 多宿：任何非顶层ISP可以与多台上游ISP相连接 对等：同层的相邻ISP之间直接连接，无需通过上游ISP进行中转，通常对等无需付费 IXP：可以使得多个ISP一起对等，类似于一个中转站 网络结构555：在网络结构444的基础上增加了内容提供商网络，更多的用于直接与较低层的ISP互联，避免由于中间ISP的收费 时延、丢包与吞吐量 时延 delay=dproc+dqueue+dtrans+dpropdelay = d_{proc} + d_{queue} + d_{trans} + d_{prop} delay=dproc​+dqueue​+dtrans​+dprop​ 处理时延：检查数据是否有错，决定输出链路等，数量级为μs\\mu sμs 排队时延：在输出队列中等待的时间，取决于网络拥塞程度，数量级为ms−μsms-\\mu sms−μs 传输时延：将数据从路由器传输到链路的时间，数量级在ms−μsms-\\mu sms−μs 传播时延：数据在链路上传播的时间，通常很小（传播速率在108m/s10^8m/s108m/s量级），但是在长距离传播中需要考虑 排队时延和丢包 流量强度定义为 ti=LaRti=\\frac{La}{R} ti=RLa​ 其中，aaa代表数据到达队列的平均速率，LLL代表分组的平均比特数，ti→0ti\\rightarrow 0ti→0时排队时延很小，ti→1−ti\\rightarrow 1^-ti→1−时排队时延很大，ti&gt;1ti&gt;1ti&gt;1的时候排队时延无界 当ti≤1ti\\leq 1ti≤1的时候，分组到达的方式（周期性或突发性等）将会影响排队时延 当路由器的输出队列已满时，新进入的分组会被丢弃，称为丢包 端到端时延 dend−end=N(dproc+dtrans+dprop)d_{end-end} = N(d_{proc} + d_{trans} + d_{prop}) dend−end​=N(dproc​+dtrans​+dprop​) 其中 dtrans=LRd_{trans} = \\frac{L}{R} dtrans​=RL​ 这个式子假设了网络是畅通的 吞吐量 定义：主机接受文件的速率，分为瞬间吞吐量与平均吞吐量 瓶颈链路：指平均传输速率最小的一条链路，限制了整个网络的吞吐量 上述的平均指的是，分配给每条链路的传输速率，例如一条速率为100Mbps的高速链路，需要同时承担100010001000个客户-服务器的通信，那平均速率将会降至100kbps，有可能成为瓶颈链路 协议层次及其服务模型 分层的体系结构 协议分层 为了更好的结构化与模块化，网络以分层的方式组织协议与硬软件，每一层通过在该层中执行动作或使用直接下层的服务来提供服务。 各层的所有协议被称为协议栈，因特网的协议栈自顶向下为应用层，运输层，网络层，链路层，物理层 应用层：网络应用程序以及其应用层协议存留的地方，其中的信息分组称为报文。应用层提供了许多协议，如： HTTP：Web文档协议 SMTP：电子邮件报文协议 FTP：端系统协议 DNS：域名系统协议 运输层：用于在应用程序端点之间传送应用层报文，有两种运输协议：TCP, UDP，其中TCP提供了截断机制与拥塞控制机制。运输层的分组称为报文段 网络层：分组称为数据报，网络层负责将数据报从一台主机移动到另一台主机，网际协议包括IP，其定义了数据报中的各个字段以及端、路由器如何作用在这些字段上 链路层：在节点之间传递数据，每个节点的网络层将数据下放给链路层，传递至下一个节点之后再上传至网络层。如以太网、WiFi、电缆接入网的DOCSIS协议，其中的分组称为帧 物理层：在物理层面上将帧中的比特移到下一个节点，每一种链路层中包括很多物理层协议，与实际的物理媒介有关 OSI模型 777层分层，包括应用层、表示层、会话层、运输层、数据链路层、物理层。 表示层用于将交换的数据可以被应用程序解释，会话层提供了数据交换的定界和同步功能，包括检查与恢复等 封装 每一层会将来自上一层的数据进行封装，也即附加一些首部信息，包括一些权限信息以及检测信息等，引测，每一层的分组都有两种字段，首部字段和有效载荷字段 坏家伙 危害终端设备 坏家伙将恶意软件植入设备中，并利用僵尸网络（被控制的主机）展开攻击，从而实现自我复制。恶意软件分为病毒与蠕虫两类： 病毒：需要用户交互来感染用户设备的恶意软件 蠕虫：无需用户交互即可进入设备 危害服务器和网络设施 拒绝服务攻击，也即DoS, 包括以下三种： 弱点攻击：攻击不完备的应用或操作系统 带宽洪泛：往目标发送大量分组，例如DDoS通过大量源向目标发送分组造成目标瘫痪 连接洪泛：在目标中创建大量的半开或全开TCP连接 嗅探分组：在传输分组时，精心布置的被动接收机可以得到传输信息的副本，并且由于其不会注入信息，所以很难被检测出来，这种接收机被称为分组嗅探器 身份伪装：通过IP哄骗，向目标发送具有恶意的信息","tags":["网原","笔记","概要"],"categories":["计算机网络原理"]},{"title":"Hexo + Stellar","path":"/2024/05/07/Hexo初探/","content":"终于弄好了www 经过一天的不懈奋斗，在经过了jekyll配置环境的痛苦折磨之后，最后选择了用hexo+github pages配置，hexo是一款静态博客工具，使用起来比较简单，指比让从来没有配过ruby的我去弄明白jekyll简单多了！ 配置方法 新建github仓库，名为&lt;username&gt;.github.io，这个是后来访问用的 回到本地命令行（笔者用的是wsl）123456npm install -g hexo-clisudo npm install -g hexo-cli (Mac) # 据说Mac得这么干cd AN-EMPTY-FLRODER # 进入你想放置的本地文件夹 一定要是空的！hexo init # 初始化hexo内容npm install # 下载配置npm install hexo-deployer-git --save # 下载部署工具 此时环境基本配置完毕了，开始修改配置，打开_config.yml，将其Deployment部分改为1234deploy: type: git repository: git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git branch: main 部署准备完成1hexo g -d # 生成页面并部署 此时可以访问https://&lt;username&gt;.github.io访问自己的博客！ 操作方法 12345678hexo new &quot;name&quot; # 新建文章hexo new page &quot;name&quot; # 新建页面hexo g # 生成页面hexo d # 部署hexo g -d # 生成页面并部署hexo s # 本地预览hexo clean # 清除缓存和已生成的静态文件hexo help # 帮助 更换主题 进入网站https://hexo.io/themes/可以选择主题，挑选好后进行配置，配置方法为在博客根目录.下执行如下命令： 1git clone THEME-REPO themes/&lt;theme-name&gt; 例如本博客使用的是stellar主题，执行命令为： 1git clone git@github.com:xaoxuu/hexo-theme-stellar.git themes/stellar 下载好后，在./_config.yml下修改theme的内容为你想要的即可 致谢 https://zhuanlan.zhihu.com/p/60578464 Debug TypeError: Cannot read properties of null (reading 'utcOffset') 时区设置错误，允许的中国时区只有Asia/Harbin,Asia/Shanghai,Asia/Chongqing,Asia/Urumqi,Asia/Kashgar 无法生成.html文件 检查themes下的文件名和配置文件中的是否相同，如果相同尝试先clean再重新创建，如果还是不行则直接重新clone一下主题库（原因未知） 行内公式无法渲染 更换md渲染器，并添加Katex支持，方法为：123npm un hexo-renderer-marked --savenpm i hexo-renderer-markdown-it --savenpm i @traptitech/markdown-it-katex --save 并在_config.yml中加入（注意缩进）：123456789101112131415161718markdown: preset: &#x27;default&#x27; render: html: true xhtmlOut: true breaks: true langPrefix: &#x27;language-&#x27; linkify: true typographer: true quotes: &#x27;“”‘’&#x27; plugins: - plugin: name: &#x27;@traptitech/markdown-it-katex&#x27; options: # see https://katex.org/docs/options.html blockClass: &quot;math-block&quot; strict: false throwOnError: false errorColor: &quot;#cc0000&quot; 单纯做了上面的操作之后会出现行内数字/字母重复渲染的现象，也即一遍纯文本一遍公式文本，例如’ISP’会被渲染成’ISPISPISPISP’ 在文章头部加上katex: true即可 静态图片问题 使用相对于source文件夹的绝对路径，例如/assets/...代表存在/blog/sources/assets/...下，这样在本地md可能显示会有问题，但是stellar可以正常生成"},{"title":"杂记","path":"/freenotes/index.html","content":"现在还是没有知识的荒原呢 1TODO"},{"title":"关于","path":"/about/index.html","content":"欢迎来到我的个人博客！本人为清华大学计算机系二字班学生，第一次尝试写博客还请大家多多担待噢~ 这里主要想写一写平时学习中遇到的笔记和内容，也方便统一管理一些，当然以后也会有可能有一些随笔和杂谈之类的"}]